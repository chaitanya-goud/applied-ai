Author,Title,Abstract,Keywords,Summary
A Jaina,Evaluation of the microangiographic fluoroscope (MAF) using generalized system performance metrics,"Cone beam computed tomography (CBCT) systems with rotational gantries that have standard flat panel detectors (FPD) are widely used for the 3D rendering of vascular structures using Feldkamp cone beam reconstruction algorithms. One of the inherent limitations of these systems is limited resolution (<3 lp/mm). There are systems available with higher resolution but their small FOV limits them to small animal imaging only. In this work, we report on region-of-interest (ROI) CBCT with a high resolution CMOS detector (75 μm pixels, 600 μm HR-CsI) mounted with motorized detector changer on a commercial FPD-based C-arm angiography gantry (194 μm pixels, 600 μm HL-CsI). A cylindrical CT phantom and neuro stents were imaged with both detectors. For each detector a total of 209 images were acquired in a rotational protocol. The technique parameters chosen for the FPD by the imaging system were used for the CMOS detector. The anti-scatter grid was removed and the incident scatter was kept the same for both detectors with identical collimator settings. The FPD images were reconstructed for the 10 cm x10 cm FOV and the CMOS images were reconstructed for a 3.84 cm × 3.84 cm FOV. Although the reconstructed images from the CMOS detector demonstrated comparable contrast to the FPD images, the reconstructed 3D images of the neuro stent clearly showed that the CMOS detector improved delineation of smaller objects such as the stent struts (~70 μm) compared to the FPD. Further development and the potential for substantial clinical impact are suggested.",,"This study demonstrates the use of a high-resolution CMOS detector in region-of-interest cone beam computed tomography (ROI CBCT) for improved visualization of small vascular structures. Compared to a standard flat panel detector, the CMOS detector achieved comparable contrast but significantly enhanced spatial resolution, enabling clearer delineation of stent struts. This advancement holds promise for clinical applications requiring high-resolution imaging of vascular anatomy."
A. A. Ross,Unique Local Features in Lip Images for Recognition,"The experiments are carried out from images taken with a camera that is used for the regular use. And the color features of a lip are not explored in the proposed research. Still the recognition system exploits the grayscale local features of a lip images and eﬃciently matches it with local features of another lip image. If the color properties of a lip image is explored for recognition along with local features, the accuracy values would increase further.","grayscale features, Lip Pattern Recognition, SIFT, lip recognition, color features, Biometric, Local Feature Extraction, local features, SURF",The paper presents the results of experiments on lip recognition using local features. The recognition system exploits the grayscale local features of lip images and achieves high accuracy. The authors suggest that exploring color properties of lip images could further improve the accuracy.
A. Al-Haj,Secure Robust and Imperceptible Algorithm for Watermarking Relational Databases,"This paper proposes a secure robust and imperceptible algorithm for watermarking relational databases. The algorithm divides the embedding algorithm into three phases: Watermark preparator, watermark position detector, and watermark embedder. The ownership identification issue is resolved by embedding owner's identity as watermark in Preparator phase.","imperceptible algorithm, Ownership identification, robust algorithm, Relational Database, watermarking, Watermark, Copyright protection, Proof of ownership, relational databases","The paper proposes a new robust secure and imperceptible embedding mechanism to resolve the two important concerns namely; owner identification and proof of ownership. The proposed mechanism involves encoding and decoding on numerical attribute of relational database in three phases; 1)Watermark preparator, 2)Watermark position detector and 3) Watermark Embedder or Detector."
A. Author,Design of VASNET: A Novel Topology for VANET,"The rapid increase of vehicular traffic and congestion on the highways began hampering the safe and efficient movement of traffic. Consequently, year by year, we see the ascending rate of car accidents and casualties in most of the countries. Therefore, exploiting the new technologies, e.g. wireless sensor networks, is required as a solution of reduction of these saddening and reprehensible statistics. This has motivated us to propose a novel and comprehensive system to utilize Wireless Sensor Networks for vehicular networks. We coin the vehicular network employing wireless Sensor networks as Vehicular Ad Hoc and Sensor Network, or VASNET in short. The proposed VASNET is particularly for highway traffic .VASNET is a self-organizing Ad Hoc and sensor network comprised of a large number of sensor nodes. In VASNET there are two kinds of sensor nodes, some are embedded on the vehicles-vehicular nodes- and others are deployed in predetermined distances besides the highway road, known as Road Side Sensor nodes (RSS). The vehicular nodes are used to sense the velocity of the vehicle for instance. We can have some Base Stations (BS) such as Police Traffic Station, Firefighting Group and Rescue Team. The base stations may be stationary or mobile. VASNET provides capability of wireless communication between vehicular nodes and stationary nodes, to increase safety and comfort for vehicles on the highway roads. In this paper we explain main fundamentals and challenges of VASNET.","Localization, Vehicular Ad Hoc and Sensor Network (VASNET), topology, Data Fusion, Wireless Sensor Networks (WSN), Vehicular Ad Hoc Networks (VANET), WSN, MANET, VANET, VASNET, Mobile Ad Hoc Networks (MANET), Routing","This paper proposes a novel system, VASNET, to utilize Wireless Sensor Networks for vehicular networks. VASNET is a self-organizing Ad Hoc and sensor network comprised of a large number of sensor nodes, including vehicular nodes and Road Side Sensor nodes. The system provides wireless communication between vehicular nodes and stationary nodes, increasing safety and comfort for vehicles on highway roads. The paper explains the main fundamentals and challenges of VASNET."
A. B. Molina,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
A. Cortesi,Secure Robust and Imperceptible Algorithm for Watermarking Relational Databases,"This paper proposes a secure robust and imperceptible algorithm for watermarking relational databases. The algorithm divides the embedding algorithm into three phases: Watermark preparator, watermark position detector, and watermark embedder. The ownership identification issue is resolved by embedding owner's identity as watermark in Preparator phase.","imperceptible algorithm, Ownership identification, robust algorithm, Relational Database, watermarking, Watermark, Copyright protection, Proof of ownership, relational databases","The paper proposes a new robust secure and imperceptible embedding mechanism to resolve the two important concerns namely; owner identification and proof of ownership. The proposed mechanism involves encoding and decoding on numerical attribute of relational database in three phases; 1)Watermark preparator, 2)Watermark position detector and 3) Watermark Embedder or Detector."
A. Deshpande,Secure Robust and Imperceptible Algorithm for Watermarking Relational Databases,"This paper proposes a secure robust and imperceptible algorithm for watermarking relational databases. The algorithm divides the embedding algorithm into three phases: Watermark preparator, watermark position detector, and watermark embedder. The ownership identification issue is resolved by embedding owner's identity as watermark in Preparator phase.","imperceptible algorithm, Ownership identification, robust algorithm, Relational Database, watermarking, Watermark, Copyright protection, Proof of ownership, relational databases","The paper proposes a new robust secure and imperceptible embedding mechanism to resolve the two important concerns namely; owner identification and proof of ownership. The proposed mechanism involves encoding and decoding on numerical attribute of relational database in three phases; 1)Watermark preparator, 2)Watermark position detector and 3) Watermark Embedder or Detector."
A. Estimating training values with sample data,Estimating Fire Events Using Naive Bayes and Tree Classifiers,"Extracting useful temporal and spatial patterns from sensor data has been seen before, the technical basis of Machine learning with Data mining is studied with the evidence collected uniformly over many years and which allow using users' perspective in collected evidence.","WEKA machine learning framework, Machine Learning, Naive Bayes, Forest fires, Fire Weather Index (FWI), UCI Forest Fire Repository, Tree Classifiers, Temporal Patterns, Datamining, Fire Events",The paper discusses the use of machine learning and datamining algorithms to predict accidental small forest fires. The authors propose a model that uses temporal and spatial patterns from sensor data to forecast fires and help the forest department plan day-to-day schedules.
A. Gangopadhyay,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
A. J. Conejo,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
A. Jain,Micro-Computed tomography (CT) based assessment of dental regenerative therapy in the canine mandible model,"High-resolution 3D bone-tissue structure measurements may provide information critical to the understanding of the bone regeneration processes and to the bone strength assessment. Tissue engineering studies rely on such nondestructive measurements to monitor bone graft regeneration area. In this study, we measured bone yield, fractal dimension and trabecular thickness through micro-CT slices for different grafts and controls. Eight canines underwent surgery to remove a bone volume (defect) in the canine’s jaw at a total of 44 different locations. We kept 11 defects empty for control and filled the remaining ones with three regenerative materials; NanoGen (NG), a FDA-approved material (n=11), a novel NanoCalcium Sulfate (NCS) material (n=11) and NCS alginate (NCS+alg) material (n=11). After a minimum of four and eight weeks, the canines were sacrificed and the jaw samples were extracted. We used a custom-built micro-CT system to acquire the data volume and developed software to measure the bone yield, fractal dimension and trabecular thickness. The software used a segmentation algorithm based on histograms derived from volumes of interest indicated by the operator. Using bone yield and fractal dimension as indices we are able to differentiate between the control and regenerative material (p<0.005). Regenerative material NCS showed an average 63.15% bone yield improvement over the control sample, NCS+alg showed 55.55% and NanoGen showed 37.5%. The bone regeneration process and quality of bone were dependent upon the position of defect and time period of healing. This study presents one of the first quantitative comparisons using non-destructive Micro-CT analysis for bone regenerative material in a large animal with a critical defect model. Our results indicate that Micro-CT measurement could be used to monitor in-vivo bone regeneration studies for greater regenerative process understanding.","Regenerative Materials, Quantitative Analysis, Bone Regeneration, Micro-CT, LabVIEW","This study investigates the effectiveness of three different bone regenerative materials (NanoGen, NanoCalcium Sulfate, and NanoCalcium Sulfate alginate) in a canine mandible model using micro-computed tomography (micro-CT). The study found that all three materials significantly improved bone regeneration compared to the control group. NanoCalcium Sulfate showed the most significant improvement, followed by NanoCalcium Sulfate alginate and NanoGen. The position of the defect and the healing time period were also found to influence the regeneration process."
A. Jaina,Quantitative Comparison of a High Resolution Micro-Angiographic Fluoroscopic (MAF) Detector with a Standard Flat Panel Detector (FPD) Using the New Metric of Generalized Measured Relative Object Detectability (GM-ROD),"A novel amorphous selenium (a-Se) direct detector with CMOS readout has been designed, and relative detector performance investigated. The detector features include a 25μm pixel pitch, and 1000μm thick a-Se layer operating at 10V/μm bias field. A simulated detector DQE was determined, and used in comparative calculations of the Relative Object Detectability (ROD) family of prewhitening matched-filter (PWMF) observer and non-prewhitening matched filter (NPWMF) observer model metrics to gauge a-Se detector performance against existing high resolution micro-angiographic fluoroscopic (MAF) detectors and a standard flat panel detector (FPD). The PWMF-ROD or ROD metric compares two x-ray imaging detectors in their relative abilities in imaging a given object by taking the integral over spatial frequencies of the Fourier transform of the detector DQE weighted by an object function, divided by the comparable integral for a different detector. The generalized-ROD (G-ROD) metric incorporates clinically relevant parameters (focal-spot size, magnification, and scatter) to show the degradation in imaging performance for detectors that are part of an imaging chain. Preliminary ROD calculations using simulated spheres as the object predicted superior imaging performance by the a-Se detector as compared to existing detectors. New PWMF-G-ROD and NPWMF-G-ROD results still indicate better performance by the a-Se detector in an imaging chain over all sphere sizes for various focal spot sizes and magnifications, although a-Se performance advantages were degraded by focal spot blurring. Nevertheless, the a-Se technology has great potential to provide breakthrough abilities such as visualization of fine details including of neuro-vascular perforator vessels and of small vascular devices.","Comparative metrics, generalized metrics, micro-angiography, DQE, Detector Performance, relative object detectability, Microangiography, CMOS, Flat Panel Detector, amorphous selenium","This paper presents a comparative study of a novel amorphous selenium (a-Se) direct detector with existing high resolution micro-angiographic fluoroscopic (MAF) detectors and a standard flat panel detector (FPD). The study utilizes the Relative Object Detectability (ROD) family of metrics, including the generalized-ROD (G-ROD) metric, to assess the performance of these detectors in imaging small objects.  The results indicate that the a-Se detector exhibits superior imaging performance compared to existing detectors, particularly in terms of resolving fine details.  While focal spot blurring can degrade the performance advantage of the a-Se detector, its potential for breakthrough imaging capabilities in neuro-vascular applications is highlighted."
A. K. Sahu,Design and Performance Analysis of MIMO Patch Antenna Using CST Microwave Studio,"This paper presents the design and performance analysis of MIMO antenna system using Computer Simulation Technology (CST) Microwave Studio software. Several design techniques are discussed in detail with examples, and the fundamental properties of different antenna types are analyzed.","CST Microwave Studio software, MIMO, microstrip patch antenna, MIMO antenna system, Patch Antenna, Wireless Communication, CST Microwave Studio","This paper presents the design and performance analysis of MIMO patch antennas using CST Microwave Studio. The antennas are designed to operate at a resonant frequency of 2.45 GHz and are suitable for applications such as industrial, scientific, and medical (ISM) band. The main objective of this paper is to implement a 2 × 2 multiple-input multiple-output (MIMO) system and design four mutually orthogonal MIMO patch antennas with a single substrate, which are fed by four microstrip lines using the same resonant frequency of 2.45 GHz."
A. Karegowda,Diabetes Classiﬁcation using Radial Basis Function Network by Combining Cluster Validity Index and BAT Optimization with Novel Fitness Function,This paper discusses the use of cluster validity indices for diabetes diagnosis. The authors present a literature survey related to the problem and propose a methodology for identifying the optimal number of clusters. The experimental outcomes confirm the performance of the proposed methodology. The paper also reviews the performance of various neural network-based classifiers on the Pima Indians data set.,"diabetes diagnosis, Optimal number of clusters, Medical Diagnosis, Classiﬁcation, methodology, Diabetes, literature survey, Bat Algorithm, Radial Basis Function Networks, cluster validity indices, neural network-based classifiers","This paper presents a new model based on cluster validity index with radial basis neural network for classiﬁcation of diabetic patients data. The proposed model is tested on Pima Indians Diabetes data set and synthetic data sets, and experimental results proved that our approach performs better in terms of accuracy, sensitivity, speciﬁcity, classiﬁcation time, training time, network complexity and computational time compared to conventional radial basis function neural network."
A. Khotanzad,Unique Local Features in Lip Images for Recognition,"The experiments are carried out from images taken with a camera that is used for the regular use. And the color features of a lip are not explored in the proposed research. Still the recognition system exploits the grayscale local features of a lip images and eﬃciently matches it with local features of another lip image. If the color properties of a lip image is explored for recognition along with local features, the accuracy values would increase further.","grayscale features, Lip Pattern Recognition, SIFT, lip recognition, color features, Biometric, Local Feature Extraction, local features, SURF",The paper presents the results of experiments on lip recognition using local features. The recognition system exploits the grayscale local features of lip images and achieves high accuracy. The authors suggest that exploring color properties of lip images could further improve the accuracy.
A. Krishna,LPLX-lexicographic-based persistent labelling scheme of XML documents,"The increasing number of XML documents over the internet motivated us to develop indexing techniques to retrieve the XML data efficiently. Assigning unique labels to each node and determining the structural relationships is a critical problem in XML query processing. Labelling schemes designed for static XML documents will not support dynamic updates on XML documents. Some dynamic labelling schemes provide dynamic updates but, with a high cost and complexity. In this paper we propose a labelling scheme which supports the dynamic update without relabelling the existing nodes. It also determines the structural relationships efficiently by looking at the labels. A set of performance tests is carried to compute the time required to generate unique labels.","sibling relation, persistent labelling scheme, XPath, dynamic updates, ancestor-descendant relationship, collision avoidance, XML documents, labelling scheme, labelling time, label size, structural relationships, lexicographic order, XML query processing, parent-child relationship, tree traversal","This paper proposes a new labelling scheme, lexicographic-based persistent labelling (LPLX) scheme, which assigns a unique label in lexicographical order to each node in the XML tree with the tuple format (prefix, level, selfcode). The LPLX supports dynamic update of XML documents without relabelling the existing nodes and computes the structural relationships such as ancestor-descendant, parent-child and siblings at constant time."
A. Mallikarjuna Reddy,Alignment Free Cancellable Fingerprint Templates Using Ellipse Structure,"In this work, a new method for alignment free cancellable fingerprint templates was proposed using ellipse structure. Ellipse was formed by selecting one of the minutiae and core point of the fingerprint as focal points and the farthest minutia as the co-vertex. This method performs well because instead of storing spatial information of the fingerprints such as distance or orientation between minutia, etc., we are storing the ellipse attributes in transformed form such that even though if any stored template got leaked, the original fingerprint information will not be revealed to the attacker. This method also performs well in terms of FAR and FRR. However for the fingerprints which does not possess a core point this method will not be suitable and is the main limitation of this work.","Template protection, Discrete Fourier transform, Fingerprint, Ellipse, cancellable templates, biometric security, fingerprint templates, ellipse structure","The proposed method uses elliptical structures generated from fingerprint minutiae to secure fingerprint templates. The method involves extracting minutiae from fingerprint images, constructing ellipses and extracting feature sets, projecting the feature sets onto a 3D space, generating a binary string, and transforming the binary string into the frequency domain using DFT."
A. Odeh,Secure Robust and Imperceptible Algorithm for Watermarking Relational Databases,"This paper proposes a secure robust and imperceptible algorithm for watermarking relational databases. The algorithm divides the embedding algorithm into three phases: Watermark preparator, watermark position detector, and watermark embedder. The ownership identification issue is resolved by embedding owner's identity as watermark in Preparator phase.","imperceptible algorithm, Ownership identification, robust algorithm, Relational Database, watermarking, Watermark, Copyright protection, Proof of ownership, relational databases","The paper proposes a new robust secure and imperceptible embedding mechanism to resolve the two important concerns namely; owner identification and proof of ownership. The proposed mechanism involves encoding and decoding on numerical attribute of relational database in three phases; 1)Watermark preparator, 2)Watermark position detector and 3) Watermark Embedder or Detector."
A. P. Patil,Augmented Reality Wordbook App for Kindergarteners (ARWAK),"In the last two decades, augmented reality educational software tools have been used to teach various subjects to schoolchildren around the world. We developed a wordbook smartphone app and used it to teach new words to children in kindergartens in New Delhi between January and April of 2018. The app uses marker-based augmented reality technology and displays three dimensional pictures of objects whose names the children are learning blended in their immediate surrounding. The app was designed to make the learning process more interactive and intuitive. We found that children can learn slightly more number of words from the app than from a printed wordbook. However, the main benefit of the app was that it was able to increase participation by the children and keep them engaged. The teachers who used the app to teach felt that it was easy to integrate the app in the kindergarten environment and it presented information in a way suitable for young children. We recommend the use of augmented reality smartphone apps to teach children various concepts in kindergartens and schools.","vocabulary, Education, Kindergarteners, Learning, smartphone app, augmented reality, wordbook, Kindergarten","This paper presents the development and evaluation of an augmented reality wordbook smartphone app for kindergarteners. The app uses marker-based augmented reality technology to display three dimensional pictures of objects whose names the children are learning. The app was found to increase participation and engagement of children, and was easy to integrate into the kindergarten environment. The authors recommend the use of augmented reality smartphone apps to teach children various concepts in kindergartens and schools."
A. Saxena,Moisture barrier properties of xylan composite films,"This study examines the reinforcement of xylan/sorbitol films with nanocrystalline cellulose, bleached acacia fiber and softwood kraft fibers and its impact on water transmission. By AFM analysis, nanocrystalline cellulose was observed to have rod like structure with an average length of sulfuric nanocrystalline cellulose in range of 150–200 nm and a width of less than 20 nm while hydrochloric nanocrystalline cellulose had an average length of 200–300 nm and a width slightly less than 20 nm. These results are consistent with the literature reported for nanocrystalline cellulose prepared from softwood kraft pulps using sulfuric acid and hydrochloric acid. Recently, studies by Saxena et al. (2009) have reported that oat-spelt xylan, plasticized with sorbitol and reinforced with 7% sulfuric nanocrystalline cellulose increased the tensile energy absorption of the xylan films by 445% and the tensile strength of the film by 141% with respect to control xylan film. Saxena and Ragauskas (2009) have also shown that when xylan films are reinforced with 10% sulfuric nanocrystalline cellulose, WVTR reduces from 304 g/h m2 for control to 174 g mil/h m2 for xylan–sulfuric nanocrystalline cellulose films. To determine the impact of alternative cellulosic fillers on water transmission properties, a series of xylan composite films were prepared and analyzed using the water vapor transmission test. In the current work, similar experiments were performed using acacia fiber and hydrochloric prepared nanocrystalline cellulose as reinforcement in a xylan film. Because the thickness of the xylan–sulfonated nanocrystalline cellulose, xylan–softwood fiber and xylan–acacia fiber are different, the WVTR was normalized to film thickness (l) with units in mm to obtain the specific water vapor transmission rate (R = WVTR × l) with units of g mm/d m2 (Hu, Topolkaraev, Hiltner, & Baer, 2000). Xylan films reinforced with 10% acacia fiber and 10% hydrochloric nanocrystalline cellulose exhibited virtually no improvement in specific water vapor transmission rate in comparison to control. Xylan film reinforced with 10% sulfuric nanocrystalline cellulose exhibited lowest specific water transmission rate of 174 g mil/h m2 and xylan film with softwood fiber exhibited highest water transmission rate as summarized in Table 1. The water transmission rate at other levels is summarized in Fig. 1. It was found that the addition of 5% softwood kraft pulp fibers yielded a xylan film with increased specific water vapor transmission rate and a significant high water vapor transmission rate at 50% dosage with respect to control. The addition of softwood kraft fibers in the xylan film causes a significant high specific water vapor transmission rate at any dosages (5%, 10% and 50%). The addition of hydrochloric acid prepared nanocrystalline cellulose to xylan films was also analyzed for specific water transmission rate. The specific WVTR values decreased as the content of HCl generated nanocrystalline cellulose in the xylan film increased from 0%","Composites, Xylan, Nanocrystalline cellulose, Moisture barrier","This study investigates the moisture barrier properties of xylan films reinforced with various cellulosic materials, including nanocrystalline cellulose, acacia kraft pulp fibers, and softwood kraft fibers.  The researchers found that films reinforced with 10% sulfuric acid-prepared nanocrystalline cellulose exhibited the lowest water vapor transmission rate, significantly outperforming films reinforced with other materials. The morphology and interactions between the reinforcing agents and the xylan matrix were also examined."
A. Shankara,Quantitative Comparison of a High Resolution Micro-Angiographic Fluoroscopic (MAF) Detector with a Standard Flat Panel Detector (FPD) Using the New Metric of Generalized Measured Relative Object Detectability (GM-ROD),"A novel amorphous selenium (a-Se) direct detector with CMOS readout has been designed, and relative detector performance investigated. The detector features include a 25μm pixel pitch, and 1000μm thick a-Se layer operating at 10V/μm bias field. A simulated detector DQE was determined, and used in comparative calculations of the Relative Object Detectability (ROD) family of prewhitening matched-filter (PWMF) observer and non-prewhitening matched filter (NPWMF) observer model metrics to gauge a-Se detector performance against existing high resolution micro-angiographic fluoroscopic (MAF) detectors and a standard flat panel detector (FPD). The PWMF-ROD or ROD metric compares two x-ray imaging detectors in their relative abilities in imaging a given object by taking the integral over spatial frequencies of the Fourier transform of the detector DQE weighted by an object function, divided by the comparable integral for a different detector. The generalized-ROD (G-ROD) metric incorporates clinically relevant parameters (focal-spot size, magnification, and scatter) to show the degradation in imaging performance for detectors that are part of an imaging chain. Preliminary ROD calculations using simulated spheres as the object predicted superior imaging performance by the a-Se detector as compared to existing detectors. New PWMF-G-ROD and NPWMF-G-ROD results still indicate better performance by the a-Se detector in an imaging chain over all sphere sizes for various focal spot sizes and magnifications, although a-Se performance advantages were degraded by focal spot blurring. Nevertheless, the a-Se technology has great potential to provide breakthrough abilities such as visualization of fine details including of neuro-vascular perforator vessels and of small vascular devices.","Comparative metrics, generalized metrics, micro-angiography, DQE, Detector Performance, relative object detectability, Microangiography, CMOS, Flat Panel Detector, amorphous selenium","This paper presents a comparative study of a novel amorphous selenium (a-Se) direct detector with existing high resolution micro-angiographic fluoroscopic (MAF) detectors and a standard flat panel detector (FPD). The study utilizes the Relative Object Detectability (ROD) family of metrics, including the generalized-ROD (G-ROD) metric, to assess the performance of these detectors in imaging small objects.  The results indicate that the a-Se detector exhibits superior imaging performance compared to existing detectors, particularly in terms of resolving fine details.  While focal spot blurring can degrade the performance advantage of the a-Se detector, its potential for breakthrough imaging capabilities in neuro-vascular applications is highlighted."
A.-C. Liew,Unique Local Features in Lip Images for Recognition,"The experiments are carried out from images taken with a camera that is used for the regular use. And the color features of a lip are not explored in the proposed research. Still the recognition system exploits the grayscale local features of a lip images and eﬃciently matches it with local features of another lip image. If the color properties of a lip image is explored for recognition along with local features, the accuracy values would increase further.","grayscale features, Lip Pattern Recognition, SIFT, lip recognition, color features, Biometric, Local Feature Extraction, local features, SURF",The paper presents the results of experiments on lip recognition using local features. The recognition system exploits the grayscale local features of lip images and achieves high accuracy. The authors suggest that exploring color properties of lip images could further improve the accuracy.
A.Bardhan,Biclustering Algorithm for E-Gov Services,"With the widespread and proactive participation of citizens through various e-governance applications, democracy in the modern era has acquired an entirely new dimension The shear diversity of e-governance users has spurred on a fresh interest in designing adaptable e-governance systems. The first step in meeting this challenge is to develop a fast and versatile automated technique to categorize users on the basis of a similarity in their online identities and behaviors. In this paper we employ a modified version of the Cheng and Church Biclustering algorithm, hitherto used primarily in the field of Genetics, to extend its applicability to a classification of e-governance users. Taking a different route from conventional approaches, we tap a variety of dynamically varying parameters that characterize the online behavior of users with a view to improving the cohesiveness of user clusters. These include the navigation patterns of a user, her access frequency and the interactivity level during her web experience. We adopt two strategies for clustering. A single level strategy categorizes users on all the three parameters taken together using the Cheng and Church (CC) algorithm. We also employ a two level clustering strategy that first finds biclusters on the basis of individual parameters using CC and then the uses cluster ids to classify the users at a second level by and K-Means clustering. An analysis of the granularity of clusters and execution time for different strategies and datasets reveals that the single level strategy is useful in categorizing experienced users who have attained a degree of familiarity with the portal and are able to change their behavior frequently. Such a group of users is quite variegated. On the other hand, the two level strategy provides a better way to classify beginners who show very slow changes and are more uniform in their web interactions.","E-Gov Services, Threshold, single levels strategy and two level strategy, Biclustering, Mean Square Residue, e-governance, CC Biclustering Algorithm","This paper proposes the most appropriate clustering strategies for differently evolving user bases. The users' online behavior is captured with a comprehensive set of attributes including navigation path, frequency of accessing each page and the interactivity level sustained by users during their web interaction. We present a comparative analysis of single level and two level clustering strategies by employing three techniques: Cheng and Church biclustering, K-Means clustering and a combination of the two. Our experiments investigate the impact on execution time, quality and number of clusters when the base dataset of users' web behaviors is changed with minor modifications and major modifications."
A.H. Rashid,Machine learning techniques for the diagnosis of Alzheimer’s disease: A review,"Alzheimer’s disease is an incurable neurodegenerative disease primarily affecting the elderly population. Efficient automated techniques are needed for early diagnosis of Alzheimers. Many novel approaches are proposed by researchers for classification of Alzheimer’s disease. However, to develop more efficient learning techniques, better understanding of the work done on Alzheimers is needed. Here, we provide a review on 165 papers from 2005-2019 using various feature extraction and machine learning techniques. The machine learning techniques are surveyed under three main categories: support vector machine (SVM), artificial neural network (ANN), and deep learning (DL) and ensemble methods.","Ensemble methods, Support vector machine, Deep learning, Alzheimer’s disease, classification, Artificial neural network, Machine learning","This paper provides a review of 165 papers on machine learning techniques for the diagnosis of Alzheimer’s disease from 2005-2019. The review covers three main categories: support vector machine (SVM), artificial neural network (ANN), and deep learning (DL) and ensemble methods. The paper discusses the importance of efficient automated techniques for early diagnosis of Alzheimers and the need for better understanding of the work done on Alzheimers to develop more efficient learning techniques."
A.P. Dimri,Impact of Eurasian Snow Cover on Indian Summer Monsoon Rainfall over the Northwestern Himalayas,"The entire Indo-Himalayan region from northwest (Kashmir) to northeast (Assam) is facing prevalence of floods and landslides in recent years causing massive loss of property, human and animal lives, infrastructure, and eventually threatening tourist activities substantially. Extremely intense rainfall event of A.D. 2013 (between 15 and 17 June) kicked off mammoth flash floods in the Kedarnath area of Uttarakhand state, resulting in huge socioeconomic losses to the state and country.","Eurasian snow cover, extreme rainfall events, flash floods, gridded data sets, Himalayas, Arctic Oscillation, northwestern Himalayas, Indian summer monsoon rainfall","The study investigates ~100-year-long monthly rainfall and air temperature time series data for a selected grid covering most parts of Uttarakhand state. The results indicate that under warming scenario, JJ rainfall (over AS) may further increase with occasional extreme rainfall spells when AO index (March) is negative."
A.S. Morris,Dynamic Equations of Motion for a Multiple Flexible Links and Flexible Joints Manipulator,"The paper presents a dynamic modelling technique for a manipulator with multiple flexible links and flexible joints, based on a combined Euler–Lagrange formulation and assumed modes method. The resulting generalised model is validated through computer simulations by considering a simplified case study of a two-link flexible manipulator with joint elasticity.","Euler-Beam theory, Rayleigh's dissipation function, Flexible joint, Flexible links, Singular perturbation, Flexible joints, Manipulator dynamics, Flexible link, Manipulator","The paper presents a dynamic modelling technique for a manipulator with multiple flexible links and flexible joints, based on a combined Euler–Lagrange formulation and assumed modes method. The resulting generalised model is validated through computer simulations by considering a simplified case study of a two-link flexible manipulator with joint elasticity. Controlling such a manipulator is more complex than controlling one with rigid joints because only a single actuation signal can be applied at each joint and this has to control the flexure of both the joint itself and the link attached to it."
A.Sudha Prasanna,Adaptive Privacy Policy Prediction for Images in Social Media,"Social Network is an emerging E-service for content sharing sites (CSS). It is emerging service which provides a reliable communication, through this communication a new attack ground for data hackers; they can easily misuses the data through these media.","A3P-Core, Policy Prediction, Adaptive Privacy Policy Prediction, Privacy-Aware Image Classification and Search, Policy Mining, Privacy Suites, A3P-Social, Image Classification, Adaptive Privacy Policy Prediction (A3P), Social Media, Polar Fourier Transform (PFT), Tag based access control of data","This paper proposes an Adaptive Privacy Policy Prediction (A3P) system to help users compose privacy settings for their images. The system handles user uploaded images and factors in social environment, personal characteristics, image content, and metadata to predict the best available privacy policy for each user's images."
A.V. Sutagundar et. al,Energy-Efficient Routing Algorithm for Wireless Sensor Networks,"Wireless Sensor Network (WSN) is a collection of sensor nodes. A sensor node covers all information which is present in its sensing range. To access the information present in some other sensor range, the networks use a process called Routing. Routing problem in wireless sensor network (WSN) concerned with maximizing the sensor network lifetime while continuously routing the collected data (information) to the base station (central server).","Network Lifetime, Energy –Efficiency, Energy-Efficient Routing, Sensor Networks, Routes, Wireless Sensor Networks, Wireless Sensor Networks (WSN), Energy Consumption, Routing problem, Routing Algorithm",The paper presents a new energy-efficient routing algorithm for wireless sensor networks. The algorithm prioritizes sensors according to their remaining battery life and selects the shortest path to maximize the total network lifetime.
AHMED BOURIDANE,Palmprint Identification Using an Ensemble of Sparse Representations,"Among various palmprint identification methods proposed in the literature, sparse representation for classification (SRC) is very attractive offering high accuracy. Although SRC has good discriminative ability, its performance strongly depends on the quality of the training data. In particular, SRC suffers from two major problems: lack of training samples per class and large intra-class variations. In fact, palmprint images not only contain identity information but they also have other information, such as illumination and geometrical distortions due to the unconstrained conditions and the movement of the hand. In this case, the sparse representation assumption may not hold well in the original space since samples from different classes may be considered from the same class. This paper aims to enhance palmprint identification performance through SRC by proposing a simple yet efficient method based on an ensemble of sparse representations through an ensemble of discriminative dictionaries satisfying SRC assumption.","sparse representations, sparse representation, ensemble learning, palmprint identification, 2D-PCA, 2D-LDA, Biometrics, palmprint",This paper proposes a new method for palmprint identification using an ensemble of sparse representations. The method aims to enhance the performance of sparse representation for classification (SRC) by proposing a simple yet efficient method based on an ensemble of discriminative dictionaries satisfying SRC assumption. The proposed method is evaluated on two publicly available palmprint data sets and shows very promising results compared with both state-of-the-art holistic and coding methods.
AKSHI KUMAR,Personality Detection using Kernel-based Ensemble Model for leveraging Social Psychology in Online Networks,"The Asian social networking market dominates the world landscape with the highest consumer penetration rate. Businesses and investors often look for winning strategies to attract consumers to increase revenues from sales, advertisements, and other services offered on social media platforms. Social media engagement and online relational cohesion have often been defined within the frameworks of social psychology and personality identification is a possible way in which social psychology can inform, engage, and learn from social media.","Natural language, MBTI personality type, Personality Psychology, kernel-based soft voting ensemble, Hindi dataset, kernel-based methods, Social Networks, Support Vector Machine, personality detection",The paper proposes a kernel-based soft voting ensemble for personality detection in natural language textual data. The model uses the Support Vector Machine (SVM) with soft voting ensembled kernels to detect different traits of the MBTI personality type in an English and a Hindi dataset. The primary contribution of this work is to develop an efficient kernel-based ensemble model for text-based personality prediction.
ALBERT Y. ZOMAYA,MSGR: A Mode-Switched Grid-Based Sustainable Routing Protocol for Wireless Sensor Networks,"A Wireless Sensor Network (WSN) consists of enormous amount of sensor nodes. These sensor nodes sense the changes in physical parameters from the sensing range and forward the information to the sink nodes or the base station. Since sensor nodes are driven with limited power batteries, prolonging the network lifetime is difficult and very expensive, especially for hostile locations. Therefore, routing protocols for WSN must strategically distribute the dissipation of energy, so as to increase the overall lifetime of the system.","mobile sink, grid-based routing, energy efficiency, grid head, scalability, Wireless sensor networks","The paper presents a comprehensive review of grid-based routing protocols for WSNs, highlighting their design principles, advantages, and limitations. It also proposes a new mode-switched grid-based sustainable routing protocol, which adapts to changing network conditions to conserve energy and improve network lifetime."
AMJAD QASHLAN,Privacy-Preserving Mechanism in Smart Home Using Blockchain,"The IoT, or Internet of Things has been a major talking point amongst technology enthusiasts in recent years. The internet of thing (IoT) has been emerged and evolved rapidly, making the world’s fabric around us smarter and more responsive. The smart home uses one such transformation of IoT, which seems to be the wave of the future. However, with the increasing wide adoption of IoT, data security, and privacy concerns about how our data is collected and shared with others, has also risen. To solve these challenges, an approach to data privacy and security in a smart home using blockchain technology is proposed in this paper. We propose authentication scheme that combines attribute-based access control with smart contracts and edge computing to create a secure framework for IoT devices in smart home systems. The edge server adds scalability to the system by offloading heavy processing activities and using a differential privacy method to aggregate data to the cloud securely and privately. We present several aspects of testing and implementing smart contracts, the differential private stochastic gradient descent algorithm, and system architecture and design. We demonstrate the efficacy of our proposed system by fully examining its security and privacy goals in terms of confidentiality, integrity, and availability. Our framework achieves desired security and privacy goals and is resilient against modification, DoS attacks, data mining and linkage attacks. Finally, we undertake a performance evaluation to demonstrate the proposed scheme’s feasibility and efficiency.","edge computing, cyber threats, smart home, access control, differential privacy, Blockchain, smart contract","This paper proposes a privacy-preserving mechanism in smart homes using blockchain technology. The proposed system combines attribute-based access control with smart contracts and edge computing to create a secure framework for IoT devices in smart home systems. The edge server adds scalability to the system by offloading heavy processing activities and using a differential privacy method to aggregate data to the cloud securely and privately. The proposed system achieves desired security and privacy goals and is resilient against modification, DoS attacks, data mining and linkage attacks."
APARAJITA NANDA,NPReId Framework for Video Surveillance,"This paper presents a neuromorphic person re-identiﬁcation (NPReId) framework to establish the correspondence among individuals observed across two disjoint camera views. The proposed framework comprises three modules (observation, cognition, and contemplation), inspired by the form-and-color-and-depth (FACADE) theory model of object recognition system.","person re-identification, recognition, FACADE theory, Surveillance, video surveillance, consensus clustering, person re-identiﬁcation, NPReId","The proposed NPReId framework comprises three interactive modules – observation, cognition, and contemplation. The observation module suppresses the background and extracts the chromatic and texture details from the segmented pedestrian. The cognition module projects the psychological result of observation to learn the underlying pedestrian signature. The results of observation and cognition modules are forwarded to the contemplation module that recognizes the correct match for any individual."
ARIF MAHMOOD,Palmprint Identification Using an Ensemble of Sparse Representations,"Among various palmprint identification methods proposed in the literature, sparse representation for classification (SRC) is very attractive offering high accuracy. Although SRC has good discriminative ability, its performance strongly depends on the quality of the training data. In particular, SRC suffers from two major problems: lack of training samples per class and large intra-class variations. In fact, palmprint images not only contain identity information but they also have other information, such as illumination and geometrical distortions due to the unconstrained conditions and the movement of the hand. In this case, the sparse representation assumption may not hold well in the original space since samples from different classes may be considered from the same class. This paper aims to enhance palmprint identification performance through SRC by proposing a simple yet efficient method based on an ensemble of sparse representations through an ensemble of discriminative dictionaries satisfying SRC assumption.","sparse representations, sparse representation, ensemble learning, palmprint identification, 2D-PCA, 2D-LDA, Biometrics, palmprint",This paper proposes a new method for palmprint identification using an ensemble of sparse representations. The method aims to enhance the performance of sparse representation for classification (SRC) by proposing a simple yet efficient method based on an ensemble of discriminative dictionaries satisfying SRC assumption. The proposed method is evaluated on two publicly available palmprint data sets and shows very promising results compared with both state-of-the-art holistic and coding methods.
ARUN KUMAR SANGAIAH,IoT-Based Wireless Polysomnography Intelligent System for Sleep Monitoring,"Polysomnography (PSG) is considered the gold standard in the diagnosis of obstructive sleep apnea (OSA). The diagnosis of OSA requires an overnight sleep experiment in a laboratory. However, due to limitations in relation to the number of labs and beds available, patients often need to wait a long time before being diagnosed and eventually treated. In addition, the unfamiliar environment and restricted mobility when a patient is being tested with a polysomnogram may disturb their sleep, resulting in an incomplete or corrupted test. Therefore, it is posed that a PSG conducted in the patient’s home would be more reliable and convenient. The Internet of Things (IoT) plays a vital role in the e-Health system. In this paper, we implement an IoT-based wireless polysomnography system for sleep monitoring, which utilizes a battery-powered, miniature, wireless, portable, and multipurpose recorder. A Java-based PSG recording program in the personal computer is designed to save several bio-signals and transfer them into the European data format. These PSG records can be used to determine a patient’s sleep stages and diagnose OSA. This system is portable, lightweight, and has low power-consumption. To demonstrate the feasibility of the proposed PSG system, a comparison was made between the standard PSG-Alice 5 Diagnostic Sleep System and the proposed system. Several healthy volunteer patients participated in the PSG experiment and were monitored by both the standard PSG-Alice 5 Diagnostic Sleep System and the proposed system simultaneously, under the supervision of specialists at the Sleep Laboratory in Taipei Veteran General Hospital. A comparison of the results of the time-domain waveform and sleep stage of the two systems shows that the proposed system is reliable and can be applied in practice. The proposed system can facilitate the long-term tracing and research of personal sleep monitoring at home.","sleep monitoring, wireless, Internet of Things, wireless PSG, JAVA, Polysomnography (PSG), IoT","This paper proposes an IoT-based wireless polysomnography system for sleep monitoring, which utilizes a battery-powered, miniature, wireless, portable, and multipurpose recorder. The system is designed to save several bio-signals and transfer them into the European data format, allowing for the determination of a patient’s sleep stages and diagnosis of OSA. The proposed system is compared to the standard PSG-Alice 5 Diagnostic Sleep System and shows reliable results, making it a viable option for long-term tracing and research of personal sleep monitoring at home."
ARUNA TIWARI,Novel quantum inspired binary neural network algorithm,"In this paper, a quantum based binary neural network algorithm is proposed, named as novel quantum binary neural network algorithm (NQ-BNN). It forms a neural network structure by deciding weights and separability parameter in quantum based manner. Quantum computing concept represents solution probabilistically and gives large search space to find optimal value of required parameters using Gaussian random number generator. The neural network structure forms constructively having three number of layers input layer: hidden layer and output layer. A constructive way of deciding the network eliminates the unnecessary training of neural network. A new parameter that is a quantum separability parameter (QSP) is introduced here, which finds an optimal separability plane to classify input samples. During learning, it searches for an optimal separability plane. This parameter is taken as the threshold of neuron for learning of neural network. This algorithm is tested with three benchmark datasets and produces improved results than existing quantum inspired and other classification approaches.","Binary Neural Network, quantum gates, separability plane, neural network, classification, Novel Algorithm, Quantum computing","A novel quantum inspired binary neural network algorithm is proposed, which uses quantum computing concept to decide the parameters like weights of neural networks and quantum separability parameter (QSP) or threshold. The algorithm forms a neural network structure with three layers, input layer, hidden layer and output layer, and uses a constructive way of deciding the network to eliminate unnecessary training. The algorithm is tested on three benchmark datasets and produces improved results than existing quantum inspired and other classification approaches."
Aashi Jain,A Line Drawing Language (LDDL) and its Compiler,A domain-specific language to draw line drawings is introduced in this paper. The compiler converts the specification of a line drawing written in this language into an image file. The language is suitable for drawing line drawings used in scientific literature.,"Line drawing, LDDL, graphic language, line drawing language, domain-specific language, compiler","This paper introduces a domain-specific language, named Line Drawing Description Language (LDDL), in which the specification of a line drawing can be written. The language is suitable for drawing line drawings used in scientific literature."
Abdul H. Abdullah,Towards Video Streaming in IoT Environments: Vehicular Communication Perspective,"Multimedia oriented Internet of Things (IoT) enables pervasive and real-time communication of video, audio and image data among devices in immediate surroundings. Today’s vehicles have the capability of supporting real time multimedia acquisition. Vehicles with high illuminating infrared cameras and customized sensors can communicate with other on-road devices using dedicated short-range communication (DSRC) and 5G enabled communication technologies. Real time incidence of both urban and highway vehicular traffic environment can be captured and transmitted using vehicle-to-vehicle and vehicle-to-infrastructure communication modes. Video streaming in vehicular IoT (VSV-IoT) environments is in growing stage with several challenges that need to be addressed ranging from limited resources in IoT devices, intermittent connection in vehicular networks, heterogeneous devices, dynamism and scalability in video encoding, bandwidth underutilization in video delivery, and attaining application-precise quality of service in video streaming. In this context, this paper presents a comprehensive review on video streaming in IoT environments focusing on vehicular communication perspective. Specifically, the significance of video streaming in vehicular IoT environments is highlighted focusing on the integration of vehicular communication with 5G enabled IoT technologies, and smart city oriented application areas for VSV-IoT. A taxonomy is presented for the classification of related literature on video streaming in vehicular network environments. Following the taxonomy, critical review of literature is performed focusing on major functional model, strengths and weaknesses. Metrics for video streaming in vehicular IoT environments are derived and comparatively analyzed in terms of their usage and evaluation capabilities. Open research challenges in VSV-IoT are identified as future directions of research in the area. The survey would benefit both IoT and vehicle industry practitioners and researchers, in terms of augmenting understanding of vehicular video streaming and its IoT related trends and issues.","Video streaming, Internet of vehicles, traffic safety, vehicular ad-hoc networks, Vehicular Communication, Intelligent transportation system, Internet of things, IoT","The paper discusses the significance of video streaming in vehicular IoT environments, presents a taxonomy for the classification of literature on video streaming over vehicular ad-hoc networks, derives performance metrics for video streaming in vehicular IoT environments, and identifies open research issues and challenges in vehicular video streaming under IoT environments."
Abdul Hanan Abdullah,A Dynamic Congestion Control Scheme for safety applications in vehicular ad hoc networks ||| A Novel EV Charging Management Scheme Considering Mobility Uncertainty ||| Virtualization in Wireless Sensor Networks: Fault Tolerant Embedding for Internet of Things,"In recent years, various types of applications have emerged from Vehicular Ad hoc Networks (VANETs) for safety, infotainment, rescue and security purposes. Safety applications have their own strict communication requirements, and they require reliable and timely data communication within networks. Due to a variety of network applications, safety applications have been negatively impacted by communication channel congestion issues. Channel congestion leads to packet loss, delay and unreliability issues, and has a serious impact on vehicular traffic, including road accidents, road jams, and wrong traffic decisions. In addressing these issues, this paper's authors have proposed a Dynamic Congestion Control Scheme (DCCS) as a means of reliable and timely data delivery, in safety applications. The proposed scheme is designed for communication channels, as a means of broadcasting safety messages, and to ensure the reliable and timely delivery of messages to all neighbours in a network. The DCCS scheme is designed for inter-vehicle communication, without fixed infrastructure. Comprehensive simulation is conducted, in order to evaluate the performance of a proposed scheme, and to compare it with other state of the art schemes. ||| This paper proposes a novel EV charging management scheme that considers mobility uncertainty due to traffic jams in a city. The scheme uses a centralized aggregator to manage charging plans for all EVs in the network, and each EV reports its charging reservation to the aggregator, including its expected arrival time and charging time. The aggregator then makes CS-selection decisions based on the reported information and updates the reservations periodically to adjust for mobility uncertainty. ||| Recently, virtualization in wireless sensor networks (WSNs) has witnessed significant attention due to the growing service domain for IoT. Related literature on virtualization in WSNs explored resource optimization without considering communication failure in WSNs environments. The failure of a communication link in WSNs impacts many virtual networks running IoT services. In this context, this paper proposes a framework for optimizing fault tolerance in virtualization in WSNs, focusing on heterogeneous networks for service-oriented IoT applications.","Charging System, Transmit Power Control, MAC Blocking, Safety, Congestion, CS-Selection Decision Making, CS-Selection, Broadcasting, Electric Vehicle, Driver's Trip Duration, Congestion Control, Fault Tolerant Embedding, Measurement-Based Detection, Urban, Internet of Things, Traffic Jams, Mobility, Mobility Uncertainty, Communication, Electric Vehicle Charging, Wireless sensor networks, Virtualization, Vehicular, Control, VANETs, Centralized Aggregator, IoT, Queue Freezing","This paper proposes a Dynamic Congestion Control Scheme (DCCS) for safety applications in Vehicular Ad hoc Networks (VANETs). The scheme detects congestion and controls it by exploiting existing network resources for road traffic safety and cum security. The main objectives of this research are to determine whether a congestion detection scheme will reduce congestion by using realistic weighting factors and whether a congestion control scheme can control congestion through message originated-based queue freezing. ||| This paper proposes an EV charging management system that considers drivers' trip duration and mobility uncertainty. The system selects charging stations based on reported EVs' reservation information and parking duration, minimizing trip duration for on-the-move EVs. ||| The paper discusses the importance of virtualization in WSNs for IoT applications, focusing on fault-tolerant embedding. It reviews existing proposals on virtualization in WSNs, highlighting their limitations and proposing a new approach to enhance fault tolerance."
AbdulMajid et al.,Deep Learning Techniques for Disease Detection in Fruits and Vegetables,"Plant Diseases are one of the leading reasons of economic shortfalls in agricultural and farming sectors worldwide. It is the most essential element since it reduces crop quantity and quality significantly. Fruits are one of the largest essential nutritional resources from plants. Unfortunately, a variety of conditions might impair both the content and outcome of fruits. As a result, an autonomous Computer Vision (CV) -based approach for reliable Fruit Disease Detection (FDD) is necessary.","Attention mechanisms, Transfer learning, Convolutional neural networks, Computer Vision, Machine Learning, Disease detection, Deep Learning, Fruits and vegetables, Fruit Disease Detection","This paper presents a detailed review of different ML and DL algorithms developed to predict and classify FDs from different fruit images. First, different FDD and classification systems designed by many researchers based on ML and DL algorithms are studied in brief. Then, a detailed analysis is carried out in order to identify the shortcomings of existing algorithms and to provide a novel strategy for properly classifying fruit pathogens."
Abhay Pratap Singh,Isoprenaline Induced Model for Myocardial Necrosis ||| Study the modern biochemical analysis techniques of proteins and alkaline phasphtase enzyme system from biological sample chicken liver,"The study used isoprenaline-induced myocardial necrosis as an experimental model to evaluate the cardioprotective effects of various herbal drugs. The pathophysiological changes following ISO administration in rats are comparable to those taking place during MI in humans. ||| The objective of the study was the biochemical analysis of proteins and Alkaline Phosphatase enzyme system from biological sample Chicken Liver using modern biochemical analysis techniques, including protein extraction, fractionation and electrophoresis separation technique and enzyme analysis.","Nelumbo nucifera, myocardial necrosis, Amino acids, alkaline phosphatase, Enzymes, Cardioprotective Effects, Biochemical analysis, peroxidases, cardioprotective effect, Isoproterenol, Herbal Drugs, acid phosphatase, Protein chains, proteases, Isoprenaline, Proteins","The study aimed to develop a pharmacologic technique for producing myocardial necrosis of standard severity in animals using isoprenaline-induced myocardial necrosis as an experimental model. ||| The paper discusses the biochemical analysis of proteins and alkaline phosphatase enzyme system from chicken liver using modern biochemical analysis techniques. It covers topics such as protein synthesis, structure, and purification, and highlights the importance of proteins in living organisms."
Abhijit Dasgupta,A Novel Approach to Derive the Current Harmonics Present in Circulating Currents and Its Necessary Controller to Suppress the Same in a Five Level MMC,"This paper presents a novel approach to derive the current harmonics present in circulating currents and its necessary controller to suppress the same in a five level modular multilevel converter (MMC). The instantaneous voltage across the capacitors are denoted as Vc1, Vc2, Vc3, Vc4…VcN Also, the voltage distribution across the capacitors is considered as unequal.","experimental approach, modular multilevel converter, MMC, Controller, Current Harmonics, harmonic mitigation, Circulating Currents","This paper presents a new harmonic mitigation scheme for modular multilevel converters, which is an experimental approach. The proposed controller is effective and easy to implement for modular multilevel inverters."
Abhinav Kolla,Health Assessment and Modal Analysis of Historical Masonry Arch Bridge,"Masonry arch bridges in India indicate the heritage value of the nation. Most of these bridges had been in service for hundreds of years and yet being serviceable even today for transportation purposes indicates the robustness of the design and construction methodology. But, some of these bridges are abandoned due to its deterioration and absence of knowledge to retroﬁt these structures. Lack of proper maintenance and retroﬁtting could eventually damage the structural integrity as these structures are old enough to deteriorate and are prone to repeated weathering and unforeseen natural calamities such as earth-quakes, ﬂoods, etc. In this study, a very old masonry arch bridge ‘Puranapul’ bridge inaugurated in the year 1578 across the river Musi in Hyderabad is considered for investigation of its health through basic visual inspection and non-destructive testing. Furthermore, the same is numerically modeled using the available ﬁnite element analysis software ANSYS in three dimensions for assessing the basic mode shapes of the structure and its behavior in different loading conditions.","modal analysis, Masonry arch bridge, Health assessment, finite element method, dynamic analysis, Heritage structure, Nondestructive testing, Finite element model, seismic behavior, Visual inspection","The paper presents a numerical modeling approach for understanding the behavior of a historical masonry arch bridge. The bridge is analyzed using finite element method and the results are presented in terms of deformations, strains, and stresses. The modal analysis is performed to understand the behavior and characteristics of the bridge under dynamic loads. The dynamic analysis is carried out to simulate the seismic behavior of the bridge and the results show that the bridge is quite adequate for lateral loads."
Abhishake Munipala,Structural Dynamics Virtual Laboratory: A Learning Tool Kit for Young Engineers and Practicing Professionals,"India has been facing earthquake problems from many centuries which need no introduction. From recent earthquakes, it is very well understood that lack of awareness is one of the major factor for huge casualty losses. While still having the probability of occurrences of earthquakes in India, it becomes very important and need to increase the awareness about the effects of earthquakes among growing  professionals involved in construction by making them understanding the concepts of Structural Dynamics and Earthquake Engineering.","Structural Dynamics, User Interface, Interactive, Virtual Lab, Virtual Laboratory",This paper will detail the use of virtual laboratory in real time environment of structural dynamics. Virtual Laboratory provides a new methodology to convey and learn concepts using the power of visualization of ideas and computations. Virtual labs rely on an active engagement of the learner in the knowledge acquisition process.
Abhishek Pratap Singh,Identification of Efficient Wireless Sensor Network Using Fuzzy Logic Method,"A wireless sensor network (WSN) consists of sensor nodes and base stations which are connected via wireless medium. A key functionality of WSNs consists in collecting information from sensor nodes & transporting the information of interest to the base stations required by the applications. Wireless connectivity, size and low cost of sensors in WSNs are its advantages which enable it to be deployed in hostile or inaccessible environments at a very low cost. However, WSNs suffer from high data loss due to error prone wireless transmission medium, transmission problems in hostile environments and node failures due to limited energy of sensor nodes. Hence reliable data transportation i.e. ensuring data delivery with minimum loss becomes the key issue in WSNs.","energy efficiency, Wireless Sensor Network, congestion, Fuzzy Logic, communication protocol",The paper proposes a fuzzy logic based system for identifying efficient wireless sensor networks. The system uses three fuzzy inputs and a rule base to determine the energy efficiency of the system. The results show that the system can prioritize energy efficient systems based on the protocol of communication and mitigation of congestion with respect to the size of the wireless sensor network.
Aditya A. Shastri,Cube Sampled K-Prototype Algorithm for Clustering,This paper proposes a novel algorithm called Cube Sampled K-Prototype for clustering mixed data types. The algorithm integrates the K-Means and K-Modes algorithms and uses cube sampling to reduce the computational complexity. The proposed algorithm is compared with other clustering algorithms and shows better performance in terms of clustering accuracy.,"Mixed Data Types, Cube Sampling, Principal Component Analysis, K-Prototype Clustering, Clustering Accuracy, Sampling, Clustering, K-Prototype",This paper proposes a probabilistic sampling technique called cube sampling along with K-Prototype clustering. Cube sampling is used because of its accurate sample selection. The novelty of this work is in obtaining the crucial inclusion probabilities for cube sampling using Principal Component Analysis (PCA).
Aditya Agarwal,An Extended Version of WordNet Incorporating Technical Terms and Subject Specific Words/Phrases,"WordNet is a huge repository being used as a tool in various fields. With an increasing number of applications referring to WordNet as a dictionary, several attempts have been made to update it. The paper proposes to extend the huge repository by adding words and relationships derived from students’ class notes through wikidata. These terms can be phrases, technical terms or any subject specific terminology appearing in students’ notes of a specific subject. Although various WordNet enriching techniques are available, it is for the first time that subject specific terminology is being added. The resulting version of WordNet has some very common phrases and technical terms along with the generic terms. Making subject specific and generic terms available in a hierarchy can improve the accuracy of various applications like text summarization and clustering for text belonging to a specific domain.","Subject Specific Words/Phrases, English WordNet, WordNet, Hyponym enrichment, Technical Terms, Wikidata","The paper proposes a novel hyponym enrichment in WordNet by enriching the database with subject related technical terms. This is important since the database has not been updated for a long time now. To the best of our knowledge, we are the first to use wikidata for adding subject specific terms and relationships to WordNet."
Aditya Bindal,An Adaptive ACO-Driven Scheme for Learning Aim Oriented Personalized E-Learning,The e-learning paradigm is now a well-established vehicle of modern education. It caters to a wide spectrum of students with diverse backgrounds who enroll with their own learning aims. A core challenge under this scenario is to generate personalized learning paths so that each student can achieve her learning aim most effectively.,"learning aim, personalized learning, Learning Aims, e-learning, adaptive learning, Dynamic Learning Ability, ontology-based EL-DSS, Personalized e-Learning, Ant Colony Optimization, Learning Success","The proposed scheme is an extension of the weighted directed acyclic precedence Course Graph (CG) that uses the concept of perspectives introduced earlier. The CG is structured into levels, with each level corresponding to a distinct topic or concept. The scheme uses three databases: Maximum Learning Success (MLS), Perspective Aim Contribution Table (PACT), and Learning Object Priority Table (LOPT) to provide personalized learning paths for each student."
Aditya Prasad,A privacy-preserving cancelable iris template generation scheme using decimal encoding and look-up table mapping,"This paper presents a privacy-preserving cancelable iris template generation scheme using decimal encoding and look-up table mapping. The proposed method consists of a number of tasks, including iris image preprocessing, decimal encoding, and look-up table mapping. The experimental results show that the proposed method outperforms existing approaches in terms of recognition accuracy and security.","Cancelable iris template, Cancelable biometrics, Privacy, Decimal encoding, Look-up table mapping, Biometric security, Biometrics, Security, Iris recognition, Iris biometric","The proposed method generates a secure cancelable iris template using decimal encoding and look-up table mapping. The method consists of several tasks, including iris image preprocessing, decimal encoding, and look-up table mapping. The experimental results show that the proposed method outperforms existing approaches in terms of recognition accuracy and security."
Ah-hwee Tan,A fast pruned-extreme learning machine for classification problem,"Extreme learning machine (ELM) represents one of the recent successful approaches in machine learning, particularly for performing pattern classification. One key strength of ELM is the significantly low computational time required for training new classifiers since the weights of the hidden and output nodes are randomly chosen and analytically determined, respectively.","Extreme learning machine (ELM), Feedforward networks, Pruned ELM, Statistical Relevance Measures, Extreme Learning Machine, Pattern classification, Generalization Ability, Hidden Node Size",This paper presents a pruned-ELM (P-ELM) algorithm as a systematic and automated approach for designing ELM classifier network. P-ELM uses statistical methods to measure the relevance of hidden nodes and provides a systematic approach for designing the network architecture of the ELM classifier.
Ahmed Aliyu,Towards Video Streaming in IoT Environments: Vehicular Communication Perspective,"Multimedia oriented Internet of Things (IoT) enables pervasive and real-time communication of video, audio and image data among devices in immediate surroundings. Today’s vehicles have the capability of supporting real time multimedia acquisition. Vehicles with high illuminating infrared cameras and customized sensors can communicate with other on-road devices using dedicated short-range communication (DSRC) and 5G enabled communication technologies. Real time incidence of both urban and highway vehicular traffic environment can be captured and transmitted using vehicle-to-vehicle and vehicle-to-infrastructure communication modes. Video streaming in vehicular IoT (VSV-IoT) environments is in growing stage with several challenges that need to be addressed ranging from limited resources in IoT devices, intermittent connection in vehicular networks, heterogeneous devices, dynamism and scalability in video encoding, bandwidth underutilization in video delivery, and attaining application-precise quality of service in video streaming. In this context, this paper presents a comprehensive review on video streaming in IoT environments focusing on vehicular communication perspective. Specifically, the significance of video streaming in vehicular IoT environments is highlighted focusing on the integration of vehicular communication with 5G enabled IoT technologies, and smart city oriented application areas for VSV-IoT. A taxonomy is presented for the classification of related literature on video streaming in vehicular network environments. Following the taxonomy, critical review of literature is performed focusing on major functional model, strengths and weaknesses. Metrics for video streaming in vehicular IoT environments are derived and comparatively analyzed in terms of their usage and evaluation capabilities. Open research challenges in VSV-IoT are identified as future directions of research in the area. The survey would benefit both IoT and vehicle industry practitioners and researchers, in terms of augmenting understanding of vehicular video streaming and its IoT related trends and issues.","Video streaming, Internet of vehicles, traffic safety, vehicular ad-hoc networks, Vehicular Communication, Intelligent transportation system, Internet of things, IoT","The paper discusses the significance of video streaming in vehicular IoT environments, presents a taxonomy for the classification of literature on video streaming over vehicular ad-hoc networks, derives performance metrics for video streaming in vehicular IoT environments, and identifies open research issues and challenges in vehicular video streaming under IoT environments."
Ahsan Hussain,Dynamic Multi‑layer Ensemble Classification Framework for Location-Based Social Network Venue Classification,"Multi-layer ensemble frameworks perform much better as compared to individual classifiers. However, selection of a classifier and its placement, impacts the overall performance of ensemble framework. This problem becomes very difficult, if there are more classifiers and layers. To address these problems in this paper, we design “Binary Particle Swarm Optimization” method for selection and placement of right classifiers in multi-layer ensemble model. Proposed classifier weight-assignment method is implemented to prioritize the selected classifiers. The model is simulated for the classification of social-user check-ins in Location-Based Social Network datasets. The experimental results show that the proposed ensemble model outperforms the state-of-the-art ensemble methods in the literature. It can be used by security firms, high level decision makers and various governmental organizations for tracking malicious users.","location-based social network, Dynamic multi-layer ensembles, User-checkins, Social-venue classification, Majority voting, ensemble classification, BPSO, classifier selection, venue classification, Location-Based Social Networks, Machine learning","This paper proposes a Dynamic Multi-Layer Ensemble Classification (DMLEC) technique that works on dynamically choosing the classifiers as per the Binary Particle Swarm Optimization (BPSO) using a novel fitness function. In addition, a new classifier weight assignment method is proposed that updates weights for the particular classifiers as per their classification accuracy. The proposed DMLEC is more flexible and can be used over big datasets for classification of various real world problems."
Aiken,Fifty years of peephole optimization,"Peephole optimization is a technique used in compilers to improve the performance of object programs by replacing sequences of instructions with equivalent single instructions. This article reviews the history and development of peephole optimization, including its application to various programming languages and target machines.","compilers, object programs, peephole optimization, Code generators, instruction sequences, replacement rules","Peephole optimization has been widely used in compilers to improve the performance of object programs. The technique involves replacing sequences of instructions with equivalent single instructions, and has been applied to various programming languages and target machines. The effectiveness of peephole optimization depends on several factors, including the nature of the source language, the parsing and code generation techniques used in the compiler, and the specifications of the target machine."
Ajay Nirula,First-­in-­Human Study of Bamlanivimab in a Randomized Trial of Hospitalized Patients With COVID-­19,"This first-in-human study in hospitalized patients with COVID-19 was supported by studies assessing in vitro viral neutralization combined with a single-dose non-human primate PK study. The nonclinical safety package to support subsequent studies included tissue cross-reactivity studies on human, rat, and monkey tissues and an in vivo toxicology study.  A complete physical examination was conducted at the screening visit, and one of three bamlanivimab doses or placebo was administered i.v. at the baseline visit (D1) with infusion rates as follows: bamlanivimab 700 mg (50 mL) administered 100 mL/hr for 30 minutes; 2,800 mg (75 mL) administered 100 mL/hr for 45 minutes; and 7,000 mg administered 100 mL/hr for 60 minutes. Placebo infusion was 0.9% normal saline, administered at the same volume and rate as the corresponding bamlanivimab dose cohort. Safety and tolerability were reviewed for sentinel participants up to 24 hours after dosing, at which point the investigators and sponsor team determined whether safety and tolerability were acceptable to continue with dosing subsequent participants. The decision to dose the next cohort was made when all participants from the previous cohort had been dosed and safety data assessed for at least 4 days after the i.v. infusion by the investigators and sponsor team in consultation with an independent safety assessment committee. Blood samples were obtained for assessment of exploratory biomarkers, serology, clinical laboratory assessments, and PD on days 1, 3, 7, 11, 15, 22, and 29, and every 7 days until discharge or day 60, if still an inpatient. Samples for the virology assay were collected using nasopharyngeal (preferred) or mid-turbinate methods. Blood samples obtained for PK analyses were assessed on days 1 (pre-infusion and just before end of infusion), 4, 15, and 29, and follow-up visits up to day 60. Symptom-related physical examinations and assessments of clinical symptoms were performed on days 1, 2, 3, 4, 7, 11, 15, 22, and 29, and the day of discharge from the hospital, with additional follow-up examinations every 7 days thereafter until day 60 if the patient was not discharged from the hospital by day 29. Participants’ clinical status and concurrent procedures of special interest were recorded, including limitation on activities due to COVID-19 and any requirements for the following procedures of special interest, such as ongoing hospital medical care, supplemental oxygen, noninvasive ventilation or a high flow oxygen device, mechanical ventilation, extracorporeal membrane oxygenation, additional organ support, or consciousness status using alert, consciousness, verbal, pain, unresponsive scale. Hospitalization events were recorded, including dates of hospital admission and discharge, admission to the intensive care unit (ICU), discharge from the ICU, and discharge location including to an extended care facility or home. Outcomes The primary objective was to assess safety and tolerability, including adverse events (AEs), serious adverse events (SAEs), and discontinuations due to AEs. Other objectives included PKs (e.g., mean concentration at day 29); PD viral load, area under the response time curve (AUC, from day 1 to day 29), and change from baseline time course; total symptom score; time to symptom resolution; duration of hospitalization; National Institute of Allergy and Infectious Diseases (NIAID), World Health Organization (WHO) scales, and National Early Warning Score (NEWS2); and analysis of viral resistance. Any hypothesis tests were conducted for treatment comparisons without adjustment for multiplicity except for the evaluation of treatment effect on endogenous antibody titers. Success for the trial was claimed using a Bayesian criterion if any of the 3 bamlanivimab doses had at least 60% probability to reduce at least 30% mean AUC (28-day viral load) over placebo.",,"This first-in-human study evaluated the safety, tolerability, pharmacokinetics, clinical course, and viral dynamics of bamlanivimab, a fully human neutralizing monoclonal antibody targeting SARS-CoV-2, in hospitalized patients with moderate to severe COVID-19.  The study found bamlanivimab to be safe and well-tolerated, with no serious adverse events or deaths reported.  Further research is needed to determine the efficacy of bamlanivimab in treating COVID-19."
Ajeet Kumar,Controlled synthesis of size-tunable nickel and nickel oxide nanoparticles using water-in-oil microemulsions,"Industrial demands have generated a growing need to synthesize pure metal and metal–oxide nanoparticles of a desired size. We report a novel and convenient method for the synthesis of spherical, size tunable, well dispersed, stable nickel and nickel oxide nanoparticles by reduction of nickel nitrate at room temperature in a TX-100/n-hexanol/cyclohexane/water system by a reverse microemulsion route. We determined that reduction with alkaline sodium borohydrate in nitrogen atmosphere leads to the formation of nickel nanoparticles, while the use of hydrazine hydrate in aerobic conditions leads to the formation of nickel oxide nanoparticles. The inﬂuence of several reaction parameters on the size of nickel and nickel oxide nanoparticles were evaluated in detail. It was found that the size can be easily controlled either by changing the molar ratio of water to surfactant or by simply altering the concentration of the reducing agent. The morphology and structure of the nanoparticles were characterized by quasi-elastic light scattering (QELS), transmission electron microscopy (TEM), x-ray diffraction (XRD), electron diffraction analysis (EDA) and energy dispersive x-ray (EDX) spectroscopy. The results show that synthesized nanoparticles are of high purity and have an average size distribution of 5–100 nm. The nanoparticles prepared by our simple methodology have been successfully used for catalyzing various chemical reactions.","non-ionic surfactant, nickel nanoparticles, microemulsion, nickel oxide nanoparticles, water-in-oil microemulsions, synthesis, nickel, water-to-surfactant ratio, nickel oxide, reducing agent, nanoparticles",This paper describes a novel method for synthesizing nickel and nickel oxide nanoparticles using a water-in-oil microemulsion system. The method allows for control over the size of the nanoparticles by adjusting reaction parameters such as the water-to-surfactant ratio and the concentration of the reducing agent. The synthesized nanoparticles were characterized using various techniques and found to be of high purity with an average size distribution of 5-100 nm. These nanoparticles have potential applications as catalysts in various chemical reactions.
Akarsha D P,Analysing the Performance of Novel Activation Functions on Deep Learning Architectures,"Deep learning is a cutting-edge technology that functions similarly to the human nervous system. Neural networks are at the heart of Deep Learning. Neural networks are made up of numerous layers, in-cluding the input layer, which accepts raw data as input, hidden layers, which process the input data, and a final layer, the output layer, which provides the result. Its workflow pattern is comparable to machine learn-ing [2], [11], allowing us to gain hands-on expertise with this technology, speed up our work, and allow us to make several efforts without hav-ing to develop a basic Machine learning algorithm from scratch. In the case of deep learning, there are several neural networks to choose from. The majority of Deep Learning architectures are built on neural networks such as CNN, RNN, and others. Deep neural network activation function development is often guided by set goals and gradual steps toward tack-ling specific challenges. The primary goal of this study is to examine the performance of innovative activation functions (SBAF parabola [6] [16], AReLU [7], Leaky ReLU, SWISH) on deep learning architectures such as CNN, DENSENET, etc. On deep learning architectures, our study will compare the classification performance of the aforementioned activation functions.","Redundancy, Network reliability, Robotics, Embedded systems","This paper explores the performance of novel activation functions (SBAF parabola, AReLU, Leaky ReLU, SWISH) on deep learning architectures like CNN and DENSENET. The study aims to compare the classification accuracy of these activation functions on various computer vision datasets."
Akhilesh Gangwar,Visual Sentiment Analysis of Customer Complaints using SOM,"With the widespread use of social media, companies now have access to a wealth of customer feedback data which has valuable applications to Customer Relationship Management (CRM). Analyzing customer grievances data, is paramount as their speedy non-redressal would lead to customer churn resulting in lower profitability. In this paper, we propose a descriptive analytics framework using Self-organizing feature map (SOM), for Visual Sentiment Analysis of customer complaints. The network learns the inherent grouping of the complaints automatically which can then be visualized too using various techniques. Analytical Customer Relationship Management (ACRM) executives can draw useful business insights from the maps and take timely remedial action. We also propose a high-performance version of the algorithm CUDASOM (CUDA based Self Organizing feature Map) implemented using NVIDIA parallel computing platform, CUDA, which speeds up the processing of high-dimensional text data and generates fast results. The efficacy of the proposed model has been demonstrated on the customer complaints data regarding the products and services of four leading Indian banks. CUDASOM achieved an average speed up of 44 times. Our approach can expand research into intelligent grievance redressal system to provide rapid solutions to the complaining customers.","CUDA, Grievance Redressal, Self-Organizing Map, Visual Sentiment Analysis, Customer Complaints, Self-Organizing Maps, Analytical CRM, SOM","This paper proposes a descriptive analytics framework using Self-organizing feature map (SOM) for Visual Sentiment Analysis of customer complaints. The framework learns the inherent grouping of complaints automatically and can be visualized using various techniques. A high-performance version of the algorithm CUDASOM is also proposed, which speeds up the processing of high-dimensional text data and generates fast results."
Akrati Saxena,Modeling Memetics using Edge Diversity,"The study of meme propagation and the prediction of meme trajectory are emerging areas of interest in the field of complex networks research. In addition to the properties of the meme itself, the structural properties of the underlying network decides the speed and the trajectory of the propagating meme.","meme virality, information propagation, meme propagation models, meme propagation, social network analysis, complex networks research, social networks, viral marketing, influence maximisation",The paper proposes a framework for studying meme propagation patterns using a synthetic network and a spreading model based on the diversity of edges in the network. The framework is validated against the real-world spreading of the Higgs boson meme on Twitter.
Akshansh Gupta,A Review of Clustering Techniques and Developments,"This paper presents a comprehensive study on clustering: exiting methods and developments made at various times. Clustering is defined as an unsupervised learning where the objects are grouped on the basis of some similarity inherent among them. There are different methods for clustering the objects such as hierarchical, partitional, grid, density based and model based. The approaches used in these methods are discussed with their respective states of art and applicability. The measures of similarity as well as the evaluation criteria, which are the central components of clustering are also presented in the paper. The applications of clustering in some fields like image segmentation, object and character recognition and data mining are highlighted.","Data mining, ROCK, Taxonomy, Unsupervised learning, Similarity measures, CURE, Clustering, Hierarchical Clustering, Clustering Approaches, CHAMELEON, Pattern recognition, BIRCH","This paper reviews clustering techniques and developments, discussing methods such as hierarchical, partitional, grid, density-based, and model-based clustering, as well as measures of similarity and evaluation criteria. The applications of clustering in fields like image segmentation, object recognition, and data mining are highlighted."
Akshi Kumar,SWOT Analysis of Ontology Driven Software Engineering,"In the past decade offshoring and outsourcing the software development phenomenon has been undeniably a key software engineering practice. The need to adapt to this new reality is obvious and is bound to have a long lasting influence on the software industry. This fosters the industry and researchers to look for intelligent supporting technologies and tools that can help interconnect and exchange Software Engineering knowledge. A rising trend to exploit ontologies for sharing and reusing information across web is well recognized. We examine the strategic alignment of ontologies to Software Engineering where the former can be used to improve and assist in intelligent software development process. The SWOT (Strengths, Weaknesses, Opportunities, and Threats) analysis is presented giving an insight to the use of ontologies to enrich and enhance Software Engineering processes.","Ontology, Ontology Driven, information sharing, distributed development environments, Software Engineering, Semantic Web, communication, SWOT Analysis, intelligent support tools","The purpose of this study is to utilize the SWOT analysis framework to determine the benefits, impact, challenges, and risks of using ontologies for Software Engineering. This will help in providing an insight to short-term and long-term practical recommendations that can enhance the Software Engineering process and impact businesses/ individuals/ organizations/ groups in a prolific and strategic manner."
Al-Garadi et. al.,Rumour Source Detection Using Game Theory,"Social networks have become a critical part of our lives as they enable us to interact with a lot of people. These networks have become the main sources for creating, sharing and also extracting information regarding various subjects. But all this information may not be true and may contain a lot of unverified rumours that have the potential of spreading incorrect information to the masses, which may even lead to situations of widespread panic. Thus, it is of great importance to identify those nodes and edges that play a crucial role in a network in order to find the most influential sources of rumour spreading. Generally, the basic idea is to classify the nodes and edges in a network with the highest criticality. Most of the existing work regarding the same focuses on using simple centrality measures which focus on the individual contribution of a node in a network. Game-theoretic approaches such as Shapley Value (SV) algorithms suggest that individual marginal contribution should be measured for a given player as the weighted average marginal increase in the yield of any coalition that this player might join. For our experiment, we have played five SV-based games to find the top 10 most influential nodes on three network datasets (Enron, USAir97 and Les Misérables). We have compared our results to the ones obtained by using primitive centrality measures. Our results show that SV-based approach is better at understanding the marginal contribution, and therefore the actual influence, of each node to the entire network.","influential nodes, Jaccard Similarity Coefficient, cooperative game, Rumour Source Detection (RSD), centrality measures, network analysis, Shapley Value (SV), Game-Theory, Network Centrality",This paper aims to identify the most influential nodes in a network that are the primary sources of rumour propagation. The authors propose a game-theoretic approach using the Shapley Value algorithm to find the most influential nodes. They compare their results with primitive centrality measures and show that the SV-based approach is better at understanding the marginal contribution of each node to the entire network.
Alexander Rumyantsev,Explicit Rate Matrix of a G/M/1-type Process with 2 Phases at a Level,In this research paper we consider the matrix polynomial equation arising naturally in the equilibrium analysis of a structured G/M/1-type Markov process. We obtain an explicit expression for the unknown rate matrix R being 2 × 2 matrix.,"Rate Matrix, Energy Efficiency, Explicit Solution, Matrix-Analytic Method, Matrix Polynomial Equation, G/M/1-type Markov Process, G/M/1-type Process, Randomized Switching","The paper presents an exact solution for the rate matrix of a structured G/M/1-type Markov process with a small number of phases. The solution is obtained using a symbolic solution of the determinant polynomial equation and the Cayley-Hamilton theorem. The method is applied to a novel approach to energy efficiency of a single-server computing system, and a new randomized regime switching scheme is proposed."
Alexey Semenkov,Generation of an EDS Key Based on a Graphic Image of a Subject’s Face Using the RC4 Algorithm,"Modern facial recognition algorithms make it possible to identify system users by their appearance with a high level of accuracy. In such cases, an image of the user’s face is converted to parameters that later are used in a recognition process. On the other hand, the obtained parameters can be used as data for pseudo-random number generators. However, the closeness of the sequence generated by such a generator to a truly random one is questionable. This paper proposes a system which is able to authenticate users by their face, and generate pseudo-random values based on the facial image that will later serve to generate an encryption key. The generator of a random value was tested with the NIST Statistical Test Suite. The subsystem of image recognition was also tested under various conditions of taking the image. The test results of the random value generator show a satisfactory level of randomness, i.e., an average of 0.47 random generation (NIST test), with 95% accuracy of the system as a whole.","random number generation, digital signatures, authenticity, neural networks, digital signature, python, NIST test battery, computer vision, programming, algorithms, cryptography, facial recognition, security","This paper proposes a system for authenticating users by their face and generating pseudo-random values based on facial images. The system uses a combination of mathematical procedures for facial recognition and a pseudo-random number generator. The generator of a random value was tested with the NIST Statistical Test Suite, and the subsystem of image recognition was tested under various conditions of taking the image. The test results show a satisfactory level of randomness and 95% accuracy of the system as a whole."
Amaas,Hybrid Architecture for Sentiment Classification,"Evolution of plethora of e-commerce sites resulted in fierce competition among their providers. In order to acquire new and retain existing customers, various producers and market managers effectively employ online feedback analytics tools. Most of the online feedback analysis tools are built using sentiment analysis models. Sentiment analysis evolved in the last one and half decades for review mining process. An important sub-task of sentiment analysis called sentiment classification is used mainly to decide whether a written review is expressing either positive or negative sentiment towards a target entity. In order to have better sentiment classification accuracy, we proposed a hybrid deep learning architecture, which is a hybrid of a two layered Restricted Boltzmann Machine and a Probabilistic Neural Network. The proposed approach yielded better accuracy for five different datasets compared to the state-of-the-art.","Restricted Boltzmann Machine, PNN, Dimensionality reduction, Deep learning, sentiment classification, Online learning, RBM, Probabilistic neural network, Sentiment analysis","The proposed architecture is a hybrid of RBM and PNN, which performs dimensionality reduction and sentiment classification in an online learning process. The time complexity of the proposed architecture is O(I*B*n) + O(m), where I is the number of iterations, B is the batch size, and m is the number of samples."
Aman Jindal,Digital Education Challenges and Opportunities,"ace traditional teaching because cannot ignore the its importance of traditional teaching for development of physical and mental health. Even after the challenges, online education is becoming popular day by day due to the opportunities it is providing to society and it's a need of the hour too. In the case of the pandemic situation, this is the only solution when we cannot compromise the health of students and teachers. But to improve its effectiveness we have overcome most of the challenges discussed in section III. For this we all students, teachers, educational Institutes, Universities, Industries, and Govt. policymakers have to join our hands and work together to overcome these challenges.","Opportunities, Recommendations, Challenges, Digital Education, Online education, Covid-19, pandemic","This paper discusses the challenges and opportunities of online education. It highlights the importance of traditional teaching and the need for online education in the pandemic situation. The paper also discusses the challenges faced by online education and the ways to overcome them. It suggests that students, teachers, educational Institutes, Universities, Industries, and Govt. policymakers should work together to improve the effectiveness of online education."
Aman Shah,Blood Bank Management and Inventory Control Database Management System,"This paper presents a detailed approach for an efficient blood bank database management system. The database is the single most useful setting for caching data, and it is also an ideal tool for contriving, managing, updating, and modifying data from different angles. The benefits of a well-structured blood bank database are limitless and yield the benefits of improving efficiency and saving time. Here, our motive is centred on this area. India faces a shortage when it comes to the amount of blood donated. The gap in demand and supply in widened due to mismanagement and inefficient databases. We have modelled a well-organized database to try and reduce this gap. Alongside, we have developed an application that reminds donors when they become eligible again, gives locations of nearby blood donation camps, makes requesting blood easier for blood recipients etc. as well as promoting a healthy community.  IOT is used for interlinking the application to the server as well as for inter-application communication. With the help of IOT this collection and exchange of data becomes more efficient.","Real-Time Access, Database, mobile application, Efficiently Interlinked, Database Management System, IOT, Management Information System, MySQL, Blood-bank, Blood Banks","This paper presents a detailed approach for an efficient blood bank database management system. The database is the single most useful setting for caching data, and it is also an ideal tool for contriving, managing, updating, and modifying data from different angles. The benefits of a well-structured blood bank database are limitless and yield the benefits of improving efficiency and saving time. Here, our motive is centred on this area. India faces a shortage when it comes to the amount of blood donated. The gap in demand and supply in widened due to mismanagement and inefficient databases. We have modelled a well-organized database to try and reduce this gap. Alongside, we have developed an application that reminds donors when they become eligible again, gives locations of nearby blood donation camps, makes requesting blood easier for blood recipients etc. as well as promoting a healthy community.  IOT is used for interlinking the application to the server as well as for inter-application communication. With the help of IOT this collection and exchange of data becomes more efficient."
Aman Soni,EXPERIMENTAL STUDY OF REGENERATIVE BRAKING SYSTEM (RBS),"In this era, the automobile sector is facing a major challenge to reduce consumption of fuel and greenhouse gases emission, this is often because limited fuel reserves and continuous degrade in air quality. An experimental setup is made for the current study to reduce the loss of energy by reusing it. In this present study, an alternator is connected to the driver shaft through chain and sprocket. When brakes are applied to slow the vehicle down or make it come to a halt, the alternator is activated with an electromagnetic clutch, and the energy lost during braking is utilized to generate electrical energy.","Generator, Automobile, Regenerative braking, Electromagnetic clutch, Energy recovery system","This paper presents an experimental study of regenerative braking system (RBS) to reduce energy loss during braking. An experimental setup is designed to reuse the energy lost during braking by activating an alternator with an electromagnetic clutch. The study shows that 16.32% of brake energy was recovered, and the current from the alternator increases with engine speed."
Amir H. Gandomi,Towards Precision Agriculture: IoT-Enabled Intelligent Irrigation Systems Using Deep Learning Neural Network,"This paper presents a deep learning NN-based IoT-enabled intelligent irrigation system for precision agriculture (DLiSA). An LSTM RNN model is employed to predict volumetric soil moisture content of the next day based on the historical temporal dynamics of climate and soil. The proposed model uses a closed-loop approach, which takes feedback from soil sensors and climate sensors that keeps its functionality higher in the unpredicted climate of any region.","Volumetric Soil Moisture Content, Deep Learning Neural Network, Deep Learning, Internet of Things, Precision Agriculture, Sensor, Long Short Term Memory, IoT-enabled Intelligent Irrigation Systems, LSTM RNN model","The proposed DLiSA system consists of a smart irrigation model and associated sensing IoT network model deployed on farmland. The system uses a closed-loop approach to predict volumetric soil moisture content of the next day based on historical temporal dynamics of climate and soil. The performance of DLiSA is compared with state-of-the-art algorithms subject to the prediction of soil moisture content, soil water deficit, and water volume irrigated over a month."
Amit Dinda,"Cardioprotection from ischemia and reperfusion injury by Withania somnifera: A hemodynamic, biochemical and histopathological assessment","The efficacy of Withania somnifera (Ws) to limit myocardial injury after ischemia and reperfusion was explored and compared to that of Vit E, a reference standard known to reduce mortality and infarct size due to myocardial infarction. Wistar rats (150–200 g) were divided into six groups and received orally saline (sham, control group), Ws-50/kg (Ws control and treated group) and Vit E-100 mg/kg (Vit E control and treated group) respectively for 1 month. On the 31st day, rats of the control, Vit E and Ws treated groups were anesthetized and subjected to 45 min occlusion of the LAD coronary artery followed by 60 min reperfusion. Hemodynamic parameters: systolic, diastolic and mean arterial pressure (SAP, DAP, MAP), heart rate (HR), left ventricular end diastolic pressure (LVEDP), left ventricular peak (+)LVdP/dt and (–)LVdP/dt were monitored. Hearts were removed and processed for histopathological and biochemical studies: Myocardial enzyme viz, creatin phosphokinase (CPK), and antioxidant parameters: malondialdehyde (MDA), glutathione (GSH), superoxide dismutase (SOD), catalase (CAT), glu-tathione peroxidase (GSHPx) were estimated. Postischemic reperfusion produced significant cardiac necrosis, depression of left ventricular functions (MAP, LVEDP, (+) and (–)LVdP/dt) and a significant fall in GSH (p < 0.01), SOD, CAT (p < 0.05), LDH and CPK (p < 0.01) as well as an increase in MDA level (p < 0.05) in the control group rats as compared to sham group. The changes in levels of protein and GPx was however, not significant. Ws and Vit E favorably modulated most of the hemo-dynamic, biochemical and histopathological parameters though no significant restoration in GSH, MAP (with Vit E) were ob-served. Ws on chronic administration markedly augmented antioxidants (GSH, GSHPx, SOD, CAT) while Vit E did not stimulate the synthesis of endogenous antioxidants compared to sham. Results indicate that Ws significantly reduced myocardial injury and emphasize the beneficial action of Ws as a cardioprotective agent.","Withania somnifera, adaptogens, Adaptogenic, myocardial infarction, Ischemia-reperfusion injury, Myocardial damage, ischemia, Vitamin E, antioxidants, reperfusion","This study investigated the cardioprotective effects of Withania somnifera (Ws) compared to Vitamin E in a rat model of ischemia and reperfusion induced myocardial injury. Ws significantly reduced myocardial injury, improved hemodynamic parameters, and enhanced antioxidant defense mechanisms. These findings suggest that Ws has potential as a cardioprotective agent."
Amit Gupta,Endogenous IRAK-M Attenuates Postinfarction Remodeling Through Effects on Macrophages and Fibroblasts,"Quantitative polymerase chain reaction analysis demonstrated significant IRAK-M mRNA upregulation in the infarcted myocardium. The time course of IRAK-M induction showed a biphasic response (Figure 1), characterized by marked early upregulation after 6 hours of reperfusion, followed by a second peak after 7 days of reperfusion (Figure 1A). IRAK-M Is Localized in Infarct Macrophages and Myofibroblasts Dual immunofluorescence was used to study IRAK-M localization in the infarcted myocardium. IRAK-M immunoreactivity in the infarcted heart was localized in Mac2+ infarct macrophages and in spindle-shaped, α–smooth muscle actin–positive myofibroblasts (Figure 1B and 1C). Moreover, infarct myofibroblasts and CD11b+ leukocytes isolated from the infarcted heart after 72 hours of reperfusion exhibited IRAK-M expression (Figure 1D–1G). To study cell-type specific changes in the timing of IRAK-M expression, we assessed IRAK-M mRNA levels in cardiac fibroblasts and CD11b+ leukocytes harvested from the infarcted heart. Isolated fibroblasts had a 3-fold increase in IRAK-M mRNA levels after 24 hours to 72 hours of reperfusion in comparison with control cardiac fibroblasts. When compared with control CD11b+ cells harvested from normal hearts, leukocytes isolated after 6 hours of reperfusion showed a trend toward increased IRAK-M mRNA expression (Figure I in the online-only Data Supplement). IRAK-M Loss Is Associated With Enhanced Adverse Remodeling Despite the Absence of Effects on the Size of the Infarct IRAK-M−null and WT animals had comparable mortality after myocardial infarction (P=NS). Triphenyltetrazolium chloride/Evans blue staining demonstrated that IRAK-M loss does not affect the size of the infarct after 1 hour of ischemia and 24 hours of reperfusion (Figure 1H–1J). Two independent techniques, echocardiographic imaging (Figure 2A–2G; Table I in the online-only Data Supplement) and quantitative morphometry (Figure 2H–2L), demonstrated that IRAK-M loss was associated with enhanced adverse remodeling after myocardial infarction. Systolic and diastolic chamber dimensions measured through echocardiography (left ventricular end-diastolic dimension, left ventricular end-systolic dimension, left ventricular end-systolic volume, and left ventricular end-diastolic volume; Figure 2A–2G) and morphometrically-derived left ventricular end-diastolic volume and left ventricular end-diastolic dimension (Figure 2H–2L) were significantly higher in IRAK-M−null mice after 7 and 28 days of reperfusion, indicating increased chamber dilation. Left ventricular mass was also significantly higher in infarcted IRAK-M−null hearts, suggesting accentuated hypertrophic remodeling. Increased adverse remodeling in the absence of IRAK-M was associated with reduced fractional shortening (FS), reflecting worse systolic dysfunction (Figure 2D). Because acute infarct size was comparable between WT and IRAK-M−null mice (Figure 1H–1J), accentuated adverse remodeling in IRAK-M−null hearts was not a result of more extensive cardiomyocyte injury. Moreover, scar size after 7 to 28 days of reperfusion was comparable between IRAK-M−/− and WT animals (Figure 2I). IRAK-M−/− Mice Have Enhanced Postinfarction Inflammation Exhibiting Increased Myocardial Cytokine mRN","metalloproteinases, cytokines, immune system, macrophages, cardiac remodeling","This study investigates the role of Interleukin-1 receptor-associated kinase (IRAK)-M in myocardial infarction.  Key findings include: 

* IRAK-M mRNA is significantly upregulated in the infarcted myocardium, with a biphasic response.
* IRAK-M is localized in macrophages and myofibroblasts within the infarcted heart.
* IRAK-M loss is associated with enhanced adverse remodeling after myocardial infarction, characterized by increased chamber dilation and hypertrophy, despite no effect on infarct size.
* IRAK-M−/− mice exhibit increased postinfarction inflammation with elevated myocardial cytokine mRNA levels."
Amit Kumar Banerjee,Classiﬁcation of Mammalian and Non-Mammalian Keratin Protein Sequences Using Machine Learning Techniques,"Keratin protein is ubiquitous in most vertebrates and invertebrates, and has several important cellular and extracellular functions that are related to survival and protection. Keratin function has played a significant role in the natural selection of an organism. Hence, it acts as a marker of evolution. Much information about an organism and its evolution can therefore be obtained by investigating this important protein. In the present study, Keratin sequences were extracted from public data repositories and various important sequential, structural and physicochemical properties were computed and used for preparing the dataset. The dataset containing two classes, namely mammals (Class-1) and non-mammals (Class-0), was prepared, and rigorous classiﬁcation analysis was performed. To reduce the complexity of the dataset containing 56 parameters and to achieve improved accuracy, feature selection was done using the t-statistic. The 20 best features (parameters) were selected for further classiﬁcation analysis using computational algorithms which included SVM, KNN, Neural Network, Logistic regression, Meta-modeling, Tree Induction, Rule Induction, Discriminant analysis and Bayesian Modeling. Statistical methods were used to evaluate the output. Logistic regression was found to be the most effective algorithm for classiﬁcation, with greater than 96% accuracy using a 10-fold cross validation analysis. KNN, SVM and Rule Induction algorithms also were found to be efﬁcacious for classiﬁcation.","Data mining, Artiﬁcial Neural Networks (ANN), Meta-modeling, Machine learning techniques, Classiﬁcation, Artiﬁcial Intelligence (AI), Keratin, Logistic regression, Discriminant analysis, Mammalian and non-mammalian origin, Support Vector Machines (SVM), Tree induction, Biological classiﬁcation, Keratin protein sequences, Machine learning, Rule induction",This study aims to classify mammals and non-mammals based on various properties of the Keratin protein molecule. The dataset containing 56 parameters was prepared and feature selection was done using the t-statistic. The 20 best features were selected for further classiﬁcation analysis using computational algorithms. Logistic regression was found to be the most effective algorithm for classiﬁcation with greater than 96% accuracy.
Amit Kumar Sharma,Cloud Computing: Different Approach & Security Challenge,"Cloud computing has generated a lot of interest and competition in the industry and it is recognize as one of the top 10 technologies of 2010. It is an internet based service delivery model which provides internet based services, computing and storage for users in all market including financial, health care & government. In this paper we did systematic review on different types of clouds and the security challenges that should be solved. Cloud security is becoming a key differentiator and competitive edge between cloud providers. This paper discusses the security issues arising in different type of clouds.","Security, Security challenges, Cloud computing, Cloud","This paper discusses the security issues arising in different types of clouds, including personal clouds, general clouds, domain-specific clouds, and hybrid clouds. It highlights the security challenges that need to be solved in each type of cloud, such as compliance and auditing, intrusion detection, access control, and anti-virus/anti-malware protection."
Amit Mehndiratta,"Magnetic Resonance Materials in Physics, Biology and Medicine",Objective  To implement an advanced spatial penalty-based reconstruction to constrain the intravoxel incoherent motion (IVIM)–diffusion kurtosis imaging (DKI) model and investigate whether it provides a suitable alternative at 1.5 T to the traditional IVIM–DKI model at 3 T for clinical characterization of prostate cancer (PCa) and benign prostatic hyperplasia (BPH).,"TV penalty function, Prostate cancer, Benign prostatic hyperplasia, Total variation penalty function, MRI, Diffusion kurtosis imaging, Intravoxel incoherent motion, IVIM–DKI model","This study compares the use of IVIM–DKI at 1.5 T and 3 T MRI for differentiating between prostate cancer and benign prostatic hyperplasia. The results show that IVIM–DKI modeled with a novel model at 1.5 T produced parameter maps with lower coefficient of variation than the traditional model at 3 T. The novel model estimated higher D with lower D*, f, and k values at both field strengths compared to the traditional model. The study concludes that the proposed novel model can be utilized for improved detection of prostate lesions."
Amit Mohan Prasad,"Seroprevalence of SARS-CoV-2 Antibodies in Uttar Pradesh, India: A Cross-Sectional Study","Population-based serological antibody test for SARS-CoV-2 infection helps in estimating the exposure in the community. We present the findings of the first district representative seroepidemiological survey conducted between 4 and 10 September 2020 among the population aged 5 years and above in the state of Uttar Pradesh, India. Multi-stage cluster sampling was used to select participants from 495 primary sampling units (villages in rural areas and wards in urban areas) across 11 selected districts to provide district-level seroprevalence disaggregated by place of residence (rural/urban), age (5–17 years/aged 18 +) and gender. A venous blood sample was collected to determine seroprevalence. Of 16,012 individuals enrolled in the study, 22.2% [95% CI 21.5–22.9] equating to about 10.4 million population in 11 districts were already exposed to SARS-CoV-2 infection by mid-September 2020. The overall seroprevalence was significantly higher in urban areas (30.6%, 95% CI 29.4–31.7) compared to rural areas (14.7%, 95% CI 13.9–15.6), and among aged 18 + years (23.2%, 95% CI 22.4–24.0) compared to aged 5–17 years (18.4%, 95% CI 17.0–19.9). No differences were observed by gender. Individuals exposed to a COVID confirmed case or residing in a COVID containment zone had higher seroprevalence (34.5% and 26.0%, respectively). There was also a wide variation (10.7–33.0%) in seropositivity across 11 districts indicating that population exposed to COVID was not uniform at the time of the study. Since about 78% of the population (36.5 million) in these districts were still susceptible to infection, public health measures remain essential to reduce further spread.","COVID-19, Seroprevalence, India, SARS-CoV-2, Heterogeneity, Uttar Pradesh","This study presents the first district-level seroprevalence survey of SARS-CoV-2 infection in Uttar Pradesh, India. Conducted in September 2020, the survey found that 22.2% of the population had been exposed to the virus by that time. Seroprevalence was significantly higher in urban areas and among individuals aged 18 and older. The findings highlight the importance of continued public health measures to reduce further spread of the virus."
Amit Saxena,"Adsorption and Photodegradation of Dyes Using Graphene Composites: A Review ||| A Review of Clustering Techniques and Developments ||| BELIMUMAB IN PATIENTS OF BLACK AFRICAN ANCESTRY ||| Cardioprotection from ischemia and reperfusion injury by Withania somnifera: A hemodynamic, biochemical and histopathological assessment ||| Cutting Edge: CD8 T Cell-Mediated Demyelination ||| Endogenous IRAK-M Attenuates Postinfarction Remodeling Through Effects on Macrophages and Fibroblasts ||| First-­in-­Human Study of Bamlanivimab in a Randomized Trial of Hospitalized Patients With COVID-­19 ||| Myelin-speciﬁc T cells also recognize neuronal autoantigen in a transgenic mouse model of multiple sclerosis ||| Opposing Actions of Fibroblast and Cardiomyocyte Smad3 Signaling in the Infarcted Myocardium ||| Oxygen Barrier Properties of Xylan-Nanocrystalline Cellulose Composite Films ||| ROS deficiency enhanced mannan-induced PsA ||| TSP-1 in Diabetic Cardiomyopathy","Water contamination has reached an alarming state due to industrialization and urbanization and has become a worldwide issue. Dyes contaminate water and are addressed extensively by researchers. Various technologies and materials have been developed for the treatment of contaminated water. Among them, adsorption has attracted great attention due to its ease and cost-effective nature. In recent years, graphene-based composites have shown great potential for the removal of contaminants from water. The literature reveals the usefulness of composites of graphene with metal oxides, carbon derivatives, metal hybrids and polymers for the removal of organic dyes from contaminated water. In this review, efforts have been made to compile the studies on the removal of cationic and anionic dyes from water using graphene-based composites. ||| This paper presents a comprehensive study on clustering: exiting methods and developments made at various times. Clustering is defined as an unsupervised learning where the objects are grouped on the basis of some similarity inherent among them. There are different methods for clustering the objects such as hierarchical, partitional, grid, density based and model based. The approaches used in these methods are discussed with their respective states of art and applicability. The measures of similarity as well as the evaluation criteria, which are the central components of clustering are also presented in the paper. The applications of clustering in some fields like image segmentation, object and character recognition and data mining are highlighted. ||| Study design. SELENA–SLEDAI = Safety of Estrogens in Lupus Erythematosus National Assessment–Systemic Lupus Erythemato-sus Disease Activity Index; IV = intravenous.

Randomization and treatment. Using an interactive voice/web response system, patients receiving standard therapy were randomized 2:1 to receive either belimumab 10 mg/kg IV or placebo, which was administered on days 0, 14, and 28 and every 28 days thereafter up to week 48, with a final evaluation at week 52. Randomization was stratified by screening SELENA–SLEDAI score (≤9 versus ≥10), region (US/Canada versus rest of world), and complement level (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]). Detailed randomization data are provided in Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Patients who successfully completed the initial 52-week double-blind phase could enter an optional 6-month open-label extension phase, during which they received belimumab 10 mg/kg IV every 28 days plus standard therapy, irrespective of their previous study assignment. The first dose was given at the week 52 (day 364) visit of the double-blind period (day 1 of the open-label extension phase). Patients who completed the 52-week double-blind phase, but did not enter the 6-month open-label extension phase, were required to return for an additional follow-up visit 8 weeks after their last dose. Patients who withdrew early were required to return for an exit visit 4 weeks after their last dose and a follow-up visit 8 weeks after their last dose.

The original protocol plan was to randomize 816 patients, providing ≥90% power to detect ≥12% absolute improvement in the SRI response rate in the belimumab group compared with the placebo group at a 5% significance level. Due to enrollment challenges, a revised sample size was calculated to include 501 patients (≥334 patients in the belimumab group and ≥167 patients in the placebo group). This sample size provided ≥90% power to detect a minimum 15.55% absolute improvement in SRI–SLEDAI-2K response rate in the belimumab group relative to the placebo group at a 5% significance level (based on the pooled data from efficacy studies BEL112341 and BEL113750) (15,21). These calculations assumed a placebo response rate of 43.95% at week 52.

Study end points and assessments. The primary efficacy end point was the SRI–SLEDAI-2K response rate (defined in the Supplementary Material) at week 52 of the double-blind phase. Unlike in the phase II and phase III studies, the SRI–SLEDAI-2K was selected because of the simplification it offers in proteinuria assessment as compared with the SELENA–SLEDAI proteinuria component; both are clinically meaningful (22). The primary efficacy end point for the open-label extension phase was SRI–SLEDAI-2K response rate at open-label extension week 24. If the open-label extension week 24 data were missing, data from the open-label extension week 28/exit visit were used. This time point is referred to as “open-label extension week 24” throughout the text. Data related to the primary efficacy end point, e.g., the response rate over time, percentage of patients with a durable SRI–SLEDAI-2K response from week 44 through week 52, time to first SRI–SLEDAI-2K response that was maintained through week 52, and duration of longest SRI–SLEDAI-2K response among patients with ≥1 SRI–SLEDAI-2K responses were summarized.

The key secondary end points were SRI–SELENA–SLEDAI at week 52 (open-label extension week 24), time to first severe SLE flare (measured by the SELENA–SLEDAI flare index [SFI]), and proportion of patients whose average prednisone dose had been reduced by ≥25% from baseline to ≤7.5 mg/day during week 40 through week 52 (open-label extension week 28/exit visit), in patients receiving >7.5 mg/day at baseline. Key renal end points included time to first renal flare over 52 weeks and over 28 weeks in the open-label extension, SELENA–SLEDAI–SLEDAI-2K renal domain improvement at week 52, SELENA–SLEDAI–SLEDAI-2K renal domain worsening at week 52, percentage reduction in proteinuria by visit and at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours, and proteinuria shift at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours. Renal flare is defined in the Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Biomarkers measured included percentage changes in serum IgG level, anti-dsDNA antibody level (in those who were anti-dsDNA positive [≥30 IU/ml] at baseline), and complement (C3 and C4) levels from baseline. Safety was evaluated by monitoring adverse events (AEs), serious AEs (SAEs), AEs of special interest, vital signs, clinical laboratory test results, and immunogenicity up to 8 weeks posttreatment and throughout the open-label extension phase.

Data analyses. For the double-blind phase, safety analyses were performed on the safety population, defined as all patients who were randomized and treated with at least 1 dose of investigational product. Data on the safety population were summarized according to the treatment the patient was randomized to receive rather than by the treatment that was received, but both were the same for this study. Efficacy analyses were performed on the modified intent-to-treat (ITT) population, defined as the safety population minus those patients who had any assessment at any of 3 study sites that were excluded from the efficacy analyses before the database lock because of potential Good Clinical Practice noncompliance.

For analysis of the primary and 3 key secondary efficacy end points, a step-down sequential testing procedure was used as described in the Supplementary Material. The following subgroup analyses were performed for the primary analysis (SRI–SLEDAI-2K response at week 52): region (US/Canada versus rest of world), baseline SELENA–SLEDAI–SLEDAI-2K score (≤9 versus ≥10), baseline anti-dsDNA antibody level (≥30 IU/ml versus <30 IU/ml), baseline complement levels (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]), and baseline complement and anti-dsDNA antibody levels (≥1 test finding showing low C3/C4 and anti-dsDNA ≥30 IU/ml versus C3/C4 other and anti-dsDNA ≥30 IU/ml). The odds of an SRI–SLEDAI-2K response with belimumab treatment versus placebo were estimated using logistic regression analysis.

For the open-label extension phase, all patients received belimumab, no formal statistical hypothesis t ||| The efficacy of Withania somnifera (Ws) to limit myocardial injury after ischemia and reperfusion was explored and compared to that of Vit E, a reference standard known to reduce mortality and infarct size due to myocardial infarction. Wistar rats (150–200 g) were divided into six groups and received orally saline (sham, control group), Ws-50/kg (Ws control and treated group) and Vit E-100 mg/kg (Vit E control and treated group) respectively for 1 month. On the 31st day, rats of the control, Vit E and Ws treated groups were anesthetized and subjected to 45 min occlusion of the LAD coronary artery followed by 60 min reperfusion. Hemodynamic parameters: systolic, diastolic and mean arterial pressure (SAP, DAP, MAP), heart rate (HR), left ventricular end diastolic pressure (LVEDP), left ventricular peak (+)LVdP/dt and (–)LVdP/dt were monitored. Hearts were removed and processed for histopathological and biochemical studies: Myocardial enzyme viz, creatin phosphokinase (CPK), and antioxidant parameters: malondialdehyde (MDA), glutathione (GSH), superoxide dismutase (SOD), catalase (CAT), glu-tathione peroxidase (GSHPx) were estimated. Postischemic reperfusion produced significant cardiac necrosis, depression of left ventricular functions (MAP, LVEDP, (+) and (–)LVdP/dt) and a significant fall in GSH (p < 0.01), SOD, CAT (p < 0.05), LDH and CPK (p < 0.01) as well as an increase in MDA level (p < 0.05) in the control group rats as compared to sham group. The changes in levels of protein and GPx was however, not significant. Ws and Vit E favorably modulated most of the hemo-dynamic, biochemical and histopathological parameters though no significant restoration in GSH, MAP (with Vit E) were ob-served. Ws on chronic administration markedly augmented antioxidants (GSH, GSHPx, SOD, CAT) while Vit E did not stimulate the synthesis of endogenous antioxidants compared to sham. Results indicate that Ws significantly reduced myocardial injury and emphasize the beneficial action of Ws as a cardioprotective agent. ||| We generated mice (DKI) in which the HA coding sequence was introduced in the ubiquitously active Rosa26 locus but where HA transcription was prevented by an upstream LoxP-flanked Stop cassette. The DKI mice were then crossed with the MOGi-Cre mice, which express Cre specifically in oligodendrocytes. The resulting DKI mice excise the Stop cassette due to MOG-controlled Cre expression, leading to restricted HA expression to oligodendrocytes.  We then decided to test whether effector CD8 T cells can mediate oligodendrocyte cell death and demyelination in vivo. Effector T cells were first generated by in vitro activation of Kd:HA512–520 pentamer-specific CD8 T cells obtained from CL4-TCR mice using HA peptide, IL-2, and IL-12. The resulting Tc1 cells produce large amounts of granzyme B (GrB) and IFN-γ and exhibit potent cytotoxicity to HA-loaded target cells in vivo. Next, we transferred these HA-specific Tc1 cells into DKI and control mice. Following i.v. injection of 3 × 107 HA-specific Tc1 cells, but not naive HA-specific CD8 T cells, ~40% of the DKI mice developed an overt monophasic disease peaking at day 8–10 and waning by 4 wk posttransfer. The clinical manifestations included weight loss and, in the more severe cases, tremors, reduced mobility, and difficulty to right when overturned without overt paralysis. Upon histological analysis, all DKI mice injected with Tc1 cells demonstrated clear CNS pathology from day 5 onwards. Inflammatory lesions were never found in control littermates injected in parallel with HA-specific Tc1 cells. ||| Quantitative polymerase chain reaction analysis demonstrated significant IRAK-M mRNA upregulation in the infarcted myocardium. The time course of IRAK-M induction showed a biphasic response (Figure 1), characterized by marked early upregulation after 6 hours of reperfusion, followed by a second peak after 7 days of reperfusion (Figure 1A). IRAK-M Is Localized in Infarct Macrophages and Myofibroblasts Dual immunofluorescence was used to study IRAK-M localization in the infarcted myocardium. IRAK-M immunoreactivity in the infarcted heart was localized in Mac2+ infarct macrophages and in spindle-shaped, α–smooth muscle actin–positive myofibroblasts (Figure 1B and 1C). Moreover, infarct myofibroblasts and CD11b+ leukocytes isolated from the infarcted heart after 72 hours of reperfusion exhibited IRAK-M expression (Figure 1D–1G). To study cell-type specific changes in the timing of IRAK-M expression, we assessed IRAK-M mRNA levels in cardiac fibroblasts and CD11b+ leukocytes harvested from the infarcted heart. Isolated fibroblasts had a 3-fold increase in IRAK-M mRNA levels after 24 hours to 72 hours of reperfusion in comparison with control cardiac fibroblasts. When compared with control CD11b+ cells harvested from normal hearts, leukocytes isolated after 6 hours of reperfusion showed a trend toward increased IRAK-M mRNA expression (Figure I in the online-only Data Supplement). IRAK-M Loss Is Associated With Enhanced Adverse Remodeling Despite the Absence of Effects on the Size of the Infarct IRAK-M−null and WT animals had comparable mortality after myocardial infarction (P=NS). Triphenyltetrazolium chloride/Evans blue staining demonstrated that IRAK-M loss does not affect the size of the infarct after 1 hour of ischemia and 24 hours of reperfusion (Figure 1H–1J). Two independent techniques, echocardiographic imaging (Figure 2A–2G; Table I in the online-only Data Supplement) and quantitative morphometry (Figure 2H–2L), demonstrated that IRAK-M loss was associated with enhanced adverse remodeling after myocardial infarction. Systolic and diastolic chamber dimensions measured through echocardiography (left ventricular end-diastolic dimension, left ventricular end-systolic dimension, left ventricular end-systolic volume, and left ventricular end-diastolic volume; Figure 2A–2G) and morphometrically-derived left ventricular end-diastolic volume and left ventricular end-diastolic dimension (Figure 2H–2L) were significantly higher in IRAK-M−null mice after 7 and 28 days of reperfusion, indicating increased chamber dilation. Left ventricular mass was also significantly higher in infarcted IRAK-M−null hearts, suggesting accentuated hypertrophic remodeling. Increased adverse remodeling in the absence of IRAK-M was associated with reduced fractional shortening (FS), reflecting worse systolic dysfunction (Figure 2D). Because acute infarct size was comparable between WT and IRAK-M−null mice (Figure 1H–1J), accentuated adverse remodeling in IRAK-M−null hearts was not a result of more extensive cardiomyocyte injury. Moreover, scar size after 7 to 28 days of reperfusion was comparable between IRAK-M−/− and WT animals (Figure 2I). IRAK-M−/− Mice Have Enhanced Postinfarction Inflammation Exhibiting Increased Myocardial Cytokine mRN ||| This first-in-human study in hospitalized patients with COVID-19 was supported by studies assessing in vitro viral neutralization combined with a single-dose non-human primate PK study. The nonclinical safety package to support subsequent studies included tissue cross-reactivity studies on human, rat, and monkey tissues and an in vivo toxicology study.  A complete physical examination was conducted at the screening visit, and one of three bamlanivimab doses or placebo was administered i.v. at the baseline visit (D1) with infusion rates as follows: bamlanivimab 700 mg (50 mL) administered 100 mL/hr for 30 minutes; 2,800 mg (75 mL) administered 100 mL/hr for 45 minutes; and 7,000 mg administered 100 mL/hr for 60 minutes. Placebo infusion was 0.9% normal saline, administered at the same volume and rate as the corresponding bamlanivimab dose cohort. Safety and tolerability were reviewed for sentinel participants up to 24 hours after dosing, at which point the investigators and sponsor team determined whether safety and tolerability were acceptable to continue with dosing subsequent participants. The decision to dose the next cohort was made when all participants from the previous cohort had been dosed and safety data assessed for at least 4 days after the i.v. infusion by the investigators and sponsor team in consultation with an independent safety assessment committee. Blood samples were obtained for assessment of exploratory biomarkers, serology, clinical laboratory assessments, and PD on days 1, 3, 7, 11, 15, 22, and 29, and every 7 days until discharge or day 60, if still an inpatient. Samples for the virology assay were collected using nasopharyngeal (preferred) or mid-turbinate methods. Blood samples obtained for PK analyses were assessed on days 1 (pre-infusion and just before end of infusion), 4, 15, and 29, and follow-up visits up to day 60. Symptom-related physical examinations and assessments of clinical symptoms were performed on days 1, 2, 3, 4, 7, 11, 15, 22, and 29, and the day of discharge from the hospital, with additional follow-up examinations every 7 days thereafter until day 60 if the patient was not discharged from the hospital by day 29. Participants’ clinical status and concurrent procedures of special interest were recorded, including limitation on activities due to COVID-19 and any requirements for the following procedures of special interest, such as ongoing hospital medical care, supplemental oxygen, noninvasive ventilation or a high flow oxygen device, mechanical ventilation, extracorporeal membrane oxygenation, additional organ support, or consciousness status using alert, consciousness, verbal, pain, unresponsive scale. Hospitalization events were recorded, including dates of hospital admission and discharge, admission to the intensive care unit (ICU), discharge from the ICU, and discharge location including to an extended care facility or home. Outcomes The primary objective was to assess safety and tolerability, including adverse events (AEs), serious adverse events (SAEs), and discontinuations due to AEs. Other objectives included PKs (e.g., mean concentration at day 29); PD viral load, area under the response time curve (AUC, from day 1 to day 29), and change from baseline time course; total symptom score; time to symptom resolution; duration of hospitalization; National Institute of Allergy and Infectious Diseases (NIAID), World Health Organization (WHO) scales, and National Early Warning Score (NEWS2); and analysis of viral resistance. Any hypothesis tests were conducted for treatment comparisons without adjustment for multiplicity except for the evaluation of treatment effect on endogenous antibody titers. Success for the trial was claimed using a Bayesian criterion if any of the 3 bamlanivimab doses had at least 60% probability to reduce at least 30% mean AUC (28-day viral load) over placebo. ||| We describe here the paradoxical development of spontaneous experimental autoimmune encephalomyelitis (EAE) in transgenic mice expressing a myelin oligodendrocyte glycoprotein (MOG)-speciﬁc T cell antigen receptor (TCR) in the absence of MOG. We report that in Mog-deﬁcient mice (Mog–/–), the autoimmune response by transgenic T cells is redirected to a neuronal cytoskeletal self antigen, neuroﬁlament-M (NF-M). Although components of radically different protein classes, the cross-reacting major histocompatibility complex I-Ab–restricted epitope sequences of MOG35–55 and NF-M18–30 share essential TCR contact positions. This pattern of cross-reaction is not speciﬁc to the transgenic TCR but is also commonly seen in MOG35–55–I-Ab–reactive T cells. We propose that in the C57BL/6 mouse, MOG and NF-M response components add up to overcome the general resistance of this strain to experimental induction of autoimmunity. Similar cumulative responses against more than one autoantigen may have a role in spontaneously developing human autoimmune diseases. ||| Transforming growth factor (TGF)–βs are highly pleiotropic mediators with critical roles in regulating cellular phenotype and function in embryonic development, tissue homeostasis, and disease. Normal tissues contain stores of latent TGF-β bound to the extracellular matrix through its association with a large binding protein, the latent TGF-β binding protein. Tissue injury is associated with marked induction of TGF-β isoforms and activation of TGF-β signaling cascades. Parenchymal cells, extravasated leukocytes, and platelets synthesize and release large amounts of TGF-β in the injury site. Reactive oxygen species, proteases, matricellular proteins, and integrins cooperate to trigger the release of bioactive TGF-β from the latent stores. Subsequent binding of the active TGF-β dimer to the type II TGF-β receptor, followed by transphosphorylation of the type I receptor, triggers the TGF-β signaling response. The cellular effects of TGF-β are mediated through a canonical pathway involving a series of intracellular effectors, the Smads, or through activation of noncanonical signaling cascades. Activation of TGF-β signaling induces phosphorylation of the receptor-activated Smads, Smad2 and Smad3, which can form heteromeric complexes with the common Smad, Smad4. These complexes are transported to the nucleus, where they regulate gene transcription. TGF–β receptors and Smads are ubiquitously expressed by all cell types. Thus, all cells are responsive to the actions of TGF-β. Cardiac injury is associated with the marked induction of TGF-β and activation of TGF-β cascades. Our laboratory and other investigators have documented activation of Smad2 and Smad3 signaling in the infarcted myocardium, localized in both cardiomyocytes and interstitial cells. In isolated cardiac fibroblasts, Smad3 signaling accentuates myofibroblast transdifferentiation and stimulates a matrix-preserving program. In a model of reperfused infarction, global loss of Smad3 attenuated remodeling after infarction. However, considering the ubiquitous expression of Smad3 in all cell types, the cell biological basis for the actions of Smad3 in the infarcted heart remains unknown. Our study dissects the cell-specific actions of Smad3 signaling in the infarcted myocardium by developing and studying mice with cell-specific loss of Smad3 in activated fibroblasts and cardiomyocytes. It is surprising that fibroblast-specific loss of Smad3 worsened remodeling after infarction, resulting in accentuated chamber dilation. The deleterious consequences of fibroblast-specific Smad3 loss reflected unrestrained fibroblast proliferation, defective scar remodeling, and perturbed organization of myofibroblast arrays in the border zone. Smad3 signaling regulated fibroblast function, activating integrin-mediated nicotinamide adenine dinucleotide phosphate (NADPH) oxidase (NOX)–2 expression. In contrast, cardiomyocyte-specific loss of Smad3 protected the infarcted heart from dysfunction after infarction. The protective effects of cardiomyocyte-specific Smad3 loss were associated with attenuated cardiomyocyte apoptosis in remodeling myocardium and accompanied by decreased NOX2 levels, reduced nitrosative stress, and decreased matrix metalloproteinase (MMP)–2 expression. ||| This study examines the oxygen barrier properties of xylan-nanocrystalline cellulose composite films. By AFM analysis, the sulfonated nanocrystalline cellulosic were observed to have rod like structure with an average length of 150-200 nm and a width of less than 20 nm (Fig. 1). AFM images, acquired using tapping mode, of the xylan/sorbitol films reinforced with nanocrystalline cellulose show well dispersed sulfonated nanocrystalline cellulose on xylan surface in comparison to more open structure of xylan/sorbitol control films (Fig. 2).  The specific oxygen transmission rate of the xylan nanocomposite films are shown in Table 1. The transmission rate decreased drastically upon reinforcement with nanocrystalline cellulose. The measured oxygen permeability is lower or comparable to the often used barrier plastic ethylene vinyl alcohol (EVOH) [33] and the films made from microfibrillar cellulose [34], see Table 1.  Oxygen permeability values were calculated by dividing the oxygen transmission rates by the differential partial pressure of oxygen across the film (1 atm or 101.3 kPa) and multiplying by the film thickness in microns [5]. Table 2 summarized the oxygen permeability of some of the literature work and current work. The oxygen transmission rates as summarized in Table 1 at 25% and 50% dosage of nanocrystalline cellulose decreased drastically with respect to control xylan films and are the two lowest values that we obtained in this study.  It will be an interesting subject to explore the porosity, bulk density and tortuosity factor at these two levels and the control xylan films. As summarized in Table 3, the density and tortuosity factor of the composite film increased while the pore diameter and porosity decreased as the loading of sulfonated nanocrystalline cellulose increased in the xylan-based films.  SEM images of the control xylan film surface showed agglomerated structures on the surface in comparison to a more uniform surface for the nanocrystalline cellulose-xylan films (Fig. 3 (a) and 3 (b)).  Oxygen transmission rate at 5% and 10% charge of nanocrystalline cellulose doesn’t differ much but a significant drop of transmission rate as compared to control. We studied xylan-10% nanocrystalline cellulose film under SEM (Fig. 3) and AFM (Fig. 2b) and found that control xylan film surface in Fig. 3 (a) shows agglomeration in comparison to well dispersed sulfonated nanocrystalline cellulose on xylan surface in Fig. 3 (b). The uneven structure and agglomeration of the xylan can be the cause of higher oxygen transmission rate of control xylan film in comparison to xylan reinforced with 10% sulfonated nanocrystalline cellulose.  SEM cross-section images of freeze fracture of control xylan films showed a rough texture with small cracks in the film as summarized in Fig. 4(a) and 4(b). The same analysis for the xylan film reinforced with nanocrystalline cellulose exhibited smooth fractured surface and less porous structure (see Fig. 4(c) and Fig. 4(d)). ||| In and joint inflammation using B10Q.Ncf1m1j/m1j mice that have a mutation in the Ncf1 gene (m1j) (the Ncf1 protein also denoted p47phox), and hence reduced ROS production (oxidative burst) (18). As shown in Fig. 1D, Ncf1 mutated mice developed severe joint inflammation within 2 d after mannan injection, which reached the mean maximal disease severity (30 ± 6 points) within 4 d. The frequency of skin lesions was 100%, with more severe cases in B10Q.Ncf1m1j/m1j mice (Fig. 1E), whereas B10.Q mice had a significantly milder disease course. Multiple Exposures to Mannan Induced a Relapsing Disease. Next, we examined the effect of multiple mannan injections in B10Q and B10Q.Ncf1m1j/m1j mice. We boosted mice twice with mannan on days 7 and 14 after disease initiation. Repetitive injections of mannan reproduced the arthritis phenotype, which reached the maximum severity level on days 9 and 17, similar to the first injection (Fig. 1F). A more severe disease course was observed in B10Q.Ncf1m1j/m1j mice than in B10Q mice (P < 0.05 and P < 0.01, respectively). Interestingly, Ps skin scaling returned only after the second mannan injection (on day 16), but the skin peeled off even more quickly than the first time (Fig. 1G). Moreover, from day 11 onward, B10Q.Ncf1m1j/m1j mice started to develop pruritus on the body, predominantly on the back and above the eye (Fig. S1E). Pruritus was only evident in B10Q.Ncf1m1j/m1j mice, but flaky skin on the tail and alopecia all over the leg was observed in both of the mouse strains. We also observed genetic heterogeneity in disease susceptibility (Fig. Fig. 1. ROS deficiency enhanced mannan-induced PsA. The arthritic joint phenotype and Ps-like skin lesions in the front (A) and hind (B) paws of B10Q.Ncf1m1j/m1j mice are shown. (C) Ps-like skin scaling in diseased B10Q.Ncf1m1j/m1j mouse ear compared with naive mouse ear. Mean arthritis (D) and Ps lesion (E) severity in B10Q (n = 5) and B10Q.Ncf1m1j/m1j (n = 5) mice after a single i.p. mannan injection. Mean arthritis (F) and Ps lesion (G) severity in B10Q (n = 5) and B10Q.Ncf1m1j/m1j (n = 5) mice after repetitive mannan injections (days 7 and 14). (H) Mannan-induced mean maximum arthritis scores ± SEM in different mouse strains: B10Q (n = 8), B10Q.Ncf1m1j/m1j (n = 9), B10RIII (n = 10), B10RIII.Ncf1m1j/m1j (n = 9), B10P (n = 3), B10P.Ncf1m1j/m1j (n = 9), BALB/cByJ/Q (n = 10), BALB/cByJ/Q.Ncf1m1j/m1j (n = 8), BALB/cByJ (n = 5), BALB/cByJ.Ncf1m1j/m1j (n = 7), C57BL/6NJ (n = 8), and C57BL/6NJ.Ncf1m1j/m1j (n = 7). Significance was calculated by comparing the maximal disease severity of B10Q and B10Q.Ncf1m1j/m1j mice with all of the other strains in their respective groups. *P < 0.05; **P < 0.01; ***P < 0.001. E3670 | www.pnas.org/cgi/doi/10.1073/pnas.1405798111 Khmaladze et al. Downloaded from https://www.pnas.org by 122.184.65.228 on February 22, 2023 from IP address 122.184.65.228. ||| Diabetes mellitus is associated with cardiac fibrosis. Matricellular proteins are induced in fibrotic conditions and modulate fibrogenic and angiogenic responses by regulating growth factor signaling. Our aim was to test the hypothesis that the prototypical matricellular protein thrombospondin (TSP)-1, a potent angiostatic molecule and crucial activator of transforming growth factor-β, may play a key role in remodeling of the diabetic heart. Obese diabetic db/db mice exhibited marked myocardial TSP-1 upregulation in the interstitial and perivascular space. To study the role of TSP-1 in remodeling of the diabetic heart, we generated and characterized db/db TSP-1–/– (dbTSP) mice. TSP-1 disruption did not significantly affect weight gain and metabolic function in db/db animals. When compared with db/db animals, dbTSP mice had increased left ventricular dilation associated with mild nonprogressive systolic dysfunction. Chamber dilation in dbTSP mice was associated with decreased myocardial collagen content and accentuated matrix metalloproteinase-2 and -9 activity. TSP-1 disruption did not affect inflammatory gene expression and activation of transforming growth factor-β/small mothers against decapendaplegic signaling in the db/db myocardium. In cardiac fibroblasts populating collagen pads, TSP-1 incorporation into the matrix did not activate transforming growth factor-β responses, but inhibited leptin-induced matrix metalloproteinase-2 activation. TSP-1 disruption abrogated age-associated capillary rarefaction in db/db mice, attenuating myocardial upregulation of angiopoietin-2, a mediator that induces vascular regression. In vitro, TSP-1 stimulation increased macrophage, but not endothelial cell, angiopoietin-2 synthesis. Conclusions: TSP-1 upregulation in the diabetic heart prevents chamber dilation by exerting matrix-preserving actions on cardiac fibroblasts and mediates capillary rarefaction through effects that may involve angiopoietin-2 upregulation.","Unsupervised learning, Water treatment, Clustering, antioxidants, cardiac remodeling, Ncf1, Contaminated water, Dye removal, Adsorption, reperfusion, Data mining, Withania somnifera, adaptogens, Graphene composites, Hierarchical Clustering, Vitamin E, composite films, remodeling, nanocrystalline cellulose, Dyes, Graphene, SMAD, ROCK, Adaptogenic, matrix metalloproteinases, Similarity measures, animal model, Clustering Approaches, cardiomyocyte, xylan, thrombospondins, fibrosis, Pattern recognition, diabetic cardiomyopathies, BIRCH, ventricular remodeling, autoimmune disease, barrier properties, metalloproteinases, Taxonomy, fibroblast, Photodegradation, cytokines, oxygen permeability, myocardial infarction, Ischemia-reperfusion injury, Myocardial damage, ischemia, immune system, Degradation, CURE, macrophages, heart failure, CHAMELEON, Composites","Graphene composites are emerging as promising materials for the removal of dyes from wastewater due to their high surface area, excellent electrical conductivity, and tunable properties. This review summarizes the recent progress in using graphene composites for both adsorption and photodegradation of dyes. It discusses the mechanisms involved, key factors affecting dye removal efficiency, and the advantages of graphene-based materials over conventional methods. The review also highlights the potential of graphene composites for sustainable and efficient dye remediation in the future. ||| This paper reviews clustering techniques and developments, discussing methods such as hierarchical, partitional, grid, density-based, and model-based clustering, as well as measures of similarity and evaluation criteria. The applications of clustering in fields like image segmentation, object recognition, and data mining are highlighted. ||| This study investigated the efficacy and safety of belimumab in patients of Black African ancestry with systemic lupus erythematosus (SLE).  Patients were randomized to receive belimumab or placebo for 52 weeks, followed by an optional 6-month open-label extension phase. The primary efficacy endpoint was the SRI–SLEDAI-2K response rate at week 52.  Key secondary endpoints included SRI–SELENA–SLEDAI at week 52, time to first severe SLE flare, and proportion of patients with a reduction in prednisone dose. Renal and biomarker assessments were also conducted.  The study found that belimumab was effective in improving SLE disease activity and reducing renal flares in patients of Black African ancestry. ||| This study investigated the cardioprotective effects of Withania somnifera (Ws) compared to Vitamin E in a rat model of ischemia and reperfusion induced myocardial injury. Ws significantly reduced myocardial injury, improved hemodynamic parameters, and enhanced antioxidant defense mechanisms. These findings suggest that Ws has potential as a cardioprotective agent. ||| This study investigates the role of CD8 T cells in multiple sclerosis (MS) pathogenesis. Researchers generated a mouse model where a model antigen (influenza hemagglutinin) is expressed specifically in oligodendrocytes, the cells responsible for producing myelin in the central nervous system. Transferring activated CD8 T cells specific for this antigen into these mice resulted in inflammatory lesions in the brain, spinal cord, and optic nerve, resembling active MS lesions. These lesions were characterized by CD8 T cell infiltration, loss of oligodendrocytes, demyelination, and microglia activation. This suggests that CD8 T cells can directly contribute to oligodendrocyte death and demyelination in MS, highlighting their potential as therapeutic targets. ||| This study investigates the role of Interleukin-1 receptor-associated kinase (IRAK)-M in myocardial infarction.  Key findings include: 

* IRAK-M mRNA is significantly upregulated in the infarcted myocardium, with a biphasic response.
* IRAK-M is localized in macrophages and myofibroblasts within the infarcted heart.
* IRAK-M loss is associated with enhanced adverse remodeling after myocardial infarction, characterized by increased chamber dilation and hypertrophy, despite no effect on infarct size.
* IRAK-M−/− mice exhibit increased postinfarction inflammation with elevated myocardial cytokine mRNA levels. ||| This first-in-human study evaluated the safety, tolerability, pharmacokinetics, clinical course, and viral dynamics of bamlanivimab, a fully human neutralizing monoclonal antibody targeting SARS-CoV-2, in hospitalized patients with moderate to severe COVID-19.  The study found bamlanivimab to be safe and well-tolerated, with no serious adverse events or deaths reported.  Further research is needed to determine the efficacy of bamlanivimab in treating COVID-19. ||| This study reports the unexpected finding that transgenic mice expressing a myelin oligodendrocyte glycoprotein (MOG)-specific T cell receptor (TCR) develop spontaneous experimental autoimmune encephalomyelitis (EAE) even in the absence of MOG. The researchers discovered that these mice redirect their autoimmune response to a neuronal cytoskeletal protein called neuroﬁlament-M (NF-M). This cross-reactivity between MOG and NF-M is mediated by shared TCR contact positions on their respective epitope sequences. The study suggests that cumulative responses against multiple autoantigens, such as MOG and NF-M, may contribute to the development of spontaneous autoimmune diseases in humans. ||| This study investigates the role of Smad3 in cardiac fibroblasts following myocardial infarction. Using a mouse model with fibroblast-specific Smad3 deletion (FS3KO), the researchers found that loss of Smad3 in fibroblasts exacerbated dilative remodeling and worsened systolic dysfunction after both reperfused and nonreperfused infarction.  While acute infarct size was not affected, FS3KO mice exhibited larger scars, increased myofibroblast density, and enhanced myofibroblast proliferation. These findings suggest that Smad3 plays a protective role in cardiac fibroblasts and its loss contributes to adverse cardiac remodeling after infarction. ||| This study investigates the oxygen barrier properties of xylan-nanocrystalline cellulose composite films.  The addition of nanocrystalline cellulose significantly reduces oxygen transmission rates, resulting in films with permeability comparable to or lower than commonly used barrier plastics like EVOH.  SEM and AFM analysis reveal a more uniform and dense structure in the composite films compared to the control xylan films, which likely contributes to the improved barrier properties. ||| This study identifies a new mechanism for psoriasis (Ps) and psoriasis arthritis (PsA) development in mice. A single injection of mannan, a component of baker's yeast, induced Ps and PsA-like symptoms. This effect was exacerbated in mice lacking reactive oxygen species (ROS), but improved when ROS production was restored in macrophages.  Blocking IL-17A, a cytokine produced by gamma delta T cells, completely prevented disease. The study suggests that mannan activates macrophages, leading to TNF-α secretion and stimulation of IL-17A production by gamma delta T cells. This, in turn, drives neutrophil infiltration and inflammation, mimicking Ps and PsA. This new mouse model could be valuable for testing new therapies for Ps and PsA. ||| This study investigates the role of thrombospondin-1 (TSP-1) in diabetic cardiomyopathy. Researchers found that TSP-1 is upregulated in the hearts of diabetic mice and that its loss attenuates cardiac fibrosis and enhances myocardial protease activity. However, TSP-1 disruption also led to mild left ventricular dilation and modest nonprogressive systolic dysfunction. These findings suggest that TSP-1 plays a complex role in diabetic heart remodeling, with both beneficial and detrimental effects."
"Amit Saxena, MD",Cardiac Neonatal Lupus: Maternal and Fetal Risk Factors for Mortality,"Background: Cardiac neonatal lupus (CNL) is a serious complication of maternal anti-Ro/SSA and anti-La/SSB antibodies.  We sought to identify maternal and fetal risk factors for mortality in infants with CNL.

Methods and Results: We retrospectively analyzed data from 325 infants with CNL born to 297 mothers. Overall, 57 deaths (17.5%) occurred. Hydrops, carditis, and EFE were associated with increased mortality in both in utero and postnatal deaths. Maternal diagnosis of SLE and/or SS was associated with increased mortality in the overall analysis and in utero deaths.  Whites were less likely to die than minorities.

Conclusions: Hydrops, carditis, EFE, and maternal SLE and/or SS are significant risk factors for mortality in infants with CNL.","mortality, morbidity, cardiomyopathy, antibodies, heart block","This study investigates maternal and fetal risk factors for mortality in infants with cardiac neonatal lupus (CNL).  Key findings include the significant association of hydrops, carditis, EFE, and maternal SLE and/or SS with increased mortality. Additionally, white infants were found to have a lower mortality rate compared to minorities."
Amita Jain,"Antioxidant Activity, Phenol and Flavonoid Content of Helicteres isora (L.) ||| Evaluation of Total Phenolic and Flavonoid Content and Antioxidant Activity of *Hibiscus isora* (L.) ||| Semi Supervised Graph Based Keyword Extraction Using Lexical Chains and Centrality Measures ||| Seroprevalence of SARS-CoV-2 Antibodies in Uttar Pradesh, India: A Cross-Sectional Study","Helicteres isora L., commonly known as Indian Screw Tree is a highly valued medicinal plant in South-East Asia. The various phytochemicals like phenols, flavonoids and other antioxidants that impart the medicinal properties in this plant, vary in their composition and concentration in different plant parts. In the present research, the total phenolic content, total flavonoids content and free radical scavenging activity (FRAP and DPPH assay) in fresh and dry sample extracts of leaf, bark, fruit and root of H. isora L., prepared in four different solvents (distilled water, ethanol, methanol and acetone) were studied, and their results compared using Pearson’s Correlation. The plant extracts were also subjected to RP-HPLC for detection and quantitation of naturally occurring phenolic compounds using six phenolic standards (Gallic acid, Vanillin, Catechol, Ferrulic acid, p-coumaric acid and Caffeic acid). The highest total phenolic content (7.22 mg/g GAE) and FRAP value (64.98 mg/g TE) were observed in aqueous dry root extract. The acetone extract of fresh leaf (57.08 mg/g of RE) was found richest in total flavonoids, while the methanolic extract of fresh fruit uniquely exhibited strong free radical scavenging activity as evidenced by the low IC50 value (34.37 mg/ml) in DPPH assay. The RP-HPLC analysis revealed that Catechol and Gallic acid were most abundantly found phenolic compounds in extracts of H. isora L. The total phenolic content showed strong positive correlation with free radical scavenging activity (FRAP and DPPH assays) in both fresh and dry plant parts, suggesting that phenols are the main compounds responsible for the antioxidant activity. The root of H. isora L. was found rich in phenolics and antioxidant capacity indicating its strong potential for medicinal use, followed by fruit, leaf and bark. ||| Plant extracts rich in polyphenols are important for preparation of medicines as polyphenols are easily obtained from natural sources. Though medicinal plants of India constitute about 20% of total plant species 19, but the medicinal properties of most of them are not completely explored.  There are very few studies available where commercially viable formulations are being prepared, therefore, it is imperative to promote their studies for their application in curing diseases. The present investigation evaluates the phenolic and flavonoid content as well as antioxidant activity of one such scantily explored but potentially useful plant species *H. isora* (L.) Solvent extraction is most frequently used technique for isolation of plant antioxidant compounds with varied characteristics and polarities that may or may not be soluble in a particular solvent. Polar solvents are frequently employed for the recovery of polyphenols from a plant matrix 13. The selection of an appropriate solvent is one of the most relevant previous steps in estimating phytochemical activities. The yield of antioxidant compounds from plant parts is influenced mainly by the conditions under which the process of liquid-solid extraction is achieved, the type of solvent used to separate the soluble fraction from the permeable solid, the degree of polymerization of phenolics and their interaction with the other components20.  In present investigation, four types of extracts with water, ethanol, methanol, and acetone were prepared from different plant parts and used to check TPC, TFC and their antioxidant potential. ||| This paper proposes a semi-supervised graph-based keyword extraction algorithm using lexical chains and centrality measures. The algorithm first extracts nouns from each paragraph and creates lexical chains based on the similarity between words. The chains are then scored using two different methods, and the best chains are selected based on their scores. The selected chains are used to create a graph, and centrality measures are applied to identify the most central words as the extracted keywords. ||| Population-based serological antibody test for SARS-CoV-2 infection helps in estimating the exposure in the community. We present the findings of the first district representative seroepidemiological survey conducted between 4 and 10 September 2020 among the population aged 5 years and above in the state of Uttar Pradesh, India. Multi-stage cluster sampling was used to select participants from 495 primary sampling units (villages in rural areas and wards in urban areas) across 11 selected districts to provide district-level seroprevalence disaggregated by place of residence (rural/urban), age (5–17 years/aged 18 +) and gender. A venous blood sample was collected to determine seroprevalence. Of 16,012 individuals enrolled in the study, 22.2% [95% CI 21.5–22.9] equating to about 10.4 million population in 11 districts were already exposed to SARS-CoV-2 infection by mid-September 2020. The overall seroprevalence was significantly higher in urban areas (30.6%, 95% CI 29.4–31.7) compared to rural areas (14.7%, 95% CI 13.9–15.6), and among aged 18 + years (23.2%, 95% CI 22.4–24.0) compared to aged 5–17 years (18.4%, 95% CI 17.0–19.9). No differences were observed by gender. Individuals exposed to a COVID confirmed case or residing in a COVID containment zone had higher seroprevalence (34.5% and 26.0%, respectively). There was also a wide variation (10.7–33.0%) in seropositivity across 11 districts indicating that population exposed to COVID was not uniform at the time of the study. Since about 78% of the population (36.5 million) in these districts were still susceptible to infection, public health measures remain essential to reduce further spread.","Semi-supervised learning, DPPH, Word sense disambiguation, Helicteres isora L., RP-HPLC, Flavonoids, Phenolic content, RP- HPLC, FRAP, India, lexical chains, WordNet, keyword extraction, Seroprevalence, Helicteres isora, Graph centrality, Centrality measures, COVID-19, small world approach, Graph-based keyword extraction, Antioxidant activity, SARS-CoV-2, Phenols, Heterogeneity, Uttar Pradesh, semantic similarity, Flavonoid content","The qualitative tests for various phytochemicals revealed presence of saponins, alkaloids, steroids, terpenoids, glycosides, cardiac glycosides, phenols and flavonoids. The glycosides, phenols and flavonoids were present in all of the 32 extracts tested. Steroids and terpenoids were mainly found in dry plant part extracts whereas only few extracts of fresh plant parts, showed their presence. Tannins were uniquely present in only aqueous extract of dry leaf. Steroids were present in all extracts of dry leaf while present only in aqueous extracts of dry fruit, root, and bark. Out of the four plant parts, dry leaf extracts in four solvents, aqueous, ethanol, methanol and acetone, showed presence of all phytochemicals (Table 2). The fresh plant extracts were found to be low in steroids, terpenoids, and tannins while moderate in saponins and alkaloids. The dry plant extracts were found richer in phytochemicals as compared to fresh ones. ||| This study investigated the antioxidant potential of different parts of the Indian screw tree (Helicteres isora) using various solvents. Dried plant parts showed higher antioxidant activity compared to fresh ones, with leaves exhibiting the highest phenolic and flavonoid content and DPPH˙ radical scavenging activity.  The study suggests that dried leaves, roots, and fruits of H. isora, particularly when prepared in distilled water or methanol, hold potential for developing herbal formulations with antioxidant properties. ||| The proposed algorithm uses a combination of lexical chains and centrality measures to extract keywords from a document. It first extracts nouns from each paragraph and creates lexical chains based on the similarity between words. The chains are then scored using two different methods, and the best chains are selected based on their scores. The selected chains are used to create a graph, and centrality measures are applied to identify the most central words as the extracted keywords. ||| This study presents the first district-level seroprevalence survey of SARS-CoV-2 infection in Uttar Pradesh, India. Conducted in September 2020, the survey found that 22.2% of the population had been exposed to the virus by that time. Seroprevalence was significantly higher in urban areas and among individuals aged 18 and older. The findings highlight the importance of continued public health measures to reduce further spread of the virus."
Amy Pierce,BELIMUMAB IN PATIENTS OF BLACK AFRICAN ANCESTRY,"Study design. SELENA–SLEDAI = Safety of Estrogens in Lupus Erythematosus National Assessment–Systemic Lupus Erythemato-sus Disease Activity Index; IV = intravenous.

Randomization and treatment. Using an interactive voice/web response system, patients receiving standard therapy were randomized 2:1 to receive either belimumab 10 mg/kg IV or placebo, which was administered on days 0, 14, and 28 and every 28 days thereafter up to week 48, with a final evaluation at week 52. Randomization was stratified by screening SELENA–SLEDAI score (≤9 versus ≥10), region (US/Canada versus rest of world), and complement level (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]). Detailed randomization data are provided in Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Patients who successfully completed the initial 52-week double-blind phase could enter an optional 6-month open-label extension phase, during which they received belimumab 10 mg/kg IV every 28 days plus standard therapy, irrespective of their previous study assignment. The first dose was given at the week 52 (day 364) visit of the double-blind period (day 1 of the open-label extension phase). Patients who completed the 52-week double-blind phase, but did not enter the 6-month open-label extension phase, were required to return for an additional follow-up visit 8 weeks after their last dose. Patients who withdrew early were required to return for an exit visit 4 weeks after their last dose and a follow-up visit 8 weeks after their last dose.

The original protocol plan was to randomize 816 patients, providing ≥90% power to detect ≥12% absolute improvement in the SRI response rate in the belimumab group compared with the placebo group at a 5% significance level. Due to enrollment challenges, a revised sample size was calculated to include 501 patients (≥334 patients in the belimumab group and ≥167 patients in the placebo group). This sample size provided ≥90% power to detect a minimum 15.55% absolute improvement in SRI–SLEDAI-2K response rate in the belimumab group relative to the placebo group at a 5% significance level (based on the pooled data from efficacy studies BEL112341 and BEL113750) (15,21). These calculations assumed a placebo response rate of 43.95% at week 52.

Study end points and assessments. The primary efficacy end point was the SRI–SLEDAI-2K response rate (defined in the Supplementary Material) at week 52 of the double-blind phase. Unlike in the phase II and phase III studies, the SRI–SLEDAI-2K was selected because of the simplification it offers in proteinuria assessment as compared with the SELENA–SLEDAI proteinuria component; both are clinically meaningful (22). The primary efficacy end point for the open-label extension phase was SRI–SLEDAI-2K response rate at open-label extension week 24. If the open-label extension week 24 data were missing, data from the open-label extension week 28/exit visit were used. This time point is referred to as “open-label extension week 24” throughout the text. Data related to the primary efficacy end point, e.g., the response rate over time, percentage of patients with a durable SRI–SLEDAI-2K response from week 44 through week 52, time to first SRI–SLEDAI-2K response that was maintained through week 52, and duration of longest SRI–SLEDAI-2K response among patients with ≥1 SRI–SLEDAI-2K responses were summarized.

The key secondary end points were SRI–SELENA–SLEDAI at week 52 (open-label extension week 24), time to first severe SLE flare (measured by the SELENA–SLEDAI flare index [SFI]), and proportion of patients whose average prednisone dose had been reduced by ≥25% from baseline to ≤7.5 mg/day during week 40 through week 52 (open-label extension week 28/exit visit), in patients receiving >7.5 mg/day at baseline. Key renal end points included time to first renal flare over 52 weeks and over 28 weeks in the open-label extension, SELENA–SLEDAI–SLEDAI-2K renal domain improvement at week 52, SELENA–SLEDAI–SLEDAI-2K renal domain worsening at week 52, percentage reduction in proteinuria by visit and at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours, and proteinuria shift at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours. Renal flare is defined in the Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Biomarkers measured included percentage changes in serum IgG level, anti-dsDNA antibody level (in those who were anti-dsDNA positive [≥30 IU/ml] at baseline), and complement (C3 and C4) levels from baseline. Safety was evaluated by monitoring adverse events (AEs), serious AEs (SAEs), AEs of special interest, vital signs, clinical laboratory test results, and immunogenicity up to 8 weeks posttreatment and throughout the open-label extension phase.

Data analyses. For the double-blind phase, safety analyses were performed on the safety population, defined as all patients who were randomized and treated with at least 1 dose of investigational product. Data on the safety population were summarized according to the treatment the patient was randomized to receive rather than by the treatment that was received, but both were the same for this study. Efficacy analyses were performed on the modified intent-to-treat (ITT) population, defined as the safety population minus those patients who had any assessment at any of 3 study sites that were excluded from the efficacy analyses before the database lock because of potential Good Clinical Practice noncompliance.

For analysis of the primary and 3 key secondary efficacy end points, a step-down sequential testing procedure was used as described in the Supplementary Material. The following subgroup analyses were performed for the primary analysis (SRI–SLEDAI-2K response at week 52): region (US/Canada versus rest of world), baseline SELENA–SLEDAI–SLEDAI-2K score (≤9 versus ≥10), baseline anti-dsDNA antibody level (≥30 IU/ml versus <30 IU/ml), baseline complement levels (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]), and baseline complement and anti-dsDNA antibody levels (≥1 test finding showing low C3/C4 and anti-dsDNA ≥30 IU/ml versus C3/C4 other and anti-dsDNA ≥30 IU/ml). The odds of an SRI–SLEDAI-2K response with belimumab treatment versus placebo were estimated using logistic regression analysis.

For the open-label extension phase, all patients received belimumab, no formal statistical hypothesis t",,"This study investigated the efficacy and safety of belimumab in patients of Black African ancestry with systemic lupus erythematosus (SLE).  Patients were randomized to receive belimumab or placebo for 52 weeks, followed by an optional 6-month open-label extension phase. The primary efficacy endpoint was the SRI–SLEDAI-2K response rate at week 52.  Key secondary endpoints included SRI–SELENA–SLEDAI at week 52, time to first severe SLE flare, and proportion of patients with a reduction in prednisone dose. Renal and biomarker assessments were also conducted.  The study found that belimumab was effective in improving SLE disease activity and reducing renal flares in patients of Black African ancestry."
Angela Pizzolla,ROS deficiency enhanced mannan-induced PsA,"In and joint inflammation using B10Q.Ncf1m1j/m1j mice that have a mutation in the Ncf1 gene (m1j) (the Ncf1 protein also denoted p47phox), and hence reduced ROS production (oxidative burst) (18). As shown in Fig. 1D, Ncf1 mutated mice developed severe joint inflammation within 2 d after mannan injection, which reached the mean maximal disease severity (30 ± 6 points) within 4 d. The frequency of skin lesions was 100%, with more severe cases in B10Q.Ncf1m1j/m1j mice (Fig. 1E), whereas B10.Q mice had a significantly milder disease course. Multiple Exposures to Mannan Induced a Relapsing Disease. Next, we examined the effect of multiple mannan injections in B10Q and B10Q.Ncf1m1j/m1j mice. We boosted mice twice with mannan on days 7 and 14 after disease initiation. Repetitive injections of mannan reproduced the arthritis phenotype, which reached the maximum severity level on days 9 and 17, similar to the first injection (Fig. 1F). A more severe disease course was observed in B10Q.Ncf1m1j/m1j mice than in B10Q mice (P < 0.05 and P < 0.01, respectively). Interestingly, Ps skin scaling returned only after the second mannan injection (on day 16), but the skin peeled off even more quickly than the first time (Fig. 1G). Moreover, from day 11 onward, B10Q.Ncf1m1j/m1j mice started to develop pruritus on the body, predominantly on the back and above the eye (Fig. S1E). Pruritus was only evident in B10Q.Ncf1m1j/m1j mice, but flaky skin on the tail and alopecia all over the leg was observed in both of the mouse strains. We also observed genetic heterogeneity in disease susceptibility (Fig. Fig. 1. ROS deficiency enhanced mannan-induced PsA. The arthritic joint phenotype and Ps-like skin lesions in the front (A) and hind (B) paws of B10Q.Ncf1m1j/m1j mice are shown. (C) Ps-like skin scaling in diseased B10Q.Ncf1m1j/m1j mouse ear compared with naive mouse ear. Mean arthritis (D) and Ps lesion (E) severity in B10Q (n = 5) and B10Q.Ncf1m1j/m1j (n = 5) mice after a single i.p. mannan injection. Mean arthritis (F) and Ps lesion (G) severity in B10Q (n = 5) and B10Q.Ncf1m1j/m1j (n = 5) mice after repetitive mannan injections (days 7 and 14). (H) Mannan-induced mean maximum arthritis scores ± SEM in different mouse strains: B10Q (n = 8), B10Q.Ncf1m1j/m1j (n = 9), B10RIII (n = 10), B10RIII.Ncf1m1j/m1j (n = 9), B10P (n = 3), B10P.Ncf1m1j/m1j (n = 9), BALB/cByJ/Q (n = 10), BALB/cByJ/Q.Ncf1m1j/m1j (n = 8), BALB/cByJ (n = 5), BALB/cByJ.Ncf1m1j/m1j (n = 7), C57BL/6NJ (n = 8), and C57BL/6NJ.Ncf1m1j/m1j (n = 7). Significance was calculated by comparing the maximal disease severity of B10Q and B10Q.Ncf1m1j/m1j mice with all of the other strains in their respective groups. *P < 0.05; **P < 0.01; ***P < 0.001. E3670 | www.pnas.org/cgi/doi/10.1073/pnas.1405798111 Khmaladze et al. Downloaded from https://www.pnas.org by 122.184.65.228 on February 22, 2023 from IP address 122.184.65.228.","autoimmune disease, Ncf1, animal model","This study identifies a new mechanism for psoriasis (Ps) and psoriasis arthritis (PsA) development in mice. A single injection of mannan, a component of baker's yeast, induced Ps and PsA-like symptoms. This effect was exacerbated in mice lacking reactive oxygen species (ROS), but improved when ROS production was restored in macrophages.  Blocking IL-17A, a cytokine produced by gamma delta T cells, completely prevented disease. The study suggests that mannan activates macrophages, leading to TNF-α secretion and stimulation of IL-17A production by gamma delta T cells. This, in turn, drives neutrophil infiltration and inflammation, mimicking Ps and PsA. This new mouse model could be valuable for testing new therapies for Ps and PsA."
Animesh Chaturvedi,Analysing the Performance of Novel Activation Functions on Deep Learning Architectures ||| Automated Web Service Change Management AWSCM - A Tool ||| A NEURAL STOCK PRICE PREDICTOR USING QUANTITATIVE DATA ||| Call Graph Evolution Analytics over a Version Series of an Evolving Software System ||| Regression Testing of Web Service with AWSCM ||| System Evolution Analytics: Deep Evolution and Change Learning of Inter-Connected Entities,"Deep learning is a cutting-edge technology that functions similarly to the human nervous system. Neural networks are at the heart of Deep Learning. Neural networks are made up of numerous layers, in-cluding the input layer, which accepts raw data as input, hidden layers, which process the input data, and a final layer, the output layer, which provides the result. Its workflow pattern is comparable to machine learn-ing [2], [11], allowing us to gain hands-on expertise with this technology, speed up our work, and allow us to make several efforts without hav-ing to develop a basic Machine learning algorithm from scratch. In the case of deep learning, there are several neural networks to choose from. The majority of Deep Learning architectures are built on neural networks such as CNN, RNN, and others. Deep neural network activation function development is often guided by set goals and gradual steps toward tack-ling specific challenges. The primary goal of this study is to examine the performance of innovative activation functions (SBAF parabola [6] [16], AReLU [7], Leaky ReLU, SWISH) on deep learning architectures such as CNN, DENSENET, etc. On deep learning architectures, our study will compare the classification performance of the aforementioned activation functions. ||| This paper presents AWSCM, a framework for regression testing and top-down development of Web services. AWSCM addresses the challenges of regression testing in the context of evolving Web services by providing a systematic approach to identify changes, analyze their impact, and construct reduced regression test suites. The framework utilizes a novel concept of SWSDLs (Service Web Service Description Language) to capture the evolution of Web services and their associated test cases. AWSCM employs a set of algorithms to generate different types of SWSDLs, including DifferenceWSDL, ReduceWSDL, UnitWSDL, and CombineWSDL, which represent various aspects of the changes in Web services. These SWSDLs are then used to construct Reduced Regression Test Suites (RRTS) tailored to the specific changes. The paper also describes the application of AWSCM in real-world Web service projects, demonstrating its effectiveness in reducing test effort and improving the efficiency of regression testing. ||| Financial forecasting is an example of a signal processing problem which is challenging due to small sample sizes, high noise, non-stationarity, and non-linearity. Neural networks have been very successful in a number of signal processing applications. We discuss fundamental limitations and inherent difficulties when using neural networks for the processing of high noise, small sample size signals. Financial forecasting employing neural networks is a highly significant area for exploratory study. It has long been known that exact prediction is more of an art than a science but attempts can be made to recognize trends and patterns which should help in predicting correctly within an order of magnitude. Our approach uses a typical back propagation neural net and employs various formulas on quantitative data. We picked our training stocks from different categories having varying prices and volumes; this enabled a better analysis while generalizing our findings. While it has not been possible to provide exact predictions, a definite trend is evident in most cases. Statistically-oriented projections of the significance of these findings using standard regression analysis techniques show our approach to be simple yet effective. The historical data was obtained over a time period of 40 days for major stocks on New York Stock Exchange (NYSE). This data was used to train the network while trying out various parameter values and techniques which are discussed below ||| Software evolution analytics can be supported by generating and comparing call graph evolution information over versions of a software system. Call Graph evolution analytics can assist a software engineer when maintaining or evolving a software system. This paper proposes Call Graph Evolution Analytics to extract information from a set of Evolving Call Graphs ECG = {𝐶𝐺1,𝐶𝐺2, ...𝐶𝐺𝑁} representing a Version Series VS = {𝑉1,𝑉2, ...𝑉𝑁} of an evolving software system. This is done using Call Graph Evolution Rules (CGERs) and Call Graph Evolution Subgraphs (CGESs). Similar to association rule mining, the CGERs are used to capture co-occurrences of dependen-cies in the system. Like subgraph patterns in a call graph, the CGESs are used to capture evolution of dependency patterns in evolving call graphs. Call graph analytics on the evolution in these patterns can identify potentially affected dependencies (or procedure calls) that need attention. The experiments are done on the evolving call graphs of 10 large evolving systems to support dependency evolution management. This is demonstrated with detailed results for evolving call graphs of Maven-Core’s version series. ||| Web service changes are the reason to perform monitoring and retesting of WS. To reduce effort of monitoring and retesting, an automated engineering is required for identifying changes (diff). Changes in any document, program, product and WS could be in three ways: deleted, inserted or modified for achieving these requirement; this paper proposed four types of  WSDL’s  i.e.  (D/U/R/C) WSDL. Firstly, DWSDL can be defined as WSDL constructed from the diff between two versions  of  WSDL,  changes  at  WSDL’s  level  are mapped by some standard automated change identifying tool. For example operation3 in Fig. 1, is an inserted operation between two subsequent versions of WS. Secondly, RWSDL can be defined as WSDL constructed by user selective operations of WSDL. Thirdly, UWSDL can be defined as WSDL which is constructed with the operation undergone through change in code level. Fourthly, CWSDL can be defined as WSDL which is constructed with the operations in (D/U/R) WSDL such that it contains only unique and non-redundant operations (i.e. remove redundant operations in (D/U/R) WSDL). Automatically gathering changes at WSDL and code (logical statement) level helps in effort reduction in RTWS. If the changes to the WS are at the code level then changes are either reflected or not reflect on the WSDL in Table I. First if change reflected on WSDL, then they can be captured by (D/R) WSDL and they are especially helpful whenever tester   is   exposed   only   to   the   WSDL’s  and   do  not  have  any   details of WS code. Limitation with (D/R) WSDL is that they do not identify the changes at logical code level. But still, tester requires performing code change based regression testing which can be done by using UWSDL. Second if coding changes are done to the WS which are not reflected on the WSDL, then they can be captured by UWSDL. By using UWSDL constructed automatically by AWSCM tester can perform code based RTWS efficiently. ||| Entities (or components) in an evolving system keeps on evolving, which makes a state series SS = {S1, S2… SN}, where Si is the ith state of the system. There exist connections (or relationships) between entities, which also evolve over system state, and make a series of evolving networks EN = {EN1, EN2… ENN}. We can use these evolving networks to do learning over evolving system states for system evolution analysis. In this paper, we introduce a System Evolution Analytics model, which is based on proposed System Evolution Learning. The network pattern information is trained using graph structure learning. The evolution information is trained using evolution and change learning. We accomplish this by implementing a deep evolution learning. This technique uses an evolving matrix to generate evolving memory in the form of a proposed System Neural Network (SysNN). The SysNN is useful to predict and recommend based on system evolution learning. The technique is prototyped as a tool, which is used to do experiments on six evolving systems. We applied our tool to do system evolution analysis. The experiments are conducted to generate and report evolving memory as SysNN that helps to do recommendation about system.","web service testing, artificial intelligence and neural networks, artificial neural network, evolving system, Dependency Analysis, Software repository, Financial forecasting, Graphs, graph (network) learning, top down development, regression testing, web service change management, Network reliability, Complexity, Embedded systems, Data Mining, Subgraph Mining, Robotics, Redundancy, change impact analysis, Call Graph Evolution, deep learning, Web service, Software evolution, machine learning, WSDL, SOAP and tool support, stock prediction","This paper explores the performance of novel activation functions (SBAF parabola, AReLU, Leaky ReLU, SWISH) on deep learning architectures like CNN and DENSENET. The study aims to compare the classification accuracy of these activation functions on various computer vision datasets. ||| AWSCM is a tool for automated web service change management. It constructs Subset WSDLs based on change impact analysis and can be used for regression testing and top down development of web services. ||| This paper explores the use of neural networks for stock price prediction. The authors discuss the challenges of financial forecasting, including noise, small sample sizes, and non-linearity. They propose a back propagation neural network approach that uses quantitative data, such as market capitalization, beta coefficient, and earnings per share. The network is trained on historical data from the New York Stock Exchange and shows promising results in identifying trends and patterns. While exact predictions are not possible, the authors demonstrate the potential of neural networks as a practical forecasting tool for individual investors. ||| This paper proposes a new method called Call Graph Evolution Analytics to analyze the evolution of software systems by examining changes in their call graphs over time. The method uses two techniques: Call Graph Evolution Rules (CGERs) and Call Graph Evolution Subgraphs (CGESs). CGERs identify patterns of co-occurring dependencies, while CGESs capture structural changes in dependency relationships. The authors demonstrate the effectiveness of their method using experiments on 10 large evolving software systems, showing that it can identify potentially affected dependencies that require attention during software maintenance and evolution. ||| This paper proposes a framework called AWSCM (Automated Web Service Change Management) for efficient regression testing of web services. AWSCM utilizes four types of WSDLs: DWSDL (Difference WSDL), RWSDL (Reduced WSDL), UWSDL (Updated WSDL), and CWSDL (Combined WSDL) to capture changes at different levels (WSDL and code). It leverages tools like JDiff, Predic8, and Regex to identify and map changes, enabling testers to generate targeted test cases for regression testing. The framework aims to reduce the effort and cost associated with regression testing by automating the process of change identification and test case generation. ||| This paper introduces a System Evolution Analytics model that uses deep learning to analyze the evolution of interconnected entities in a system. The model, based on System Evolution Learning, leverages graph structure learning and evolution and change learning to generate evolving memory in the form of a System Neural Network (SysNN). This SysNN can then be used for prediction and recommendation regarding system evolution. The model is prototyped as a tool and tested on six evolving systems, demonstrating its ability to generate and report evolving memory for system analysis and recommendation."
Anirudh P. Shanbhag,Classiﬁcation of Mammalian and Non-Mammalian Keratin Protein Sequences Using Machine Learning Techniques,"Keratin protein is ubiquitous in most vertebrates and invertebrates, and has several important cellular and extracellular functions that are related to survival and protection. Keratin function has played a significant role in the natural selection of an organism. Hence, it acts as a marker of evolution. Much information about an organism and its evolution can therefore be obtained by investigating this important protein. In the present study, Keratin sequences were extracted from public data repositories and various important sequential, structural and physicochemical properties were computed and used for preparing the dataset. The dataset containing two classes, namely mammals (Class-1) and non-mammals (Class-0), was prepared, and rigorous classiﬁcation analysis was performed. To reduce the complexity of the dataset containing 56 parameters and to achieve improved accuracy, feature selection was done using the t-statistic. The 20 best features (parameters) were selected for further classiﬁcation analysis using computational algorithms which included SVM, KNN, Neural Network, Logistic regression, Meta-modeling, Tree Induction, Rule Induction, Discriminant analysis and Bayesian Modeling. Statistical methods were used to evaluate the output. Logistic regression was found to be the most effective algorithm for classiﬁcation, with greater than 96% accuracy using a 10-fold cross validation analysis. KNN, SVM and Rule Induction algorithms also were found to be efﬁcacious for classiﬁcation.","Data mining, Artiﬁcial Neural Networks (ANN), Meta-modeling, Machine learning techniques, Classiﬁcation, Artiﬁcial Intelligence (AI), Keratin, Logistic regression, Discriminant analysis, Mammalian and non-mammalian origin, Support Vector Machines (SVM), Tree induction, Biological classiﬁcation, Keratin protein sequences, Machine learning, Rule induction",This study aims to classify mammals and non-mammals based on various properties of the Keratin protein molecule. The dataset containing 56 parameters was prepared and feature selection was done using the t-statistic. The 20 best features were selected for further classiﬁcation analysis using computational algorithms. Logistic regression was found to be the most effective algorithm for classiﬁcation with greater than 96% accuracy.
Anita Pal,A Genetic Algorithm for Solving Fuzzy Shortest Path Problems with Interval Type-2 Fuzzy Arc Lengths ||| The Fuzzy Robust Graph Coloring Problem,"Shortest path problem is one of the most fundamental and well-known optimization problems in graph theory due to its various real-world applications. Fuzzy set can manage the uncertainty, associated with the information of a problem, where conventional mathematical models may fail to reveal satisfactory result. In most cases, shortest path problem in fuzzy graph, called fuzzy shortest path problem, uses type-1 fuzzy set as arc length. The uncertainty associated with the linguistic description of information is not represented properly by type-1 fuzzy set due to inexactness of human perception in the evaluation of membership degrees having crisp values.  An interval type-2 fuzzy set is able to tackle this type of uncertainty. In this paper, we have proposed an algorithmic approach based on genetic algorithm for finding shortest path from a source node to a destination node in a fuzzy graph with interval type-2 fuzzy arc lengths. We have designed a new crossover operator which does not need mutation operation. The purpose of mutation operation has been taken care by the proposed crossover operation. We have compared our algorithm with two other existing genetic algorithms for the fuzzy shortest path problem, where superiority of the proposed algorithm is shown. To the best of our knowledge, no algorithm based on genetic algorithm exists in the literature for fuzzy shortest path problem with interval type-2 fuzzy arc lengths. A numerical example is used to illustrate the effectiveness of the proposed approach. ||| Fuzzy graph model can represent a complex, imprecise and uncertain problem, where classical graph model may fail. In this paper, we propose a fuzzy graph model to represent the examination scheduling problem of a university and introduce a genetic algorithm based method to find the robust solution of the scheduling problem that remains feasible and optimal or close to optimal for all scenarios of the input data.","fuzzy event, fuzzy graph coloring, robust coloring, Genetic algorithm, Type-1 fuzzy set, robustness, genetic algorithm, Fuzzy shortest path problem, Fuzzy graph, Interval type-2 fuzzy set, interval type-2 fuzzy sets, fuzzy probability","This paper proposes a genetic algorithm for solving fuzzy shortest path problems with interval type-2 fuzzy arc lengths. The algorithm uses a new crossover operator that does not require mutation operation, and it has been compared with two existing genetic algorithms for the fuzzy shortest path problem. The results show the superiority of the proposed algorithm, and a numerical example is used to illustrate its effectiveness. ||| The paper proposes a method for graph coloring that can handle uncertain environments, represented by a fuzzy graph model. The examination scheduling problem of a university is considered, where courses are represented by nodes of a graph and every pair of incompatible courses is connected by an edge. The coloring of this graph provides a feasible schedule of the courses and computes the minimum number of time slots. The problem arises if after the examination schedule is published, some students choose a new course that makes the schedule invalid. The proposed method uses a genetic algorithm to find the robust solution of the scheduling problem."
Ankaj Tiwari,"Estimate of variability, heritability and genetic advance with respect to yield and yield contributing characters in field pea (Pisum sativum L.)","The present investigation entitled “Estimate of variability, heritability and genetic advance with respect to yield and yield contributing characters in field pea (Pisum sativum L.)” for 10 characters. The experiment comprising of 23 genotypes of pea were grown in a Randomized Block Design (RBD), with three replications at Research Farm, Department of Genetics & Plant Breeding, Post Graduate College, Ghazipur, during rabi season of 2017-2018, plant to plant and row to row distance was kept 10 cm and 45 cm, respectively.","Pisum sativum L., heritability, Genetic variability, yield contributing characters, genetic advance, field pea","The estimates of genotypic coefficient of variation (GCV) and phenotypic coefficient of variation (PCV) and environmental coefficient of variation (ECV) showed a wide range. The high estimates of genotypic coefficient of variation (GCV) were observed for plant height, biological yield per plant, number of pods per plant, seed yield per plant, number, 100 seed weight. The high estimates of phenotypic coefficient of variation (PCV) were observed for seed yield per pod, number of pods per plant, biological yield per plant, harvest index, plant height."
Ankit Misra,A deep learning model for mass screening of COVID-19,"The objective of this research is to develop a convolutional neural network model ‘COVID-Screen-Net’ for multi-class classification of chest X-ray images into three classes viz. COVID-19, bacterial pneumonia, and normal.","COVID-19, deep learning, X-ray, global pandemic, CNN model, Corona",The authors developed a deep learning model ‘COVID-Screen-Net’ for mass screening of COVID-19 from chest X-ray images. The model achieves an average accuracy of 97.71% and a maximum recall of 100%. It outperforms existing systems for screening of COVID-19 and may prove a useful tool for quick and low-cost mass screening of patients.
Ankita Jain,"Antioxidant Activity, Phenol and Flavonoid Content of Helicteres isora (L.)","Helicteres isora L., commonly known as Indian Screw Tree is a highly valued medicinal plant in South-East Asia. The various phytochemicals like phenols, flavonoids and other antioxidants that impart the medicinal properties in this plant, vary in their composition and concentration in different plant parts. In the present research, the total phenolic content, total flavonoids content and free radical scavenging activity (FRAP and DPPH assay) in fresh and dry sample extracts of leaf, bark, fruit and root of H. isora L., prepared in four different solvents (distilled water, ethanol, methanol and acetone) were studied, and their results compared using Pearson’s Correlation. The plant extracts were also subjected to RP-HPLC for detection and quantitation of naturally occurring phenolic compounds using six phenolic standards (Gallic acid, Vanillin, Catechol, Ferrulic acid, p-coumaric acid and Caffeic acid). The highest total phenolic content (7.22 mg/g GAE) and FRAP value (64.98 mg/g TE) were observed in aqueous dry root extract. The acetone extract of fresh leaf (57.08 mg/g of RE) was found richest in total flavonoids, while the methanolic extract of fresh fruit uniquely exhibited strong free radical scavenging activity as evidenced by the low IC50 value (34.37 mg/ml) in DPPH assay. The RP-HPLC analysis revealed that Catechol and Gallic acid were most abundantly found phenolic compounds in extracts of H. isora L. The total phenolic content showed strong positive correlation with free radical scavenging activity (FRAP and DPPH assays) in both fresh and dry plant parts, suggesting that phenols are the main compounds responsible for the antioxidant activity. The root of H. isora L. was found rich in phenolics and antioxidant capacity indicating its strong potential for medicinal use, followed by fruit, leaf and bark.","Flavonoids, FRAP, DPPH, Phenols, Helicteres isora L., RP-HPLC","The qualitative tests for various phytochemicals revealed presence of saponins, alkaloids, steroids, terpenoids, glycosides, cardiac glycosides, phenols and flavonoids. The glycosides, phenols and flavonoids were present in all of the 32 extracts tested. Steroids and terpenoids were mainly found in dry plant part extracts whereas only few extracts of fresh plant parts, showed their presence. Tannins were uniquely present in only aqueous extract of dry leaf. Steroids were present in all extracts of dry leaf while present only in aqueous extracts of dry fruit, root, and bark. Out of the four plant parts, dry leaf extracts in four solvents, aqueous, ethanol, methanol and acetone, showed presence of all phytochemicals (Table 2). The fresh plant extracts were found to be low in steroids, terpenoids, and tannins while moderate in saponins and alkaloids. The dry plant extracts were found richer in phytochemicals as compared to fresh ones."
Ankita Jaiswal,Towards Precision Agriculture: IoT-Enabled Intelligent Irrigation Systems Using Deep Learning Neural Network,"This paper presents a deep learning NN-based IoT-enabled intelligent irrigation system for precision agriculture (DLiSA). An LSTM RNN model is employed to predict volumetric soil moisture content of the next day based on the historical temporal dynamics of climate and soil. The proposed model uses a closed-loop approach, which takes feedback from soil sensors and climate sensors that keeps its functionality higher in the unpredicted climate of any region.","Volumetric Soil Moisture Content, Deep Learning Neural Network, Deep Learning, Internet of Things, Precision Agriculture, Sensor, Long Short Term Memory, IoT-enabled Intelligent Irrigation Systems, LSTM RNN model","The proposed DLiSA system consists of a smart irrigation model and associated sensing IoT network model deployed on farmland. The system uses a closed-loop approach to predict volumetric soil moisture content of the next day based on historical temporal dynamics of climate and soil. The performance of DLiSA is compared with state-of-the-art algorithms subject to the prediction of soil moisture content, soil water deficit, and water volume irrigated over a month."
Ankur Kulhari,Chaotic Kbest gravitational search algorithm (CKGSA),"Gravitational search algorithm is a popular adaptive search algorithm among nature-inspired algorithms and has been successfully used for optimizing many real-world problems. Gravitational search algorithm uses the law of Newton gravity for finding the optimal solution. The performance of gravitational search algorithm is controlled by exploration and exploitation capabilities and Kbest is one of its parameters that controls this trade-off. In this paper, a novel chaotic Kbest gravitational search algorithm has been proposed that uses the chaotic model in Kbest to balance the exploration and exploitation non-linearly. The proposed algorithm shows better convergence rate at later iterations with high precision and does not trap into local optima.","Chaotic, Kbest, Chaotic Kbest Gravitational Search Algorithm, Gravitational search algorithm, optimization algorithm, global optimization, Adaptive search algorithm",This paper proposes a novel chaotic Kbest gravitational search algorithm (CKGSA) that uses the chaotic model in Kbest to balance exploration and exploitation non-linearly. The proposed algorithm shows better convergence rate at later iterations with high precision and does not trap into local optima.
Anna Biernacka,TSP-1 in Diabetic Cardiomyopathy,"Diabetes mellitus is associated with cardiac fibrosis. Matricellular proteins are induced in fibrotic conditions and modulate fibrogenic and angiogenic responses by regulating growth factor signaling. Our aim was to test the hypothesis that the prototypical matricellular protein thrombospondin (TSP)-1, a potent angiostatic molecule and crucial activator of transforming growth factor-β, may play a key role in remodeling of the diabetic heart. Obese diabetic db/db mice exhibited marked myocardial TSP-1 upregulation in the interstitial and perivascular space. To study the role of TSP-1 in remodeling of the diabetic heart, we generated and characterized db/db TSP-1–/– (dbTSP) mice. TSP-1 disruption did not significantly affect weight gain and metabolic function in db/db animals. When compared with db/db animals, dbTSP mice had increased left ventricular dilation associated with mild nonprogressive systolic dysfunction. Chamber dilation in dbTSP mice was associated with decreased myocardial collagen content and accentuated matrix metalloproteinase-2 and -9 activity. TSP-1 disruption did not affect inflammatory gene expression and activation of transforming growth factor-β/small mothers against decapendaplegic signaling in the db/db myocardium. In cardiac fibroblasts populating collagen pads, TSP-1 incorporation into the matrix did not activate transforming growth factor-β responses, but inhibited leptin-induced matrix metalloproteinase-2 activation. TSP-1 disruption abrogated age-associated capillary rarefaction in db/db mice, attenuating myocardial upregulation of angiopoietin-2, a mediator that induces vascular regression. In vitro, TSP-1 stimulation increased macrophage, but not endothelial cell, angiopoietin-2 synthesis. Conclusions: TSP-1 upregulation in the diabetic heart prevents chamber dilation by exerting matrix-preserving actions on cardiac fibroblasts and mediates capillary rarefaction through effects that may involve angiopoietin-2 upregulation.","matrix metalloproteinases, thrombospondins, fibrosis, diabetic cardiomyopathies, ventricular remodeling","This study investigates the role of thrombospondin-1 (TSP-1) in diabetic cardiomyopathy. Researchers found that TSP-1 is upregulated in the hearts of diabetic mice and that its loss attenuates cardiac fibrosis and enhances myocardial protease activity. However, TSP-1 disruption also led to mild left ventricular dilation and modest nonprogressive systolic dysfunction. These findings suggest that TSP-1 plays a complex role in diabetic heart remodeling, with both beneficial and detrimental effects."
Anne James-Taylor,"Toward a Heterogeneous Mist, Fog, and Cloud-Based Framework for the Internet of Healthcare Things","Rapid developments in the fields of information and communication technology and microelectronics allowed seamless interconnection among various devices letting them to communicate with each other. This technological integration opened up new possibilities in many disciplines including healthcare and well-being. With the aim of reducing healthcare costs and providing improved and reliable services, several healthcare frameworks based on Internet of Healthcare Things (IoHT) have been developed. However, due to the critical and heterogeneous nature of healthcare data, maintaining high quality of service (QoS)—in terms of faster responsiveness and data-specific complex analytics—has always been the main challenge in designing such systems. Addressing these issues, this paper proposes a five-layered heterogeneous mist, fog, and cloud-based IoHT framework capable of efficiently handling and routing (near-)real-time as well as offline/batch mode data. Also, by employing software defined networking and link adaptation-based load balancing, the framework ensures optimal resource allocation and efficient resource utilization. The results, obtained by simulating the framework, indicate that the designed network via its various components can achieve high QoS, with reduced end-to-end latency and packet drop rate, which is essential for developing next generation e-healthcare systems.","QoS, healthcare big data, load balancing, healthcare application, healthcare, e-healthcare, IoHT, fog computing, quality of service (QoS), reduced latency, IoT, mist computing, Data fusion, cloud computing, heterogeneous framework, low power consumption, real-time computing, resource allocation","This paper proposes a five-layered heterogeneous mist, fog, and cloud-based Internet of Healthcare Things (IoHT) framework to efficiently handle and route healthcare data. The framework employs software defined networking and link adaptation-based load balancing to ensure optimal resource allocation and efficient resource utilization. The results show that the designed network can achieve high quality of service with reduced latency and packet drop rate, making it essential for developing next generation e-healthcare systems."
Annushree Bablani,Survey on Brain-Computer Interface,"A brain-computer interface (BCI) provides a way to develop interaction between a brain and a computer. The communication is developed as a result of neural responses generated in the brain because of motor movements or cognitive activities. The means of communication here includes muscular and non-muscular actions. These actions generate brain activities or brain waves that are directed to a hardware device to perform a specific task. BCI initially was developed as the communication device for patients suffering from neuromuscular disorders. Owing to recent advancements in BCI devices—such as passive electrodes, wireless headsets, adaptive software, and decreased costs—it is also being used for developing communication between the general public. The BCI device records brain responses using various invasive and non-invasive acquisition techniques such as electrocorticography (ECoG), electroencephalography (EEG), magnetoencephalography (MEG), and magnetic resonance imaging (MRI). In this article, a survey on these techniques has been provided. The brain response needs to be translated using machine learning and pattern recognition methods to control any application. A brief review of various existing feature extraction techniques and classification algorithms applied on data recorded from the brain has been included in this article. A significant comparative analysis of popular existing BCI techniques is presented and possible future directives are provided.","fuzzy inference system, feature extraction, electrocorticography, Brain-computer interface, Brain Signal Acquisition, Neural Tissue, classification, electroencephalogram, Electrodes","This survey provides a comprehensive overview of brain-computer interface (BCI) techniques, including signal acquisition, feature extraction, and classification algorithms. It discusses the recent advancements in BCI devices and their applications in developing communication between the general public. The survey also presents a comparative analysis of popular existing BCI techniques and provides possible future directives."
Anshika Arora,Real Time Smartphone Data for Prediction of Nomophobia Severity using Supervised Machine Learning,"Excessive use of smartphones throughout the day having dependency on them for social interaction, entertainment and information retrieval may lead users to develop nomophobia. This makes them feel anxious during non-availability of smartphones. This study describes the usefulness of real time smartphone usage data for prediction of nomophobia severity using machine learning.","real time data, smartphone addiction, smartphone usage, nomophobia questionnaire, machine learning, nomophobia","The study concludes that real time smartphone usage features extracted from the smartphones of students are effective for prediction of nomophobia among students using machine learning. In future, deep learning models can be implemented for prediction of nomophobia using real time smartphone usage features."
Anton Konev,Generation of an EDS Key Based on a Graphic Image of a Subject’s Face Using the RC4 Algorithm,"Modern facial recognition algorithms make it possible to identify system users by their appearance with a high level of accuracy. In such cases, an image of the user’s face is converted to parameters that later are used in a recognition process. On the other hand, the obtained parameters can be used as data for pseudo-random number generators. However, the closeness of the sequence generated by such a generator to a truly random one is questionable. This paper proposes a system which is able to authenticate users by their face, and generate pseudo-random values based on the facial image that will later serve to generate an encryption key. The generator of a random value was tested with the NIST Statistical Test Suite. The subsystem of image recognition was also tested under various conditions of taking the image. The test results of the random value generator show a satisfactory level of randomness, i.e., an average of 0.47 random generation (NIST test), with 95% accuracy of the system as a whole.","random number generation, digital signatures, authenticity, neural networks, digital signature, python, NIST test battery, computer vision, programming, algorithms, cryptography, facial recognition, security","This paper proposes a system for authenticating users by their face and generating pseudo-random values based on facial images. The system uses a combination of mathematical procedures for facial recognition and a pseudo-random number generator. The generator of a random value was tested with the NIST Statistical Test Suite, and the subsystem of image recognition was tested under various conditions of taking the image. The test results show a satisfactory level of randomness and 95% accuracy of the system as a whole."
Apoorva N,Analysing the Performance of Novel Activation Functions on Deep Learning Architectures,"Deep learning is a cutting-edge technology that functions similarly to the human nervous system. Neural networks are at the heart of Deep Learning. Neural networks are made up of numerous layers, in-cluding the input layer, which accepts raw data as input, hidden layers, which process the input data, and a final layer, the output layer, which provides the result. Its workflow pattern is comparable to machine learn-ing [2], [11], allowing us to gain hands-on expertise with this technology, speed up our work, and allow us to make several efforts without hav-ing to develop a basic Machine learning algorithm from scratch. In the case of deep learning, there are several neural networks to choose from. The majority of Deep Learning architectures are built on neural networks such as CNN, RNN, and others. Deep neural network activation function development is often guided by set goals and gradual steps toward tack-ling specific challenges. The primary goal of this study is to examine the performance of innovative activation functions (SBAF parabola [6] [16], AReLU [7], Leaky ReLU, SWISH) on deep learning architectures such as CNN, DENSENET, etc. On deep learning architectures, our study will compare the classification performance of the aforementioned activation functions.","Redundancy, Network reliability, Robotics, Embedded systems","This paper explores the performance of novel activation functions (SBAF parabola, AReLU, Leaky ReLU, SWISH) on deep learning architectures like CNN and DENSENET. The study aims to compare the classification accuracy of these activation functions on various computer vision datasets."
Archana Vadiraj Malagi,"Magnetic Resonance Materials in Physics, Biology and Medicine",Objective  To implement an advanced spatial penalty-based reconstruction to constrain the intravoxel incoherent motion (IVIM)–diffusion kurtosis imaging (DKI) model and investigate whether it provides a suitable alternative at 1.5 T to the traditional IVIM–DKI model at 3 T for clinical characterization of prostate cancer (PCa) and benign prostatic hyperplasia (BPH).,"TV penalty function, Prostate cancer, Benign prostatic hyperplasia, Total variation penalty function, MRI, Diffusion kurtosis imaging, Intravoxel incoherent motion, IVIM–DKI model","This study compares the use of IVIM–DKI at 1.5 T and 3 T MRI for differentiating between prostate cancer and benign prostatic hyperplasia. The results show that IVIM–DKI modeled with a novel model at 1.5 T produced parameter maps with lower coefficient of variation than the traditional model at 3 T. The novel model estimated higher D with lower D*, f, and k values at both field strengths compared to the traditional model. The study concludes that the proposed novel model can be utilized for improved detection of prostate lesions."
Archanaa Dongre,Impact on structural behavior due to installation of billboard,"Installation of billboards on various structures adjacent to busy roads has become common practice as they provide high economic to the local municipal corporation or private business organisations. Till recent, design of billboards and its installation on a structure was of less importance, but recent large wind cyclones had led to the collapse of billboards and structural cracks. This incident has raised doubts in structural engineering community for the resistance of buildings with billboards during earthquakes.","structural response, modal analysis, time history analysis, Building with billboard, structural behavior, time period","This study aims to understand the change in behavior of existing structure after installation of billboard. The study considers a G+2 structure with billboard located at Raidurg, Hyderabad and carries out dynamic analysis for three different ground motions to understand the change in its behavior with and without billboard."
Archita Goyal,A Line Drawing Language (LDDL) and its Compiler,A domain-specific language to draw line drawings is introduced in this paper. The compiler converts the specification of a line drawing written in this language into an image file. The language is suitable for drawing line drawings used in scientific literature.,"Line drawing, LDDL, graphic language, line drawing language, domain-specific language, compiler","This paper introduces a domain-specific language, named Line Drawing Description Language (LDDL), in which the specification of a line drawing can be written. The language is suitable for drawing line drawings used in scientific literature."
Ari Waisman,Cutting Edge: CD8 T Cell-Mediated Demyelination,"We generated mice (DKI) in which the HA coding sequence was introduced in the ubiquitously active Rosa26 locus but where HA transcription was prevented by an upstream LoxP-flanked Stop cassette. The DKI mice were then crossed with the MOGi-Cre mice, which express Cre specifically in oligodendrocytes. The resulting DKI mice excise the Stop cassette due to MOG-controlled Cre expression, leading to restricted HA expression to oligodendrocytes.  We then decided to test whether effector CD8 T cells can mediate oligodendrocyte cell death and demyelination in vivo. Effector T cells were first generated by in vitro activation of Kd:HA512–520 pentamer-specific CD8 T cells obtained from CL4-TCR mice using HA peptide, IL-2, and IL-12. The resulting Tc1 cells produce large amounts of granzyme B (GrB) and IFN-γ and exhibit potent cytotoxicity to HA-loaded target cells in vivo. Next, we transferred these HA-specific Tc1 cells into DKI and control mice. Following i.v. injection of 3 × 107 HA-specific Tc1 cells, but not naive HA-specific CD8 T cells, ~40% of the DKI mice developed an overt monophasic disease peaking at day 8–10 and waning by 4 wk posttransfer. The clinical manifestations included weight loss and, in the more severe cases, tremors, reduced mobility, and difficulty to right when overturned without overt paralysis. Upon histological analysis, all DKI mice injected with Tc1 cells demonstrated clear CNS pathology from day 5 onwards. Inflammatory lesions were never found in control littermates injected in parallel with HA-specific Tc1 cells.",,"This study investigates the role of CD8 T cells in multiple sclerosis (MS) pathogenesis. Researchers generated a mouse model where a model antigen (influenza hemagglutinin) is expressed specifically in oligodendrocytes, the cells responsible for producing myelin in the central nervous system. Transferring activated CD8 T cells specific for this antigen into these mice resulted in inflammatory lesions in the brain, spinal cord, and optic nerve, resembling active MS lesions. These lesions were characterized by CD8 T cell infiltration, loss of oligodendrocytes, demyelination, and microglia activation. This suggests that CD8 T cells can directly contribute to oligodendrocyte death and demyelination in MS, highlighting their potential as therapeutic targets."
Ariel Kay,First-­in-­Human Study of Bamlanivimab in a Randomized Trial of Hospitalized Patients With COVID-­19,"This first-in-human study in hospitalized patients with COVID-19 was supported by studies assessing in vitro viral neutralization combined with a single-dose non-human primate PK study. The nonclinical safety package to support subsequent studies included tissue cross-reactivity studies on human, rat, and monkey tissues and an in vivo toxicology study.  A complete physical examination was conducted at the screening visit, and one of three bamlanivimab doses or placebo was administered i.v. at the baseline visit (D1) with infusion rates as follows: bamlanivimab 700 mg (50 mL) administered 100 mL/hr for 30 minutes; 2,800 mg (75 mL) administered 100 mL/hr for 45 minutes; and 7,000 mg administered 100 mL/hr for 60 minutes. Placebo infusion was 0.9% normal saline, administered at the same volume and rate as the corresponding bamlanivimab dose cohort. Safety and tolerability were reviewed for sentinel participants up to 24 hours after dosing, at which point the investigators and sponsor team determined whether safety and tolerability were acceptable to continue with dosing subsequent participants. The decision to dose the next cohort was made when all participants from the previous cohort had been dosed and safety data assessed for at least 4 days after the i.v. infusion by the investigators and sponsor team in consultation with an independent safety assessment committee. Blood samples were obtained for assessment of exploratory biomarkers, serology, clinical laboratory assessments, and PD on days 1, 3, 7, 11, 15, 22, and 29, and every 7 days until discharge or day 60, if still an inpatient. Samples for the virology assay were collected using nasopharyngeal (preferred) or mid-turbinate methods. Blood samples obtained for PK analyses were assessed on days 1 (pre-infusion and just before end of infusion), 4, 15, and 29, and follow-up visits up to day 60. Symptom-related physical examinations and assessments of clinical symptoms were performed on days 1, 2, 3, 4, 7, 11, 15, 22, and 29, and the day of discharge from the hospital, with additional follow-up examinations every 7 days thereafter until day 60 if the patient was not discharged from the hospital by day 29. Participants’ clinical status and concurrent procedures of special interest were recorded, including limitation on activities due to COVID-19 and any requirements for the following procedures of special interest, such as ongoing hospital medical care, supplemental oxygen, noninvasive ventilation or a high flow oxygen device, mechanical ventilation, extracorporeal membrane oxygenation, additional organ support, or consciousness status using alert, consciousness, verbal, pain, unresponsive scale. Hospitalization events were recorded, including dates of hospital admission and discharge, admission to the intensive care unit (ICU), discharge from the ICU, and discharge location including to an extended care facility or home. Outcomes The primary objective was to assess safety and tolerability, including adverse events (AEs), serious adverse events (SAEs), and discontinuations due to AEs. Other objectives included PKs (e.g., mean concentration at day 29); PD viral load, area under the response time curve (AUC, from day 1 to day 29), and change from baseline time course; total symptom score; time to symptom resolution; duration of hospitalization; National Institute of Allergy and Infectious Diseases (NIAID), World Health Organization (WHO) scales, and National Early Warning Score (NEWS2); and analysis of viral resistance. Any hypothesis tests were conducted for treatment comparisons without adjustment for multiplicity except for the evaluation of treatment effect on endogenous antibody titers. Success for the trial was claimed using a Bayesian criterion if any of the 3 bamlanivimab doses had at least 60% probability to reduce at least 30% mean AUC (28-day viral load) over placebo.",,"This first-in-human study evaluated the safety, tolerability, pharmacokinetics, clinical course, and viral dynamics of bamlanivimab, a fully human neutralizing monoclonal antibody targeting SARS-CoV-2, in hospitalized patients with moderate to severe COVID-19.  The study found bamlanivimab to be safe and well-tolerated, with no serious adverse events or deaths reported.  Further research is needed to determine the efficacy of bamlanivimab in treating COVID-19."
Arindam Dey,A Genetic Algorithm for Solving Fuzzy Shortest Path Problems with Interval Type-2 Fuzzy Arc Lengths ||| The Fuzzy Robust Graph Coloring Problem,"Shortest path problem is one of the most fundamental and well-known optimization problems in graph theory due to its various real-world applications. Fuzzy set can manage the uncertainty, associated with the information of a problem, where conventional mathematical models may fail to reveal satisfactory result. In most cases, shortest path problem in fuzzy graph, called fuzzy shortest path problem, uses type-1 fuzzy set as arc length. The uncertainty associated with the linguistic description of information is not represented properly by type-1 fuzzy set due to inexactness of human perception in the evaluation of membership degrees having crisp values.  An interval type-2 fuzzy set is able to tackle this type of uncertainty. In this paper, we have proposed an algorithmic approach based on genetic algorithm for finding shortest path from a source node to a destination node in a fuzzy graph with interval type-2 fuzzy arc lengths. We have designed a new crossover operator which does not need mutation operation. The purpose of mutation operation has been taken care by the proposed crossover operation. We have compared our algorithm with two other existing genetic algorithms for the fuzzy shortest path problem, where superiority of the proposed algorithm is shown. To the best of our knowledge, no algorithm based on genetic algorithm exists in the literature for fuzzy shortest path problem with interval type-2 fuzzy arc lengths. A numerical example is used to illustrate the effectiveness of the proposed approach. ||| Fuzzy graph model can represent a complex, imprecise and uncertain problem, where classical graph model may fail. In this paper, we propose a fuzzy graph model to represent the examination scheduling problem of a university and introduce a genetic algorithm based method to find the robust solution of the scheduling problem that remains feasible and optimal or close to optimal for all scenarios of the input data.","fuzzy event, fuzzy graph coloring, robust coloring, Genetic algorithm, Type-1 fuzzy set, robustness, genetic algorithm, Fuzzy shortest path problem, Fuzzy graph, Interval type-2 fuzzy set, interval type-2 fuzzy sets, fuzzy probability","This paper proposes a genetic algorithm for solving fuzzy shortest path problems with interval type-2 fuzzy arc lengths. The algorithm uses a new crossover operator that does not require mutation operation, and it has been compared with two existing genetic algorithms for the fuzzy shortest path problem. The results show the superiority of the proposed algorithm, and a numerical example is used to illustrate its effectiveness. ||| The paper proposes a method for graph coloring that can handle uncertain environments, represented by a fuzzy graph model. The examination scheduling problem of a university is considered, where courses are represented by nodes of a graph and every pair of incompatible courses is connected by an edge. The coloring of this graph provides a feasible schedule of the courses and computes the minimum number of time slots. The problem arises if after the examination schedule is published, some students choose a new course that makes the schedule invalid. The proposed method uses a genetic algorithm to find the robust solution of the scheduling problem."
Arjun Choudhry,An Emotion-Based Multi-Task Approach to Fake News Detection,"Social media, blogs, and online articles are instant sources of news for internet users globally. But due to their unmoderated nature, a significant percentage of these texts are fake news or rumors. Their deceptive nature and ability to propagate instantly can have an adverse effect on society. In this work, we hypothesize that legitimacy of news has a correlation with its emotion, and propose a multi-task framework predicting both the emotion and legitimacy of news. Experimental results verify that our multi-task models outperform their single-task counterparts in terms of accuracy.","social media, legitimacy of news, rumors, fake news detection, emotion-based multi-task approach","This paper proposes an emotion-based multi-task approach to fake news detection, which predicts both the emotion and legitimacy of news. The approach uses a multi-task framework and outperforms single-task models in terms of accuracy. The results show that there is a correlation between the legitimacy of news and its emotion, and that the proposed approach can effectively detect fake news and rumors."
Arjun Kumar,Source parameters and f max in lower Siang region of Arunachal lesser Himalaya,"A data set of 60 local events (1.9≤Mw≤3.6) collected by a temporary digital network deployed in the Siang region of Arunachal Lesser Himalaya during July 2011 to February 2012 is analysed to study the source parameters and fmax. The software EQK_SRC_PARA (Kumar et al. in Int J Geosci 3(5):1142–1149, 2012) that considers Brune’s model with a high-frequency diminution factor (Boore in Bull Seismol Soc Am 73:1865–1894, 1983) has been used to estimate the spectral parameters namely: low-frequency displacement spectral level (Ω0), corner frequency (fc) and fmax. These obtained spectral parameters are used to estimate source parameters, namely: seismic moment, source dimension and stress drop and to study the characteristics of fmax in this region.","Accelerometers, Seismometers, fmax, Lower Siang, Source parameters, Seismicity, Arunachal Lesser Himalaya, Siang region","This study investigates the source parameters and fmax in the lower Siang region of Arunachal Lesser Himalaya using a data set of 60 local events. The results show that fmax has similar behavior as fc to seismic moment, indicating that it is also due to source process. The study also finds that fmax is independent of epicentral distance and focal depth."
Arjunlokesh Netaji,"Magnetic Resonance Materials in Physics, Biology and Medicine",Objective  To implement an advanced spatial penalty-based reconstruction to constrain the intravoxel incoherent motion (IVIM)–diffusion kurtosis imaging (DKI) model and investigate whether it provides a suitable alternative at 1.5 T to the traditional IVIM–DKI model at 3 T for clinical characterization of prostate cancer (PCa) and benign prostatic hyperplasia (BPH).,"TV penalty function, Prostate cancer, Benign prostatic hyperplasia, Total variation penalty function, MRI, Diffusion kurtosis imaging, Intravoxel incoherent motion, IVIM–DKI model","This study compares the use of IVIM–DKI at 1.5 T and 3 T MRI for differentiating between prostate cancer and benign prostatic hyperplasia. The results show that IVIM–DKI modeled with a novel model at 1.5 T produced parameter maps with lower coefficient of variation than the traditional model at 3 T. The novel model estimated higher D with lower D*, f, and k values at both field strengths compared to the traditional model. The study concludes that the proposed novel model can be utilized for improved detection of prostate lesions."
Arti Shinde,TSP-1 in Diabetic Cardiomyopathy,"Diabetes mellitus is associated with cardiac fibrosis. Matricellular proteins are induced in fibrotic conditions and modulate fibrogenic and angiogenic responses by regulating growth factor signaling. Our aim was to test the hypothesis that the prototypical matricellular protein thrombospondin (TSP)-1, a potent angiostatic molecule and crucial activator of transforming growth factor-β, may play a key role in remodeling of the diabetic heart. Obese diabetic db/db mice exhibited marked myocardial TSP-1 upregulation in the interstitial and perivascular space. To study the role of TSP-1 in remodeling of the diabetic heart, we generated and characterized db/db TSP-1–/– (dbTSP) mice. TSP-1 disruption did not significantly affect weight gain and metabolic function in db/db animals. When compared with db/db animals, dbTSP mice had increased left ventricular dilation associated with mild nonprogressive systolic dysfunction. Chamber dilation in dbTSP mice was associated with decreased myocardial collagen content and accentuated matrix metalloproteinase-2 and -9 activity. TSP-1 disruption did not affect inflammatory gene expression and activation of transforming growth factor-β/small mothers against decapendaplegic signaling in the db/db myocardium. In cardiac fibroblasts populating collagen pads, TSP-1 incorporation into the matrix did not activate transforming growth factor-β responses, but inhibited leptin-induced matrix metalloproteinase-2 activation. TSP-1 disruption abrogated age-associated capillary rarefaction in db/db mice, attenuating myocardial upregulation of angiopoietin-2, a mediator that induces vascular regression. In vitro, TSP-1 stimulation increased macrophage, but not endothelial cell, angiopoietin-2 synthesis. Conclusions: TSP-1 upregulation in the diabetic heart prevents chamber dilation by exerting matrix-preserving actions on cardiac fibroblasts and mediates capillary rarefaction through effects that may involve angiopoietin-2 upregulation.","matrix metalloproteinases, thrombospondins, fibrosis, diabetic cardiomyopathies, ventricular remodeling","This study investigates the role of thrombospondin-1 (TSP-1) in diabetic cardiomyopathy. Researchers found that TSP-1 is upregulated in the hearts of diabetic mice and that its loss attenuates cardiac fibrosis and enhances myocardial protease activity. However, TSP-1 disruption also led to mild left ventricular dilation and modest nonprogressive systolic dysfunction. These findings suggest that TSP-1 plays a complex role in diabetic heart remodeling, with both beneficial and detrimental effects."
Arti V. Shinde,Opposing Actions of Fibroblast and Cardiomyocyte Smad3 Signaling in the Infarcted Myocardium,"Transforming growth factor (TGF)–βs are highly pleiotropic mediators with critical roles in regulating cellular phenotype and function in embryonic development, tissue homeostasis, and disease. Normal tissues contain stores of latent TGF-β bound to the extracellular matrix through its association with a large binding protein, the latent TGF-β binding protein. Tissue injury is associated with marked induction of TGF-β isoforms and activation of TGF-β signaling cascades. Parenchymal cells, extravasated leukocytes, and platelets synthesize and release large amounts of TGF-β in the injury site. Reactive oxygen species, proteases, matricellular proteins, and integrins cooperate to trigger the release of bioactive TGF-β from the latent stores. Subsequent binding of the active TGF-β dimer to the type II TGF-β receptor, followed by transphosphorylation of the type I receptor, triggers the TGF-β signaling response. The cellular effects of TGF-β are mediated through a canonical pathway involving a series of intracellular effectors, the Smads, or through activation of noncanonical signaling cascades. Activation of TGF-β signaling induces phosphorylation of the receptor-activated Smads, Smad2 and Smad3, which can form heteromeric complexes with the common Smad, Smad4. These complexes are transported to the nucleus, where they regulate gene transcription. TGF–β receptors and Smads are ubiquitously expressed by all cell types. Thus, all cells are responsive to the actions of TGF-β. Cardiac injury is associated with the marked induction of TGF-β and activation of TGF-β cascades. Our laboratory and other investigators have documented activation of Smad2 and Smad3 signaling in the infarcted myocardium, localized in both cardiomyocytes and interstitial cells. In isolated cardiac fibroblasts, Smad3 signaling accentuates myofibroblast transdifferentiation and stimulates a matrix-preserving program. In a model of reperfused infarction, global loss of Smad3 attenuated remodeling after infarction. However, considering the ubiquitous expression of Smad3 in all cell types, the cell biological basis for the actions of Smad3 in the infarcted heart remains unknown. Our study dissects the cell-specific actions of Smad3 signaling in the infarcted myocardium by developing and studying mice with cell-specific loss of Smad3 in activated fibroblasts and cardiomyocytes. It is surprising that fibroblast-specific loss of Smad3 worsened remodeling after infarction, resulting in accentuated chamber dilation. The deleterious consequences of fibroblast-specific Smad3 loss reflected unrestrained fibroblast proliferation, defective scar remodeling, and perturbed organization of myofibroblast arrays in the border zone. Smad3 signaling regulated fibroblast function, activating integrin-mediated nicotinamide adenine dinucleotide phosphate (NADPH) oxidase (NOX)–2 expression. In contrast, cardiomyocyte-specific loss of Smad3 protected the infarcted heart from dysfunction after infarction. The protective effects of cardiomyocyte-specific Smad3 loss were associated with attenuated cardiomyocyte apoptosis in remodeling myocardium and accompanied by decreased NOX2 levels, reduced nitrosative stress, and decreased matrix metalloproteinase (MMP)–2 expression.","SMAD, fibroblast, heart failure, cardiomyocyte, remodeling","This study investigates the role of Smad3 in cardiac fibroblasts following myocardial infarction. Using a mouse model with fibroblast-specific Smad3 deletion (FS3KO), the researchers found that loss of Smad3 in fibroblasts exacerbated dilative remodeling and worsened systolic dysfunction after both reperfused and nonreperfused infarction.  While acute infarct size was not affected, FS3KO mice exhibited larger scars, increased myofibroblast density, and enhanced myofibroblast proliferation. These findings suggest that Smad3 plays a protective role in cardiac fibroblasts and its loss contributes to adverse cardiac remodeling after infarction."
Arun Kumar Singh,EXPERIMENTAL STUDY OF REGENERATIVE BRAKING SYSTEM (RBS),"In this era, the automobile sector is facing a major challenge to reduce consumption of fuel and greenhouse gases emission, this is often because limited fuel reserves and continuous degrade in air quality. An experimental setup is made for the current study to reduce the loss of energy by reusing it. In this present study, an alternator is connected to the driver shaft through chain and sprocket. When brakes are applied to slow the vehicle down or make it come to a halt, the alternator is activated with an electromagnetic clutch, and the energy lost during braking is utilized to generate electrical energy.","Generator, Automobile, Regenerative braking, Electromagnetic clutch, Energy recovery system","This paper presents an experimental study of regenerative braking system (RBS) to reduce energy loss during braking. An experimental setup is designed to reuse the energy lost during braking by activating an alternator with an electromagnetic clutch. The study shows that 16.32% of brake energy was recovered, and the current from the alternator increases with engine speed."
Aruna Rao S.L.,Trusted Secure Geographic Routing Protocol for Detecting Insider Attacks in MANET,"In Mobile Ad hoc Network (MANET), the nodes are linked to one another wirelessly and are self sustaining. The member nodes of MANET are very robust and minute. The deployment and maintenance of this network is less expensive and comparatively easy when compared with the conventional networks. However, MANET is highly susceptible to attacks due to its infrastructureless topology. The possible attacks vary over a wide range and affect the network in different levels. To overcome these attacks and safeguard the network performance, in this paper we propose to develop a trusted secure geographical routing protocol for detecting insider attacks.","trust value estimation, Insider Attacks, Mobile Ad hoc Network, Trusted Secure Geographic Routing Protocol, MANET","The protocol estimates the overall trust value of neighboring nodes in two steps: initially, the agent in each node computes the trust value based on two desired functionalities at every Trust Update Interval (TUI); then, after packets are transmitted to the next hop node, the transmitting node overhears the channel to determine the number of packets forwarded and dropped by the next hop node, and computes the trust value of the next hop node based on the overheard information."
Aruna Tiwari,A Novel Scalable Apache Spark Based Feature Extraction Approaches for Huge Protein Sequence and their Clustering Performance Analysis ||| A Review of Clustering Techniques and Developments ||| System Evolution Analytics: Deep Evolution and Change Learning of Inter-Connected Entities,"Genome sequencing projects are rapidly increasing the number of high-dimensional protein sequence datasets. Clustering a high-dimensional protein sequence dataset using traditional machine learning approaches poses many challenges. Many different feature extraction methods exist and are widely used. However, extracting features from millions of protein sequences becomes impractical because they are not scalable with current algorithms. Therefore, there is a need for an efficient feature extraction approach that extracts significant features. We have proposed two scalable feature extraction approaches for extracting features from huge protein sequences using Apache Spark, which are termed 60d-SPF (60-dimensional Scalable Protein Feature) and 6d-SCPSF (6-dimensional Scalable Co-occurrence-based Probability-Speciﬁc Feature). The proposed 60d-SPF and 6d-SCPSF approaches capture the statistical properties of amino acids to create a fixed-length numeric feature vector that represents each protein sequence in terms of 60-dimensional and 6-dimensional features, respectively. ||| This paper presents a comprehensive study on clustering: exiting methods and developments made at various times. Clustering is defined as an unsupervised learning where the objects are grouped on the basis of some similarity inherent among them. There are different methods for clustering the objects such as hierarchical, partitional, grid, density based and model based. The approaches used in these methods are discussed with their respective states of art and applicability. The measures of similarity as well as the evaluation criteria, which are the central components of clustering are also presented in the paper. The applications of clustering in some fields like image segmentation, object and character recognition and data mining are highlighted. ||| Entities (or components) in an evolving system keeps on evolving, which makes a state series SS = {S1, S2… SN}, where Si is the ith state of the system. There exist connections (or relationships) between entities, which also evolve over system state, and make a series of evolving networks EN = {EN1, EN2… ENN}. We can use these evolving networks to do learning over evolving system states for system evolution analysis. In this paper, we introduce a System Evolution Analytics model, which is based on proposed System Evolution Learning. The network pattern information is trained using graph structure learning. The evolution information is trained using evolution and change learning. We accomplish this by implementing a deep evolution learning. This technique uses an evolving matrix to generate evolving memory in the form of a proposed System Neural Network (SysNN). The SysNN is useful to predict and recommend based on system evolution learning. The technique is prototyped as a tool, which is used to do experiments on six evolving systems. We applied our tool to do system evolution analysis. The experiments are conducted to generate and report evolving memory as SysNN that helps to do recommendation about system.","Unsupervised learning, Apache Spark Cluster, Clustering, artificial neural network, evolving system, Data mining, protein sequences, graph (network) learning, Feature Extraction, Hierarchical Clustering, Big Data, ROCK, Fuzzy Clustering, Scalable Algorithms, Similarity measures, Clustering Approaches, Pattern recognition, BIRCH, Taxonomy, deep learning, machine learning, CURE, CHAMELEON, Apache Spark, Huge Protein Sequences","This paper proposes two scalable feature extraction approaches for huge protein sequences using Apache Spark, which are termed 60d-SPF and 6d-SCPSF. The proposed approaches capture the statistical properties of amino acids to create a fixed-length numeric feature vector that represents each protein sequence in terms of 60-dimensional and 6-dimensional features, respectively. The paper also discusses the clustering of huge protein sequences using SRSIO-FCM and SLFCM algorithms. ||| This paper reviews clustering techniques and developments, discussing methods such as hierarchical, partitional, grid, density-based, and model-based clustering, as well as measures of similarity and evaluation criteria. The applications of clustering in fields like image segmentation, object recognition, and data mining are highlighted. ||| This paper introduces a System Evolution Analytics model that uses deep learning to analyze the evolution of interconnected entities in a system. The model, based on System Evolution Learning, leverages graph structure learning and evolution and change learning to generate evolving memory in the form of a System Neural Network (SysNN). This SysNN can then be used for prediction and recommendation regarding system evolution. The model is prototyped as a tool and tested on six evolving systems, demonstrating its ability to generate and report evolving memory for system analysis and recommendation."
Ashish Jain,Automated Cryptanalysis of Substitution Ciphers using Swarm Intelligence Techniques,"This paper presents a comparative analysis of various swarm intelligence techniques for automated cryptanalysis of substitution ciphers. The techniques used include particle swarm optimization (PSO), bees algorithm, ant colony optimization, firefly algorithm, and cuckoo search. The results show that the cuckoo search technique is the most effective, with an average number of key elements correctly recovered of 26.17 out of 27, and a mean performance time of 0.137 seconds.","Bees Algorithm, Automated Cryptanalysis, Firefly Algorithm, Substitution Ciphers, Particle Swarm Optimization, Swarm Intelligence, Ant Colony Optimization, Classical Substitution Cipher, Cuckoo Search","This paper presents a comparative analysis of various swarm intelligence techniques for automated cryptanalysis of substitution ciphers. The results show that the cuckoo search technique is the most effective, with an average number of key elements correctly recovered of 26.17 out of 27, and a mean performance time of 0.137 seconds."
Ashish Kumar Tripathi,Map-reduce-based tournament empowered whale optimization algorithm for recommendation,"In the era of Web 2.0, the data are growing immensely and is assisting E-commerce websites for better decision-making. Collaborative filtering, one of the prominent recommendation approaches, performs recommendation by finding similarity. However, this approach fails in managing large-scale datasets. To mitigate the same, an efficient map-reduce-based clustering recommendation system is presented. The proposed method uses a novel variant of the whale optimization algorithm, tournament selection empowered whale optimization algorithm, to attain the optimal clusters.","tournament empowered WOA, Map-reduce, Recommendation system, Clustering, Whale optimization algorithm, Big data, map-reduce architecture","This paper presents a novel meta-heuristic-based recommendation system for the big data environment. The proposed method uses a novel variant of the whale optimization algorithm, tournament selection empowered whale optimization algorithm, to attain the optimal clusters. The clustering efficiency of the proposed method is measured on four large-scale datasets in terms of F-measure and computation time."
Ashish Tripathi,Improved Gravitational Search Algorithm for COVID-19 Diagnosis ||| Technological Advancements in Automated Crop Pest and Disease Detection: A Review & Ongoing Research,"This paper presents a novel variant of the gravitational search algorithm, improved gravitational search algorithm (IGSA), to enhance the vicinity to optimal solutions. The proposed variant is employed to obtain optimal clusters in the proposed clustering method for the CoVID19 diagnosis. An extensive experimental analysis of IGSA has been conducted against 16 metaheuristic algorithms over 17 standard benchmark functions belonging to unimodal and multimodal categories. The results are studied over four different dimensional settings, i.e. 10, 30, 50, and 90. ||| Automated crop pests and disease detection have fateful effects on food safety, leading to significant deterioration in agriculture products. The effects of crop diseases and pests can be so severe that a harvest may even be ruined entirely. Therefore, automatic recognition and diagnosis of crop disease is required in the agricultural field. However, Fast and accurate crop disease detection is still a challenging and error-prone task. Earlier, traditional methods were used to detect abnormalities in crops caused by fungus, pests and nutritional deficiency. Moreover, in some cases, it is time-consuming, expensive and impractical. To overcome these issues, experimental research is being performed into the use of image processing techniques for crop disease detection using machine learning, artificial intelligence, deep learning, generative adversarial networks and the internet of things. In this study, a comprehensive literature review of current studies is performed in crop disease and pest recognition using image processing to extract the features and algorithms used in prediction studies. In particular, several models have reported better accuracy on specific data sets. In contrast, in the case of different data sets or field conditions, the performance of the models degraded significantly. Despite this, progress has been encouraging so far. Furthermore, different inputs gained from the literature indicate that the aforementioned techniques provide better accuracy in comparison with existing techniques. Additionally, a detailed study has been performed on several unresolved challenges to develop a framework for automated crop pests and disease detection to use in real field conditions.","Clustering Method, crop disease detection, Gravitational search algorithm, GANs, Machine learning, Deep learning, transfer learning, CoVID19 diagnosis, Clustering, Metaheuristic algorithm, COVID-19 Diagnosis, leaf disease recognition, Internet of things, Metaheuristic Algorithms, Generative adversarial networks","This paper presents a new clustering method for the diagnosis of CoVID19 using medical images. The method employs a novel variant of a gravitational search algorithm to obtain optimal clusters. The performance of the proposed method is compared with recent metaheuristic algorithms using benchmark functions and publicly available CoVID19 medical images. The results demonstrate that the proposed method is outperforming in terms of accuracy, precision, sensitivity, specificity, and F1-score. ||| The paper presents a comprehensive review of the current state of leaf disease recognition using deep learning techniques. It discusses the use of pre-trained CNNs, transfer learning, and GANs for generating synthetic images and addressing the problem of data scarcity. The paper also presents several architectures and methods for leaf disease recognition, including the use of YOLOv3 and AlexNet for predicting bounding boxes and the use of a softmax layer and a CNN architecture for crop disease recognition."
Ashok Kumar Tripathi,Analgesic activity of synthesized compounds,"In an approach to synthesize some potent benzoxazole derivatives, some compounds were synthesized. The details of these compounds are given below- The structures were confirmed using IR and NMR spectroscopy. The potency of synthesized compounds were established using following pharmacological screening- Analgesic activity  Paw edema- Male or female Wistar rats with a body weight between 100 and 150 g are used. The animals are starved overnight. To insure uniform hydration, the rats receive 5 ml of water by stomach tube (controls) or the test drug dissolved or suspended in the same volume. Thirty minutes later, the rats are challenged by a subcutaneous injection of 0.05 ml of 1% solution of carrageenan into the plantar side of the left hind paw. The paw is marked with ink at the level of the lateral malleolus and immersed in mercury up to this mark. The paw volume is measured plethysmographically immediately after injection, again 3 and 6 h, and eventually 24 h after challenge. [3] Analgesic activity Writhing tests- Mice of either sex with a weight between 20 and 25 g are used. Acetic acid in a concentration of 1% (1ml/kg) is used to produce writhing. An aliquot of 0.025 ml of this suspension is injected intraperitoneally. Groups of 6 animals are used for controls and treated mice. Preferably, two groups of 6 mice are used as controls. Test animals are administered the drug or the standard at various pretreatment times prior to Acetic acid administration. The mice are placed individually into glass beakers and five min are allowed to elapse. The mice are then observed for a period of ten min and the number of writhes is recorded for each animal. For scoring purposes, a writhe is indicated by stretching of the abdomen with simultaneous stretching of at least one hind limb. The formula for computing percent inhibition is: average writhes in the control group minus writhes in the drug group divided by writhes in the control group times 100%. The time period with the greatest percent of inhibition is considered the peak time. A dose range is reserved for interesting compounds or those which inhibit writhing more than 70%. Compounds with less than 70% inhibition are considered to have minimal activity. [4] Microbiological screening For both antibacterial and assay compounds were dissolved in absolute ethanol (0.8 mg/ml). Further dilutions of the compounds and standard drugs in the test medium have concentrations of 400, 200, 100, 50, 25, 12.5, 6.25, 3.12, 1.56, 0.78 mg/ml. The minimum inhibitory concentrations (MIC) were determined using the method of two-fold serial dilution. In order to ensure that the solvent ‘per se’ had no effect on bacterial growth, a control test was also performed containing inoculated broth supplemented with only ethanol at the same dilutions used in our experiments and found inactive in culture medium. Antibacterial assay- The cultures were obtained in Nutrient agar broth (Difco) for all the bacteria after 24 h of incubation at 37+1°C. Testing was carried out in Nutrient agar broth at pH 7.4 and the two-fold serial dilution technique was applied. The final inoculums size was 105 CFU/ml. A set of tubes containing only inoculated broth was kept as controls. Ciprofoxacine was taken as standard. After incubation for 24 h at 37+1°C, the last tube with no growth of microorganism was recorded to represent MIC expressed in g/ml. [5]","pharmacological screening, Benzoxazole, benzoxazole derivatives, antibacterial assay, Anti-inflammatory activity, Analgesic activity, Microbiological screening","The study aimed to synthesize potent benzoxazole derivatives and evaluate their analgesic activity using pharmacological screening. The compounds were synthesized and their structures confirmed using IR and NMR spectroscopy. The potency of the synthesized compounds was established using analgesic activity tests, including paw edema and writhing tests. The results showed that some of the compounds exhibited significant analgesic activity, with one compound showing 63.33% inhibition at a dose of 30 mg/kg. The study also evaluated the antibacterial activity of the compounds using the two-fold serial dilution technique and found that some of the compounds exhibited significant antibacterial activity. The study concluded that the synthesized compounds have potential as analgesic and antibacterial agents."
Atreya Kala,Analyzing emotion based movie recommender system using fuzzy emotion features,"User generated contents like reviews and comments contain both the information about a given product and also the opinions asserted by the user. With the surge in internet usage, there is a cascade of user generated data such a reviews and comments. People share their experiences, opinions, sentiments and emotions by writing reviews and comments for products they purchase online or after watching a movie, reading books etc. These user generated data contains emotion lexicons such as happiness, sadness, and surprise. Analysis of such emotion can provide a new aspect for recommending new items based on their emotional preferences. In this work, we extract the emotions from this user generated data using the lexical ontology, WordNet and information from the domain of psychology. These extracted emotions can be used for recommendations. Evaluation on emotion prediction further verifies the effectiveness of the proposed model in comparison to traditional rating based item similarity model. We further compare this with fuzziness in emotion features.","WorldNet, Collaborative recommender system, emotion based recommendation, top N recommendation, Emotion analysis, Content based recommender system, movie recommendation","This paper proposes a new item based recommender system using both CF and CBF based approaches to recommend items using emotions. Emotions are extracted from user generated data using lexical ontology, WordNet and information from the domain of psychology. The extracted emotions are used for recommendations and evaluated on emotion prediction. The proposed model is compared with traditional rating based item similarity model and fuzziness in emotion features."
Atul Gupta,Regression Testing of Web Service with AWSCM,"Web service changes are the reason to perform monitoring and retesting of WS. To reduce effort of monitoring and retesting, an automated engineering is required for identifying changes (diff). Changes in any document, program, product and WS could be in three ways: deleted, inserted or modified for achieving these requirement; this paper proposed four types of  WSDL’s  i.e.  (D/U/R/C) WSDL. Firstly, DWSDL can be defined as WSDL constructed from the diff between two versions  of  WSDL,  changes  at  WSDL’s  level  are mapped by some standard automated change identifying tool. For example operation3 in Fig. 1, is an inserted operation between two subsequent versions of WS. Secondly, RWSDL can be defined as WSDL constructed by user selective operations of WSDL. Thirdly, UWSDL can be defined as WSDL which is constructed with the operation undergone through change in code level. Fourthly, CWSDL can be defined as WSDL which is constructed with the operations in (D/U/R) WSDL such that it contains only unique and non-redundant operations (i.e. remove redundant operations in (D/U/R) WSDL). Automatically gathering changes at WSDL and code (logical statement) level helps in effort reduction in RTWS. If the changes to the WS are at the code level then changes are either reflected or not reflect on the WSDL in Table I. First if change reflected on WSDL, then they can be captured by (D/R) WSDL and they are especially helpful whenever tester   is   exposed   only   to   the   WSDL’s  and   do  not  have  any   details of WS code. Limitation with (D/R) WSDL is that they do not identify the changes at logical code level. But still, tester requires performing code change based regression testing which can be done by using UWSDL. Second if coding changes are done to the WS which are not reflected on the WSDL, then they can be captured by UWSDL. By using UWSDL constructed automatically by AWSCM tester can perform code based RTWS efficiently.","web service testing, Web service, WSDL, web service change management, regression testing","This paper proposes a framework called AWSCM (Automated Web Service Change Management) for efficient regression testing of web services. AWSCM utilizes four types of WSDLs: DWSDL (Difference WSDL), RWSDL (Reduced WSDL), UWSDL (Updated WSDL), and CWSDL (Combined WSDL) to capture changes at different levels (WSDL and code). It leverages tools like JDiff, Predic8, and Regex to identify and map changes, enabling testers to generate targeted test cases for regression testing. The framework aims to reduce the effort and cost associated with regression testing by automating the process of change identification and test case generation."
Aurobinda Bag,An Adaptive Sliding Mode Control Scheme for Grid Integration of a PV System ||| A Combined Reinforcement Learning and Sliding Mode Control Scheme for Grid Integration of a PV System,"This paper presents an adaptive sliding mode control scheme for grid integration of a PV system. The proposed scheme is compared with the SMC-IC-IPT scheme and the results show that the ASMC-IC-IPT scheme reduces the grid current THD from 29.35% to 2.80%. ||| The paper presents development of a reinforcement learning (RL) and sliding mode control (SMC) algorithm for a 3-phase PV system integrated to a grid. The PV system is integrated to grid through a voltage source inverter (VSI), in which PV-VSI combination supplies active power and compensates reactive power of the local non-linear load connected to the point of common coupling (PCC). For extraction of maximum power from the PV panel, we develop a RL based maximum power point tracking (MPPT) algorithm. The instantaneous power theory (IPT) is adopted for generation reference inverter current (RIC). An SMC algorithm has been developed for injecting current to the local non-linear load at a reference value. The RL-SMC scheme is implemented in both simulation using MATLAB/SIMULINK software and on a prototype PV experimental. The performance of the proposed RL-SMC scheme is compared with that of fuzzy logic-sliding mode control (FL-SMC) and incremental conductance-sliding mode control (IC-SMC) algorithms. From the obtained results, it is observed that the proposed RL-SMC scheme provides better maximum power extraction and active power control than the FL-SMC and IC-SMC schemes.","grid synchronization, Sliding Mode Control, Lyapunov function, total harmonic distortion, PV System, reinforcement learning, Grid Integration, Maximum Power Point Tracking, instantaneous power theory, incremental conductance, Adaptive sliding mode control, Fuzzy logic, sliding mode controller","This paper presents an Adaptive Sliding Mode Control (ASMC) algorithm for grid synchronization of a photovoltaic (PV) system. The ASMC algorithm minimizes the difference between the reference inverter current and the actual inverter current of the grid connected PV system during unbalanced loading, grid voltage distortion and variation in solar irradiance. ||| This paper presents a combined reinforcement learning and sliding mode control scheme for grid integration of a PV system. The proposed scheme uses a reinforcement learning based maximum power point tracking algorithm and a sliding mode control algorithm to inject current to the local non-linear load at a reference value. The performance of the proposed scheme is compared with that of fuzzy logic-sliding mode control and incremental conductance-sliding mode control schemes."
Author Name,Detecting Stealth DHCP Starvation Attack using Machine Learning Approach ||| Towards Seamless Authentication for Zoom-Based Online Teaching and Meeting,"Dynamic Host Configuration Protocol (DHCP) is used to automatically configure clients with IP address and other network configuration parameters. Due to absence of any in-built authentication, the protocol is vulnerable to a class of Denial-of-Service (DoS) attacks, popularly known as DHCP starvation attacks. ||| This paper proposes a seamless authentication scheme for Zoom-based online meetings using PRNU-based camera authentication. The proposed method authenticates meeting participants using their camera fingerprints, eliminating the need for passwords or biometric authentication. A small-scale experiment demonstrates the feasibility of the proposed method, but a large-scale experiment is required to determine its error rates.","PRNU-based source camera attribution, Stealth DHCP starvation attack, Video conferencing, One-class Classifiers, Anomaly Detection, PRNU-based camera authentication, DHCP Starvation Attack, seamless authentication, Zoom-based online meetings, IPv4 networks, camera fingerprints, Online meeting and teaching, DHCPv6, Machine learning approach, IPv6 networks, DHCP","The proposed attack is a stealth DHCP starvation attack that can be launched in both IPv4 and IPv6 networks. The attack is easier to launch and stealthier as compared to previously known starvation attacks. The proposed attack does not require MAC address spoofing and can be launched in wireless networks. ||| This paper proposes a preliminary work towards a seamless authentication mechanism for Zoom-based teaching and meeting. The proposed method is based on PRNU (Photo Response Non Uniformity)-based camera authentication, which can authenticate the camera of a device used in a Zoom meeting without requiring any assistance from the participants."
Author Not Specified,Analysis of Wireless Sensor Networks ||| Induced DHCP Starvation Attack,"This paper presents an analysis of wireless sensor networks, focusing on the impact of flooding protocols on energy consumption and node involvement. The study compares pure and controlled flooding in binary and nested tree networks, highlighting the effects of depth and interval values on total energy wasted and nodes unnecessarily involved. ||| Dynamic Host Configuration Protocol (DHCP) is used by clients in a network to configure their interface with IP address and other network configuration parameters such as Default Gateway and DNS server IP addresses. This protocol is vulnerable to a Denial of Service (DoS) attack popularly known as classic DHCP starvation attack. In this paper, we make threefold contribution. First, we highlight the practical difficulty in generating classic DHCP starvation attack in wireless networks. Secondly, we propose a stealth starvation attack which is effective in wireless networks, easier to launch, requires fewer number of messages to be transmitted and difficult to detect by known detection methods. We also show a structurally similar attack in IPv6 networks which can affect address configuration protocols such as DHCPv6 and StateLess Address Autoconfiguration (SLAAC). Subsequently, we also describe an anomaly detection method to detect the proposed attack. We design and generate the attacks in a real network setup and report the results. The proposed detection method use the Hellinger distance between two probability distributions generated from training and testing data to detect starvation.","malicious client, 802.11 Wi-Fi Network, Energy Efficiency, Pure Flooding, Flooding Protocols, Wireless Sensor Networks, Energy Consumption, DHCP Starvation Attack, SLAAC, ARP spoofing, DHCP, Node Involvement, DHCPv6, ARP Poisoning, Controlled Flooding, Hellinger Distance, Routing","The paper explores the limitations of wireless sensor networks and proposes solutions to mitigate energy waste and node involvement. The study provides simulation results for binary and nested tree networks, demonstrating the impact of depth and interval values on total energy wasted and nodes unnecessarily involved. ||| This paper proposes a new DHCP starvation attack termed as Induced DHCP Starvation that does not require a malicious client to inject large number of IP request messages using random MAC addresses to exhaust IP address pool. Instead, the attack is intended to exploit a loophole present in DHCP client-side IP address conflict detection scheme. The proposed attack is equally effective in both wired and wireless networks and can affect address configuration protocols such as DHCPv6 and SLAAC. A statistical abnormality measurement technique is proposed to detect starvation using the Hellinger distance between two probability distributions generated from training and testing data."
Author not specified,A Novel Network Architecture for Cognitive Wireless Sensor Network ||| Event-Triggered Distributed Optimization Scheme for Economic Dispatch ||| Sparse Decomposition Framework for Maximum Likelihood Classiﬁcation under Alpha-Stable Noise,"Recent advances in wireless communications and electronics have enabled the development of low cost, low power, multi-functional sensor nodes that are small in size. These nodes coordinate to perform distributed sensing in various fields such as health, military, home etc. But these small devices in Wireless Sensor Network (WSN) are still limited with some constrains, and efforts are required to increase the lifetime and other performance measures of the network. ||| To reduce information exchange requirements in smart grids, an event-triggered communication based distributed optimization is proposed for economic dispatch. In this work, the θ-logarithmic barrier based method is employed to reformulate the economic dispatch problem and the consensus based approach is considered for developing fully distributed technology-enabled algorithms. ||| Abstract—Recently, automatic modulation classiﬁcation has gained a lot of attention in the area of cognitive radio (CR), signal detection, electronic warfare and surveillance etc. Most of the existing modulation classiﬁcation algorithms are developed based on the assumption that the received signal to be identiﬁed is corrupted by only additive white Gaussian noise. The performances of these conventional algorithms degrade signiﬁcantly by addition of impulse noise. In this paper, we propose a robust algorithm using sparse signal decomposition which comprises of an overcomplete dictionary for detection and classiﬁcation of modulated signals. In this work, an overcomplete dictionary is constructed using the identity basis, cosine and sine elementary waveforms to capture morphological components of the impulse noise and deterministic modulated signals effectively. The proposed method of modulation classiﬁcation consists of the three major steps: sparse signal decomposition (SSD) on hybrid dictionaries, modulated signal extraction, and maximum likelihood (ML) based classiﬁcation. The testing and validation of both direct ML and SSD-based ML classiﬁcation methods are carried out under different Gaussian and impulse noise conditions for modulation classiﬁcation. Our proposed method achieves a classiﬁcation accuracy of 85% at 5 dB SNR and outperforms the conventional classiﬁcation methods.","Maximum likelihood classiﬁcation, Cognitive WSN, tree construction, Fast gradient method, leveling, α-stable noise, event-triggered, sensor network, sectoring, Event-triggered distributed optimization, Wireless Sensor Network, distributed optimization, MSTs, Modulation classiﬁcation, Overcomplete dictionary, Gaussian noise, Dynamic Spectrum Access, Sparse representation, Cognitive Radio, clustering, Architecture, Impulse noise, fast gradient, Maximum likelihood, Digital modulation classification, Prim's algorithm, TDMA, economic dispatch, Distributed consensus algorithm, minimum connected dominating set","The paper presents a method for constructing a sensor network, including sectoring, leveling, clustering, and tree construction. The authors propose a technique for interconnecting MSTs between neighboring sectors and discuss routing and data transmission using TDMA schedules. ||| This paper proposes a distributed event-triggered scheme for economic dispatch in smart grids. The scheme reduces information exchange requirements and employs a θ-logarithmic barrier based method to reformulate the economic dispatch problem. The consensus based approach is used to develop fully distributed technology-enabled algorithms. The scheme is evaluated using the IEEE 57-bus test system and demonstrates good performance and effectiveness. ||| This paper proposes a robust algorithm for automatic modulation classiﬁcation using sparse signal decomposition under alpha-stable noise. The proposed method consists of three major steps: sparse signal decomposition, modulated signal extraction, and maximum likelihood based classiﬁcation. The algorithm achieves a classiﬁcation accuracy of 85% at 5 dB SNR and outperforms conventional classiﬁcation methods."
Author's Name,2DCrypt: Image Scaling and Cropping in Encrypted Domains ||| Adversarial Alignment Framework for Unsupervised Domain Adaptation ||| Analysis of various ARP Poisoning mitigation techniques : A comparison ||| A Novel Technique for Recognizing Modulation Type in the Presence of Non-Gaussian Noise ||| A Reliable Energy-Efficient Pressure-Based Routing Protocol for Underwater Wireless Sensor Network ||| A Robust Watermarking Approach for Non Numeric Relational Database ||| A Scheme for Robust Biometric Watermarking in Web Databases for Ownership Proof with Identification ||| COMPUTATIONAL PROPERTIES AND CONVERGENCE ANALYSIS OF BPNN FOR CYCLIC AND ALMOST CYCLIC LEARNING WITH PENALTY ||| ECM Based Imputation for Missing Data ||| Exponential Spider Monkey Optimization for Feature Selection in Plant Disease Identification ||| Formal Ontology of Punctuators ||| Full-Duplex eNodeB and UE Design for 5G Networks ||| Sparse Representation for Blind Spectrum Sensing in Cognitive Radio: A Compressed Sensing Approach ||| SVM based Methods for Arrhythmia Classification in ECG ||| Tailoring the resonant modes in liquid crystal based all-dielectric metasurfaces,"The evolution of cloud computing and a drastic increase in image size are making the outsourcing of image storage and processing an attractive business model. Although this outsourcing has many advantages, ensuring data confidentiality in the cloud is one of the main concerns. There are state-of-the-art encryption schemes for ensuring confidentiality in the cloud. However, such schemes do not allow cloud datacenters to perform operations over encrypted images. In this paper, we address this concern by proposing 2DCrypt, a modified Paillier cryptosystem-based image scaling and cropping scheme for multi-user settings that allows cloud datacenters to scale and crop an image in the encrypted domain. ||| This paper proposes a novel adversarial alignment framework for unsupervised domain adaptation. The framework learns shared hidden representations while matching the distributions between the source and target data via some distance metric. ||| Address Resolution Protocol (ARP) is the fundamental and one of the most frequently used protocol involved in computer communications. Within a LAN, ARP messages are used to resolve IP addresses into corresponding MAC addresses.Nevertheless, some of the limitations within this protocol make it rather vulnerable. The two most prominent limitations are - unauthenticated and stateless nature of ARP. The attackers can easily exploit these loopholes for their personal gain. ARP poisoning is considered as unitary of the basic attacks which is utilized to launch higher level attacks. ||| In recent years, automatic signal detection and modulation classiﬁcation play a vital role in the ﬁeld of cognitive radio applications. The majority of the existing signals detection and classiﬁcation methods assume that the received signal is contaminated by additive white Gaussian noise. Under impulsive noise condition, the performance of the traditional modulation classiﬁcation methods may be degraded. Therefore, in this paper, we investigate the application of sparse signal decomposition using an overcomplete dictionary for detection and classiﬁcation of digital modulation signals. ||| Underwater wireless sensor networks (UWSNs) are similar to the terrestrial sensor networks. Nevertheless, there are different characteristics among them such as low battery power, limited bandwidth and high variable propagation delay. One of the common major problems in UWSNs is determining an efficient and reliable routing between the source node and the destination node. Therefore, researchers tend to design efficient protocols with consideration of the different characteristics of underwater communication. Furthermore, many routing protocols have been proposed and these protocols may be classified as location-based and location-free routing protocols. Pressure-based routing protocols are a subcategory of the location-free routing protocols. This paper focuses on reviewing the pressure-based routing protocols that may further be classified into non-void avoidance protocols and void avoidance protocols. Moreover, non-void avoidance protocols have been classified into single factor based and multi factor based routing protocols. Finally, this paper provides a comparison between these protocols based on their features, performance and simulation parameters and the paper concludes with some future works on which further study can be conducted. ||| This paper proposes a novel robust method for watermarking non-numeric attributes in databases. The approach embeds a vowel in the attributes depending upon the key value generated. Experimental results show that the method maintains integrity of the database even under various attacks. ||| We propose a robust technique for watermarking relational databases using voice as a biometric identifier of ownership. The choice of voice as the distinguishing factor is influenced by its uniqueness, stability, universality and ease of use. The watermark is generated by creating a statistical model of the features extracted from the owner’s voice. This biometric watermark is then securely embedded into selected positions of the fractional parts of selected numeric attributes using a reversible bit encoding technique. In case of a dispute regarding true ownership, the relative scores of the extracted watermark are generated by comparing features of the disputed voices with the extracted one. ||| This paper presents a convergence analysis of cyclic and almost cyclic learning of BP with penalty. The authors propose two algorithms, CBP-P and ACBP-P, and prove their convergence properties. The results show that the learning sequence generated by these algorithms is uniformly bounded and satisfies the weak convergence. ||| This paper presents a novel approach for imputing missing data using the Expectation-Maximization (ECM) algorithm. The proposed method is based on clustering the complete records and imputing the missing values by the corresponding values of the attribute in the center of the nearest cluster. ||| Agriculture is one of the prime sources of economy and a large community is involved in cropping various plants based on the environmental conditions. However, a number of challenges are faced by the farmers including different diseases of plants. The detection and prevention of plant diseases are the serious concern and should be treated well on time for increasing the productivity. Therefore, an automated plant disease detection system can be more beneficial for monitoring the plants. ||| This paper presents a formal ontology of punctuators, which are used to define the relationships between entities. The ontology is based on three basic punctuators: self-linking, inseparable, and separable. The paper also introduces the concept of abstract of punctuator, which maps the relational context of a punctuator to two abstract entities. ||| This paper proposes a successive interference cancellation with optimal ordering (SSIC-OO) algorithm for uplink and downlink operation in multiple antenna systems. The algorithm estimates the user signal by iteratively canceling out the effect of the strongest user signal from the overall received signal. ||| This paper investigates the spectrum sensing problem for noisy primary user signals using compressed sensing. The proposed method is based on the fact that the signal components on different receive antennas are correlated, while the noise components are uncorrelated. The method reconstructs the noise signals using OMP and other recovery algorithms, and then calculates the cross-correlation between noise-corrupted signals at multiple receive antennas. The large noise terms are removed, enabling signal detection. ||| This paper presents a multiclass classification algorithm using support vector machines (SVMs). The algorithm is applied to the standard multivariate ECG dataset taken from the University of California at Irvine (UCI) Cardiac Arrhythmias database. The results show that the one-against-all algorithm shows the highest percentage of accuracy rate. ||| High refractive index dielectic metasurfaces are being increasingly studied for their novel light-matter interactions such as Huygen’s lens, absolute transmission and complete absorption. Liquid crystal is a versatile medium with high dielectric anisotropy and hence interaction of light with the dielectric metasurfaces immersed in liquid crystal medium show complex behaviour compared to isotropic media. Most of the investigations on liquid crystal based electromagnetic response of dielectric metasurfaces focus on tunability of resonant frequencies and switching between the resonant states as a function of external stimuli such as electric field, temperature, etc. In the current work we present a detailed investigation of scattering response, near-ﬁeld and far-ﬁeld radiation proﬁles of cubic Tellurium metasurfaces as a function of liquid crystal orientations in infrared frequencies. We show that the near-ﬁeld and far-ﬁeld radiation proﬁles of primary resonant modes - electric dipoles and magnetic dipoles reorient as a function of liquid crystal orientations. In particular, we study the effect of liquid crystal orientations on novel non-radiative states called anapoles. It is observed that liquid crystal orientations effect the excitation and orientation of anapole states within the Tellurium structures. This paves way for design of an electrically-driven switch between non-radiative and radiative states. Further, controlling the near-ﬁeld and far-ﬁeld radiation proﬁles opens up possibilities in designing liquid crystal based tunable multi-functional metasurfaces which can change the directionality of incident light.","Evolving Clustering Method, Image Outsourcing, Energy Consumption, Orthogonal Matching Pursuit, multipole analysis, BP, non-numeric attributes, Space-Efficient Tiling Scheme, Vaiśesika, Communication Void, watermarking, convergence analysis, anapoles, Relationships, Security, maximum likelihood classification, Missing Data, Optimal Ordering, Hacking, Cognitive Radio, clustering, 5G, Imputation, Adversarial Alignment, Scaling and Cropping Operations, Cyclic, metasurfaces, Punctuators, OFDMA, 2DCrypt, Support vector machine, Classification, Routing Protocols, Compressed Sensing, Generative Ontology, Spider Monkey Optimization, MMSE, Spectrum Sensing, cyclic learning, near-ﬁeld radiation, ECG Database, Full-Duplex, Backpropagation, Exponential Spider Monkey Optimization, Void Avoidance Routing Protocols, Arrhythmias, Cyber Defense, Classiﬁers, Voice Biometrics, Punctuator, maximum likelihood classiﬁcation, Successive Interference Cancellation, Entities, noisy primary user signals, Subtractive Pixel Adjacency Model, Te metasurface, Reliability, Network Security, far-ﬁeld radiation, electromagnetic response, Relational Database, Non Numeric Attributes, Non-Avoidance Routing Protocols, Unsupervised Domain Adaptation, Multiclass Classification, Single Factor Based Routing Protocols, Graph Grammar, SVD, databases, Plant Disease Identification, dielectric metasurfaces, Linear Prediction, Uplink and Downlink Operation, Nature Inspired Algorithm, Optimization, non-Gaussian noise, Pressure Based Routing Protocols, secure data hiding, almost cyclic learning, Multiple Antenna Systems, Pressure Sensors, Almost cyclic, Local Learning, Formal Ontology, Insider Threats, modulation type recognition, sparse signal decomposition, Convergence, Multi Factor Based Routing Protocols, Generative Grammar, SPAM, UWSNs, digital modulation, Ownership Protection, Man-In-The-Middle, sparse separation, SIC, cryptography-based schemes, mitigation schemes, SC-FDMA, Secure Image Processing, Weight decay, kernel-based patches, Deep Neural Networks, Digital Watermarking, ECM, Support Vector Machines, SSIC-OO, Electrocardiogram, liquid crystal, Hidden Image Processing, Paillier Cryptosystem, Encrypted Scaling and Cropping, Feature Selection, IP Exhaustion, Relational Databases, penalty term, Underwater Wireless Sensor Network, ARP Poisoning, Address Resolution Protocol, Robust Watermarking","This paper proposes 2DCrypt, a modified Paillier cryptosystem-based image scaling and cropping scheme for multi-user settings that allows cloud datacenters to scale and crop an image in the encrypted domain. The scheme is designed to ensure data confidentiality in the cloud and to allow cloud datacenters to perform operations over encrypted images. The paper also presents an analysis and results that show that 2DCrypt is IND-CPA secure and incurs an acceptable overhead. ||| The proposed framework consists of three alternating steps: training the source classifier, adversarial adaptation, and centroid alignment. The framework aligns the conditional distributions of the domains using pseudo-labels of the target samples, reducing the impact of noise on the alignment. ||| The paper presents a comprehensive analysis of various mitigation schemes for ARP poisoning attacks, highlighting their strengths and weaknesses. The schemes are evaluated based on five key factors, including resistance to flooding of spoofed ARP messages, IP Exhaustion problem, backward compatibility with existing network infrastructure, single point of failure problem, and compatibility with IP Aliasing configurations. ||| The proposed method is effective in recognizing the modulation type in the presence of non-Gaussian noise. The SS stage uses an overcomplete dictionary to separate the modulated signal and impulse noise, and the ML classification stage identifies the modulation type based on the probability of given set of modulation schemes. ||| This paper reviews the pressure-based routing protocols for underwater wireless sensor networks, which are a subcategory of location-free routing protocols. The paper provides a comparison between these protocols based on their features, performance, and simulation parameters, and concludes with some future works on which further study can be conducted. ||| The proposed method is robust against various attacks, including subset deletion, addition, and modification attacks. The experimental results show that the method maintains integrity of the database even under these attacks, making it suitable for real-world applications. ||| This paper proposes a robust biometric watermarking technique for relational databases using voice as a biometric identifier of ownership. The technique generates a statistical model of the features extracted from the owner’s voice and securely embeds it into the database using a reversible bit encoding technique. The paper demonstrates the robustness of the technique against various attacks and shows that it can identify the correct owner even when 60% of the watermark suffers degradation. ||| The paper presents a convergence analysis of two algorithms, CBP-P and ACBP-P, which are used for cyclic and almost cyclic learning of BP with penalty. The authors prove that the learning sequence generated by these algorithms is uniformly bounded and satisfies the weak convergence. ||| The paper discusses the problem of missing data in various disciplines and proposes an Evolving Clustering Method (ECM) based imputation method. The authors performed sensitivity analysis of the influence of threshold value (Dthr) on imputation results over 12 datasets and compared the performance of ECM with K-Means+MLP. ||| This paper introduces a novel exponential spider monkey optimization which is employed to fix the significant features from high dimensional set of features generated by SPAM. The selected features are fed to support vector machine for classification of plants into diseased plants and healthy plants using some important characteristics of the leaves. ||| The paper presents a formal ontology of punctuators, which are used to define the relationships between entities. The ontology is based on three basic punctuators: self-linking, inseparable, and separable. The paper also introduces the concept of abstract of punctuator, which maps the relational context of a punctuator to two abstract entities. ||| The proposed SSIC-OO algorithm is designed to estimate the user signal by iteratively canceling out the effect of the strongest user signal from the overall received signal. The algorithm calculates the received power for all users and estimates the user signal with the highest power. The estimated signal is then used to cancel out its effect from the overall received signal, and the process is repeated until all user signals are estimated. ||| The paper presents a novel spectrum sensing algorithm for noisy primary user signals using compressed sensing. The algorithm is based on the correlation between signal components on different receive antennas and the uncorrelated nature of noise components. The method reconstructs the noise signals using OMP and other recovery algorithms, and then calculates the cross-correlation between noise-corrupted signals at multiple receive antennas. ||| The paper presents a study on the use of Support Vector Machine (SVM) based methods for classifying electrocardiogram (ECG) arrhythmias. The authors used three well-known SVM methods, one-against-one, one-against-all, and fuzzy decision function, to distinguish between the presence and absence of cardiac arrhythmia and classify them into one of the arrhythmia groups. ||| This work presents a detailed investigation of the effect of liquid crystal orientations on the electromagnetic response, near-ﬁeld and far-ﬁeld radiation of cubic Tellurium metasurfaces. The study shows that the near-ﬁeld and far-ﬁeld radiation proﬁles of primary resonant modes reorient as a function of liquid crystal orientations, and that liquid crystal orientations effect the excitation and orientation of anapole states within the Tellurium structures. The results pave the way for design of an electrically-driven switch between non-radiative and radiative states, and open up possibilities in designing liquid crystal based tunable multi-functional metasurfaces."
Author's name not specified,"A ﬁngerprint based crypto-biometric system for secure communication ||| Collaborative Pairing in Learning Systems ||| FUTURISTIC TRENDS AND INNOVATIONS IN MULTIMEDIA SYSTEMS USING BIG DATA, IOT AND CLOUD TECHNOLOGIES (FTIMS) ||| Intelligent System for Classroom Studies and Dynamic Environment ||| Investigating Approaches for Improving Security in Remote User Authentication Schemes for IoT Paradigm","To ensure the secure transmission of data, cryptography is treated as the most eﬀective solution. Cryptographic key is an important entity in this procedure. In general, randomly generated cryptographic key (of 256 bits) is diﬃcult to remember. However, such a key needs to be stored in a protected place or transported through a shared communication line which, in fact, poses another threat to security. As an alternative, researchers advocate the generation of cryptographic key using the biometric traits of both sender and receiver during the sessions of communication, thus avoiding key storing and at the same time without compromising the strength in security. ||| We propose an innovative approach of pairing learners in competitive and complementary way based on the learner’s learning skills. Students are assessed to determine their inherent learning skills and after their assessment; students are paired up for collaborative learning. ||| Image segmentation is an essential phase of computer vision in which useful information is extracted from an image that can range from finding objects while moving across a room to detect abnormalities in a medical image. As image pixels are generally unlabelled, the commonly used approach for the same is clustering. This paper reviews various existing clustering based image segmentation methods. Two main clustering methods have been surveyed, namely hierarchical and partitional based clustering methods. As partitional clustering is computationally better, further study is done in the perspective of methods belonging to this class. Further, literature bifurcates the partitional based clustering methods into three categories, namely K-means based methods, histogram-based methods, and meta-heuristic based methods. The survey of various performance parameters for the quantitative evaluation of segmentation results is also included. Further, the publicly available benchmark datasets for image-segmentation are briefed. ||| The paper discusses an intelligent system that links classroom studies to a dynamic environment. The system extracts relevant information from handwritten notes and images, and uses a Mutual Influence Factor (MIF) to filter search results. The system was tested with notes and images of students studying operating systems and high performance computing, and the results showed that the system was able to provide relevant information to the students. ||| Internet of Things (IoT) is a network of interconnected tiny resource constraint devices. These devices can be sensors, actuators, gateways or other microcontrollers and microprocessors. An intra-device communication (a.c.a. Machine to Machine Communication (M2M)), as well as an inter-device communication in the IoT, must be protected from both, active and passive attackers. Traditional cryptography protocols (i.e. RSA or DES or AES) provides well suited reliable security mechanism in the current internet topology that is built up using highly resource capable devices such as computers and servers. Fundamental different between internet cryptography and IoT cryptography lies in types of devices used to build up the topology. The internet is built up using resource capable devices such as computers and servers while the IoT network is built up using resource constraint devices such as sensors and actuators. Devices in the IoT suffers from copious limitations such as poor battery backup, less processing capabilities and lower storage capabilities. Hence, it is highly erratic and inept at using traditional internet cryptography in IoT communication.","Benchmark datasets, Search results, Stable Marriages Problem, KLin, Fingerprint, perfect forward secrecy, IoT, crypto-biometric system, Image segmentation, Minutiae, SMP, Dynamic Environment, Collaborative Pairing, Kernighan Lin Algorithm, Template security, secure communication, Biometric security, Revocability, IoT Applications, Mutual Influence Factor, Partitional clustering, Security, Classroom studies, Learning Skills, Secure Lightweight Key Exchange, User-Gateway Paradigm, QC, Clustering methods, Cryptography, Hierarchical clustering, E-learning, Diversity, Image Based Search, Learning Systems, Remote User Authentication, Collaborative Learning, Performance parameters, Intelligent system","This work addresses the concerns of biometric-based cryptographic key generation, including privacy of biometrics, sharing of biometric data, and generating revocable key from irrevocable biometric. A framework for secure communication between two users using fingerprint based crypto-biometric system has been proposed, which ensures the security of biometric data and perfect forward secrecy using session keys. ||| The paper proposes a skill-based pairing scheme for effective collaborations. It assesses learners' learning skills and pairs them up for collaborative learning using the Stable Marriages Problem and the recursive Kernighan-Lin partitioning algorithm. ||| The paper presents a comprehensive review of hierarchical and partitional clustering methods for image segmentation. It highlights the limitations of hierarchical clustering and the advantages of partitional clustering. The paper also presents various clustering methods and discusses their time complexity and accuracy. ||| The system uses a combination of natural language processing and computer vision to extract relevant information from handwritten notes and images. The MIF is used to filter search results and provide relevant information to the students. The system was tested with notes and images of students studying operating systems and high performance computing, and the results showed that the system was able to provide relevant information to the students. ||| The proposed work aims to propose a highly efficient and computationally reliable authentication mechanism for mutually authenticated session key generation between either User - GateWay (U-GW) or between User - GateWay - Sensing device (U-GW-S) in the constrained IoT environment."
Author's personal copy,A comprehensive overview of feature representation for biometric recognition,"The performance of any biometric recognition system heavily dependents on finding a good and suitable feature representation space where observations from different classes are well separated. Unfortunately, finding this proper representation is a challenging problem which has taken a huge interest in machine learning and computer vision communities. In the this paper we present a comprehensive overview of the different existing feature representation techniques. This is carried out by introducing simple and clear taxonomies as well as effective explanation of the prominent techniques. This is intended to guide the neophyte and provide researchers with state-of-the-art approaches in order to help advance the research topic in biometrics.","Feature selection, Laplacian Eigenmaps, Dimensionality reduction, Decomposition learning, Feature representation, Locally Linear Embedding, Biometrics, Isomap, nonlinear dimensionality reduction","The paper presents a comprehensive overview of nonlinear dimensionality reduction techniques, highlighting their advantages and limitations. It discusses the local and global approaches, and introduces several widely used techniques, including Isomap, Locally Linear Embedding, and Laplacian Eigenmaps."
Author1,A New Multi-Objective Evolutionary Algorithm ||| A Novel Evaluation Scheme using Formal Concept Analysis ||| Multifactorial Optimization: A Paradigm Inspired by Multifactorial Inheritance ||| Wrapper-Filter Feature Selection Algorithm Using A Memetic Framework,"In this paper we have proposed a new archive based steady state multi-objective genetic algorithm, which performs well, especially in higher dimensional space. An improved archive maintenance strategy has been introduced in this algorithm which is adaptive as well as dynamic in size. The archive maintenance strategy tries to maintain only the set of nondominated solutions in the archive. However, it maintains a minimum size of population when the nondominated solutions are not sufficient to fill the population. In this algorithm we have proposed a new environmental selection and a new mating selection. The mating selection reduces the exploration in less probable search region enhancing the exploitation of existing solutions. A new crossover operator DE-3 has also been proposed in this article. The proposed algorithm has been compared with three other existing multi-objective optimization algorithms NSGA-II, SPEA2 and AbYSS. Our algorithm outperforms the other three algorithms for its better diversity and convergence to true Pareto optimal front. ||| This paper presents a novel approach to automated performance evaluation of students using Formal Concept Analysis (FCA). The proposed system extracts a lattice of formal concepts from a Questions-Skills Table (QST) and uses it to evaluate students' performance in a Student Assessment Table (SAT). The system generates a Performance Table (PT) that shows students' performance in each Performance Parameter (PP). ||| The design of evolutionary algorithms has typically been focused on efficiently solving a single optimization problem at a time. Despite the implicit parallelism of population-based search, no attempt has yet been made to multitask, i.e., to solve multiple optimization problems simultaneously using a single population of evolving individuals. Accordingly, this paper introduces evolutionary multitasking as a new paradigm in the field of optimization and evolutionary computation. We first formalize the concept of evolutionary multitasking and then propose an algorithm to handle such problems. The methodology is inspired by bio-cultural models of multifactorial inheritance, which explain the transmission of complex developmental traits to offspring through the interactions of genetic and cultural factors. Furthermore, we develop a cross-domain optimization platform that allows one to solve diverse problems concurrently. The numerical experiments reveal several potential advantages of implicit genetic transfer in a multitasking environment. Most notably, we discover that the creation and transfer of refined genetic material can often lead to accelerated convergence for a variety of complex optimization functions. ||| This paper presents a hybrid genetic algorithm for feature selection, which combines the strengths of filter and wrapper methods. The algorithm uses a filter ranking method to select the most relevant features and a local search strategy to improve the solution. The authors investigate three different local search strategies and compare their performance on several benchmark and biological datasets.","Discrete Optimization, Constraint handling, genetic algorithms, Evolutionary Algorithms, Multifactorial Inheritance, Assessment, Evolutionary Multitasking, Automated Performance Evaluation, Pareto optimality, Performance Parameters, Memetic Algorithm, Gain Ratio, Filter Ranking Method, Wrapper, Multifactorial Optimization, Evaluation, Archive Truncation Technique, Learning, Filter, Formal Concept Analysis, Genetic Algorithm, Student Assessment, Continuous Optimization, Feature Selection, multi-objective optimization, Memetic Computation, Hybrid Genetic Algorithm, Local Search Strategy, Skills, Multi-Objective Evolutionary Algorithm, DE Crossover Operator, Chi-Square, Relief","This paper proposes a new archive based steady state genetic algorithm that performs well in higher dimensional space. The algorithm introduces an improved archive maintenance strategy, new environmental selection, and new mating selection. It also proposes a new crossover operator DE-3. The algorithm is compared with three existing multi-objective optimization algorithms and outperforms them in terms of diversity and convergence to the true Pareto optimal front. ||| The paper presents a novel evaluation scheme for a course that focuses on the various sets of learning skills required for each concept of the course. It employs Formal Concept Analysis on a complete set of questions prepared by experts covering all the concepts of a given course. ||| This paper introduces evolutionary multitasking as a new paradigm in the field of optimization and evolutionary computation. It proposes an algorithm to handle multiple optimization problems simultaneously using a single population of evolving individuals, inspired by bio-cultural models of multifactorial inheritance. The numerical experiments reveal several potential advantages of implicit genetic transfer in a multitasking environment. ||| The paper proposes a hybrid genetic algorithm for feature selection, which combines the strengths of filter and wrapper methods. The algorithm uses a filter ranking method to select the most relevant features and a local search strategy to improve the solution. The authors investigate three different local search strategies and compare their performance on several benchmark and biological datasets."
Author2,A New Multi-Objective Evolutionary Algorithm ||| A Novel Evaluation Scheme using Formal Concept Analysis ||| Multifactorial Optimization: A Paradigm Inspired by Multifactorial Inheritance ||| Wrapper-Filter Feature Selection Algorithm Using A Memetic Framework,"In this paper we have proposed a new archive based steady state multi-objective genetic algorithm, which performs well, especially in higher dimensional space. An improved archive maintenance strategy has been introduced in this algorithm which is adaptive as well as dynamic in size. The archive maintenance strategy tries to maintain only the set of nondominated solutions in the archive. However, it maintains a minimum size of population when the nondominated solutions are not sufficient to fill the population. In this algorithm we have proposed a new environmental selection and a new mating selection. The mating selection reduces the exploration in less probable search region enhancing the exploitation of existing solutions. A new crossover operator DE-3 has also been proposed in this article. The proposed algorithm has been compared with three other existing multi-objective optimization algorithms NSGA-II, SPEA2 and AbYSS. Our algorithm outperforms the other three algorithms for its better diversity and convergence to true Pareto optimal front. ||| This paper presents a novel approach to automated performance evaluation of students using Formal Concept Analysis (FCA). The proposed system extracts a lattice of formal concepts from a Questions-Skills Table (QST) and uses it to evaluate students' performance in a Student Assessment Table (SAT). The system generates a Performance Table (PT) that shows students' performance in each Performance Parameter (PP). ||| The design of evolutionary algorithms has typically been focused on efficiently solving a single optimization problem at a time. Despite the implicit parallelism of population-based search, no attempt has yet been made to multitask, i.e., to solve multiple optimization problems simultaneously using a single population of evolving individuals. Accordingly, this paper introduces evolutionary multitasking as a new paradigm in the field of optimization and evolutionary computation. We first formalize the concept of evolutionary multitasking and then propose an algorithm to handle such problems. The methodology is inspired by bio-cultural models of multifactorial inheritance, which explain the transmission of complex developmental traits to offspring through the interactions of genetic and cultural factors. Furthermore, we develop a cross-domain optimization platform that allows one to solve diverse problems concurrently. The numerical experiments reveal several potential advantages of implicit genetic transfer in a multitasking environment. Most notably, we discover that the creation and transfer of refined genetic material can often lead to accelerated convergence for a variety of complex optimization functions. ||| This paper presents a hybrid genetic algorithm for feature selection, which combines the strengths of filter and wrapper methods. The algorithm uses a filter ranking method to select the most relevant features and a local search strategy to improve the solution. The authors investigate three different local search strategies and compare their performance on several benchmark and biological datasets.","Discrete Optimization, Constraint handling, genetic algorithms, Evolutionary Algorithms, Multifactorial Inheritance, Assessment, Evolutionary Multitasking, Automated Performance Evaluation, Pareto optimality, Performance Parameters, Memetic Algorithm, Gain Ratio, Filter Ranking Method, Wrapper, Multifactorial Optimization, Evaluation, Archive Truncation Technique, Learning, Filter, Formal Concept Analysis, Genetic Algorithm, Student Assessment, Continuous Optimization, Feature Selection, multi-objective optimization, Memetic Computation, Hybrid Genetic Algorithm, Local Search Strategy, Skills, Multi-Objective Evolutionary Algorithm, DE Crossover Operator, Chi-Square, Relief","This paper proposes a new archive based steady state genetic algorithm that performs well in higher dimensional space. The algorithm introduces an improved archive maintenance strategy, new environmental selection, and new mating selection. It also proposes a new crossover operator DE-3. The algorithm is compared with three existing multi-objective optimization algorithms and outperforms them in terms of diversity and convergence to the true Pareto optimal front. ||| The paper presents a novel evaluation scheme for a course that focuses on the various sets of learning skills required for each concept of the course. It employs Formal Concept Analysis on a complete set of questions prepared by experts covering all the concepts of a given course. ||| This paper introduces evolutionary multitasking as a new paradigm in the field of optimization and evolutionary computation. It proposes an algorithm to handle multiple optimization problems simultaneously using a single population of evolving individuals, inspired by bio-cultural models of multifactorial inheritance. The numerical experiments reveal several potential advantages of implicit genetic transfer in a multitasking environment. ||| The paper proposes a hybrid genetic algorithm for feature selection, which combines the strengths of filter and wrapper methods. The algorithm uses a filter ranking method to select the most relevant features and a local search strategy to improve the solution. The authors investigate three different local search strategies and compare their performance on several benchmark and biological datasets."
Author3,Wrapper-Filter Feature Selection Algorithm Using A Memetic Framework,"This paper presents a hybrid genetic algorithm for feature selection, which combines the strengths of filter and wrapper methods. The algorithm uses a filter ranking method to select the most relevant features and a local search strategy to improve the solution. The authors investigate three different local search strategies and compare their performance on several benchmark and biological datasets.","Filter Ranking Method, Wrapper, Genetic Algorithm, Feature Selection, Hybrid Genetic Algorithm, Memetic Algorithm, Local Search Strategy, Chi-Square, Gain Ratio, Relief, Filter","The paper proposes a hybrid genetic algorithm for feature selection, which combines the strengths of filter and wrapper methods. The algorithm uses a filter ranking method to select the most relevant features and a local search strategy to improve the solution. The authors investigate three different local search strategies and compare their performance on several benchmark and biological datasets."
Avinash Chandra Pandey,Improved Gravitational Search Algorithm for COVID-19 Diagnosis,"This paper presents a novel variant of the gravitational search algorithm, improved gravitational search algorithm (IGSA), to enhance the vicinity to optimal solutions. The proposed variant is employed to obtain optimal clusters in the proposed clustering method for the CoVID19 diagnosis. An extensive experimental analysis of IGSA has been conducted against 16 metaheuristic algorithms over 17 standard benchmark functions belonging to unimodal and multimodal categories. The results are studied over four different dimensional settings, i.e. 10, 30, 50, and 90.","Clustering Method, Gravitational search algorithm, CoVID19 diagnosis, Clustering, Metaheuristic algorithm, COVID-19 Diagnosis, Metaheuristic Algorithms","This paper presents a new clustering method for the diagnosis of CoVID19 using medical images. The method employs a novel variant of a gravitational search algorithm to obtain optimal clusters. The performance of the proposed method is compared with recent metaheuristic algorithms using benchmark functions and publicly available CoVID19 medical images. The results demonstrate that the proposed method is outperforming in terms of accuracy, precision, sensitivity, specificity, and F1-score."
Avinash K. Shrivastava,Vulnerability Discovery Modeling for Open and Closed Source Software,"With growing concern for security, the researchers began with the quantitative modeling of vulnerabilities termed as vulnerability discovery models (VDM). These models aim at finding the trend of vulnerability discovery with time and facilitate the developers in patch management, optimal resource allocation and assessing associated security risks.","Vulnerability, Open Source, Ranking, Normalized Criteria Distance (NCD), Closed Source, Modeling, Prediction",This paper proposes a new vulnerability discovery model to capture a wide variety of datasets irrespective of their shape accounting for better goodness of fit. The proposed model has been evaluated on three real life datasets each for open and closed source software and the models are ranked based on their suitability to discover vulnerabilities using normalized criteria distance (NCD) technique.
Avraham Ben-Nun,Myelin-speciﬁc T cells also recognize neuronal autoantigen in a transgenic mouse model of multiple sclerosis,"We describe here the paradoxical development of spontaneous experimental autoimmune encephalomyelitis (EAE) in transgenic mice expressing a myelin oligodendrocyte glycoprotein (MOG)-speciﬁc T cell antigen receptor (TCR) in the absence of MOG. We report that in Mog-deﬁcient mice (Mog–/–), the autoimmune response by transgenic T cells is redirected to a neuronal cytoskeletal self antigen, neuroﬁlament-M (NF-M). Although components of radically different protein classes, the cross-reacting major histocompatibility complex I-Ab–restricted epitope sequences of MOG35–55 and NF-M18–30 share essential TCR contact positions. This pattern of cross-reaction is not speciﬁc to the transgenic TCR but is also commonly seen in MOG35–55–I-Ab–reactive T cells. We propose that in the C57BL/6 mouse, MOG and NF-M response components add up to overcome the general resistance of this strain to experimental induction of autoimmunity. Similar cumulative responses against more than one autoantigen may have a role in spontaneously developing human autoimmune diseases.",,"This study reports the unexpected finding that transgenic mice expressing a myelin oligodendrocyte glycoprotein (MOG)-specific T cell receptor (TCR) develop spontaneous experimental autoimmune encephalomyelitis (EAE) even in the absence of MOG. The researchers discovered that these mice redirect their autoimmune response to a neuronal cytoskeletal protein called neuroﬁlament-M (NF-M). This cross-reactivity between MOG and NF-M is mediated by shared TCR contact positions on their respective epitope sequences. The study suggests that cumulative responses against multiple autoantigens, such as MOG and NF-M, may contribute to the development of spontaneous autoimmune diseases in humans."
Ayush Aggarwal,Semi Supervised Graph Based Keyword Extraction Using Lexical Chains and Centrality Measures,"This paper proposes a semi-supervised graph-based keyword extraction algorithm using lexical chains and centrality measures. The algorithm first extracts nouns from each paragraph and creates lexical chains based on the similarity between words. The chains are then scored using two different methods, and the best chains are selected based on their scores. The selected chains are used to create a graph, and centrality measures are applied to identify the most central words as the extracted keywords.","Semi-supervised learning, small world approach, Graph-based keyword extraction, lexical chains, WordNet, Graph centrality, Word sense disambiguation, Centrality measures, keyword extraction, semantic similarity","The proposed algorithm uses a combination of lexical chains and centrality measures to extract keywords from a document. It first extracts nouns from each paragraph and creates lexical chains based on the similarity between words. The chains are then scored using two different methods, and the best chains are selected based on their scores. The selected chains are used to create a graph, and centrality measures are applied to identify the most central words as the extracted keywords."
B. Jayaram,QL-implications: Some properties and intersections,"In this paper, we attempt a systematic study of QL-implications. Towards this end, firstly, we investigate the conditions under which a QL-operation becomes a fuzzy implication without imposing any conditions on the underlying operations. Following this, we discuss the conditions under which this family satisfies some desirable algebraic properties. Based on the obtained results and existing characterization results, the intersections between QL-implications and the two most established families of fuzzy implications, viz., (S,N)- and R-implications are determined.","S-implication, fuzzy logic, R-implication, (S,N)-implication, t-norms, fuzzy sets, Fuzzy implication, QL-implication, t-conorms","This paper studies the family of QL-implications in fuzzy logic, without any restrictions on the underlying operations. Necessary and/or sufficient conditions on the underlying operations under which QL-implications satisfy some of the most desirable algebraic properties are proposed. A partial characterization of the intersections that exist between the family of QL-implications and the families of (S,N)- and R-implications is given."
B. Li,High-Energy-First (HEF) Heuristic for Energy-Efficient Target Coverage Problem,"Target coverage problem in wireless sensor networks is concerned with maximizing the lifetime of the network while continuously monitoring a set of targets. A sensor covers targets which are within the sensing range. For a set of sensors and a set of targets, the sensor-target coverage relationship is assumed to be known. A sensor cover is a set of sensors that covers all the targets. The target coverage problem is to determine a set of sensor covers with maximum aggregated lifetime while constraining the life of each sensor by its initial battery life. The problem is proved to be NP-complete and heuristic algorithms to solve this problem are proposed. In the present study, we give a unified interpretation of earlier algorithms and propose a new and efficient algorithm. We show that all known algorithms are based on a common reasoning though they seem to be derived from different algorithmic paradigms.  We also show that though some algorithms guarantee bound on the quality of the solution, this bound is not meaningful and not practical too.  Our interpretation provides a better insight to the solution techniques. We propose a new greedy heuristic which prioritizes sensors on residual battery life. We show empirically that the proposed algorithm outperforms all other heuristics in terms of quality of solution. Our experimental study over a large set of randomly generated problem instances also reveals that a very naïve greedy approach yields solutions which is reasonably (appx. 10%) close to the actual optimal solutions.","Network Lifetime, QoS constraints, connected coverage, sensing ranges, Target Coverage Problem, Greedy Heuristic, Wireless Sensor Networks, Energy-Efficiency, target coverage",The paper proposes a new heuristic algorithm for the energy-efficient target coverage problem in wireless sensor networks. The algorithm prioritizes sensors based on their residual battery life and is shown to outperform other heuristics in terms of quality of solution. The paper also provides a unified interpretation of earlier algorithms and shows that they are based on a common reasoning. The experimental study reveals that a naïve greedy approach yields solutions close to the actual optimal solutions.
B. Lipinski,Iris Detection,"For iris boundary detection, circular summation of intensity approach is used as proposed in [5]. The original grayscale image is blurred using median filter to remove external noise. After filtering, the contrast of image is enhanced to have sharp variation at image boundaries using histogram equalisation as shown in Figure 5(a). This contrast enhanced image is used for finding the outer iris boundary by drawing concentric circles (Figure 5(b) shows an example) of different radii from the pupil center and the intensities lying over the perimeter of the circle are summed up.","Adaptive Threshold, Circular Hough Transform, Spectrum Image, histogram equalisation, iris recognition, circular summation of intensity, Connected Components, Iris detection, pupil boundary, Iris Segmentation",The proposed system has been tested on two publicly available databases BATH and CASIA V3. From experimental analysis it has been observed that the system is capable of handling unconstrained scenarios as well. The system is capable of performing segmentation for unconstrained scenarios in significantly less time compared to Hough transform.
B. M. Mehtre,Detection and Prevention of ARP Poisoning,This paper presents a feasible technique to detect and prevent the ARP poisoning by removing the multiple entries for the same MAC address or IP address from the ARP table using a secondary cache.,"ICMP protocol, Network Security, Man-in-the-Middle, IP Exhaustion, secondary ARP cache, ARP Poisoning, Address Resolution Protocol, Cyber Defense, IP-MAC bindings, ICMP","The paper proposes a technique to detect and prevent ARP poisoning by using a secondary cache that contains entries according to ICMP responses. This approach prevents multiple entries for the same IP address or MAC address, mitigates IP exhaustion, and is distributed in nature, preventing single point failure."
B. Majhi,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
B. Pang,Sentiment Analysis of Training Programmes,"Sentiment analysis found various applications in banking, financial, service, and insurance sector. In order to increase return on investment, services industry needs to improve customer satisfaction at any cost.  In this regard, we proposed to analyze customer reviews on the basis of sentiment score. We analyzed a set of credible text reviews collected on 270 training programmes posted by 2688 participants in an organization. In order to evaluate the efficacy of the proposed approach, we computed correlation coefficient between sentiment score obtained from the unstructured reviews and the overall numerical rating assigned by all participants. Further, we employed visualization techniques to visualize different aspects of the programmes.","programme rating, Text Mining, Visualization, Training Programmes, participants' feedback, Customer Reviews, Sentiment analysis","The paper proposes a sentiment analysis approach to analyze customer reviews on the basis of sentiment score. The approach is divided into five sections: data collection, text preprocessing, sentiment score computation, evaluation, and visualization. The paper presents the results of the proposed approach and discusses the future directions of work."
B. Richhariya,Machine learning techniques for the diagnosis of Alzheimer’s disease: A review,"Alzheimer’s disease is an incurable neurodegenerative disease primarily affecting the elderly population. Efficient automated techniques are needed for early diagnosis of Alzheimers. Many novel approaches are proposed by researchers for classification of Alzheimer’s disease. However, to develop more efficient learning techniques, better understanding of the work done on Alzheimers is needed. Here, we provide a review on 165 papers from 2005-2019 using various feature extraction and machine learning techniques. The machine learning techniques are surveyed under three main categories: support vector machine (SVM), artificial neural network (ANN), and deep learning (DL) and ensemble methods.","Ensemble methods, Support vector machine, Deep learning, Alzheimer’s disease, classification, Artificial neural network, Machine learning","This paper provides a review of 165 papers on machine learning techniques for the diagnosis of Alzheimer’s disease from 2005-2019. The review covers three main categories: support vector machine (SVM), artificial neural network (ANN), and deep learning (DL) and ensemble methods. The paper discusses the importance of efficient automated techniques for early diagnosis of Alzheimers and the need for better understanding of the work done on Alzheimers to develop more efficient learning techniques."
B. Schneier,Secure Robust and Imperceptible Algorithm for Watermarking Relational Databases,"This paper proposes a secure robust and imperceptible algorithm for watermarking relational databases. The algorithm divides the embedding algorithm into three phases: Watermark preparator, watermark position detector, and watermark embedder. The ownership identification issue is resolved by embedding owner's identity as watermark in Preparator phase.","imperceptible algorithm, Ownership identification, robust algorithm, Relational Database, watermarking, Watermark, Copyright protection, Proof of ownership, relational databases","The paper proposes a new robust secure and imperceptible embedding mechanism to resolve the two important concerns namely; owner identification and proof of ownership. The proposed mechanism involves encoding and decoding on numerical attribute of relational database in three phases; 1)Watermark preparator, 2)Watermark position detector and 3) Watermark Embedder or Detector."
B. Subudhi,Dynamic Equations of Motion for a Multiple Flexible Links and Flexible Joints Manipulator,"The paper presents a dynamic modelling technique for a manipulator with multiple flexible links and flexible joints, based on a combined Euler–Lagrange formulation and assumed modes method. The resulting generalised model is validated through computer simulations by considering a simplified case study of a two-link flexible manipulator with joint elasticity.","Euler-Beam theory, Rayleigh's dissipation function, Flexible joint, Flexible links, Singular perturbation, Flexible joints, Manipulator dynamics, Flexible link, Manipulator","The paper presents a dynamic modelling technique for a manipulator with multiple flexible links and flexible joints, based on a combined Euler–Lagrange formulation and assumed modes method. The resulting generalised model is validated through computer simulations by considering a simplified case study of a two-link flexible manipulator with joint elasticity. Controlling such a manipulator is more complex than controlling one with rigid joints because only a single actuation signal can be applied at each joint and this has to control the flexure of both the joint itself and the link attached to it."
B. Uma Shankar,Active Support Vector Learning for Pixel Classification,"This paper presents an active support vector learning algorithm for pixel classification in remote sensing images. The algorithm is based on the principle of breaking down the large quadratic programming problem into a series of smaller problems, and identifying the support vectors while discarding the non-support vectors.","Semi-supervised learning, Pixel Classification, Query support vector machine, Active Learning, Support Vector Machine, Image segmentation, Transductive learning, Remote Sensing","The paper proposes an active support vector learning algorithm for pixel classification in remote sensing images, which uses a smaller number of labeled samples and has a substantial improvement in performance compared to the conventional support vector machine."
BACZY  NSKI,DISTRIBUTIVITY OF FUZZY IMPLICATIONS OVER NILPOTENT OR STRICT TRIANGULAR CONORMS,"Recently, many works have appeared in this very journal dealing with the distributivity of fuzzy implications over t-norms and t-conorms. These equations have a very important role to play in efficient inferencing in approximate reasoning, especially fuzzy control systems.","nilpotent conorms, fuzzy implication, t-norm, R-implication, t-conorm, fuzzy implications, triangular conorms, functional equations, strict conorms, Combs methods","This paper characterizes functions I that satisfy the functional equation when S1, S2 are either both strict or nilpotent t-conorms. Then, using these characterizations, it investigates the conditions under which the equation holds when I is an R-implication obtained from a strict t-norm."
BANERJEE ET AL,Design Space Exploration Using the AccelFPGA Compiler,This paper discusses the use of the AccelFPGA compiler to perform design space exploration of various area-performance tradeoffs. The compiler allows the user to use compiler directives to demarcate parts of the input source that are targeted for hardware synthesis and parts that are not. The paper presents a case study of a 16 tap FIR filter implemented using the AccelFPGA compiler and discusses the performance and area tradeoffs of the design.,"design space exploration, High level synthesis, MATLAB, area-performance tradeoffs, VHDL, FPGAs, RTL, AccelFPGA, Verilog, compiler, FIR filter",The paper presents a case study of a 16 tap FIR filter implemented using the AccelFPGA compiler and discusses the performance and area tradeoffs of the design. The compiler allows the user to use compiler directives to demarcate parts of the input source that are targeted for hardware synthesis and parts that are not. The paper also discusses the use of the compiler to perform high-level estimates of area and performance.
BANSHIDHAR MAJHI,NPReId Framework for Video Surveillance,"This paper presents a neuromorphic person re-identiﬁcation (NPReId) framework to establish the correspondence among individuals observed across two disjoint camera views. The proposed framework comprises three modules (observation, cognition, and contemplation), inspired by the form-and-color-and-depth (FACADE) theory model of object recognition system.","person re-identification, recognition, FACADE theory, Surveillance, video surveillance, consensus clustering, person re-identiﬁcation, NPReId","The proposed NPReId framework comprises three interactive modules – observation, cognition, and contemplation. The observation module suppresses the background and extracts the chromatic and texture details from the segmented pedestrian. The cognition module projects the psychological result of observation to learn the underlying pedestrian signature. The results of observation and cognition modules are forwarded to the contemplation module that recognizes the correct match for any individual."
BVL Narayana,Understanding Helicoverpa armigera Pest Population Dynamics related to Chickpea Crop Using Neural Networks,Insect pests are a major cause of crop loss globally. Pest management will be effective and efficient if we can predict the occurrence of peak activities of a given pest. Research efforts are going on to understand the pest dynamics by applying analytical and other techniques on pest surveillance data sets. In this study we make an effort to understand pest population dynamics using Neural Networks by analyzing  pest surveillance data set of Helicoverpa armigera or Pod borer on chickpea (Cicer arietinum L.)  crop. The results show that neural network method successfully predicts the pest attack incidences for one week in advance.,"Climatic Data, Pest Population Dynamics, Neural Networks, Pest Surveillance Databases, Chickpea Crop, Helicoverpa armigera, Neural Network, Pest Attack Prediction","The experimental results show that it is possible to predict the pest attack with high probability for one week in advance. These predictions would help the farmers in pest management programs by avoiding the crop losses with improved environment quality, as it can avoid unnecessary sprays of chemical pesticides."
Bach and Jordan,A Spectral Learning Based Model to Evaluate Semantic Textual Similarity,"Semantic Textual Similarity (STS) is a task in NLP that compares two sentences in a sentence-pair and scores the relationship between them using the degree of semantic equivalence. It has wide applicability in various fields. Consequently, the research around the task is constantly evolving. The demand for new as well as improved methods is endless. Numerous methods have been proposed that largely belong to either unsupervised or supervised learning approaches. The model proposed here is fairly simple and provides a fresh take on this classification problem using spectral learning. The model does not engage a large labeled corpus or lexical database like most STS supervised and unsupervised methods. Although, supervised STS methods achieve an accuracy that outperforms humans in some cases, but are often held back due to a lack of interpretation of the features instrumental in molding the decision-making process. The proposed model on the other hand generates features (latent knowledge) that are easy to ascertain and have a mathematical foundation. Given a sentence pair, the work focuses on finding latent states and variables from each sentence and performs classification by generating a similarity score. The latent variables are a result of projections learned by performing Canonical Correlation Analysis (CCA) amongst the sentence pair. To perform matching and determine the similarity score, Cosine similarity and Word Mover’s Distance (WMD) are employed. The performance of the proposed model does exhibit an improvement over various sophisticated supervised techniques such as LSTM and BiLSTM.","Natural Language Processing, Hidden Variables, Canonical Correlation Analysis, Word Mover’s Distance, Semantic Textual Similarity, Latent Variables, Latent State, Hidden state, Spectral Learning",This study aims to design a structure that can not only generate and evaluate latent/semantic components but also elevate their part in the learning process. The proposed model is a spectral learning based model that uses Canonical Correlation Analysis (CCA) to estimate the latent state from each sentence and employs Cosine Similarity and Word Mover’s Distance (WMD) to output a similarity score. The model does not require a large labeled dataset and is particularly suited for settings where labeled data is scarce. The process of learning the latent state from a sentence pair is transparent and has a mathematical grounding.
Baidya Kayal,Non-invasive intravoxel incoherent motion MRI in prediction of histopathological response to neoadjuvant chemotherapy and survival outcome in osteosarcoma at the time of diagnosis,"This study evaluates the effectiveness of chemotherapy in patients with osteosarcoma and its impact on long-term survival outcome. The study includes 11 patients who underwent neoadjuvant chemotherapy (NACT) and were followed up for a median of 4.5 years. The results show that patients who responded well to NACT had better overall survival and event-free survival compared to those who did not respond well. The study also found that certain imaging parameters, such as ADC and D*, were associated with chemotherapy response and survival outcome.","Chemotherapy response evaluation, neoadjuvant chemotherapy, chemotherapy, long-term survival outcome, Osteosarcoma, Biomarkers, imaging parameters, Intravoxel incoherent motion, Survival outcome, Diffusion weighted imaging",This study aimed to evaluate the predictive value of IVIM MRI for response to neoadjuvant chemotherapy and survival outcome in osteosarcoma. The results showed that IVIM parameters obtained with a 1.5T scanner along with novel BETV method and their histogram analysis indicating tumour heterogeneity were informative in characterizing NACT response and survival outcome in osteosarcoma.
Balasubramaniam Jayaram,A Novel Fuzzy Rule Based Inference System for Contrast Enhancement ||| On the Suitability of the Bandler–Kohout Subproduct as an Inference Mechanism ||| What are Clusters in High Dimensions and are they Difﬁcult to Find? ||| Yager’s Classes of Fuzzy Implications: Some Properties and Intersections,"In this work, we propose a fuzzy inference system based contrast enhancement of gray level images. We propose a new method of generating the fuzzy if-then rules specific to a given image based on the local information available to be used by a fuzzy inference system. ||| Fuzzy relational inference (FRI) systems form an important part of approximate reasoning schemes using fuzzy sets. The compositional rule of inference (CRI), which was introduced by Zadeh, has attracted the most attention so far. In this paper, we show that the FRI scheme that is based on the Bandler–Kohout (BK) subproduct, along with a suitable realization of the fuzzy rules, possesses all the important properties that are cited in favor of using CRI, viz., equivalent and reasonable conditions for their solvability, their interpolative properties, and the preservation of the indistinguishability that may be inherent in the input fuzzy sets. Moreover, we show that under certain conditions, the equivalence of first-infer-then-aggregate (FITA) and first-aggregate-then-infer (FATI) inference strategies can be shown for the BK subproduct, much like in the case of CRI. Finally, by addressing the computational complexity that may exist in the BK subproduct, we suggest a hierarchical inferencing scheme. Thus, this paper shows that the BK-subproduct-based FRI is as effective and efficient as the CRI itself. ||| This paper discusses clustering in high dimensions, including hierarchical clustering, prototype-based clustering, fuzzy k-means clustering, Gaussian mixture models, and subspace clustering. It also touches on the challenges of clustering high-dimensional data and provides examples of applications where high-dimensional data is relevant. ||| Recently, Yager in the article “On some new classes of implication operators and their role in approximate reasoning” [12] has introduced two new classes of fuzzy implications called the f-generated and g-generated implications. Along similar lines, one of us has proposed another class of fuzzy implications called the h-generated implications. In this article we discuss in detail some properties of the above mentioned classes of fuzzy implications and we describe their relationships amongst themselves and with the well established (S, N)-implications and R-implications. In the cases where they intersect the precise sub-families have been determined.","Fuzzy relational compositions, Histogram Equalisation, Inference mechanisms, hierarchical clustering, Bandler–Kohout (BK) subproduct, Fuzzy Inference Systems, Mamdani fuzzy inference system, hierarchical CRI, Image Enhancement, high-dimensional data, Gaussian mixture models, Bandler–Kohout subproduct, f-generated implication, contrast enhancement, hubness phenomenon, fuzzy relational equations, Histogram Matching, Gray level transformations, fuzzy implication, S-implication, Fuzzy rule-based systems, Compositional rule of inference, fuzzy relational inference (FRI) systems, cluster analysis, clustering, Contrast Stretching, concentration of norm, h-generated implication, prototype-based clustering, g-generated implication, compositional rule of inference (CRI), Fuzzy Partition, partial histogram, R-implication, correctness and continuity of inference, fuzzy k-means clustering, subspace clustering, fuzzy rule based inference system, (S; N)-implication, high dimensions","The paper proposes a fuzzy inference system based contrast enhancement of gray level images. It presents a new method of generating fuzzy if-then rules specific to a given image based on local information available. The method generates a partial histogram and saves on computational costs. The enhanced images from the proposed algorithm are comparable or even better than those obtained from histogram equalization. ||| This paper explores the suitability of the Bandler–Kohout subproduct as an inference mechanism in fuzzy relational inference systems. The authors compare the properties of the Bandler–Kohout subproduct with those of the compositional rule of inference and show that it possesses similar properties, including equivalent and reasonable conditions for solvability, interpolative properties, and preservation of indistinguishability. The authors also suggest a hierarchical inferencing scheme to address computational complexity and demonstrate the equivalence of first-infer-then-aggregate and first-aggregate-then-infer inference strategies under certain conditions. ||| This paper investigates consequences that the special properties of high-dimensional data have for cluster analysis. We discuss questions like when clustering in high dimensions is meaningful at all, can the clusters just be artifacts and what are the algorithmic problems for clustering methods in high dimensions. ||| This paper discusses the properties and intersections of Yager’s classes of fuzzy implications, including f-generated, g-generated, and h-generated implications, as well as their relationships with (S, N)-implications and R-implications."
Balasubramaniam Jayarama,On special fuzzy implications,"Special implications were introduced by Hájek and Kohout [Fuzzy implications and generalized quantiﬁers, Int. J. Uncertain. Fuzziness Knowl.-Based Syst. 4 (1996) 225–233] in their investigations on some statistics on marginals. They have either suggested or only partially answered three important questions, especially related to special implications and residuals of t-norms. In this work we investigate these posers in-depth and give complete answers.","Fuzzy connectives, identity principle, special implications, (S,N)-implication, fuzzy implications, Fuzzy implication, Residual of conjunction, exchange principle, 1-Lipschitzianity, Special implication, ordering property","This paper investigates special fuzzy implications, which were introduced by Hájek and Kohout. The authors give a geometric interpretation of the specialty condition and obtain bounds on special implications. They also attempt to answer three problems related to special implications and residuals of t-norms."
"Bandyopadhyay, S. (2011)",Quantum-inspired evolutionary approach for selection of optimal parameters of fuzzy clustering,"Recently, Fuzzy c-Means (FCM) algorithm is most widely used because of its efficiency and simplicity. However, FCM is sensitive to the initialization of fuzziness factor (m) and the number of clusters (c) due to which it easily trapped in local optima. A selection of these parameters is a critical issue because an adverse selection can blur the clusters in the data.","Fuzzy clustering, Cluster validity index, Quantum-Inspired Evolutionary Fuzzy c-Means, Fuzzy c-Means algorithm, Fuzzy c-Means, Quantum computing","This paper proposes a hybrid fuzzy clustering algorithm, Quantum-Inspired Evolutionary Fuzzy c-Means (QIE–FCM), which uses the merits of quantum computing for finding the global optimal value of m and its corresponding value of c in the FCM. The proposed approach improves the way of initialization of the fuzziness factor (m) in the FCM and provides the diversity in selecting the optimal value of m and c from a large quantum search space."
"Bandyopadhyay, S., & Maulik, U. (2001)",Quantum-inspired evolutionary approach for selection of optimal parameters of fuzzy clustering,"Recently, Fuzzy c-Means (FCM) algorithm is most widely used because of its efficiency and simplicity. However, FCM is sensitive to the initialization of fuzziness factor (m) and the number of clusters (c) due to which it easily trapped in local optima. A selection of these parameters is a critical issue because an adverse selection can blur the clusters in the data.","Fuzzy clustering, Cluster validity index, Quantum-Inspired Evolutionary Fuzzy c-Means, Fuzzy c-Means algorithm, Fuzzy c-Means, Quantum computing","This paper proposes a hybrid fuzzy clustering algorithm, Quantum-Inspired Evolutionary Fuzzy c-Means (QIE–FCM), which uses the merits of quantum computing for finding the global optimal value of m and its corresponding value of c in the FCM. The proposed approach improves the way of initialization of the fuzziness factor (m) in the FCM and provides the diversity in selecting the optimal value of m and c from a large quantum search space."
Bansal,Fifty years of peephole optimization,"Peephole optimization is a technique used in compilers to improve the performance of object programs by replacing sequences of instructions with equivalent single instructions. This article reviews the history and development of peephole optimization, including its application to various programming languages and target machines.","compilers, object programs, peephole optimization, Code generators, instruction sequences, replacement rules","Peephole optimization has been widely used in compilers to improve the performance of object programs. The technique involves replacing sequences of instructions with equivalent single instructions, and has been applied to various programming languages and target machines. The effectiveness of peephole optimization depends on several factors, including the nature of the source language, the parsing and code generation techniques used in the compiler, and the specifications of the target machine."
Banshidhar Majhi,Direction Estimation for Pedestrian Monitoring System in Smart Cities: An HMM Based Approach ||| Evaluation of Background Subtraction for Object Detection Vis-a-Vis Mitigating Challenging Scenarios,"The paper proposes a novel approach for direction estimation of a moving pedestrian as perceived in a 2-D coordinate of field camera. The proposed direction estimation method is intended for pedestrian monitoring in traffic control systems. Apart from traffic control, direction of motion estimation is also very important in accident avoidance system for smart cars, assisted living systems, in occlusion prediction for seamless tracking in visual surveillance, and so on. ||| Background subtraction is a popular technique for detecting objects moving across a fixed camera view. The performance of this paradigm is influenced by various challenges, such as object relocation, illumination change, cast shadows, waving background, camera shake, bootstrapping, camouflage, and so on. In this paper, we present a synopsis on the evolution of the background subtraction techniques over the last two decades. The different ways of mathematical modeling are taken into consideration to categorize the methods. We also evaluate the performance of some of the state-of-the-art techniques vis-a-vis the challenges associated. Eleven different algorithms of background subtraction have been simulated on thirty-four image sequences collected from five benchmark datasets. For each image sequence, seven performance metrics are evaluated and an exhaustive comparative analysis has been made to derive inferences. The potential findings in the result analysis are presented for future exploration. The obtained image and video results are uploaded at https://sites.google.com/site/soaBSevaluation.","object detection, challenging scenarios, learning model, direction estimation, HMM, pedestrian monitoring, fuzzy model, perspective distortion, background subtraction, non-parametric model, shadow removal model, foreground extraction, background maintenance, background modeling, hidden Markov model, low-rank sparse decomposition, non-recursive buffer-based subtraction, pedestrian direction estimation, surveillance video, Video surveillance, occlusion handling, shadow removal, Visual surveillance","The proposed method is robust to various issues like illumination changes, environmental factors, partial occlusion, and low resolution of surveillance videos. It can be used alone or with existing methods of orientation estimation over consecutive frames to enhance the direction estimation results. ||| This paper evaluates the performance of background subtraction techniques for object detection in challenging scenarios. The authors present a synopsis of the evolution of background subtraction techniques over the last two decades and evaluate the performance of eleven state-of-the-art algorithms on thirty-four image sequences collected from five benchmark datasets. The results reveal some key findings in background subtraction methodologies and are available at https://sites.google.com/site/soaBSevaluation."
Barathram Ramkumar,Performance Study of Cyclostationary based Digital Modulation Classiﬁcation Schemes,"This paper presents a comparative study of various classifiers in cyclostationary features. The classifiers considered are Neural Network, Naive Bayes, Linear Discriminant Analysis, k-Nearest Neighbor, Support Vector Machine, and Neuro-Fuzzy. The performance of these classifiers is evaluated using confusion matrix and computational complexity.","k-Nearest Neighbor, Classifiers, Naive Bayes, Classiﬁcation, Cyclostationary Features, Cognitive Radio, Neuro-Fuzzy, Digital Modulation, Cyclostationary, Linear Discriminant Analysis, Neural Network, Support Vector Machine","This paper studies the performance of digital modulation classiﬁcation technique based on the cyclostationary features and different classiﬁers such as Neural Network, Support Vector Machine, k-Nearest Neighbor, Naive Bayes, Linear Discriminant Analysis and Neuro-Fuzzy classiﬁer."
Barathram.Ramkumar,ECG Noise Detection and Classification Method,"An assessment of electrocardiogram (ECG) signal quality has become an unavoidable ﬁrst step in most holter and ambulatory ECG signal analysis applications. In this paper, we present a simple method for automatically detection and classiﬁcation of ECG noises.","ECG noise detection, ECG classiﬁcation, signal processing, ECG, noise detection, classification, Wearable ECG monitoring devices, ECG signal quality","The proposed method consists of four major steps: moving average ﬁlter, blocking, feature extraction, and multistage decision-tree algorithm. The dynamic amplitude range and autocorrelation maximum peak features are extracted for each block. The method can achieve an average sensitivity (Se) of 97.88%, positive productivity (+P) of 91.18% and accuracy of 89.06%."
Barbara Caci,Personality in AR gaming: the case of Pokémon GO,"The latest business reports showed that Augmented Real-ity (AR) and Artiﬁcial Intelligence (AI) are ranked among the top 10 strategic trends for 2018. For these reasons, in this paper, we provide an interdisciplinary focus on design and personality issues, trying to discuss the interplay between games with personality and Artiﬁcial Intelligence.","AR gaming, chess personality, extraversion, Pokémon GO, virtual humans, agreeableness, conscientiousness, neuroticism, personality, openness, gaming, Augmented Reality, chess","The authors conclude that personality traits play a significant role in shaping player behavior in Pokémon GO, with extraversion, agreeableness, and conscientiousness being particularly relevant. They also highlight the importance of considering the role of virtual humans in exploring personalities in chess games."
Bateman et al.,Typeface size and weight and word location inüluence on relative size judgments in tag clouds,"This paper focuses on viewers’ perception of the relative size of words presented in tag clouds. Tag clouds are a type of visualization that displays the contents of a document as a cluster (cloud) of key words (tags) with frequency (importance) indicated by tag word features such as size or color, with variation of size within a tag cloud being the most common indicator of tag importance. Prior studies have shown that word size is the most inüluential factor of tag importance and tag memory. Systematic biases in relative size perception in tag clouds are therefore likely to have important implications for viewer understanding of tag cloud visualizations.","layout, typeface size, size judgment, perception, psychophysics, perceptual biases, tag cloud, search tasks, tag clouds","The study focuses on documenting systematic biases in relative size judgment in tag clouds while varying typeface weight and the location of the target tag word pair under comparison. The results provide a first report of systematic biases in relative size judgment in tag clouds, suggest that simple power-law scaling models developed for simple displays containing 1-2 objects on a blank background, may be applicable to relative size judgments in complex tag clouds."
Berman et al.,Maximum Coverage First: A New Heuristic for Target Coverage Problem in Wireless Sensor Networks,"This paper proposes a new heuristic, Maximum Coverage First (MCF), to solve the target coverage problem in wireless sensor networks. MCF generates sensor covers by selecting sensors that cover the maximum number of uncovered targets, and assigns lifetime to each cover based on the minimum residual battery life of its sensors.","Maximum Coverage First, Target Coverage Problem, Wireless Sensor Networks, Network lifetime, Lifetime Assignment, Heuristic Algorithms, Heuristic, NP completeness","The paper presents a new heuristic, MCF, to solve the target coverage problem in wireless sensor networks. MCF generates sensor covers by selecting sensors that cover the maximum number of uncovered targets, and assigns lifetime to each cover based on the minimum residual battery life of its sensors. The paper also compares the performance of MCF with other existing heuristics and presents simulation results to demonstrate its effectiveness."
Bettahally N. Keshavamurthy,Dynamic Multi‑layer Ensemble Classification Framework for Location-Based Social Network Venue Classification,"Multi-layer ensemble frameworks perform much better as compared to individual classifiers. However, selection of a classifier and its placement, impacts the overall performance of ensemble framework. This problem becomes very difficult, if there are more classifiers and layers. To address these problems in this paper, we design “Binary Particle Swarm Optimization” method for selection and placement of right classifiers in multi-layer ensemble model. Proposed classifier weight-assignment method is implemented to prioritize the selected classifiers. The model is simulated for the classification of social-user check-ins in Location-Based Social Network datasets. The experimental results show that the proposed ensemble model outperforms the state-of-the-art ensemble methods in the literature. It can be used by security firms, high level decision makers and various governmental organizations for tracking malicious users.","location-based social network, Dynamic multi-layer ensembles, User-checkins, Social-venue classification, Majority voting, ensemble classification, BPSO, classifier selection, venue classification, Location-Based Social Networks, Machine learning","This paper proposes a Dynamic Multi-Layer Ensemble Classification (DMLEC) technique that works on dynamically choosing the classifiers as per the Binary Particle Swarm Optimization (BPSO) using a novel fitness function. In addition, a new classifier weight assignment method is proposed that updates weights for the particular classifiers as per their classification accuracy. The proposed DMLEC is more flexible and can be used over big datasets for classification of various real world problems."
Beulah Ji,BELIMUMAB IN PATIENTS OF BLACK AFRICAN ANCESTRY,"Study design. SELENA–SLEDAI = Safety of Estrogens in Lupus Erythematosus National Assessment–Systemic Lupus Erythemato-sus Disease Activity Index; IV = intravenous.

Randomization and treatment. Using an interactive voice/web response system, patients receiving standard therapy were randomized 2:1 to receive either belimumab 10 mg/kg IV or placebo, which was administered on days 0, 14, and 28 and every 28 days thereafter up to week 48, with a final evaluation at week 52. Randomization was stratified by screening SELENA–SLEDAI score (≤9 versus ≥10), region (US/Canada versus rest of world), and complement level (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]). Detailed randomization data are provided in Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Patients who successfully completed the initial 52-week double-blind phase could enter an optional 6-month open-label extension phase, during which they received belimumab 10 mg/kg IV every 28 days plus standard therapy, irrespective of their previous study assignment. The first dose was given at the week 52 (day 364) visit of the double-blind period (day 1 of the open-label extension phase). Patients who completed the 52-week double-blind phase, but did not enter the 6-month open-label extension phase, were required to return for an additional follow-up visit 8 weeks after their last dose. Patients who withdrew early were required to return for an exit visit 4 weeks after their last dose and a follow-up visit 8 weeks after their last dose.

The original protocol plan was to randomize 816 patients, providing ≥90% power to detect ≥12% absolute improvement in the SRI response rate in the belimumab group compared with the placebo group at a 5% significance level. Due to enrollment challenges, a revised sample size was calculated to include 501 patients (≥334 patients in the belimumab group and ≥167 patients in the placebo group). This sample size provided ≥90% power to detect a minimum 15.55% absolute improvement in SRI–SLEDAI-2K response rate in the belimumab group relative to the placebo group at a 5% significance level (based on the pooled data from efficacy studies BEL112341 and BEL113750) (15,21). These calculations assumed a placebo response rate of 43.95% at week 52.

Study end points and assessments. The primary efficacy end point was the SRI–SLEDAI-2K response rate (defined in the Supplementary Material) at week 52 of the double-blind phase. Unlike in the phase II and phase III studies, the SRI–SLEDAI-2K was selected because of the simplification it offers in proteinuria assessment as compared with the SELENA–SLEDAI proteinuria component; both are clinically meaningful (22). The primary efficacy end point for the open-label extension phase was SRI–SLEDAI-2K response rate at open-label extension week 24. If the open-label extension week 24 data were missing, data from the open-label extension week 28/exit visit were used. This time point is referred to as “open-label extension week 24” throughout the text. Data related to the primary efficacy end point, e.g., the response rate over time, percentage of patients with a durable SRI–SLEDAI-2K response from week 44 through week 52, time to first SRI–SLEDAI-2K response that was maintained through week 52, and duration of longest SRI–SLEDAI-2K response among patients with ≥1 SRI–SLEDAI-2K responses were summarized.

The key secondary end points were SRI–SELENA–SLEDAI at week 52 (open-label extension week 24), time to first severe SLE flare (measured by the SELENA–SLEDAI flare index [SFI]), and proportion of patients whose average prednisone dose had been reduced by ≥25% from baseline to ≤7.5 mg/day during week 40 through week 52 (open-label extension week 28/exit visit), in patients receiving >7.5 mg/day at baseline. Key renal end points included time to first renal flare over 52 weeks and over 28 weeks in the open-label extension, SELENA–SLEDAI–SLEDAI-2K renal domain improvement at week 52, SELENA–SLEDAI–SLEDAI-2K renal domain worsening at week 52, percentage reduction in proteinuria by visit and at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours, and proteinuria shift at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours. Renal flare is defined in the Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Biomarkers measured included percentage changes in serum IgG level, anti-dsDNA antibody level (in those who were anti-dsDNA positive [≥30 IU/ml] at baseline), and complement (C3 and C4) levels from baseline. Safety was evaluated by monitoring adverse events (AEs), serious AEs (SAEs), AEs of special interest, vital signs, clinical laboratory test results, and immunogenicity up to 8 weeks posttreatment and throughout the open-label extension phase.

Data analyses. For the double-blind phase, safety analyses were performed on the safety population, defined as all patients who were randomized and treated with at least 1 dose of investigational product. Data on the safety population were summarized according to the treatment the patient was randomized to receive rather than by the treatment that was received, but both were the same for this study. Efficacy analyses were performed on the modified intent-to-treat (ITT) population, defined as the safety population minus those patients who had any assessment at any of 3 study sites that were excluded from the efficacy analyses before the database lock because of potential Good Clinical Practice noncompliance.

For analysis of the primary and 3 key secondary efficacy end points, a step-down sequential testing procedure was used as described in the Supplementary Material. The following subgroup analyses were performed for the primary analysis (SRI–SLEDAI-2K response at week 52): region (US/Canada versus rest of world), baseline SELENA–SLEDAI–SLEDAI-2K score (≤9 versus ≥10), baseline anti-dsDNA antibody level (≥30 IU/ml versus <30 IU/ml), baseline complement levels (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]), and baseline complement and anti-dsDNA antibody levels (≥1 test finding showing low C3/C4 and anti-dsDNA ≥30 IU/ml versus C3/C4 other and anti-dsDNA ≥30 IU/ml). The odds of an SRI–SLEDAI-2K response with belimumab treatment versus placebo were estimated using logistic regression analysis.

For the open-label extension phase, all patients received belimumab, no formal statistical hypothesis t",,"This study investigated the efficacy and safety of belimumab in patients of Black African ancestry with systemic lupus erythematosus (SLE).  Patients were randomized to receive belimumab or placebo for 52 weeks, followed by an optional 6-month open-label extension phase. The primary efficacy endpoint was the SRI–SLEDAI-2K response rate at week 52.  Key secondary endpoints included SRI–SELENA–SLEDAI at week 52, time to first severe SLE flare, and proportion of patients with a reduction in prednisone dose. Renal and biomarker assessments were also conducted.  The study found that belimumab was effective in improving SLE disease activity and reducing renal flares in patients of Black African ancestry."
"Bezdek, J. C. (1974, 2013)",Quantum-inspired evolutionary approach for selection of optimal parameters of fuzzy clustering,"Recently, Fuzzy c-Means (FCM) algorithm is most widely used because of its efficiency and simplicity. However, FCM is sensitive to the initialization of fuzziness factor (m) and the number of clusters (c) due to which it easily trapped in local optima. A selection of these parameters is a critical issue because an adverse selection can blur the clusters in the data.","Fuzzy clustering, Cluster validity index, Quantum-Inspired Evolutionary Fuzzy c-Means, Fuzzy c-Means algorithm, Fuzzy c-Means, Quantum computing","This paper proposes a hybrid fuzzy clustering algorithm, Quantum-Inspired Evolutionary Fuzzy c-Means (QIE–FCM), which uses the merits of quantum computing for finding the global optimal value of m and its corresponding value of c in the FCM. The proposed approach improves the way of initialization of the fuzziness factor (m) in the FCM and provides the diversity in selecting the optimal value of m and c from a large quantum search space."
"Bharill, J. P., & Tiwari, R. (2014)",Quantum-inspired evolutionary approach for selection of optimal parameters of fuzzy clustering,"Recently, Fuzzy c-Means (FCM) algorithm is most widely used because of its efficiency and simplicity. However, FCM is sensitive to the initialization of fuzziness factor (m) and the number of clusters (c) due to which it easily trapped in local optima. A selection of these parameters is a critical issue because an adverse selection can blur the clusters in the data.","Fuzzy clustering, Cluster validity index, Quantum-Inspired Evolutionary Fuzzy c-Means, Fuzzy c-Means algorithm, Fuzzy c-Means, Quantum computing","This paper proposes a hybrid fuzzy clustering algorithm, Quantum-Inspired Evolutionary Fuzzy c-Means (QIE–FCM), which uses the merits of quantum computing for finding the global optimal value of m and its corresponding value of c in the FCM. The proposed approach improves the way of initialization of the fuzziness factor (m) in the FCM and provides the diversity in selecting the optimal value of m and c from a large quantum search space."
Bharti,Adsorption and Photodegradation of Dyes Using Graphene Composites: A Review,"Water contamination has reached an alarming state due to industrialization and urbanization and has become a worldwide issue. Dyes contaminate water and are addressed extensively by researchers. Various technologies and materials have been developed for the treatment of contaminated water. Among them, adsorption has attracted great attention due to its ease and cost-effective nature. In recent years, graphene-based composites have shown great potential for the removal of contaminants from water. The literature reveals the usefulness of composites of graphene with metal oxides, carbon derivatives, metal hybrids and polymers for the removal of organic dyes from contaminated water. In this review, efforts have been made to compile the studies on the removal of cationic and anionic dyes from water using graphene-based composites.","Graphene, Dye removal, Photodegradation, Graphene composites, Degradation, Water treatment, Composites, Contaminated water, Adsorption, Dyes","Graphene composites are emerging as promising materials for the removal of dyes from wastewater due to their high surface area, excellent electrical conductivity, and tunable properties. This review summarizes the recent progress in using graphene composites for both adsorption and photodegradation of dyes. It discusses the mechanisms involved, key factors affecting dye removal efficiency, and the advantages of graphene-based materials over conventional methods. The review also highlights the potential of graphene composites for sustainable and efficient dye remediation in the future."
Bhatia et al.,Ontology Driven Software Development for Automated Documentation,"Recent outsourcing /off-shoring software development practices testify that any development done without a proper sharing mechanism leads to the generation of inconsistent information, which further results in an undesired, error-prone software. Further, with the business process automation, a significant way to minimize human effort involves various development, support and maintenance activities to reuse available information. Thus, reusing and sharing information in a standardized way is the key operative challenges which foster the need to identify and exploit novel knowledge-based frameworks. The proposed research provides a tool-based solution to automate the software documentation process using ontologies. This multi-phase framework has overall six phases where each phase output contributes to the final automated documentation. To evaluate the extent of automated documentation it is compared using free and open source software known as WCopyfind to the existing manual documentation for a Result Management System case study. Preliminary results show a highest automation of 60 percent, which is clearly noteworthy.","Ontology driven, Ontology, software architecture documentation, Software’s documentation, Automatic documentation, technical documentation, ontology driven software development, Semantic Web, automated documentation, Software engineering","The paper presents a framework for ontology driven software development for automated documentation, which is divided into six phases. The framework is designed to capture key concepts of the domain under consideration and generate documentation in both human and machine-understandable forms. The paper also discusses the related work in the field of ontology driven software development and automated documentation."
Bhavana Shah,"MACHINE LEARNING: APPLICATIONS, TECHNIQUES AND CURRENT SCENARIO","Machine Learning (ML) used in day-to-day life. ML can use data and use it for self-learning. It is widely used in many fields like finance, agriculture, education, and security, etc. This paper discusses the potential of utilizing machine learning technologies in various sector.ML categorized in mainly four Learning process. Supervised learning which contains labelled data where unsupervised learning includes unlabelled data. Semi-supervised learning is a combination of supervised and unsupervised learning. The reinforcement learning algorithm is learned by receiving feedback on the effect of modifying some parameters. We can study in detail with different techniques and different methods and also check which algorithm is more accurate in less runtime. This paper summarizes some application of machine learning such as prediction, disease detection, fraud detection and more. This paper helps in reducing the research gap for ML applications.","decision trees, SVM, ANN, Machine Learning, finance, support vector machines, education, Naïve Bayes, artificial neural networks, Detection, Prediction, KNN, security","This paper discusses the potential of utilizing machine learning technologies in various sectors. It categorizes machine learning into four main learning processes: supervised, unsupervised, semi-supervised, and reinforcement learning. The paper also summarizes some applications of machine learning such as prediction, disease detection, and fraud detection."
Bhupendar P. Singh,Diurnal Variation of Ozone Levels in Academic Hostel in Delhi,"Urban air pollution has become a serious environmental problem in the last few decades in most of the developing countries including India. Due to widespread industrialization, rapid urbanization and huge growth in the number of motor vehicles have brought about severe deterioration in the urban air quality. Among the various gaseous pollutants, ozone is one of the important pollutants because of its health as well as climatic impacts. This study investigates the levels of ozone concentration at thirteen different hostels in an academic institute, Delhi. The measurements of ozone were carried out in indoor environments by ozone analyzer (Model S-5014 SIR) for 24 hours.","hostels, Delhi, academic hostels, ozone levels, diurnal variation, CPCB, anthropogenic activities, Indoor ozone, VOCs, NOx","The study reveals that the ozone concentration in the entire indoor environment of the JNU campus lies in the range (2.81 to 4.17 ppb for 24 hours) are well below the permissible limits (100 µg/m3 for 8 hours) prescribed by CPCB, India. Also the outdoor ozone concentration is found to lie in the range (13.93 ppb to 78. 15 ppb for 8 hours), which well above the standard (100 µg/m3 for 8 hours) prescribed by CPCB."
Bhupinder Chahal,Digital Education Challenges and Opportunities,"ace traditional teaching because cannot ignore the its importance of traditional teaching for development of physical and mental health. Even after the challenges, online education is becoming popular day by day due to the opportunities it is providing to society and it's a need of the hour too. In the case of the pandemic situation, this is the only solution when we cannot compromise the health of students and teachers. But to improve its effectiveness we have overcome most of the challenges discussed in section III. For this we all students, teachers, educational Institutes, Universities, Industries, and Govt. policymakers have to join our hands and work together to overcome these challenges.","Opportunities, Recommendations, Challenges, Digital Education, Online education, Covid-19, pandemic","This paper discusses the challenges and opportunities of online education. It highlights the importance of traditional teaching and the need for online education in the pandemic situation. The paper also discusses the challenges faced by online education and the ways to overcome them. It suggests that students, teachers, educational Institutes, Universities, Industries, and Govt. policymakers should work together to improve the effectiveness of online education."
Biao Luo,Off-policy Reinforcement Learning for H∞Control Design,"The H∞control design problem is considered for nonlinear systems with unknown internal system model. An off-policy reinforcement leaning (RL) method is introduced to learn the solution of HJI equation from real system data instead of mathematical system model, and its convergence is proved.","Reinforcement learning, Hamilton-Jacobi-Isaacs equation, Neural Network, H∞control design, Off-policy learning","The paper introduces an off-policy reinforcement learning method to solve the H∞control design problem for nonlinear systems with unknown internal system model. The method learns the solution of the Hamilton-Jacobi-Isaacs equation from real system data instead of a mathematical system model, and its convergence is proved. The paper also discusses the relationship between reinforcement learning and control communities, and reviews some existing results on reinforcement learning for optimal control problems."
Bidyadhar Dehury,"Seroprevalence of SARS-CoV-2 Antibodies in Uttar Pradesh, India: A Cross-Sectional Study","Population-based serological antibody test for SARS-CoV-2 infection helps in estimating the exposure in the community. We present the findings of the first district representative seroepidemiological survey conducted between 4 and 10 September 2020 among the population aged 5 years and above in the state of Uttar Pradesh, India. Multi-stage cluster sampling was used to select participants from 495 primary sampling units (villages in rural areas and wards in urban areas) across 11 selected districts to provide district-level seroprevalence disaggregated by place of residence (rural/urban), age (5–17 years/aged 18 +) and gender. A venous blood sample was collected to determine seroprevalence. Of 16,012 individuals enrolled in the study, 22.2% [95% CI 21.5–22.9] equating to about 10.4 million population in 11 districts were already exposed to SARS-CoV-2 infection by mid-September 2020. The overall seroprevalence was significantly higher in urban areas (30.6%, 95% CI 29.4–31.7) compared to rural areas (14.7%, 95% CI 13.9–15.6), and among aged 18 + years (23.2%, 95% CI 22.4–24.0) compared to aged 5–17 years (18.4%, 95% CI 17.0–19.9). No differences were observed by gender. Individuals exposed to a COVID confirmed case or residing in a COVID containment zone had higher seroprevalence (34.5% and 26.0%, respectively). There was also a wide variation (10.7–33.0%) in seropositivity across 11 districts indicating that population exposed to COVID was not uniform at the time of the study. Since about 78% of the population (36.5 million) in these districts were still susceptible to infection, public health measures remain essential to reduce further spread.","COVID-19, Seroprevalence, India, SARS-CoV-2, Heterogeneity, Uttar Pradesh","This study presents the first district-level seroprevalence survey of SARS-CoV-2 infection in Uttar Pradesh, India. Conducted in September 2020, the survey found that 22.2% of the population had been exposed to the virus by that time. Seroprevalence was significantly higher in urban areas and among individuals aged 18 and older. The findings highlight the importance of continued public health measures to reduce further spread of the virus."
Bidyadhar Subudhi,An Adaptive Sliding Mode Control Scheme for Grid Integration of a PV System ||| A Combined Reinforcement Learning and Sliding Mode Control Scheme for Grid Integration of a PV System ||| A Comparative Study on Maximum Power Point Tracking Techniques for Photovoltaic Power Systems ||| Differential Evolution: A Simple and Efficient Heuristic for Global Optimization over Continuous Spaces ||| Ensemble-Kalman-Filter-Based Power System Harmonic Estimation,"This paper presents an adaptive sliding mode control scheme for grid integration of a PV system. The proposed scheme is compared with the SMC-IC-IPT scheme and the results show that the ASMC-IC-IPT scheme reduces the grid current THD from 29.35% to 2.80%. ||| The paper presents development of a reinforcement learning (RL) and sliding mode control (SMC) algorithm for a 3-phase PV system integrated to a grid. The PV system is integrated to grid through a voltage source inverter (VSI), in which PV-VSI combination supplies active power and compensates reactive power of the local non-linear load connected to the point of common coupling (PCC). For extraction of maximum power from the PV panel, we develop a RL based maximum power point tracking (MPPT) algorithm. The instantaneous power theory (IPT) is adopted for generation reference inverter current (RIC). An SMC algorithm has been developed for injecting current to the local non-linear load at a reference value. The RL-SMC scheme is implemented in both simulation using MATLAB/SIMULINK software and on a prototype PV experimental. The performance of the proposed RL-SMC scheme is compared with that of fuzzy logic-sliding mode control (FL-SMC) and incremental conductance-sliding mode control (IC-SMC) algorithms. From the obtained results, it is observed that the proposed RL-SMC scheme provides better maximum power extraction and active power control than the FL-SMC and IC-SMC schemes. ||| This paper provides a comprehensive review of the maximum power point tracking (MPPT) techniques applied to photovoltaic (PV) power system available until January, 2012. ||| Several gradient-based approaches such as back propagation (BP) and Levenberg Marquardt (LM) methods have been developed for training the neural network (NN) based systems. But, for multimodal cost functions these procedures may lead to local minima, therefore, the evolutionary algorithms (EAs) based procedures are considered as promising alternatives. In this paper we focus on a memetic algorithm based approach for training the multilayer perceptron NN applied to nonlinear system identiﬁcation. The proposed memetic algorithm is an alternative to gradient search methods, such as back-propagation and back-propagation with momentum which has inherent limitations of many local optima. Here we have proposed the identiﬁcation of a nonlinear system using memetic differential evolution (DE) algorithm and compared the results with other six algorithms such as Back-propagation (BP), Genetic Algorithm (GA), Particle Swarm Optimization (PSO), Differential Evolution (DE), Genetic Algorithm Back-propagation (GABP), Particle Swarm Optimization combined with Back-propagation (PSOBP). In the proposed system identiﬁcation scheme, we have exploited DE to be hybridized with the back propagation algorithm, i.e. differential evolution back-propagation (DEBP) where the local search BP algorithm is used as an operator to DE. These algorithms have been tested on a standard benchmark problem for nonlinear system identiﬁcation to prove their efﬁcacy. First examples shows the comparison of different algorithms which proves that the proposed DEBP is having better identiﬁcation capability in comparison to other. In example 2 good behavior of the identiﬁcation method is tested on an one degree of freedom (1DOF) experimental aerodynamic test rig, a twin rotor multi-input–multi-output system (TRMS), ﬁnally it is applied to Box and Jenkins Gas furnace benchmark identiﬁcation problem and its efﬁcacy has been tested through correlation analysis. ||| This paper presents an ensemble Kalman filter (EnKF)-based algorithm for power system harmonic estimation. The proposed algorithm is compared with four other algorithms, namely, recursive least squares (RLS), recursive least mean squares (RLMS), Kalman filter (KF), and EnKF. The results show that the EnKF algorithm provides better estimation accuracy compared to the other algorithms.","photovoltaic (PV) array, grid synchronization, Nonlinear system identiﬁcation, total harmonic distortion, reinforcement learning, Evolutionary Algorithms, instantaneous power theory, Ensemble Kalman filter, Maximum power point tracking (MPPT) techniques, Recursive least squares, Evolutionary computation, Power system harmonic estimation, Ensemble Kalman filter (EnKF), Recursive least mean squares, Differential evolution, PV System, fast Fourier transform (FFT), Back propagation, Photovoltaic Power Systems, harmonic estimation, MPPT, Lyapunov function, Continuous Spaces, recursive least square (RLS), Comparative Study, Global Optimization, incremental conductance, Adaptive sliding mode control, Fuzzy logic, sliding mode controller, Particle swarm optimization, Sliding Mode Control, Grid Integration, Maximum Power Point Tracking, KF, Heuristic, Kalman filter","This paper presents an Adaptive Sliding Mode Control (ASMC) algorithm for grid synchronization of a photovoltaic (PV) system. The ASMC algorithm minimizes the difference between the reference inverter current and the actual inverter current of the grid connected PV system during unbalanced loading, grid voltage distortion and variation in solar irradiance. ||| This paper presents a combined reinforcement learning and sliding mode control scheme for grid integration of a PV system. The proposed scheme uses a reinforcement learning based maximum power point tracking algorithm and a sliding mode control algorithm to inject current to the local non-linear load at a reference value. The performance of the proposed scheme is compared with that of fuzzy logic-sliding mode control and incremental conductance-sliding mode control schemes. ||| The paper discusses various MPPT techniques, including feedback of power variation with voltage and current techniques, perturbation and observation (P&O) and hill-climbing technique, incremental conductance (Inc-Cond) technique, forced oscillation technique, ripple correlation control (RCC) technique, current sweep technique, estimated-perturb-perturb (EPP) technique, and parasitic capacitance technique. ||| This paper proposes a memetic algorithm based approach for training the multilayer perceptron neural network applied to nonlinear system identification. The proposed memetic algorithm is an alternative to gradient search methods and has been tested on a standard benchmark problem for nonlinear system identification. The results show that the proposed differential evolution back-propagation algorithm has better identification capability compared to other algorithms. ||| A new algorithm for the estimation of harmonics using EnKF is proposed. The performance is assessed with respect to some available harmonic estimation techniques, and the comparison indicates that the proposed method outperforms the existing methods in terms of accuracy and robustness with respect to sudden variations in measured signal amplitudes."
Bijender Kumar,Energy-Efficient Node Scheduling Mechanism for Target Coverage Problem in Wireless Sensor Networks ||| Improved-Coverage Preserving Clustering Protocol in Wireless Sensor Networks ||| Maximising network lifetime for target coverage problem in wireless sensor networks,"In wireless sensors networks, the sensor nodes are densely deployed. Owing to this excessive deployment of sensor nodes, each target is covered by multiple sensors at a time. To prolong the network lifetime, the authors can schedule the sensor activity in such a way that only a subset of sensor nodes, called cover set, is sufficient enough to cover all the targets. In this study, they propose an energy-efficient scheduling algorithm based on learning automata for target coverage problem. The learning automata-based technique helps a sensor node to select its appropriate state (either active or sleep). To prove the effectiveness of their proposed scheduling method, they conduct a detailed set of simulations and compare the performance of their algorithm with the existing algorithms. ||| Coverage maintenance for longer period is crucial problem in wireless sensor network (WSNs) due to limited inbuilt battery in sensors. Coverage maintenance can be prolonged by using the network energy efficiently, which can be done by keeping sufficient number of sensors in sensor covers. There has been discussed a Coverage-Preserving Clustering Protocol (CPCP) to increase the network lifetime in clustered WSNs. It selects sensors for various roles such as cluster heads and sensor cover members by considering various coverage aware cost metrics. In this paper, we propose a new heuristic called Improved-Coverage-Preserving Clustering Protocol (I-CPCP) to maximize the total network lifetime. In our proposed method, minimal numbers of sensor are selected to construct a sensor covers based on various coverage aware cost metrics. These cost metrics are evaluated by using residual energy of a sensor and their coverage. The simulation results show that our method has longer network lifetime as compared to generic CPCP. ||| Target coverage problem is one of the important problems in wireless sensor network in which each target should be covered by at least one sensor. All the sensors are organised into different groups called sensor cover in such a way that each cover can monitor all the targets for a fixed duration. By keeping one sensor cover active at a time while others in sleep mode, sensors batteries can be utilised in efficient way. This helps in prolonging the network lifetime. In this study, the authors propose a new energy-efficient heuristic to schedule the sensors in different non-disjoint sensor covers which helps to maximise network lifetime.","energy-efficient scheduling, coverage aware cost metrics, sensor networks, clustering protocol, sensor roles, clustering, energy-efficient node scheduling, target coverage problem, learning automata, network lifetime, energy-efficient heuristic, wireless sensor networks, energy-efficiency, coverage","This paper proposes an energy-efficient scheduling algorithm based on learning automata for target coverage problem in wireless sensor networks. The algorithm helps a sensor node to select its appropriate state (either active or sleep) to prolong the network lifetime. The effectiveness of the proposed scheduling method is proven through simulations and comparison with existing algorithms. ||| The paper proposes a Coverage Preserving Clustering Protocol (CPCP) to decide the roles of sensors for various activities in wireless sensor networks. The protocol estimates the total energy available to cover each point in the network area and considers various parameters like residual energy, number of 1-hop neighbouring sensor nodes, number of n-hop neighbouring sensor nodes and distance from the base station. The authors also discuss various coverage aware cost metrics to decide the roles of sensors for various activities. ||| The authors propose a new energy-efficient heuristic to schedule the sensors in different non-disjoint sensor covers which helps to maximise network lifetime. The heuristic identifies all the critical targets (least covered) and the critical sensors (covering critical targets). The critical targets, covered by minimum number of sensors, will be the targets that become uncovered first. Utilising critical sensors efficiently will help to increase the network lifetime."
Bijun Chen,Opposing Actions of Fibroblast and Cardiomyocyte Smad3 Signaling in the Infarcted Myocardium,"Transforming growth factor (TGF)–βs are highly pleiotropic mediators with critical roles in regulating cellular phenotype and function in embryonic development, tissue homeostasis, and disease. Normal tissues contain stores of latent TGF-β bound to the extracellular matrix through its association with a large binding protein, the latent TGF-β binding protein. Tissue injury is associated with marked induction of TGF-β isoforms and activation of TGF-β signaling cascades. Parenchymal cells, extravasated leukocytes, and platelets synthesize and release large amounts of TGF-β in the injury site. Reactive oxygen species, proteases, matricellular proteins, and integrins cooperate to trigger the release of bioactive TGF-β from the latent stores. Subsequent binding of the active TGF-β dimer to the type II TGF-β receptor, followed by transphosphorylation of the type I receptor, triggers the TGF-β signaling response. The cellular effects of TGF-β are mediated through a canonical pathway involving a series of intracellular effectors, the Smads, or through activation of noncanonical signaling cascades. Activation of TGF-β signaling induces phosphorylation of the receptor-activated Smads, Smad2 and Smad3, which can form heteromeric complexes with the common Smad, Smad4. These complexes are transported to the nucleus, where they regulate gene transcription. TGF–β receptors and Smads are ubiquitously expressed by all cell types. Thus, all cells are responsive to the actions of TGF-β. Cardiac injury is associated with the marked induction of TGF-β and activation of TGF-β cascades. Our laboratory and other investigators have documented activation of Smad2 and Smad3 signaling in the infarcted myocardium, localized in both cardiomyocytes and interstitial cells. In isolated cardiac fibroblasts, Smad3 signaling accentuates myofibroblast transdifferentiation and stimulates a matrix-preserving program. In a model of reperfused infarction, global loss of Smad3 attenuated remodeling after infarction. However, considering the ubiquitous expression of Smad3 in all cell types, the cell biological basis for the actions of Smad3 in the infarcted heart remains unknown. Our study dissects the cell-specific actions of Smad3 signaling in the infarcted myocardium by developing and studying mice with cell-specific loss of Smad3 in activated fibroblasts and cardiomyocytes. It is surprising that fibroblast-specific loss of Smad3 worsened remodeling after infarction, resulting in accentuated chamber dilation. The deleterious consequences of fibroblast-specific Smad3 loss reflected unrestrained fibroblast proliferation, defective scar remodeling, and perturbed organization of myofibroblast arrays in the border zone. Smad3 signaling regulated fibroblast function, activating integrin-mediated nicotinamide adenine dinucleotide phosphate (NADPH) oxidase (NOX)–2 expression. In contrast, cardiomyocyte-specific loss of Smad3 protected the infarcted heart from dysfunction after infarction. The protective effects of cardiomyocyte-specific Smad3 loss were associated with attenuated cardiomyocyte apoptosis in remodeling myocardium and accompanied by decreased NOX2 levels, reduced nitrosative stress, and decreased matrix metalloproteinase (MMP)–2 expression.","SMAD, fibroblast, heart failure, cardiomyocyte, remodeling","This study investigates the role of Smad3 in cardiac fibroblasts following myocardial infarction. Using a mouse model with fibroblast-specific Smad3 deletion (FS3KO), the researchers found that loss of Smad3 in fibroblasts exacerbated dilative remodeling and worsened systolic dysfunction after both reperfused and nonreperfused infarction.  While acute infarct size was not affected, FS3KO mice exhibited larger scars, increased myofibroblast density, and enhanced myofibroblast proliferation. These findings suggest that Smad3 plays a protective role in cardiac fibroblasts and its loss contributes to adverse cardiac remodeling after infarction."
Bin Qian,"Explainable AI (XAI): Core Ideas, Techniques and Solutions","As our dependence on intelligent machines continues to grow, so does the demand for more transparent and interpretable models. In addition, the ability to explain the model generally is now the gold standard for building trust and deployment of Artificial Intelligence (AI) systems in critical domains. Explainable Artificial Intelligence (XAI) aims to provide a suite of machine learning (ML) techniques that enable human users to understand, appropriately trust, and produce more explainable models.","Explainable AI, Stakeholders, Machine Learning, Software toolkits, Programming framework, Bias, Robustness, Interpretable AI, Explainable Artiﬁcial Intelligence, XAI, Decision Making","The paper presents the core ideas, techniques, and solutions of XAI, emphasizing its importance in various phases of the machine learning process. It discusses the stakeholders involved in these phases, including developers, theorists, data scientists, users, consumers, businesses, regulators, and scientists, and highlights the use cases of XAI in detecting bias, scientific understanding, building robust models, and better decision making."
Bingpeng Zhou,Mobile Edge Computing for Big Data-Enabled Electric Vehicle Charging,"As one of the key drivers of smart grid, Electric Vehicles (EVs) are environment-friendly to alleviate CO2 pollution. Big data analytics could enable the move from Internet of EVs, to optimized EV charging in smart transportation. In this paper, we propose a Mobile Edge Computing (MEC) based system, in line with a big data-driven planning strategy on which Charging Station (CS) to charge.","Big Data, MEC Based System, EV Charging, Communication Technologies, Network Entities, Smart Transportation, Smart Cities, Decentralized Charging Management, Centralized Charging Management, Charging Planning, Smart Grid, Big Data-Enabled Electric Vehicle Charging, Mobile Edge Computing","This paper proposes a Mobile Edge Computing (MEC) based system for big data-enabled electric vehicle charging. The system integrates big data analytics to opportunistically disseminate the outcome from a Global Controller and collect driving big data from mobile clients. The MEC servers implement big data mining and aggregation in a decentralized way, alleviating the size of data to be processed by the Global Controller."
Bisan Alsalibi,Hybrid Harmony Search Algorithm to Solve the Feature Selection for Data Mining Applications,"The increasing size of all sorts text and data information on websites makes the method of text clustering (TC) a lot more complicated. The TC technique is employed to cluster an enormous variety of documents into a set of intelligible and connected clusters. Usually, TC is employed in several domains like text mining, data processing, pattern recognition, image clustering.","Hybrid Harmony Search Algorithm, Vector Space Model, Feature Selection, Text Clustering, Data Mining, Data Mining Applications","This paper proposes a hybrid harmony search algorithm to solve the feature selection problem for data mining applications. The algorithm uses the harmony search rule to select and obtain a new set of informative knowledge features, reducing the runtime of the system and decreasing the uninformative knowledge feature. The results show that the proposed modification of the harmony search rule enriched the performance value of the feature choice method in regard to the correct set, owing to its fine features."
Bo-Hao Jin,Deep Sparse Representation Classifier for Facial Recognition  and Detection System,"This paper proposes a two-layer Convolutional Neural Network (CNN) to learn the high-level features which utilizes to the face identification via sparse representation. Feature extraction plays a vital role in real-world pattern recognition and classification tasks. The details description of the given input face image, significantly improve the performance of the facial recognition system. Sparse Representation Classifier (SRC) is a popular face classifier that sparsely represents the face image by a subset of training data, which is known as insensitive to the choice of feature space. The proposed method shows the performance improvement of SRC via a precisely selected feature exactor. The experimental results show that the proposed method outperform other methods on given datasets.","Sparse Feature Extraction, Convolutional neural network, Deep learning, CNN, Sparse representation classifier, Face recognition, Support Vector Machines, Feature extraction","This paper presents a robust face recognition framework based on the combination of sparse feature extraction using Convolutional Neural Networks (CNNs) and Support Vector Machines (SVMs). The proposed framework is evaluated on four widely used face datasets, including Extended YALE B database, AR database, MIT faces database, and ORL faces database. The experimental results show that the proposed framework outperforms the state-of-the-art methods in terms of recognition rate."
"Bowyer, K. W.",A Multi-Task Approach to Open Domain Suggestion Mining,"Consumer reviews online may contain suggestions useful for improving the target products and services. Mining suggestions is challenging because the field lacks large labelled and balanced datasets. Furthermore, most prior studies have only focused on mining suggestions in a single domain. In this work, we introduce a novel up-sampling technique to address the problem of class imbalance, and propose a multi-task deep learning approach for mining suggestions from multiple domains.","Deep Learning, Suggestion Mining, Artificial Intelligence, Class Imbalance, Multi-Task Learning","This paper presents a multi-task approach to open domain suggestion mining, addressing the class imbalance problem using a novel up-sampling technique and a multi-task deep learning framework. Experimental results show that the proposed approach outperforms state-of-the-art models in terms of F-1 measure and AUC."
"Breiman, 2001",Supervised Heterogeneous Domain Adaptation via Random Forests,This paper proposes a novel approach to heterogeneous domain adaptation using random forests. The algorithm leverages the common label information between the source and target domains as the pivot for knowledge transfer. The proposed algorithm determines the mapping PS between source and target features based on the estimate of the contribution of the features towards creating data partitions having similar label distributions.,"Label Information, Supervised Heterogeneous Domain Adaptation, Feature Mapping, Heterogeneous Domain Adaptation, Random Forests, Knowledge Transfer, Feature Transfer, Domain Adaptation",The paper proposes a novel supervised domain adaptation algorithm (SHDA-RF) that learns the mapping between heterogeneous features of different dimensions. The algorithm uses the shared label distributions present across the domains as pivots for learning a sparse feature transformation. The shared label distributions and the relationship between the feature spaces and the label distributions are estimated in a supervised manner using random forests.
"Bruke, R.",Feature Weighting in Content Based Recommendation System Using Social Network Analysis,A hybridization of content based and collaborative filtering based recommendation is proposed. The weights of different attributes of an item are computed from the collaborative social network using regression analysis.,"Feature Similarity, hybrid recommender systems, Recommender System, content-based filtering, collaborative filtering, Social Network, regression analysis",This paper proposes a hybridization of collaborative filtering and content based recommendation system. The authors assign weights to attributes used for content based recommendations based on their importance to users. The weights are estimated from a social network graph which captures human judgment about similarity of items.
Brunda S,Analysing the Performance of Novel Activation Functions on Deep Learning Architectures,"Deep learning is a cutting-edge technology that functions similarly to the human nervous system. Neural networks are at the heart of Deep Learning. Neural networks are made up of numerous layers, in-cluding the input layer, which accepts raw data as input, hidden layers, which process the input data, and a final layer, the output layer, which provides the result. Its workflow pattern is comparable to machine learn-ing [2], [11], allowing us to gain hands-on expertise with this technology, speed up our work, and allow us to make several efforts without hav-ing to develop a basic Machine learning algorithm from scratch. In the case of deep learning, there are several neural networks to choose from. The majority of Deep Learning architectures are built on neural networks such as CNN, RNN, and others. Deep neural network activation function development is often guided by set goals and gradual steps toward tack-ling specific challenges. The primary goal of this study is to examine the performance of innovative activation functions (SBAF parabola [6] [16], AReLU [7], Leaky ReLU, SWISH) on deep learning architectures such as CNN, DENSENET, etc. On deep learning architectures, our study will compare the classification performance of the aforementioned activation functions.","Redundancy, Network reliability, Robotics, Embedded systems","This paper explores the performance of novel activation functions (SBAF parabola, AReLU, Leaky ReLU, SWISH) on deep learning architectures like CNN and DENSENET. The study aims to compare the classification accuracy of these activation functions on various computer vision datasets."
C N Ionitaa,Evaluation of the microangiographic fluoroscope (MAF) using generalized system performance metrics,"Cone beam computed tomography (CBCT) systems with rotational gantries that have standard flat panel detectors (FPD) are widely used for the 3D rendering of vascular structures using Feldkamp cone beam reconstruction algorithms. One of the inherent limitations of these systems is limited resolution (<3 lp/mm). There are systems available with higher resolution but their small FOV limits them to small animal imaging only. In this work, we report on region-of-interest (ROI) CBCT with a high resolution CMOS detector (75 μm pixels, 600 μm HR-CsI) mounted with motorized detector changer on a commercial FPD-based C-arm angiography gantry (194 μm pixels, 600 μm HL-CsI). A cylindrical CT phantom and neuro stents were imaged with both detectors. For each detector a total of 209 images were acquired in a rotational protocol. The technique parameters chosen for the FPD by the imaging system were used for the CMOS detector. The anti-scatter grid was removed and the incident scatter was kept the same for both detectors with identical collimator settings. The FPD images were reconstructed for the 10 cm x10 cm FOV and the CMOS images were reconstructed for a 3.84 cm × 3.84 cm FOV. Although the reconstructed images from the CMOS detector demonstrated comparable contrast to the FPD images, the reconstructed 3D images of the neuro stent clearly showed that the CMOS detector improved delineation of smaller objects such as the stent struts (~70 μm) compared to the FPD. Further development and the potential for substantial clinical impact are suggested.",,"This study demonstrates the use of a high-resolution CMOS detector in region-of-interest cone beam computed tomography (ROI CBCT) for improved visualization of small vascular structures. Compared to a standard flat panel detector, the CMOS detector achieved comparable contrast but significantly enhanced spatial resolution, enabling clearer delineation of stent struts. This advancement holds promise for clinical applications requiring high-resolution imaging of vascular anatomy."
C. J. M. Rao,On the Distributivity of Implication Operators Over T and S Norms,"It may be noted that a fuzzy implication will be of the form “If X is A, then Y is B,” where X and Y are the variables and A and B are fuzzy sets on the domain of X and Y, respectively. The implication is represented as and often as . It is common in fuzzy control to have two different antecedents (observations) leading to the same consequent (action). The two rules may be joined by “else” or “and.” These lead to the RHS of (1) and (2) respectively. The the left-hand side of these equations reduce these to a single rule. Similarly, in the case of fuzzy expert systems, it is possible that one antecedent (symptom) may lead to different consequents (diseases). These lead to the right-hand side of (3) and (4). The left-hand side of these equations once again enable reduction in number of rules. The advantage of this rule reduction is lossless inferencing, i.e., the inferences drawn from the original system and the reduced system are the same. It is quite satisfying to note that all S-implications and R-implications have this property. The requirement on any binary operator to satisfy these equations is also not too stringent. The discussion in this work is on the framework of single-input–single-output fuzzy systems, but can be extended in an obvious way to multiple-input–single-output systems.","Sugeno (S)-norms, Takagi (T)-norms, fuzzy implication, fuzzy logic, fuzzy control, fuzzy expert systems, Distributivity, implication operators, rule reduction, fuzzy systems",The authors discuss the distributivity of implication operators in fuzzy systems and their application to rule reduction. They show that all S-implications and R-implications have the property of lossless inferencing and that the requirement on any binary operator to satisfy these equations is not too stringent.
C. Jiang,Secure Robust and Imperceptible Algorithm for Watermarking Relational Databases,"This paper proposes a secure robust and imperceptible algorithm for watermarking relational databases. The algorithm divides the embedding algorithm into three phases: Watermark preparator, watermark position detector, and watermark embedder. The ownership identification issue is resolved by embedding owner's identity as watermark in Preparator phase.","imperceptible algorithm, Ownership identification, robust algorithm, Relational Database, watermarking, Watermark, Copyright protection, Proof of ownership, relational databases","The paper proposes a new robust secure and imperceptible embedding mechanism to resolve the two important concerns namely; owner identification and proof of ownership. The proposed mechanism involves encoding and decoding on numerical attribute of relational database in three phases; 1)Watermark preparator, 2)Watermark position detector and 3) Watermark Embedder or Detector."
C. Kim,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
C. N. Ionita,Micro-Computed tomography (CT) based assessment of dental regenerative therapy in the canine mandible model,"High-resolution 3D bone-tissue structure measurements may provide information critical to the understanding of the bone regeneration processes and to the bone strength assessment. Tissue engineering studies rely on such nondestructive measurements to monitor bone graft regeneration area. In this study, we measured bone yield, fractal dimension and trabecular thickness through micro-CT slices for different grafts and controls. Eight canines underwent surgery to remove a bone volume (defect) in the canine’s jaw at a total of 44 different locations. We kept 11 defects empty for control and filled the remaining ones with three regenerative materials; NanoGen (NG), a FDA-approved material (n=11), a novel NanoCalcium Sulfate (NCS) material (n=11) and NCS alginate (NCS+alg) material (n=11). After a minimum of four and eight weeks, the canines were sacrificed and the jaw samples were extracted. We used a custom-built micro-CT system to acquire the data volume and developed software to measure the bone yield, fractal dimension and trabecular thickness. The software used a segmentation algorithm based on histograms derived from volumes of interest indicated by the operator. Using bone yield and fractal dimension as indices we are able to differentiate between the control and regenerative material (p<0.005). Regenerative material NCS showed an average 63.15% bone yield improvement over the control sample, NCS+alg showed 55.55% and NanoGen showed 37.5%. The bone regeneration process and quality of bone were dependent upon the position of defect and time period of healing. This study presents one of the first quantitative comparisons using non-destructive Micro-CT analysis for bone regenerative material in a large animal with a critical defect model. Our results indicate that Micro-CT measurement could be used to monitor in-vivo bone regeneration studies for greater regenerative process understanding.","Regenerative Materials, Quantitative Analysis, Bone Regeneration, Micro-CT, LabVIEW","This study investigates the effectiveness of three different bone regenerative materials (NanoGen, NanoCalcium Sulfate, and NanoCalcium Sulfate alginate) in a canine mandible model using micro-computed tomography (micro-CT). The study found that all three materials significantly improved bone regeneration compared to the control group. NanoCalcium Sulfate showed the most significant improvement, followed by NanoCalcium Sulfate alginate and NanoGen. The position of the defect and the healing time period were also found to influence the regeneration process."
C. N. Ionitaa,Quantitative Comparison of a High Resolution Micro-Angiographic Fluoroscopic (MAF) Detector with a Standard Flat Panel Detector (FPD) Using the New Metric of Generalized Measured Relative Object Detectability (GM-ROD),"A novel amorphous selenium (a-Se) direct detector with CMOS readout has been designed, and relative detector performance investigated. The detector features include a 25μm pixel pitch, and 1000μm thick a-Se layer operating at 10V/μm bias field. A simulated detector DQE was determined, and used in comparative calculations of the Relative Object Detectability (ROD) family of prewhitening matched-filter (PWMF) observer and non-prewhitening matched filter (NPWMF) observer model metrics to gauge a-Se detector performance against existing high resolution micro-angiographic fluoroscopic (MAF) detectors and a standard flat panel detector (FPD). The PWMF-ROD or ROD metric compares two x-ray imaging detectors in their relative abilities in imaging a given object by taking the integral over spatial frequencies of the Fourier transform of the detector DQE weighted by an object function, divided by the comparable integral for a different detector. The generalized-ROD (G-ROD) metric incorporates clinically relevant parameters (focal-spot size, magnification, and scatter) to show the degradation in imaging performance for detectors that are part of an imaging chain. Preliminary ROD calculations using simulated spheres as the object predicted superior imaging performance by the a-Se detector as compared to existing detectors. New PWMF-G-ROD and NPWMF-G-ROD results still indicate better performance by the a-Se detector in an imaging chain over all sphere sizes for various focal spot sizes and magnifications, although a-Se performance advantages were degraded by focal spot blurring. Nevertheless, the a-Se technology has great potential to provide breakthrough abilities such as visualization of fine details including of neuro-vascular perforator vessels and of small vascular devices.","Comparative metrics, generalized metrics, micro-angiography, DQE, Detector Performance, relative object detectability, Microangiography, CMOS, Flat Panel Detector, amorphous selenium","This paper presents a comparative study of a novel amorphous selenium (a-Se) direct detector with existing high resolution micro-angiographic fluoroscopic (MAF) detectors and a standard flat panel detector (FPD). The study utilizes the Relative Object Detectability (ROD) family of metrics, including the generalized-ROD (G-ROD) metric, to assess the performance of these detectors in imaging small objects.  The results indicate that the a-Se detector exhibits superior imaging performance compared to existing detectors, particularly in terms of resolving fine details.  While focal spot blurring can degrade the performance advantage of the a-Se detector, its potential for breakthrough imaging capabilities in neuro-vascular applications is highlighted."
C. Scottb,Quantitative Comparison of a High Resolution Micro-Angiographic Fluoroscopic (MAF) Detector with a Standard Flat Panel Detector (FPD) Using the New Metric of Generalized Measured Relative Object Detectability (GM-ROD),"A novel amorphous selenium (a-Se) direct detector with CMOS readout has been designed, and relative detector performance investigated. The detector features include a 25μm pixel pitch, and 1000μm thick a-Se layer operating at 10V/μm bias field. A simulated detector DQE was determined, and used in comparative calculations of the Relative Object Detectability (ROD) family of prewhitening matched-filter (PWMF) observer and non-prewhitening matched filter (NPWMF) observer model metrics to gauge a-Se detector performance against existing high resolution micro-angiographic fluoroscopic (MAF) detectors and a standard flat panel detector (FPD). The PWMF-ROD or ROD metric compares two x-ray imaging detectors in their relative abilities in imaging a given object by taking the integral over spatial frequencies of the Fourier transform of the detector DQE weighted by an object function, divided by the comparable integral for a different detector. The generalized-ROD (G-ROD) metric incorporates clinically relevant parameters (focal-spot size, magnification, and scatter) to show the degradation in imaging performance for detectors that are part of an imaging chain. Preliminary ROD calculations using simulated spheres as the object predicted superior imaging performance by the a-Se detector as compared to existing detectors. New PWMF-G-ROD and NPWMF-G-ROD results still indicate better performance by the a-Se detector in an imaging chain over all sphere sizes for various focal spot sizes and magnifications, although a-Se performance advantages were degraded by focal spot blurring. Nevertheless, the a-Se technology has great potential to provide breakthrough abilities such as visualization of fine details including of neuro-vascular perforator vessels and of small vascular devices.","Comparative metrics, generalized metrics, micro-angiography, DQE, Detector Performance, relative object detectability, Microangiography, CMOS, Flat Panel Detector, amorphous selenium","This paper presents a comparative study of a novel amorphous selenium (a-Se) direct detector with existing high resolution micro-angiographic fluoroscopic (MAF) detectors and a standard flat panel detector (FPD). The study utilizes the Relative Object Detectability (ROD) family of metrics, including the generalized-ROD (G-ROD) metric, to assess the performance of these detectors in imaging small objects.  The results indicate that the a-Se detector exhibits superior imaging performance compared to existing detectors, particularly in terms of resolving fine details.  While focal spot blurring can degrade the performance advantage of the a-Se detector, its potential for breakthrough imaging capabilities in neuro-vascular applications is highlighted."
C. Sharma,Impact of Eurasian Snow Cover on Indian Summer Monsoon Rainfall over the Northwestern Himalayas,"The entire Indo-Himalayan region from northwest (Kashmir) to northeast (Assam) is facing prevalence of floods and landslides in recent years causing massive loss of property, human and animal lives, infrastructure, and eventually threatening tourist activities substantially. Extremely intense rainfall event of A.D. 2013 (between 15 and 17 June) kicked off mammoth flash floods in the Kedarnath area of Uttarakhand state, resulting in huge socioeconomic losses to the state and country.","Eurasian snow cover, extreme rainfall events, flash floods, gridded data sets, Himalayas, Arctic Oscillation, northwestern Himalayas, Indian summer monsoon rainfall","The study investigates ~100-year-long monthly rainfall and air temperature time series data for a selected grid covering most parts of Uttarakhand state. The results indicate that under warming scenario, JJ rainfall (over AS) may further increase with occasional extreme rainfall spells when AO index (March) is negative."
C.-H. Teh,Unique Local Features in Lip Images for Recognition,"The experiments are carried out from images taken with a camera that is used for the regular use. And the color features of a lip are not explored in the proposed research. Still the recognition system exploits the grayscale local features of a lip images and eﬃciently matches it with local features of another lip image. If the color properties of a lip image is explored for recognition along with local features, the accuracy values would increase further.","grayscale features, Lip Pattern Recognition, SIFT, lip recognition, color features, Biometric, Local Feature Extraction, local features, SURF",The paper presents the results of experiments on lip recognition using local features. The recognition system exploits the grayscale local features of lip images and achieves high accuracy. The authors suggest that exploring color properties of lip images could further improve the accuracy.
C.P. Katti,Fifty Years of Automata Simulation: A Review,"This paper reviews the development of automata simulators over the past fifty years. It discusses various approaches to modeling automata, including notational, assembly-like, procedural, and descriptive languages. The paper also presents several examples of automata simulators, including a Pushdown Automata Simulator, a Turing Machine Simulator, and a Finite Automaton Description Language.","automata theory, automata simulation, procedural languages, simulation, notational languages, assembly-like languages, descriptive languages, computer science education",The article reviews the major initiatives in the field of simulation of automata in the last five decades with emphasis on those automata simulators actually used at universities for teaching. It also identifies some salient trends in the research on simulation of automata and concludes with an advocacy for continuing research on simulation of automata and integration of automata simulators in teaching.
C.T. Lin,Machine learning techniques for the diagnosis of Alzheimer’s disease: A review,"Alzheimer’s disease is an incurable neurodegenerative disease primarily affecting the elderly population. Efficient automated techniques are needed for early diagnosis of Alzheimers. Many novel approaches are proposed by researchers for classification of Alzheimer’s disease. However, to develop more efficient learning techniques, better understanding of the work done on Alzheimers is needed. Here, we provide a review on 165 papers from 2005-2019 using various feature extraction and machine learning techniques. The machine learning techniques are surveyed under three main categories: support vector machine (SVM), artificial neural network (ANN), and deep learning (DL) and ensemble methods.","Ensemble methods, Support vector machine, Deep learning, Alzheimer’s disease, classification, Artificial neural network, Machine learning","This paper provides a review of 165 papers on machine learning techniques for the diagnosis of Alzheimer’s disease from 2005-2019. The review covers three main categories: support vector machine (SVM), artificial neural network (ANN), and deep learning (DL) and ensemble methods. The paper discusses the importance of efficient automated techniques for early diagnosis of Alzheimers and the need for better understanding of the work done on Alzheimers to develop more efficient learning techniques."
CHEN et al.,A Multi-Facet Survey on Memetic Computation,"This paper presents a comprehensive multi-facet exposition of recent research in memetic computation. It begins with a brief review on the early manifestations of memetic computation within the context of evolutionary computation, and then takes a focus on the recent developments of hybrids and adaptive hybrids. The paper highlights “Memetic Automaton,” a natural progression toward establishing “meme” as the focal point of memetic computation and pinpoints some noteworthy emerging research trends in the field that have remained under-explored.","memetic algorithms in uncertain environments, evolution and learning, hybrids, memetic algorithm design issues, memetic automaton, multiobjective memetic algorithms, multiagent system, hybridization, surrogate-assisted memetic algorithms, memetic computation, Adaptive memetic algorithms, adaptive hybrids, memes imitation","The paper presents a comprehensive survey of recent research in memetic computation, including simple hybrids, adaptive hybrids, and memetic automaton. It highlights the importance of hybridization in memetic computation and discusses the main issues in simple hybrids, including the types of population-based search methods and reﬁnement procedures, the levels of hybridization, modes of inheritance as well as the types of domain-speciﬁc information incorporated into simple hybrids."
CHIA-HSIN CHUNG,IoT-Based Wireless Polysomnography Intelligent System for Sleep Monitoring,"Polysomnography (PSG) is considered the gold standard in the diagnosis of obstructive sleep apnea (OSA). The diagnosis of OSA requires an overnight sleep experiment in a laboratory. However, due to limitations in relation to the number of labs and beds available, patients often need to wait a long time before being diagnosed and eventually treated. In addition, the unfamiliar environment and restricted mobility when a patient is being tested with a polysomnogram may disturb their sleep, resulting in an incomplete or corrupted test. Therefore, it is posed that a PSG conducted in the patient’s home would be more reliable and convenient. The Internet of Things (IoT) plays a vital role in the e-Health system. In this paper, we implement an IoT-based wireless polysomnography system for sleep monitoring, which utilizes a battery-powered, miniature, wireless, portable, and multipurpose recorder. A Java-based PSG recording program in the personal computer is designed to save several bio-signals and transfer them into the European data format. These PSG records can be used to determine a patient’s sleep stages and diagnose OSA. This system is portable, lightweight, and has low power-consumption. To demonstrate the feasibility of the proposed PSG system, a comparison was made between the standard PSG-Alice 5 Diagnostic Sleep System and the proposed system. Several healthy volunteer patients participated in the PSG experiment and were monitored by both the standard PSG-Alice 5 Diagnostic Sleep System and the proposed system simultaneously, under the supervision of specialists at the Sleep Laboratory in Taipei Veteran General Hospital. A comparison of the results of the time-domain waveform and sleep stage of the two systems shows that the proposed system is reliable and can be applied in practice. The proposed system can facilitate the long-term tracing and research of personal sleep monitoring at home.","sleep monitoring, wireless, Internet of Things, wireless PSG, JAVA, Polysomnography (PSG), IoT","This paper proposes an IoT-based wireless polysomnography system for sleep monitoring, which utilizes a battery-powered, miniature, wireless, portable, and multipurpose recorder. The system is designed to save several bio-signals and transfer them into the European data format, allowing for the determination of a patient’s sleep stages and diagnosis of OSA. The proposed system is compared to the standard PSG-Alice 5 Diagnostic Sleep System and shows reliable results, making it a viable option for long-term tracing and research of personal sleep monitoring at home."
CHIN-TENG LIN,IoT-Based Wireless Polysomnography Intelligent System for Sleep Monitoring ||| Robust Feature-Based Automated Multi-View Human Action Recognition System,"Polysomnography (PSG) is considered the gold standard in the diagnosis of obstructive sleep apnea (OSA). The diagnosis of OSA requires an overnight sleep experiment in a laboratory. However, due to limitations in relation to the number of labs and beds available, patients often need to wait a long time before being diagnosed and eventually treated. In addition, the unfamiliar environment and restricted mobility when a patient is being tested with a polysomnogram may disturb their sleep, resulting in an incomplete or corrupted test. Therefore, it is posed that a PSG conducted in the patient’s home would be more reliable and convenient. The Internet of Things (IoT) plays a vital role in the e-Health system. In this paper, we implement an IoT-based wireless polysomnography system for sleep monitoring, which utilizes a battery-powered, miniature, wireless, portable, and multipurpose recorder. A Java-based PSG recording program in the personal computer is designed to save several bio-signals and transfer them into the European data format. These PSG records can be used to determine a patient’s sleep stages and diagnose OSA. This system is portable, lightweight, and has low power-consumption. To demonstrate the feasibility of the proposed PSG system, a comparison was made between the standard PSG-Alice 5 Diagnostic Sleep System and the proposed system. Several healthy volunteer patients participated in the PSG experiment and were monitored by both the standard PSG-Alice 5 Diagnostic Sleep System and the proposed system simultaneously, under the supervision of specialists at the Sleep Laboratory in Taipei Veteran General Hospital. A comparison of the results of the time-domain waveform and sleep stage of the two systems shows that the proposed system is reliable and can be applied in practice. The proposed system can facilitate the long-term tracing and research of personal sleep monitoring at home. ||| Automated human action recognition has the potential to play an important role in public security, for example, in relation to the multiview surveillance videos taken in public places, such as train stations or airports. This paper compares three practical, reliable, and generic systems for multiview video-based human action recognition, namely, the nearest neighbor classiﬁer, Gaussian mixture model classiﬁer, and the nearest mean classiﬁer. To describe the different actions performed in different views, view-invariant features are proposed to address multiview action recognition. These features are obtained by extracting the holistic features from different temporal scales which are modeled as points of interest which represent the global spatial-temporal distribution. Experiments and cross-data testing are conducted on the KTH, WEIZMANN, and MuHAVi datasets. The system does not need to be retrained when scenarios are changed which means the trained database can be applied in a wide variety of environments, such as view angle or background changes. The experiment results show that the proposed approach outperforms the existing methods on the KTH and WEIZMANN datasets.","feature extraction, points of interest extraction, background subtraction, sleep monitoring, wireless, machine learning, Internet of Things, moving object localization, wireless PSG, multi-view human action recognition, action recognition, JAVA, Multi-view video, classiﬁcation, Polysomnography (PSG), IoT","This paper proposes an IoT-based wireless polysomnography system for sleep monitoring, which utilizes a battery-powered, miniature, wireless, portable, and multipurpose recorder. The system is designed to save several bio-signals and transfer them into the European data format, allowing for the determination of a patient’s sleep stages and diagnosis of OSA. The proposed system is compared to the standard PSG-Alice 5 Diagnostic Sleep System and shows reliable results, making it a viable option for long-term tracing and research of personal sleep monitoring at home. ||| This paper proposes a robust feature-based automated multi-view human action recognition system. The system uses view-invariant features to address multi-view action recognition from a range of perspectives. The proposed approach labels the beginning and end of an action sequence in a video stream automatically and captures sequence motions and occlusions at a low computational cost. The system is evaluated using the KTH, WEIZMAN, and MuHAVi datasets and outperforms existing methods on the KTH and WEIZMANN datasets."
CLL Gowda,Understanding Helicoverpa armigera Pest Population Dynamics related to Chickpea Crop Using Neural Networks,Insect pests are a major cause of crop loss globally. Pest management will be effective and efficient if we can predict the occurrence of peak activities of a given pest. Research efforts are going on to understand the pest dynamics by applying analytical and other techniques on pest surveillance data sets. In this study we make an effort to understand pest population dynamics using Neural Networks by analyzing  pest surveillance data set of Helicoverpa armigera or Pod borer on chickpea (Cicer arietinum L.)  crop. The results show that neural network method successfully predicts the pest attack incidences for one week in advance.,"Climatic Data, Pest Population Dynamics, Neural Networks, Pest Surveillance Databases, Chickpea Crop, Helicoverpa armigera, Neural Network, Pest Attack Prediction","The experimental results show that it is possible to predict the pest attack with high probability for one week in advance. These predictions would help the farmers in pest management programs by avoiding the crop losses with improved environment quality, as it can avoid unnecessary sprays of chemical pesticides."
Cardei et al.,Maximum Coverage First: A New Heuristic for Target Coverage Problem in Wireless Sensor Networks,"This paper proposes a new heuristic, Maximum Coverage First (MCF), to solve the target coverage problem in wireless sensor networks. MCF generates sensor covers by selecting sensors that cover the maximum number of uncovered targets, and assigns lifetime to each cover based on the minimum residual battery life of its sensors.","Maximum Coverage First, Target Coverage Problem, Wireless Sensor Networks, Network lifetime, Lifetime Assignment, Heuristic Algorithms, Heuristic, NP completeness","The paper presents a new heuristic, MCF, to solve the target coverage problem in wireless sensor networks. MCF generates sensor covers by selecting sensors that cover the maximum number of uncovered targets, and assigns lifetime to each cover based on the minimum residual battery life of its sensors. The paper also compares the performance of MCF with other existing heuristics and presents simulation results to demonstrate its effectiveness."
Carlos Gonzalez-Quesada,TSP-1 in Diabetic Cardiomyopathy,"Diabetes mellitus is associated with cardiac fibrosis. Matricellular proteins are induced in fibrotic conditions and modulate fibrogenic and angiogenic responses by regulating growth factor signaling. Our aim was to test the hypothesis that the prototypical matricellular protein thrombospondin (TSP)-1, a potent angiostatic molecule and crucial activator of transforming growth factor-β, may play a key role in remodeling of the diabetic heart. Obese diabetic db/db mice exhibited marked myocardial TSP-1 upregulation in the interstitial and perivascular space. To study the role of TSP-1 in remodeling of the diabetic heart, we generated and characterized db/db TSP-1–/– (dbTSP) mice. TSP-1 disruption did not significantly affect weight gain and metabolic function in db/db animals. When compared with db/db animals, dbTSP mice had increased left ventricular dilation associated with mild nonprogressive systolic dysfunction. Chamber dilation in dbTSP mice was associated with decreased myocardial collagen content and accentuated matrix metalloproteinase-2 and -9 activity. TSP-1 disruption did not affect inflammatory gene expression and activation of transforming growth factor-β/small mothers against decapendaplegic signaling in the db/db myocardium. In cardiac fibroblasts populating collagen pads, TSP-1 incorporation into the matrix did not activate transforming growth factor-β responses, but inhibited leptin-induced matrix metalloproteinase-2 activation. TSP-1 disruption abrogated age-associated capillary rarefaction in db/db mice, attenuating myocardial upregulation of angiopoietin-2, a mediator that induces vascular regression. In vitro, TSP-1 stimulation increased macrophage, but not endothelial cell, angiopoietin-2 synthesis. Conclusions: TSP-1 upregulation in the diabetic heart prevents chamber dilation by exerting matrix-preserving actions on cardiac fibroblasts and mediates capillary rarefaction through effects that may involve angiopoietin-2 upregulation.","matrix metalloproteinases, thrombospondins, fibrosis, diabetic cardiomyopathies, ventricular remodeling","This study investigates the role of thrombospondin-1 (TSP-1) in diabetic cardiomyopathy. Researchers found that TSP-1 is upregulated in the hearts of diabetic mice and that its loss attenuates cardiac fibrosis and enhances myocardial protease activity. However, TSP-1 disruption also led to mild left ventricular dilation and modest nonprogressive systolic dysfunction. These findings suggest that TSP-1 plays a complex role in diabetic heart remodeling, with both beneficial and detrimental effects."
"Carolina Llanos, MD",Cardiac Neonatal Lupus: Maternal and Fetal Risk Factors for Mortality,"Background: Cardiac neonatal lupus (CNL) is a serious complication of maternal anti-Ro/SSA and anti-La/SSB antibodies.  We sought to identify maternal and fetal risk factors for mortality in infants with CNL.

Methods and Results: We retrospectively analyzed data from 325 infants with CNL born to 297 mothers. Overall, 57 deaths (17.5%) occurred. Hydrops, carditis, and EFE were associated with increased mortality in both in utero and postnatal deaths. Maternal diagnosis of SLE and/or SS was associated with increased mortality in the overall analysis and in utero deaths.  Whites were less likely to die than minorities.

Conclusions: Hydrops, carditis, EFE, and maternal SLE and/or SS are significant risk factors for mortality in infants with CNL.","mortality, morbidity, cardiomyopathy, antibodies, heart block","This study investigates maternal and fetal risk factors for mortality in infants with cardiac neonatal lupus (CNL).  Key findings include the significant association of hydrops, carditis, EFE, and maternal SLE and/or SS with increased mortality. Additionally, white infants were found to have a lower mortality rate compared to minorities."
Ch.Ravi Kishore,Performance Evaluation of Entropy and Gini using Threaded and Non Threaded ID3 on Anaemia Dataset,"Classification is an important data mining task, and decision trees have emerged as a popular classifier due to their simplicity and relatively low computational complexity. Time required to build a decision tree becomes intractable, as datasets get extremely large. To overcome this problem we proposed a parallel mode of ID3 algorithm. Decision tree building is well-suited for thread-level parallelism as it requires a large number of independent computations. In this paper, we present the analysis and parallel implementation of the ID3 algorithm using Entropy and Gini as heuristics, along data set.","Entropy Heuristic, Threaded ID3, Parallel data mining, Gini Heuristic, Data Mining, Decision tree, ID3, Parallelism, Gini, Entropy, Anemia Database","The paper presents a parallel mode of ID3 algorithm for decision tree building, using Entropy and Gini as heuristics, and analyzes its performance on an anaemia dataset. The proposed method helps in analyzing two types of anaemia, Iron deficiency anaemia (ID) and B12 deficiency anaemia (B12), and identifies the most significant attributes for determining the transferred, number of frozen embryos, and culture days of embryo."
Chandan Jyoti Das,"Magnetic Resonance Materials in Physics, Biology and Medicine",Objective  To implement an advanced spatial penalty-based reconstruction to constrain the intravoxel incoherent motion (IVIM)–diffusion kurtosis imaging (DKI) model and investigate whether it provides a suitable alternative at 1.5 T to the traditional IVIM–DKI model at 3 T for clinical characterization of prostate cancer (PCa) and benign prostatic hyperplasia (BPH).,"TV penalty function, Prostate cancer, Benign prostatic hyperplasia, Total variation penalty function, MRI, Diffusion kurtosis imaging, Intravoxel incoherent motion, IVIM–DKI model","This study compares the use of IVIM–DKI at 1.5 T and 3 T MRI for differentiating between prostate cancer and benign prostatic hyperplasia. The results show that IVIM–DKI modeled with a novel model at 1.5 T produced parameter maps with lower coefficient of variation than the traditional model at 3 T. The novel model estimated higher D with lower D*, f, and k values at both field strengths compared to the traditional model. The study concludes that the proposed novel model can be utilized for improved detection of prostate lesions."
Chandan Pradhan,Prediction of Willingness of Users in V-MIMO,"In cellular systems, virtual multiple-input multiple-output (V-MIMO) technology promises to achieve performance gains comparable to conventional MIMO. In this paper, we propose cooperative relay selection algorithm based on machine learning techniques. Willingness of user to cooperate in V-MIMO depends on his current battery power, time and day along with incentives offered by service provider.","Artificial Neural network, SVM, ANN, Machine Learning, Virtual MIMO, Support Vector Machine, V-MIMO, Virtual Antenna Array","This paper proposes a cooperative relay selection algorithm based on machine learning techniques for virtual MIMO systems. The algorithm predicts potential willing users in the neighborhood of the source user and reduces cooperative node discovery time. The performance of the algorithm is evaluated using metrics such as MSE, accuracy, precision, and recall."
Chandra K. Jaggi,Credit Financing in Economic Ordering Policies for Defective Items with Order Overlapping,"In the classical inventory models, most of the time the issue of quality of the items has not been given due attention. However, in realistic environment, it can be observed that there may be some defective items in an ordered lot, because of these defective items retailer may incurs additional cost due to rejection, repair and refund etc. Thus, inspection/screening of lot becomes essential in most of the organizations.","imperfect items, profit maximization, permissible delay, inventory model, Inventory, supplier credit period, optimal order quantity, overlapping",This paper develops an inventory model for imperfect quality items under permissible delay in payments. The screening rate is assumed to be more than the demand rate. An order is placed during the screening process at the time when inventory level is good enough to meet demand. The proposed model optimizes retailer's order quantity by maximizing his expected total profit.
Charles Benson,First-­in-­Human Study of Bamlanivimab in a Randomized Trial of Hospitalized Patients With COVID-­19,"This first-in-human study in hospitalized patients with COVID-19 was supported by studies assessing in vitro viral neutralization combined with a single-dose non-human primate PK study. The nonclinical safety package to support subsequent studies included tissue cross-reactivity studies on human, rat, and monkey tissues and an in vivo toxicology study.  A complete physical examination was conducted at the screening visit, and one of three bamlanivimab doses or placebo was administered i.v. at the baseline visit (D1) with infusion rates as follows: bamlanivimab 700 mg (50 mL) administered 100 mL/hr for 30 minutes; 2,800 mg (75 mL) administered 100 mL/hr for 45 minutes; and 7,000 mg administered 100 mL/hr for 60 minutes. Placebo infusion was 0.9% normal saline, administered at the same volume and rate as the corresponding bamlanivimab dose cohort. Safety and tolerability were reviewed for sentinel participants up to 24 hours after dosing, at which point the investigators and sponsor team determined whether safety and tolerability were acceptable to continue with dosing subsequent participants. The decision to dose the next cohort was made when all participants from the previous cohort had been dosed and safety data assessed for at least 4 days after the i.v. infusion by the investigators and sponsor team in consultation with an independent safety assessment committee. Blood samples were obtained for assessment of exploratory biomarkers, serology, clinical laboratory assessments, and PD on days 1, 3, 7, 11, 15, 22, and 29, and every 7 days until discharge or day 60, if still an inpatient. Samples for the virology assay were collected using nasopharyngeal (preferred) or mid-turbinate methods. Blood samples obtained for PK analyses were assessed on days 1 (pre-infusion and just before end of infusion), 4, 15, and 29, and follow-up visits up to day 60. Symptom-related physical examinations and assessments of clinical symptoms were performed on days 1, 2, 3, 4, 7, 11, 15, 22, and 29, and the day of discharge from the hospital, with additional follow-up examinations every 7 days thereafter until day 60 if the patient was not discharged from the hospital by day 29. Participants’ clinical status and concurrent procedures of special interest were recorded, including limitation on activities due to COVID-19 and any requirements for the following procedures of special interest, such as ongoing hospital medical care, supplemental oxygen, noninvasive ventilation or a high flow oxygen device, mechanical ventilation, extracorporeal membrane oxygenation, additional organ support, or consciousness status using alert, consciousness, verbal, pain, unresponsive scale. Hospitalization events were recorded, including dates of hospital admission and discharge, admission to the intensive care unit (ICU), discharge from the ICU, and discharge location including to an extended care facility or home. Outcomes The primary objective was to assess safety and tolerability, including adverse events (AEs), serious adverse events (SAEs), and discontinuations due to AEs. Other objectives included PKs (e.g., mean concentration at day 29); PD viral load, area under the response time curve (AUC, from day 1 to day 29), and change from baseline time course; total symptom score; time to symptom resolution; duration of hospitalization; National Institute of Allergy and Infectious Diseases (NIAID), World Health Organization (WHO) scales, and National Early Warning Score (NEWS2); and analysis of viral resistance. Any hypothesis tests were conducted for treatment comparisons without adjustment for multiplicity except for the evaluation of treatment effect on endogenous antibody titers. Success for the trial was claimed using a Bayesian criterion if any of the 3 bamlanivimab doses had at least 60% probability to reduce at least 30% mean AUC (28-day viral load) over placebo.",,"This first-in-human study evaluated the safety, tolerability, pharmacokinetics, clinical course, and viral dynamics of bamlanivimab, a fully human neutralizing monoclonal antibody targeting SARS-CoV-2, in hospitalized patients with moderate to severe COVID-19.  The study found bamlanivimab to be safe and well-tolerated, with no serious adverse events or deaths reported.  Further research is needed to determine the efficacy of bamlanivimab in treating COVID-19."
"Chawla, N. V.",A Multi-Task Approach to Open Domain Suggestion Mining,"Consumer reviews online may contain suggestions useful for improving the target products and services. Mining suggestions is challenging because the field lacks large labelled and balanced datasets. Furthermore, most prior studies have only focused on mining suggestions in a single domain. In this work, we introduce a novel up-sampling technique to address the problem of class imbalance, and propose a multi-task deep learning approach for mining suggestions from multiple domains.","Deep Learning, Suggestion Mining, Artificial Intelligence, Class Imbalance, Multi-Task Learning","This paper presents a multi-task approach to open domain suggestion mining, addressing the class imbalance problem using a novel up-sampling technique and a multi-task deep learning framework. Experimental results show that the proposed approach outperforms state-of-the-art models in terms of F-1 measure and AUC."
Chayanika Sharma,Hybrid Mobile Learning - Book Chapter 2 - Me and Addisu,"This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the material is concerned, specifically the rights of translation, reprinting, reuse of illustrations, recitation, broadcasting, reproduction on microfilms or in any other physical way, and transmission or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now known or hereafter developed.","extensible and adaptable computing, agile software development, machine learning, computing in education, comparative analysis, user story acceptance tests, Web intelligence, meta-heuristic techniques","This book investigates various challenges in extensible and adaptable methods in computing, including agile software development, data management, machine learning, Web intelligence, and computing in education. It presents elegant solutions for cost-efficient storage of data, transmitting data securely, and processing data in specific applications such as health care. The book also showcases innovative algorithms and applications, including portfolio optimization, disruption classification, and outlier detection, as well as emerging Web applications in dynamic social contexts."
Chen and Teng,Rumour Source Detection Using Game Theory,"Social networks have become a critical part of our lives as they enable us to interact with a lot of people. These networks have become the main sources for creating, sharing and also extracting information regarding various subjects. But all this information may not be true and may contain a lot of unverified rumours that have the potential of spreading incorrect information to the masses, which may even lead to situations of widespread panic. Thus, it is of great importance to identify those nodes and edges that play a crucial role in a network in order to find the most influential sources of rumour spreading. Generally, the basic idea is to classify the nodes and edges in a network with the highest criticality. Most of the existing work regarding the same focuses on using simple centrality measures which focus on the individual contribution of a node in a network. Game-theoretic approaches such as Shapley Value (SV) algorithms suggest that individual marginal contribution should be measured for a given player as the weighted average marginal increase in the yield of any coalition that this player might join. For our experiment, we have played five SV-based games to find the top 10 most influential nodes on three network datasets (Enron, USAir97 and Les Misérables). We have compared our results to the ones obtained by using primitive centrality measures. Our results show that SV-based approach is better at understanding the marginal contribution, and therefore the actual influence, of each node to the entire network.","influential nodes, Jaccard Similarity Coefficient, cooperative game, Rumour Source Detection (RSD), centrality measures, network analysis, Shapley Value (SV), Game-Theory, Network Centrality",This paper aims to identify the most influential nodes in a network that are the primary sources of rumour propagation. The authors propose a game-theoretic approach using the Shapley Value algorithm to find the most influential nodes. They compare their results with primitive centrality measures and show that the SV-based approach is better at understanding the marginal contribution of each node to the entire network.
Cheol-Jin Park,Bandwidth-Efﬁcient OFDM transmission with iterative cyclic preﬁx reconstruction,"Abstract—Orthogonal frequency division multiplexing (OFDM) systems are now a part of all major wireless standards, because of its potential to offer high data rate. Cyclic prefix (CP) in OFDM system converts a multipath channel to a flat fading channel, thus simplifies the design of equalizer. However, there is a lot of ambiguity in choosing the length of CP. In this paper, we propose a new method for calculation of length of CP using cumulant features. The merits of proposed method are verified by computer simulation.","bandwidth efﬁciency, OFDM, channel length estimation, cumulant features, Orthogonal frequency division multiplexing (OFDM), Cyclic prefix (CP), cyclic preﬁx, Blind channel length estimation","This paper proposes a novel method for blind channel length estimation in OFDM systems using cumulant features. The proposed method is well-suited for dynamic spectrum access (DSA) setups and does not require pilot or training sequences, thus saving bandwidth. The method is based on exploiting the properties of nth order cumulant features and is verified by computer simulation."
Chhavi Sharma,Semi Supervised Graph Based Keyword Extraction Using Lexical Chains and Centrality Measures,"This paper proposes a semi-supervised graph-based keyword extraction algorithm using lexical chains and centrality measures. The algorithm first extracts nouns from each paragraph and creates lexical chains based on the similarity between words. The chains are then scored using two different methods, and the best chains are selected based on their scores. The selected chains are used to create a graph, and centrality measures are applied to identify the most central words as the extracted keywords.","Semi-supervised learning, small world approach, Graph-based keyword extraction, lexical chains, WordNet, Graph centrality, Word sense disambiguation, Centrality measures, keyword extraction, semantic similarity","The proposed algorithm uses a combination of lexical chains and centrality measures to extract keywords from a document. It first extracts nouns from each paragraph and creates lexical chains based on the similarity between words. The chains are then scored using two different methods, and the best chains are selected based on their scores. The selected chains are used to create a graph, and centrality measures are applied to identify the most central words as the extracted keywords."
Chin-Teng Lin,A Layered-Coevolution-Based Attribute-Boosted Reduction Using Adaptive Quantum Behavior PSO and Its Consistent Segmentation for Neonates Brain Tissue ||| A Review of Clustering Techniques and Developments ||| Deep Sparse Representation Classifier for Facial Recognition  and Detection System,"The main challenge of attribute reduction in large data applications is to develop a new algorithm to deal with large, noisy, and uncertain large data linking multiple relevant data sources, structured or unstructured. This paper proposes a new and efficient layered-coevolution-based attribute-boosted reduction algorithm (LCQ-ABR*) using adaptive quantum behavior particle swarm optimization (PSO). ||| This paper presents a comprehensive study on clustering: exiting methods and developments made at various times. Clustering is defined as an unsupervised learning where the objects are grouped on the basis of some similarity inherent among them. There are different methods for clustering the objects such as hierarchical, partitional, grid, density based and model based. The approaches used in these methods are discussed with their respective states of art and applicability. The measures of similarity as well as the evaluation criteria, which are the central components of clustering are also presented in the paper. The applications of clustering in some fields like image segmentation, object and character recognition and data mining are highlighted. ||| This paper proposes a two-layer Convolutional Neural Network (CNN) to learn the high-level features which utilizes to the face identification via sparse representation. Feature extraction plays a vital role in real-world pattern recognition and classification tasks. The details description of the given input face image, significantly improve the performance of the facial recognition system. Sparse Representation Classifier (SRC) is a popular face classifier that sparsely represents the face image by a subset of training data, which is known as insensitive to the choice of feature space. The proposed method shows the performance improvement of SRC via a precisely selected feature exactor. The experimental results show that the proposed method outperform other methods on given datasets.","Sparse Feature Extraction, Unsupervised learning, Convolutional neural network, Deep learning, Clustering, sulci and gyrus estimate, Face recognition, Data mining, Neonatal Brain Tissue 3D-MRI, Hierarchical Clustering, Self-Adaptive Memeplexes, layered-coevolution with multi-agent interaction, ROCK, Quantum-Behavior PSO, Similarity measures, Clustering Approaches, CNN, consistent segmentation for neonates brain tissue, Sparse representation classifier, Support Vector Machines, Pattern recognition, BIRCH, Layered Co-Evolutionary Model, Taxonomy, adaptive quantum behavior PSO, Attribute-boosted reduction, CURE, Multi-Agent Interaction, CHAMELEON, Feature extraction","This paper proposes a new attribute reduction algorithm using quantum behavior PSO, which aims to choose attribute subsets for large-scale, noisy, and uncertain datasets. The algorithm is evaluated on several benchmark datasets and compared with other representative algorithms. The results show that the proposed algorithm has better feasibility and effectiveness than the compared algorithms. ||| This paper reviews clustering techniques and developments, discussing methods such as hierarchical, partitional, grid, density-based, and model-based clustering, as well as measures of similarity and evaluation criteria. The applications of clustering in fields like image segmentation, object recognition, and data mining are highlighted. ||| This paper presents a robust face recognition framework based on the combination of sparse feature extraction using Convolutional Neural Networks (CNNs) and Support Vector Machines (SVMs). The proposed framework is evaluated on four widely used face datasets, including Extended YALE B database, AR database, MIT faces database, and ORL faces database. The experimental results show that the proposed framework outperforms the state-of-the-art methods in terms of recognition rate."
Christopher Cruzen,An innovative employment of the NetLogo AIDS model in developing a new chain code for compression,"In this paper, we utilize the NetLogo HIV model in constructing an environment for bi-level image encoding and employ it in compression. Our model considers converting an image into a virtual environment that comprises female agents testing positive and negative for HIV. Female agents are scattered according to the allocation of the pixels in the original images to be tested. The simulation considers introducing male agents that test positive for HIV, the purpose of which is to track their movements while infecting other HIV- female agents. The progressions of the HIV+ male agents within the simulation take advantage of the relative encoding approach previously used by other image processing and agent-based modeling researchers. That is to say, the simulation allows generating a high proportion of similar movement forms that are similarly encoded regardless of the movements of agents. This is followed up by applying Huffman coding to the obtained chains of movement strings for further reduction. The ultimate results reveal that our product could outperform existing benchmarks using all the images we employed in testing.","compression, AIDS, image encoding, agent-based model, chain code, HIV transmission, Huffman coding, NetLogo",The authors designed and implemented an agent-based model of HIV transmission within a social society to encode bi-level image information and compress the new chains. The results showed that the current model outperformed well-known standardized benchmarks in bi-level compression.
Chuandong Li,Global Exponential Synchronization of Multiple Riemann-Liouville Neural Networks with Time-Varying Impulsive Delays,"This paper investigates the global exponential synchronization of multiple Riemann-Liouville neural networks with time-varying impulsive delays. By constructing a suitable Lyapunov function and using the linear matrix inequality (LMI) technique, some sufficient conditions are derived to ensure the global exponential synchronization of the considered neural networks. The obtained results are expressed in terms of the network parameters, impulsive delays, and coupling strengths. Finally, two numerical examples are provided to demonstrate the effectiveness of the proposed synchronization scheme.","time-varying impulsive delays, memristor, global exponential synchronization, Lyapunov function, recurrent neural networks, linear matrix inequality, synchronization, time-varying delay, Impulse, Riemann-Liouville neural networks","This paper presents a study on the global exponential synchronization of multiple Riemann-Liouville neural networks with time-varying impulsive delays. The authors derive sufficient conditions for synchronization using a Lyapunov function and linear matrix inequality (LMI) technique. The results are expressed in terms of network parameters, impulsive delays, and coupling strengths. Two numerical examples are provided to demonstrate the effectiveness of the proposed synchronization scheme."
Chuanjin Yao,History Matching of Naturally Fractured Reservoirs Using a Deep Sparse Autoencoder,"This work proposes a new characterization method and a method to reduce dimensionality for history matching of naturally fractured reservoirs. The forward simulator is modeled after the EDFM given its computational efficiency. The fracture network can be represented with length, orientation, and position, including large-scale fractures and small-scale fractures.","History matching, characterization method, EDFM, Naturally fractured reservoirs, Deep sparse autoencoder, dimensionality reduction, fracture network","This paper proposes a new characterization method for the multiscale fracture network, and a powerful dimensionality-reduction method by means of an autoencoder for model parameters. The characterization method of the fracture network is dependent on the length, orientation, and position of fractures, including large-scale and small-scale fractures."
"Clark, C.",A Multi-Task Approach to Open Domain Suggestion Mining,"Consumer reviews online may contain suggestions useful for improving the target products and services. Mining suggestions is challenging because the field lacks large labelled and balanced datasets. Furthermore, most prior studies have only focused on mining suggestions in a single domain. In this work, we introduce a novel up-sampling technique to address the problem of class imbalance, and propose a multi-task deep learning approach for mining suggestions from multiple domains.","Deep Learning, Suggestion Mining, Artificial Intelligence, Class Imbalance, Multi-Task Learning","This paper presents a multi-task approach to open domain suggestion mining, addressing the class imbalance problem using a novel up-sampling technique and a multi-task deep learning framework. Experimental results show that the proposed approach outperforms state-of-the-art models in terms of F-1 measure and AUC."
Coello et al.,Multi-Objective Genetic Algorithm for Optimization of Catalytic Reaction,"This paper discusses the use of a multi-objective genetic algorithm (MOGA) for the optimization of a catalytic reaction. The MOGA is used to find a set of solutions that are close to the Pareto front, well spread, and cover the whole spectrum of the Pareto front. The algorithm is applied to a competitive enzyme inhibition reaction scheme and the results are discussed.","Genetic Algorithm, Cellular Automata, Optimization, Enzyme kinetics, Pareto Front, Multi-Objective Optimization, Multi-Objective Genetic Algorithm, Catalytic Reaction","The paper presents a multi-objective genetic algorithm for the optimization of a catalytic reaction. The algorithm is used to find a set of solutions that are close to the Pareto front, well spread, and cover the whole spectrum of the Pareto front. The results of the algorithm are discussed and compared with other optimization methods."
Cotta and Neri,Memetic search in artiﬁcial bee colony algorithm,"Artiﬁcial bee colony (ABC) optimization algorithm is relatively a simple and recent population based probabilistic approach for global optimization. ABC has been outperformed over some Nature Inspired Algorithms (NIAs) when tested over benchmark as well as real world optimization problems. The solution search equation of ABC is signiﬁcantly inﬂuenced by a random quantity which helps in exploration at the cost of exploitation of the search space. In the solution search equation of ABC, there is a enough chance to skip the true solution due to large step size. In order to balance between diversity and con-vergence capability of the ABC, a new local search phase is integrated with the basic ABC to exploit the search space identiﬁed by the best individual in the swarm. In the proposed phase, ABC works as a local search algorithm in which, the step size that is required to update the best solution, is controlled by Golden Section Search approach. The proposed strategy is named as Memetic ABC (MeABC). In MeABC, new solutions are generated around the best solution and it helps to enhance the exploitation capability of ABC. MeABC is established as a modiﬁed ABC algorithm through experiments over 20 test problems of different complexities and 4 well known engineering optimization problems.","Exploration-exploitation, Swarm intelligence, Memetic algorithm, Memetic Search, Honey Bees, Artiﬁcial bee colony","This paper proposes a new local search strategy, Memetic ABC (MeABC), which integrates a Golden Section Search approach with the basic Artificial Bee Colony (ABC) algorithm to balance exploration and exploitation behavior. MeABC is established as a modified ABC algorithm through experiments over 20 test problems and 4 engineering optimization problems."
D R Bednareka,Evaluation of the microangiographic fluoroscope (MAF) using generalized system performance metrics,"Cone beam computed tomography (CBCT) systems with rotational gantries that have standard flat panel detectors (FPD) are widely used for the 3D rendering of vascular structures using Feldkamp cone beam reconstruction algorithms. One of the inherent limitations of these systems is limited resolution (<3 lp/mm). There are systems available with higher resolution but their small FOV limits them to small animal imaging only. In this work, we report on region-of-interest (ROI) CBCT with a high resolution CMOS detector (75 μm pixels, 600 μm HR-CsI) mounted with motorized detector changer on a commercial FPD-based C-arm angiography gantry (194 μm pixels, 600 μm HL-CsI). A cylindrical CT phantom and neuro stents were imaged with both detectors. For each detector a total of 209 images were acquired in a rotational protocol. The technique parameters chosen for the FPD by the imaging system were used for the CMOS detector. The anti-scatter grid was removed and the incident scatter was kept the same for both detectors with identical collimator settings. The FPD images were reconstructed for the 10 cm x10 cm FOV and the CMOS images were reconstructed for a 3.84 cm × 3.84 cm FOV. Although the reconstructed images from the CMOS detector demonstrated comparable contrast to the FPD images, the reconstructed 3D images of the neuro stent clearly showed that the CMOS detector improved delineation of smaller objects such as the stent struts (~70 μm) compared to the FPD. Further development and the potential for substantial clinical impact are suggested.",,"This study demonstrates the use of a high-resolution CMOS detector in region-of-interest cone beam computed tomography (ROI CBCT) for improved visualization of small vascular structures. Compared to a standard flat panel detector, the CMOS detector achieved comparable contrast but significantly enhanced spatial resolution, enabling clearer delineation of stent struts. This advancement holds promise for clinical applications requiring high-resolution imaging of vascular anatomy."
D. Anil Kumar and V. Ravi,Predicting credit card customer churn in banks using data mining,"In this paper, we solve the customer credit card churn prediction via data mining. We developed an ensemble system incorporating majority voting and involving Multilayer Perceptron (MLP), Logistic Regression (LR), decision trees (J48), Random Forest (RF), Radial Basis Function (RBF) network and Support Vector Machine (SVM) as the constituents. The dataset was taken from the Business Intelligence Cup organised by the University of Chile in 2004. Since it is a highly unbalanced dataset with 93% loyal and 7% churned customers, we employed (1) undersampling, (2) oversampling, (3) a combination of undersampling and oversampling and (4) the Synthetic Minority Oversampling Technique (SMOTE) for balancing it. Furthermore, tenfold cross-validation was employed. The results indicated that SMOTE achieved good overall accuracy. Also, SMOTE and a combination of undersampling and oversampling improved the sensitivity and overall accuracy in majority voting. In addition, the Classification and Regression Tree (CART) was used for the purpose of feature selection. The reduced feature set was fed to the classifiers mentioned above. Thus, this paper outlines the most important predictor variables in solving the credit card churn prediction problem. Moreover, the rules generated by decision tree J48 act as an early warning expert system.","decision tree, Multilayer Perceptron, undersample, intelligent techniques, credit card churn prediction, radial basis function network, SVM, oversampling, churn prediction, Synthetic Minority Oversampling Technique, MLP, CRISP-DM, Support Vector Machine, SMOTE, Logistic Regression, Random Forest, RF, customer churn, LR, data mining","This paper presents a data mining approach to predict credit card customer churn in banks. An ensemble system incorporating majority voting and involving various machine learning algorithms is developed to classify customers as churned or loyal. The dataset is taken from the Business Intelligence Cup and is highly unbalanced. Various techniques such as undersampling, oversampling, and SMOTE are employed to balance the dataset. The results show that SMOTE achieves good overall accuracy and improves sensitivity and overall accuracy in majority voting. The paper outlines the most important predictor variables in solving the credit card churn prediction problem and presents an early warning expert system using decision tree J48."
D. G. Lowe,Unique Local Features in Lip Images for Recognition,"The experiments are carried out from images taken with a camera that is used for the regular use. And the color features of a lip are not explored in the proposed research. Still the recognition system exploits the grayscale local features of a lip images and eﬃciently matches it with local features of another lip image. If the color properties of a lip image is explored for recognition along with local features, the accuracy values would increase further.","grayscale features, Lip Pattern Recognition, SIFT, lip recognition, color features, Biometric, Local Feature Extraction, local features, SURF",The paper presents the results of experiments on lip recognition using local features. The recognition system exploits the grayscale local features of lip images and achieves high accuracy. The authors suggest that exploring color properties of lip images could further improve the accuracy.
D. Gopinathan,New Path Based Index Structure for Processing CAS Queries Over XML Database,"Querying nested data has become one of the most challenging issues for retrieving desired information from the Web. Today diverse applications generate a tremendous amount of data in different formats. These data and information exchanged on the Web are commonly expressed as nested representation such as XML, JSON, etc. Unlike the traditional database system, they do not possess a rigid schema. In general, the nested data is managed by storing data and its structures separately which significantly reduces the performance of data retrieving. Ensuring efficiency of processing queries which locates the exact positions of the elements has become a big challenging issue.","database storage, XML databases, XML, CAS query, WWW, XPath, query evaluation engine, CAS queries, index engine, index, query processing, path-based index structure",The proposed system uses integration of data structures B+ Tree and HashMap to construct the indices. The Hash Map stores the structural component of the XML document and an offset to the B+ Tree. The B+ tree stores the content information in the XML document. The path combined index (pc_index) is constructed by combining the terminal siblings with same ancestor paths into a single path.
D. Hanyurwimfura,Secure Robust and Imperceptible Algorithm for Watermarking Relational Databases,"This paper proposes a secure robust and imperceptible algorithm for watermarking relational databases. The algorithm divides the embedding algorithm into three phases: Watermark preparator, watermark position detector, and watermark embedder. The ownership identification issue is resolved by embedding owner's identity as watermark in Preparator phase.","imperceptible algorithm, Ownership identification, robust algorithm, Relational Database, watermarking, Watermark, Copyright protection, Proof of ownership, relational databases","The paper proposes a new robust secure and imperceptible embedding mechanism to resolve the two important concerns namely; owner identification and proof of ownership. The proposed mechanism involves encoding and decoding on numerical attribute of relational database in three phases; 1)Watermark preparator, 2)Watermark position detector and 3) Watermark Embedder or Detector."
D. J. Nawal,Augmented Reality Wordbook App for Kindergarteners (ARWAK),"In the last two decades, augmented reality educational software tools have been used to teach various subjects to schoolchildren around the world. We developed a wordbook smartphone app and used it to teach new words to children in kindergartens in New Delhi between January and April of 2018. The app uses marker-based augmented reality technology and displays three dimensional pictures of objects whose names the children are learning blended in their immediate surrounding. The app was designed to make the learning process more interactive and intuitive. We found that children can learn slightly more number of words from the app than from a printed wordbook. However, the main benefit of the app was that it was able to increase participation by the children and keep them engaged. The teachers who used the app to teach felt that it was easy to integrate the app in the kindergarten environment and it presented information in a way suitable for young children. We recommend the use of augmented reality smartphone apps to teach children various concepts in kindergartens and schools.","vocabulary, Education, Kindergarteners, Learning, smartphone app, augmented reality, wordbook, Kindergarten","This paper presents the development and evaluation of an augmented reality wordbook smartphone app for kindergarteners. The app uses marker-based augmented reality technology to display three dimensional pictures of objects whose names the children are learning. The app was found to increase participation and engagement of children, and was easy to integrate into the kindergarten environment. The authors recommend the use of augmented reality smartphone apps to teach children various concepts in kindergartens and schools."
D. Jain,Augmented Reality Wordbook App for Kindergarteners (ARWAK),"In the last two decades, augmented reality educational software tools have been used to teach various subjects to schoolchildren around the world. We developed a wordbook smartphone app and used it to teach new words to children in kindergartens in New Delhi between January and April of 2018. The app uses marker-based augmented reality technology and displays three dimensional pictures of objects whose names the children are learning blended in their immediate surrounding. The app was designed to make the learning process more interactive and intuitive. We found that children can learn slightly more number of words from the app than from a printed wordbook. However, the main benefit of the app was that it was able to increase participation by the children and keep them engaged. The teachers who used the app to teach felt that it was easy to integrate the app in the kindergarten environment and it presented information in a way suitable for young children. We recommend the use of augmented reality smartphone apps to teach children various concepts in kindergartens and schools.","vocabulary, Education, Kindergarteners, Learning, smartphone app, augmented reality, wordbook, Kindergarten","This paper presents the development and evaluation of an augmented reality wordbook smartphone app for kindergarteners. The app uses marker-based augmented reality technology to display three dimensional pictures of objects whose names the children are learning. The app was found to increase participation and engagement of children, and was easy to integrate into the kindergarten environment. The authors recommend the use of augmented reality smartphone apps to teach children various concepts in kindergartens and schools."
D. Jayasri,Liquid crystal films on curved surfaces: An entropic sampling study,"We report a Monte Carlo study of the phase transition in liquid crystals using the Wang-Landau algorithm. We compute the representative density of states of the film under consideration and make the system perform an energy-uniform random walk by biasing the walk against its own density of states. We then extract the canonical ensembles by simultaneously applying two biasing probabilities to the microstates, one according to the density of states and the other due to the assumed statistical distribution corresponding to the temperature under consideration. We adopt this procedure in reporting the following equilibrium properties of the film under different boundary conditions.","curved substrates, Monte Carlo simulation, Monte Carlo study, phase transition, liquid crystals, nematic thin film, Wang-Landau algorithm","We study the phase transition in liquid crystals using the Wang-Landau algorithm and report the equilibrium properties of the film under different boundary conditions. We find that the temperature at which the transition takes place is not the same as the temperature near which the uniaxial phase actually forms, and that the surface anchoring seems to be too strong for the elastic response of the nematic medium to force a uniaxial order above a certain threshold value."
D. R. Bednarek,Micro-Computed tomography (CT) based assessment of dental regenerative therapy in the canine mandible model,"High-resolution 3D bone-tissue structure measurements may provide information critical to the understanding of the bone regeneration processes and to the bone strength assessment. Tissue engineering studies rely on such nondestructive measurements to monitor bone graft regeneration area. In this study, we measured bone yield, fractal dimension and trabecular thickness through micro-CT slices for different grafts and controls. Eight canines underwent surgery to remove a bone volume (defect) in the canine’s jaw at a total of 44 different locations. We kept 11 defects empty for control and filled the remaining ones with three regenerative materials; NanoGen (NG), a FDA-approved material (n=11), a novel NanoCalcium Sulfate (NCS) material (n=11) and NCS alginate (NCS+alg) material (n=11). After a minimum of four and eight weeks, the canines were sacrificed and the jaw samples were extracted. We used a custom-built micro-CT system to acquire the data volume and developed software to measure the bone yield, fractal dimension and trabecular thickness. The software used a segmentation algorithm based on histograms derived from volumes of interest indicated by the operator. Using bone yield and fractal dimension as indices we are able to differentiate between the control and regenerative material (p<0.005). Regenerative material NCS showed an average 63.15% bone yield improvement over the control sample, NCS+alg showed 55.55% and NanoGen showed 37.5%. The bone regeneration process and quality of bone were dependent upon the position of defect and time period of healing. This study presents one of the first quantitative comparisons using non-destructive Micro-CT analysis for bone regenerative material in a large animal with a critical defect model. Our results indicate that Micro-CT measurement could be used to monitor in-vivo bone regeneration studies for greater regenerative process understanding.","Regenerative Materials, Quantitative Analysis, Bone Regeneration, Micro-CT, LabVIEW","This study investigates the effectiveness of three different bone regenerative materials (NanoGen, NanoCalcium Sulfate, and NanoCalcium Sulfate alginate) in a canine mandible model using micro-computed tomography (micro-CT). The study found that all three materials significantly improved bone regeneration compared to the control group. NanoCalcium Sulfate showed the most significant improvement, followed by NanoCalcium Sulfate alginate and NanoGen. The position of the defect and the healing time period were also found to influence the regeneration process."
D. R. Bednareka,Quantitative Comparison of a High Resolution Micro-Angiographic Fluoroscopic (MAF) Detector with a Standard Flat Panel Detector (FPD) Using the New Metric of Generalized Measured Relative Object Detectability (GM-ROD),"A novel amorphous selenium (a-Se) direct detector with CMOS readout has been designed, and relative detector performance investigated. The detector features include a 25μm pixel pitch, and 1000μm thick a-Se layer operating at 10V/μm bias field. A simulated detector DQE was determined, and used in comparative calculations of the Relative Object Detectability (ROD) family of prewhitening matched-filter (PWMF) observer and non-prewhitening matched filter (NPWMF) observer model metrics to gauge a-Se detector performance against existing high resolution micro-angiographic fluoroscopic (MAF) detectors and a standard flat panel detector (FPD). The PWMF-ROD or ROD metric compares two x-ray imaging detectors in their relative abilities in imaging a given object by taking the integral over spatial frequencies of the Fourier transform of the detector DQE weighted by an object function, divided by the comparable integral for a different detector. The generalized-ROD (G-ROD) metric incorporates clinically relevant parameters (focal-spot size, magnification, and scatter) to show the degradation in imaging performance for detectors that are part of an imaging chain. Preliminary ROD calculations using simulated spheres as the object predicted superior imaging performance by the a-Se detector as compared to existing detectors. New PWMF-G-ROD and NPWMF-G-ROD results still indicate better performance by the a-Se detector in an imaging chain over all sphere sizes for various focal spot sizes and magnifications, although a-Se performance advantages were degraded by focal spot blurring. Nevertheless, the a-Se technology has great potential to provide breakthrough abilities such as visualization of fine details including of neuro-vascular perforator vessels and of small vascular devices.","Comparative metrics, generalized metrics, micro-angiography, DQE, Detector Performance, relative object detectability, Microangiography, CMOS, Flat Panel Detector, amorphous selenium","This paper presents a comparative study of a novel amorphous selenium (a-Se) direct detector with existing high resolution micro-angiographic fluoroscopic (MAF) detectors and a standard flat panel detector (FPD). The study utilizes the Relative Object Detectability (ROD) family of metrics, including the generalized-ROD (G-ROD) metric, to assess the performance of these detectors in imaging small objects.  The results indicate that the a-Se detector exhibits superior imaging performance compared to existing detectors, particularly in terms of resolving fine details.  While focal spot blurring can degrade the performance advantage of the a-Se detector, its potential for breakthrough imaging capabilities in neuro-vascular applications is highlighted."
"D. Sharma, R. Mittal, R. Sekhar",A bibliometric analysis of cyber security and cyber forensics research,"Cybersecurity is one of the most important concerns associated with ever expanding internet based technologies, products, services and networks. If cybersecurity is prevention then cyber forensics is the cure. Both are equally important pillars of digital security. This paper presents an extensive bibliometric analysis of cybersecurity and cyberforensic research published in Web of Science during the past decade (2011–2021). The analysis included yearly publications, publication types and trends across different verticals such as publishing sources, organizations, researchers, countries and keywords. Full counting method was used for citation analysis, whereas fractional counting method was implemented to analyze co-citation, co-author collaborations as well as keyword co-occurrences across all these verticals. Furthermore, timeline and burst detection analyses were carried out to unravel significant topic trends and citations in the last decade. The study presents bibliometric results in terms of the authors, organizations, countries, keywords, sources and documents with the highest collaborative link strengths worldwide in the field of cybersecurity and forensics. Latest trends, under-investigated topics and future directions are also presented.","citation networks, inter-journal linkages, Cyber forensics, Malware detection, bibliometric analysis, Cyber security, keywords, Deep learning, Anomaly detection, cybersecurity, top publishing journals, Bibliometry, collaboration, trending topics, Cyber attack, Machine learning","This paper presents a bibliometric analysis of cybersecurity and cyberforensic research published in Web of Science during the past decade (2011–2021). The analysis included yearly publications, publication types and trends across different verticals such as publishing sources, organizations, researchers, countries and keywords. The study presents bibliometric results in terms of the authors, organizations, countries, keywords, sources and documents with the highest collaborative link strengths worldwide in the field of cybersecurity and forensics."
D. Sinwar et al.,AI-Based Yield Prediction and Smart Irrigation,"The paper discusses the use of AI-based techniques for yield prediction and smart irrigation in agriculture. It highlights the importance of precision agriculture and the challenges faced by traditional methods. The authors propose the use of machine learning techniques, such as convolutional neural networks, to predict crop yields and identify weeds. They also discuss the use of remote sensing and proximity sensing to monitor soil and weather conditions. The paper concludes by emphasizing the need for farmers to adopt new technologies and techniques to improve crop yields and reduce environmental pollution.","Crop, Convolutional Neural Networks, Proximity Sensing, Machine Learning, Precision agriculture, Smart irrigation, Yield prediction, Artificial intelligence, Smart farming, Temperature monitoring, Soil moisture, IoT, Remote Sensing",The chapter acknowledges the past breakthroughs and emerging Artificial Intelligence-based techniques in precision farming specifically for yield prediction and smart irrigation. Artificial Intelligence-based system provides sufficient information about crop yields at an early stage and its associated smart irrigation management system is effective in the judicious use of essential resources such as water and energy for agriculture.
D. Veranna,Machine Learning Techniques Applied to Profile Mobile Banking Users in India,"This paper profiles mobile banking users using machine learning techniques viz. Decision Tree, Logistic Regression, Multilayer Perceptron, and SVM to test a research model with fourteen independent variables and a dependent variable (adoption). A survey was conducted and the results were analysed using these techniques. Using Decision Trees the profile of the mobile banking adopter’s profile was identified. Comparing different machine learning techniques it was found that Decision Trees outperformed the Logistic Regression and Multilayer Perceptron and SVM. Out of all the techniques, Decision Tree is recommended for profiling studies because apart from obtaining high accurate results, it also yields ‘if–then’ classification rules. The classification rules provided here can be used to target potential customers to adopt mobile banking by offering them appropriate incentives.","Machine Learning, Logistic Regression, Multilayer Perceptron, Mobile Banking User Profiles, Decision Tree","This paper studies the various factors that affect the intention of users to adopt mobile banking. The major influential factors have been identified through literature, and a survey was conducted with two hundred respondents in the Indian context. The paper analyses the survey data through the use of machine learning techniques to arrive at the most important and critical success factors that influences the adoption of mobile."
D. Walker,Cost Eﬀective Inﬂuence Maximisation,"In the context of virality prediction, many researchers have leveraged the existence of a core-periphery structure in a network to identify the super-spreaders of information. Topologically, the nodes in the core of a network are the most eﬃcient spreaders. However, these nodes are less susceptible, i.e., unlikely to be inﬂuenced by the periphery nodes. Consequently, large payoﬀs are required to market information (ideas, products, memes, etc.) via them. In this paper, we show the presence of several non-core nodes whose spreading power is close to that of the core nodes.","Virality, Inﬂuence maximisation, Information diﬀusion, cost-effective, Core-periphery structure, information diffusion, social networks, influence maximisation","This paper proposes a cost-eﬀective strategy to make a meme reach the super-spreaders without the need for global information. The proposed hill-climbing based strategy can be eﬀectively used with both, global as well as local characteristics of the nodes in a network. In terms of the cost metric, it outperforms the conventional independent cascade model by more than 5 times for the core and 2 times for the non-core super-spreaders."
D. Zhang,Iris Detection,"For iris boundary detection, circular summation of intensity approach is used as proposed in [5]. The original grayscale image is blurred using median filter to remove external noise. After filtering, the contrast of image is enhanced to have sharp variation at image boundaries using histogram equalisation as shown in Figure 5(a). This contrast enhanced image is used for finding the outer iris boundary by drawing concentric circles (Figure 5(b) shows an example) of different radii from the pupil center and the intensities lying over the perimeter of the circle are summed up.","Adaptive Threshold, Circular Hough Transform, Spectrum Image, histogram equalisation, iris recognition, circular summation of intensity, Connected Components, Iris detection, pupil boundary, Iris Segmentation",The proposed system has been tested on two publicly available databases BATH and CASIA V3. From experimental analysis it has been observed that the system is capable of handling unconstrained scenarios as well. The system is capable of performing segmentation for unconstrained scenarios in significantly less time compared to Hough transform.
D.-B. Chen,Cost Eﬀective Inﬂuence Maximisation,"In the context of virality prediction, many researchers have leveraged the existence of a core-periphery structure in a network to identify the super-spreaders of information. Topologically, the nodes in the core of a network are the most eﬃcient spreaders. However, these nodes are less susceptible, i.e., unlikely to be inﬂuenced by the periphery nodes. Consequently, large payoﬀs are required to market information (ideas, products, memes, etc.) via them. In this paper, we show the presence of several non-core nodes whose spreading power is close to that of the core nodes.","Virality, Inﬂuence maximisation, Information diﬀusion, cost-effective, Core-periphery structure, information diffusion, social networks, influence maximisation","This paper proposes a cost-eﬀective strategy to make a meme reach the super-spreaders without the need for global information. The proposed hill-climbing based strategy can be eﬀectively used with both, global as well as local characteristics of the nodes in a network. In terms of the cost metric, it outperforms the conventional independent cascade model by more than 5 times for the core and 2 times for the non-core super-spreaders."
D.R. Edla,Selector: PSO as model selector for dual stage diabetes network,"This paper proposes a novel approach for selecting the optimal model for a dual-stage diabetes network using Particle Swarm Optimization (PSO). The proposed method, called Selector, combines the advantages of Probabilistic Neural Network (PNN) and Radial Basis Function Neural Network (RBFNN) to achieve high accuracy in classification tasks. The PSO-based clustering algorithm is used to determine the optimal number of hidden layer neurons in the RBFNN and PNN models. Experimental results on the PID dataset show that the proposed method outperforms other state-of-the-art methods in terms of accuracy and computational efficiency.","optimal number of clusters, PNN, Dual-stage diabetes network, Diabetes classification, Particle Swarm Optimization, Probabilistic Neural Network, RBFNN, highly dense regions, Radial Basis Function Neural Network, Model selection",This paper proposes a dual-stage diabetes network (Dia-Net) that combines optimized probabilistic neural network (OPNN) and optimized radial basis function neural network (ORBFNN) in the first stage and linear support vector machine in the second stage. Particle swarm optimization-based clustering is employed to reduce the complexity of Dia-Net.
DEEPAK PUTHAL,IoT-Based Wireless Polysomnography Intelligent System for Sleep Monitoring ||| MSGR: A Mode-Switched Grid-Based Sustainable Routing Protocol for Wireless Sensor Networks,"Polysomnography (PSG) is considered the gold standard in the diagnosis of obstructive sleep apnea (OSA). The diagnosis of OSA requires an overnight sleep experiment in a laboratory. However, due to limitations in relation to the number of labs and beds available, patients often need to wait a long time before being diagnosed and eventually treated. In addition, the unfamiliar environment and restricted mobility when a patient is being tested with a polysomnogram may disturb their sleep, resulting in an incomplete or corrupted test. Therefore, it is posed that a PSG conducted in the patient’s home would be more reliable and convenient. The Internet of Things (IoT) plays a vital role in the e-Health system. In this paper, we implement an IoT-based wireless polysomnography system for sleep monitoring, which utilizes a battery-powered, miniature, wireless, portable, and multipurpose recorder. A Java-based PSG recording program in the personal computer is designed to save several bio-signals and transfer them into the European data format. These PSG records can be used to determine a patient’s sleep stages and diagnose OSA. This system is portable, lightweight, and has low power-consumption. To demonstrate the feasibility of the proposed PSG system, a comparison was made between the standard PSG-Alice 5 Diagnostic Sleep System and the proposed system. Several healthy volunteer patients participated in the PSG experiment and were monitored by both the standard PSG-Alice 5 Diagnostic Sleep System and the proposed system simultaneously, under the supervision of specialists at the Sleep Laboratory in Taipei Veteran General Hospital. A comparison of the results of the time-domain waveform and sleep stage of the two systems shows that the proposed system is reliable and can be applied in practice. The proposed system can facilitate the long-term tracing and research of personal sleep monitoring at home. ||| A Wireless Sensor Network (WSN) consists of enormous amount of sensor nodes. These sensor nodes sense the changes in physical parameters from the sensing range and forward the information to the sink nodes or the base station. Since sensor nodes are driven with limited power batteries, prolonging the network lifetime is difficult and very expensive, especially for hostile locations. Therefore, routing protocols for WSN must strategically distribute the dissipation of energy, so as to increase the overall lifetime of the system.","mobile sink, grid-based routing, sleep monitoring, wireless, energy efficiency, Internet of Things, grid head, wireless PSG, scalability, JAVA, Polysomnography (PSG), IoT, Wireless sensor networks","This paper proposes an IoT-based wireless polysomnography system for sleep monitoring, which utilizes a battery-powered, miniature, wireless, portable, and multipurpose recorder. The system is designed to save several bio-signals and transfer them into the European data format, allowing for the determination of a patient’s sleep stages and diagnosis of OSA. The proposed system is compared to the standard PSG-Alice 5 Diagnostic Sleep System and shows reliable results, making it a viable option for long-term tracing and research of personal sleep monitoring at home. ||| The paper presents a comprehensive review of grid-based routing protocols for WSNs, highlighting their design principles, advantages, and limitations. It also proposes a new mode-switched grid-based sustainable routing protocol, which adapts to changing network conditions to conserve energy and improve network lifetime."
DI WU,Robust Feature-Based Automated Multi-View Human Action Recognition System,"Automated human action recognition has the potential to play an important role in public security, for example, in relation to the multiview surveillance videos taken in public places, such as train stations or airports. This paper compares three practical, reliable, and generic systems for multiview video-based human action recognition, namely, the nearest neighbor classiﬁer, Gaussian mixture model classiﬁer, and the nearest mean classiﬁer. To describe the different actions performed in different views, view-invariant features are proposed to address multiview action recognition. These features are obtained by extracting the holistic features from different temporal scales which are modeled as points of interest which represent the global spatial-temporal distribution. Experiments and cross-data testing are conducted on the KTH, WEIZMANN, and MuHAVi datasets. The system does not need to be retrained when scenarios are changed which means the trained database can be applied in a wide variety of environments, such as view angle or background changes. The experiment results show that the proposed approach outperforms the existing methods on the KTH and WEIZMANN datasets.","feature extraction, points of interest extraction, background subtraction, machine learning, moving object localization, multi-view human action recognition, action recognition, Multi-view video, classiﬁcation","This paper proposes a robust feature-based automated multi-view human action recognition system. The system uses view-invariant features to address multi-view action recognition from a range of perspectives. The proposed approach labels the beginning and end of an action sequence in a video stream automatically and captures sequence motions and occlusions at a low computational cost. The system is evaluated using the KTH, WEIZMAN, and MuHAVi datasets and outperforms existing methods on the KTH and WEIZMANN datasets."
DIPIKA JAIN,Personality Detection using Kernel-based Ensemble Model for leveraging Social Psychology in Online Networks,"The Asian social networking market dominates the world landscape with the highest consumer penetration rate. Businesses and investors often look for winning strategies to attract consumers to increase revenues from sales, advertisements, and other services offered on social media platforms. Social media engagement and online relational cohesion have often been defined within the frameworks of social psychology and personality identification is a possible way in which social psychology can inform, engage, and learn from social media.","Natural language, MBTI personality type, Personality Psychology, kernel-based soft voting ensemble, Hindi dataset, kernel-based methods, Social Networks, Support Vector Machine, personality detection",The paper proposes a kernel-based soft voting ensemble for personality detection in natural language textual data. The model uses the Support Vector Machine (SVM) with soft voting ensembled kernels to detect different traits of the MBTI personality type in an English and a Hindi dataset. The primary contribution of this work is to develop an efficient kernel-based ensemble model for text-based personality prediction.
DONG-LIN LI,Robust Feature-Based Automated Multi-View Human Action Recognition System,"Automated human action recognition has the potential to play an important role in public security, for example, in relation to the multiview surveillance videos taken in public places, such as train stations or airports. This paper compares three practical, reliable, and generic systems for multiview video-based human action recognition, namely, the nearest neighbor classiﬁer, Gaussian mixture model classiﬁer, and the nearest mean classiﬁer. To describe the different actions performed in different views, view-invariant features are proposed to address multiview action recognition. These features are obtained by extracting the holistic features from different temporal scales which are modeled as points of interest which represent the global spatial-temporal distribution. Experiments and cross-data testing are conducted on the KTH, WEIZMANN, and MuHAVi datasets. The system does not need to be retrained when scenarios are changed which means the trained database can be applied in a wide variety of environments, such as view angle or background changes. The experiment results show that the proposed approach outperforms the existing methods on the KTH and WEIZMANN datasets.","feature extraction, points of interest extraction, background subtraction, machine learning, moving object localization, multi-view human action recognition, action recognition, Multi-view video, classiﬁcation","This paper proposes a robust feature-based automated multi-view human action recognition system. The system uses view-invariant features to address multi-view action recognition from a range of perspectives. The proposed approach labels the beginning and end of an action sequence in a video stream automatically and captures sequence motions and occlusions at a low computational cost. The system is evaluated using the KTH, WEIZMAN, and MuHAVi datasets and outperforms existing methods on the KTH and WEIZMANN datasets."
DR K V SAMBASIVA RAO,Real-Time Monitoring System for Aquaculture,The idea behind building up the real-time monitoring system is to lessen the manual fish farming which uses more work powers. There are sensors which measure water parameters and control those to keep aquarium clean and fishes healthy. Farmers are given alert messages if the water parameters exceed and also remedial actions are performed before he reached to the Aquarium. This device is useful for fishes as well as other Aqua life also. By using this we can save the aqua life.,"Fish Farming, IOT, Sensors, Sensor Networks, Arduino, Water Parameters, Real-Time Monitoring, GSM, Aquaculture",The proposed method aims at continuously monitoring the harmful gases and relative humidity in a cost effective way by polling sensor at fixed interval of time. Arduino processes data and will be updated continuously on the system.
Damodar Reddy Edla,Advances in Machine Learning and Data Science—Recent Achievements and Research Directives ||| Automatic disease diagnosis using optimised weightless neural networks for low-power wearable devices ||| Diabetes-Finder: A Bat Optimized Classification System for Type-2 Diabetes ||| Survey on Brain-Computer Interface,"ooperation to publish the proceedings as a volume of “Advances in Machine Learning and Data Science—Recent Achievements and Research Directives.” We wish to extend our gratitude to all the keynote speakers and participants who enabled the success of this year’s edition of LAMDA. ||| Low-power wearable devices for disease diagnosis are used at anytime and anywhere. These are non-invasive and pain-free for the better quality of life. However, these devices are resource constrained in terms of memory and processing capability. Memory constraint allows these devices to store a limited number of patterns and processing constraint provides delayed response. It is a challenging task to design a robust classiﬁcation system under above constraints with high accuracy. In this Letter, to resolve this problem, a novel architecture for weightless neural networks (WNNs) has been proposed. It uses variable sized random access memories to optimise the memory usage and a modiﬁed binary TRIE data structure for reducing the test time. In addition, a bio-inspired-based genetic algorithm has been employed to improve the accuracy. The proposed architecture is experimented on various disease datasets using its software and hardware realisations. The experimental results prove that the proposed architecture achieves better performance in terms of accuracy, memory saving and test time as compared to standard WNNs. It also outperforms in terms of accuracy as compared to conventional neural network-based classiﬁers. ||| Type-2 Diabetes is one of the foremost causes for the increase in mortality across the world-wide. In this context, classification systems help doctors by analyzing the disease data. Radial Basis Function Neural Networks (RBFNN) are extensively used as classifier in medical domain because of its non-iterative nature. The size of the RBFNNs hidden-layer increases on par with dataset size. It's difficult to determining the optimal number of neurons in hidden-layer by cost effectively. In this paper, to address this problem, we have proposed Bat-based clustering algorithm. The proposed method experimented on Pima Indians Diabetes dataset and results outperform the competing approaches. ||| A brain-computer interface (BCI) provides a way to develop interaction between a brain and a computer. The communication is developed as a result of neural responses generated in the brain because of motor movements or cognitive activities. The means of communication here includes muscular and non-muscular actions. These actions generate brain activities or brain waves that are directed to a hardware device to perform a specific task. BCI initially was developed as the communication device for patients suffering from neuromuscular disorders. Owing to recent advancements in BCI devices—such as passive electrodes, wireless headsets, adaptive software, and decreased costs—it is also being used for developing communication between the general public. The BCI device records brain responses using various invasive and non-invasive acquisition techniques such as electrocorticography (ECoG), electroencephalography (EEG), magnetoencephalography (MEG), and magnetic resonance imaging (MRI). In this article, a survey on these techniques has been provided. The brain response needs to be translated using machine learning and pattern recognition methods to control any application. A brief review of various existing feature extraction techniques and classification algorithms applied on data recorded from the brain has been included in this article. A significant comparative analysis of popular existing BCI techniques is presented and possible future directives are provided.","feature extraction, Machine Learning, genetic algorithm, Bat Optimization Algorithm, neuron memory search, Data Science, Clustering, disease diagnosis, fuzzy inference system, electrocorticography, Brain Signal Acquisition, Recent Achievements, classification, Type-2 Diabetes Classification, Class by Class Approach, low-power wearable devices, Neural Tissue, Research Directives, RBFNN, electroencephalogram, VVG-RAM, modified TRIE data structure, Electrodes, Brain-computer interface, binary TRIE data structure, TRIE data structure, Pima Indians Diabetes dataset, weightless neural networks, VG-RAM, Bat Optimization","The proceedings of LAMDA 2017, a conference on machine learning and data science, are published as a volume of Advances in Machine Learning and Data Science—Recent Achievements and Research Directives. The editors extend their gratitude to the keynote speakers and participants who made the conference a success. ||| A novel architecture for weightless neural networks (WNNs) is proposed to improve the classiﬁcation accuracy, reduce the memory usage, and decrease the test time for low-power wearable devices. The proposed architecture uses variable sized random access memories and a modiﬁed binary TRIE data structure. A bio-inspired-based genetic algorithm is employed to improve the accuracy. The experimental results show that the proposed architecture outperforms the standard WNNs and conventional neural network-based classiﬁers in terms of accuracy, memory saving, and test time. ||| This paper proposes a Bat-based clustering algorithm to address the problem of determining the optimal number of neurons in the hidden layer of Radial Basis Function Neural Networks (RBFNN) for Type-2 Diabetes classification. The proposed method is applied in a class-by-class fashion and outperforms competing approaches on the Pima Indians Diabetes dataset. ||| This survey provides a comprehensive overview of brain-computer interface (BCI) techniques, including signal acquisition, feature extraction, and classification algorithms. It discusses the recent advancements in BCI devices and their applications in developing communication between the general public. The survey also presents a comparative analysis of popular existing BCI techniques and provides possible future directives."
Damon L. Bass,BELIMUMAB IN PATIENTS OF BLACK AFRICAN ANCESTRY,"Study design. SELENA–SLEDAI = Safety of Estrogens in Lupus Erythematosus National Assessment–Systemic Lupus Erythemato-sus Disease Activity Index; IV = intravenous.

Randomization and treatment. Using an interactive voice/web response system, patients receiving standard therapy were randomized 2:1 to receive either belimumab 10 mg/kg IV or placebo, which was administered on days 0, 14, and 28 and every 28 days thereafter up to week 48, with a final evaluation at week 52. Randomization was stratified by screening SELENA–SLEDAI score (≤9 versus ≥10), region (US/Canada versus rest of world), and complement level (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]). Detailed randomization data are provided in Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Patients who successfully completed the initial 52-week double-blind phase could enter an optional 6-month open-label extension phase, during which they received belimumab 10 mg/kg IV every 28 days plus standard therapy, irrespective of their previous study assignment. The first dose was given at the week 52 (day 364) visit of the double-blind period (day 1 of the open-label extension phase). Patients who completed the 52-week double-blind phase, but did not enter the 6-month open-label extension phase, were required to return for an additional follow-up visit 8 weeks after their last dose. Patients who withdrew early were required to return for an exit visit 4 weeks after their last dose and a follow-up visit 8 weeks after their last dose.

The original protocol plan was to randomize 816 patients, providing ≥90% power to detect ≥12% absolute improvement in the SRI response rate in the belimumab group compared with the placebo group at a 5% significance level. Due to enrollment challenges, a revised sample size was calculated to include 501 patients (≥334 patients in the belimumab group and ≥167 patients in the placebo group). This sample size provided ≥90% power to detect a minimum 15.55% absolute improvement in SRI–SLEDAI-2K response rate in the belimumab group relative to the placebo group at a 5% significance level (based on the pooled data from efficacy studies BEL112341 and BEL113750) (15,21). These calculations assumed a placebo response rate of 43.95% at week 52.

Study end points and assessments. The primary efficacy end point was the SRI–SLEDAI-2K response rate (defined in the Supplementary Material) at week 52 of the double-blind phase. Unlike in the phase II and phase III studies, the SRI–SLEDAI-2K was selected because of the simplification it offers in proteinuria assessment as compared with the SELENA–SLEDAI proteinuria component; both are clinically meaningful (22). The primary efficacy end point for the open-label extension phase was SRI–SLEDAI-2K response rate at open-label extension week 24. If the open-label extension week 24 data were missing, data from the open-label extension week 28/exit visit were used. This time point is referred to as “open-label extension week 24” throughout the text. Data related to the primary efficacy end point, e.g., the response rate over time, percentage of patients with a durable SRI–SLEDAI-2K response from week 44 through week 52, time to first SRI–SLEDAI-2K response that was maintained through week 52, and duration of longest SRI–SLEDAI-2K response among patients with ≥1 SRI–SLEDAI-2K responses were summarized.

The key secondary end points were SRI–SELENA–SLEDAI at week 52 (open-label extension week 24), time to first severe SLE flare (measured by the SELENA–SLEDAI flare index [SFI]), and proportion of patients whose average prednisone dose had been reduced by ≥25% from baseline to ≤7.5 mg/day during week 40 through week 52 (open-label extension week 28/exit visit), in patients receiving >7.5 mg/day at baseline. Key renal end points included time to first renal flare over 52 weeks and over 28 weeks in the open-label extension, SELENA–SLEDAI–SLEDAI-2K renal domain improvement at week 52, SELENA–SLEDAI–SLEDAI-2K renal domain worsening at week 52, percentage reduction in proteinuria by visit and at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours, and proteinuria shift at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours. Renal flare is defined in the Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Biomarkers measured included percentage changes in serum IgG level, anti-dsDNA antibody level (in those who were anti-dsDNA positive [≥30 IU/ml] at baseline), and complement (C3 and C4) levels from baseline. Safety was evaluated by monitoring adverse events (AEs), serious AEs (SAEs), AEs of special interest, vital signs, clinical laboratory test results, and immunogenicity up to 8 weeks posttreatment and throughout the open-label extension phase.

Data analyses. For the double-blind phase, safety analyses were performed on the safety population, defined as all patients who were randomized and treated with at least 1 dose of investigational product. Data on the safety population were summarized according to the treatment the patient was randomized to receive rather than by the treatment that was received, but both were the same for this study. Efficacy analyses were performed on the modified intent-to-treat (ITT) population, defined as the safety population minus those patients who had any assessment at any of 3 study sites that were excluded from the efficacy analyses before the database lock because of potential Good Clinical Practice noncompliance.

For analysis of the primary and 3 key secondary efficacy end points, a step-down sequential testing procedure was used as described in the Supplementary Material. The following subgroup analyses were performed for the primary analysis (SRI–SLEDAI-2K response at week 52): region (US/Canada versus rest of world), baseline SELENA–SLEDAI–SLEDAI-2K score (≤9 versus ≥10), baseline anti-dsDNA antibody level (≥30 IU/ml versus <30 IU/ml), baseline complement levels (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]), and baseline complement and anti-dsDNA antibody levels (≥1 test finding showing low C3/C4 and anti-dsDNA ≥30 IU/ml versus C3/C4 other and anti-dsDNA ≥30 IU/ml). The odds of an SRI–SLEDAI-2K response with belimumab treatment versus placebo were estimated using logistic regression analysis.

For the open-label extension phase, all patients received belimumab, no formal statistical hypothesis t",,"This study investigated the efficacy and safety of belimumab in patients of Black African ancestry with systemic lupus erythematosus (SLE).  Patients were randomized to receive belimumab or placebo for 52 weeks, followed by an optional 6-month open-label extension phase. The primary efficacy endpoint was the SRI–SLEDAI-2K response rate at week 52.  Key secondary endpoints included SRI–SELENA–SLEDAI at week 52, time to first severe SLE flare, and proportion of patients with a reduction in prednisone dose. Renal and biomarker assessments were also conducted.  The study found that belimumab was effective in improving SLE disease activity and reducing renal flares in patients of Black African ancestry."
"Dan Wang, MS",Cardiac Neonatal Lupus: Maternal and Fetal Risk Factors for Mortality,"Background: Cardiac neonatal lupus (CNL) is a serious complication of maternal anti-Ro/SSA and anti-La/SSB antibodies.  We sought to identify maternal and fetal risk factors for mortality in infants with CNL.

Methods and Results: We retrospectively analyzed data from 325 infants with CNL born to 297 mothers. Overall, 57 deaths (17.5%) occurred. Hydrops, carditis, and EFE were associated with increased mortality in both in utero and postnatal deaths. Maternal diagnosis of SLE and/or SS was associated with increased mortality in the overall analysis and in utero deaths.  Whites were less likely to die than minorities.

Conclusions: Hydrops, carditis, EFE, and maternal SLE and/or SS are significant risk factors for mortality in infants with CNL.","mortality, morbidity, cardiomyopathy, antibodies, heart block","This study investigates maternal and fetal risk factors for mortality in infants with cardiac neonatal lupus (CNL).  Key findings include the significant association of hydrops, carditis, EFE, and maternal SLE and/or SS with increased mortality. Additionally, white infants were found to have a lower mortality rate compared to minorities."
David A. Roth,BELIMUMAB IN PATIENTS OF BLACK AFRICAN ANCESTRY,"Study design. SELENA–SLEDAI = Safety of Estrogens in Lupus Erythematosus National Assessment–Systemic Lupus Erythemato-sus Disease Activity Index; IV = intravenous.

Randomization and treatment. Using an interactive voice/web response system, patients receiving standard therapy were randomized 2:1 to receive either belimumab 10 mg/kg IV or placebo, which was administered on days 0, 14, and 28 and every 28 days thereafter up to week 48, with a final evaluation at week 52. Randomization was stratified by screening SELENA–SLEDAI score (≤9 versus ≥10), region (US/Canada versus rest of world), and complement level (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]). Detailed randomization data are provided in Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Patients who successfully completed the initial 52-week double-blind phase could enter an optional 6-month open-label extension phase, during which they received belimumab 10 mg/kg IV every 28 days plus standard therapy, irrespective of their previous study assignment. The first dose was given at the week 52 (day 364) visit of the double-blind period (day 1 of the open-label extension phase). Patients who completed the 52-week double-blind phase, but did not enter the 6-month open-label extension phase, were required to return for an additional follow-up visit 8 weeks after their last dose. Patients who withdrew early were required to return for an exit visit 4 weeks after their last dose and a follow-up visit 8 weeks after their last dose.

The original protocol plan was to randomize 816 patients, providing ≥90% power to detect ≥12% absolute improvement in the SRI response rate in the belimumab group compared with the placebo group at a 5% significance level. Due to enrollment challenges, a revised sample size was calculated to include 501 patients (≥334 patients in the belimumab group and ≥167 patients in the placebo group). This sample size provided ≥90% power to detect a minimum 15.55% absolute improvement in SRI–SLEDAI-2K response rate in the belimumab group relative to the placebo group at a 5% significance level (based on the pooled data from efficacy studies BEL112341 and BEL113750) (15,21). These calculations assumed a placebo response rate of 43.95% at week 52.

Study end points and assessments. The primary efficacy end point was the SRI–SLEDAI-2K response rate (defined in the Supplementary Material) at week 52 of the double-blind phase. Unlike in the phase II and phase III studies, the SRI–SLEDAI-2K was selected because of the simplification it offers in proteinuria assessment as compared with the SELENA–SLEDAI proteinuria component; both are clinically meaningful (22). The primary efficacy end point for the open-label extension phase was SRI–SLEDAI-2K response rate at open-label extension week 24. If the open-label extension week 24 data were missing, data from the open-label extension week 28/exit visit were used. This time point is referred to as “open-label extension week 24” throughout the text. Data related to the primary efficacy end point, e.g., the response rate over time, percentage of patients with a durable SRI–SLEDAI-2K response from week 44 through week 52, time to first SRI–SLEDAI-2K response that was maintained through week 52, and duration of longest SRI–SLEDAI-2K response among patients with ≥1 SRI–SLEDAI-2K responses were summarized.

The key secondary end points were SRI–SELENA–SLEDAI at week 52 (open-label extension week 24), time to first severe SLE flare (measured by the SELENA–SLEDAI flare index [SFI]), and proportion of patients whose average prednisone dose had been reduced by ≥25% from baseline to ≤7.5 mg/day during week 40 through week 52 (open-label extension week 28/exit visit), in patients receiving >7.5 mg/day at baseline. Key renal end points included time to first renal flare over 52 weeks and over 28 weeks in the open-label extension, SELENA–SLEDAI–SLEDAI-2K renal domain improvement at week 52, SELENA–SLEDAI–SLEDAI-2K renal domain worsening at week 52, percentage reduction in proteinuria by visit and at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours, and proteinuria shift at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours. Renal flare is defined in the Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Biomarkers measured included percentage changes in serum IgG level, anti-dsDNA antibody level (in those who were anti-dsDNA positive [≥30 IU/ml] at baseline), and complement (C3 and C4) levels from baseline. Safety was evaluated by monitoring adverse events (AEs), serious AEs (SAEs), AEs of special interest, vital signs, clinical laboratory test results, and immunogenicity up to 8 weeks posttreatment and throughout the open-label extension phase.

Data analyses. For the double-blind phase, safety analyses were performed on the safety population, defined as all patients who were randomized and treated with at least 1 dose of investigational product. Data on the safety population were summarized according to the treatment the patient was randomized to receive rather than by the treatment that was received, but both were the same for this study. Efficacy analyses were performed on the modified intent-to-treat (ITT) population, defined as the safety population minus those patients who had any assessment at any of 3 study sites that were excluded from the efficacy analyses before the database lock because of potential Good Clinical Practice noncompliance.

For analysis of the primary and 3 key secondary efficacy end points, a step-down sequential testing procedure was used as described in the Supplementary Material. The following subgroup analyses were performed for the primary analysis (SRI–SLEDAI-2K response at week 52): region (US/Canada versus rest of world), baseline SELENA–SLEDAI–SLEDAI-2K score (≤9 versus ≥10), baseline anti-dsDNA antibody level (≥30 IU/ml versus <30 IU/ml), baseline complement levels (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]), and baseline complement and anti-dsDNA antibody levels (≥1 test finding showing low C3/C4 and anti-dsDNA ≥30 IU/ml versus C3/C4 other and anti-dsDNA ≥30 IU/ml). The odds of an SRI–SLEDAI-2K response with belimumab treatment versus placebo were estimated using logistic regression analysis.

For the open-label extension phase, all patients received belimumab, no formal statistical hypothesis t",,"This study investigated the efficacy and safety of belimumab in patients of Black African ancestry with systemic lupus erythematosus (SLE).  Patients were randomized to receive belimumab or placebo for 52 weeks, followed by an optional 6-month open-label extension phase. The primary efficacy endpoint was the SRI–SLEDAI-2K response rate at week 52.  Key secondary endpoints included SRI–SELENA–SLEDAI at week 52, time to first severe SLE flare, and proportion of patients with a reduction in prednisone dose. Renal and biomarker assessments were also conducted.  The study found that belimumab was effective in improving SLE disease activity and reducing renal flares in patients of Black African ancestry."
David Brooks,Design of Next-Generation Low-Power Sensor Network Nodes,This paper presents the design of next-generation low-power sensor network nodes that can scavenge energy from the environment and use this energy to power the sensor network device.,"Ultra Low Power System Architecture, Fine-Grain Power Management, low-power sensor network nodes, hardware acceleration, Sensor Network Applications, event-driven system, Event-Driven Computation, energy scavenging","The paper discusses the design of next-generation low-power sensor network nodes that can scavenge energy from the environment and use this energy to power the sensor network device. The system architecture is designed to be event-driven, with hardware accelerators offloading common tasks to improve performance and power efficiency."
David D’Cruz,BELIMUMAB IN PATIENTS OF BLACK AFRICAN ANCESTRY,"Study design. SELENA–SLEDAI = Safety of Estrogens in Lupus Erythematosus National Assessment–Systemic Lupus Erythemato-sus Disease Activity Index; IV = intravenous.

Randomization and treatment. Using an interactive voice/web response system, patients receiving standard therapy were randomized 2:1 to receive either belimumab 10 mg/kg IV or placebo, which was administered on days 0, 14, and 28 and every 28 days thereafter up to week 48, with a final evaluation at week 52. Randomization was stratified by screening SELENA–SLEDAI score (≤9 versus ≥10), region (US/Canada versus rest of world), and complement level (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]). Detailed randomization data are provided in Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Patients who successfully completed the initial 52-week double-blind phase could enter an optional 6-month open-label extension phase, during which they received belimumab 10 mg/kg IV every 28 days plus standard therapy, irrespective of their previous study assignment. The first dose was given at the week 52 (day 364) visit of the double-blind period (day 1 of the open-label extension phase). Patients who completed the 52-week double-blind phase, but did not enter the 6-month open-label extension phase, were required to return for an additional follow-up visit 8 weeks after their last dose. Patients who withdrew early were required to return for an exit visit 4 weeks after their last dose and a follow-up visit 8 weeks after their last dose.

The original protocol plan was to randomize 816 patients, providing ≥90% power to detect ≥12% absolute improvement in the SRI response rate in the belimumab group compared with the placebo group at a 5% significance level. Due to enrollment challenges, a revised sample size was calculated to include 501 patients (≥334 patients in the belimumab group and ≥167 patients in the placebo group). This sample size provided ≥90% power to detect a minimum 15.55% absolute improvement in SRI–SLEDAI-2K response rate in the belimumab group relative to the placebo group at a 5% significance level (based on the pooled data from efficacy studies BEL112341 and BEL113750) (15,21). These calculations assumed a placebo response rate of 43.95% at week 52.

Study end points and assessments. The primary efficacy end point was the SRI–SLEDAI-2K response rate (defined in the Supplementary Material) at week 52 of the double-blind phase. Unlike in the phase II and phase III studies, the SRI–SLEDAI-2K was selected because of the simplification it offers in proteinuria assessment as compared with the SELENA–SLEDAI proteinuria component; both are clinically meaningful (22). The primary efficacy end point for the open-label extension phase was SRI–SLEDAI-2K response rate at open-label extension week 24. If the open-label extension week 24 data were missing, data from the open-label extension week 28/exit visit were used. This time point is referred to as “open-label extension week 24” throughout the text. Data related to the primary efficacy end point, e.g., the response rate over time, percentage of patients with a durable SRI–SLEDAI-2K response from week 44 through week 52, time to first SRI–SLEDAI-2K response that was maintained through week 52, and duration of longest SRI–SLEDAI-2K response among patients with ≥1 SRI–SLEDAI-2K responses were summarized.

The key secondary end points were SRI–SELENA–SLEDAI at week 52 (open-label extension week 24), time to first severe SLE flare (measured by the SELENA–SLEDAI flare index [SFI]), and proportion of patients whose average prednisone dose had been reduced by ≥25% from baseline to ≤7.5 mg/day during week 40 through week 52 (open-label extension week 28/exit visit), in patients receiving >7.5 mg/day at baseline. Key renal end points included time to first renal flare over 52 weeks and over 28 weeks in the open-label extension, SELENA–SLEDAI–SLEDAI-2K renal domain improvement at week 52, SELENA–SLEDAI–SLEDAI-2K renal domain worsening at week 52, percentage reduction in proteinuria by visit and at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours, and proteinuria shift at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours. Renal flare is defined in the Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Biomarkers measured included percentage changes in serum IgG level, anti-dsDNA antibody level (in those who were anti-dsDNA positive [≥30 IU/ml] at baseline), and complement (C3 and C4) levels from baseline. Safety was evaluated by monitoring adverse events (AEs), serious AEs (SAEs), AEs of special interest, vital signs, clinical laboratory test results, and immunogenicity up to 8 weeks posttreatment and throughout the open-label extension phase.

Data analyses. For the double-blind phase, safety analyses were performed on the safety population, defined as all patients who were randomized and treated with at least 1 dose of investigational product. Data on the safety population were summarized according to the treatment the patient was randomized to receive rather than by the treatment that was received, but both were the same for this study. Efficacy analyses were performed on the modified intent-to-treat (ITT) population, defined as the safety population minus those patients who had any assessment at any of 3 study sites that were excluded from the efficacy analyses before the database lock because of potential Good Clinical Practice noncompliance.

For analysis of the primary and 3 key secondary efficacy end points, a step-down sequential testing procedure was used as described in the Supplementary Material. The following subgroup analyses were performed for the primary analysis (SRI–SLEDAI-2K response at week 52): region (US/Canada versus rest of world), baseline SELENA–SLEDAI–SLEDAI-2K score (≤9 versus ≥10), baseline anti-dsDNA antibody level (≥30 IU/ml versus <30 IU/ml), baseline complement levels (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]), and baseline complement and anti-dsDNA antibody levels (≥1 test finding showing low C3/C4 and anti-dsDNA ≥30 IU/ml versus C3/C4 other and anti-dsDNA ≥30 IU/ml). The odds of an SRI–SLEDAI-2K response with belimumab treatment versus placebo were estimated using logistic regression analysis.

For the open-label extension phase, all patients received belimumab, no formal statistical hypothesis t",,"This study investigated the efficacy and safety of belimumab in patients of Black African ancestry with systemic lupus erythematosus (SLE).  Patients were randomized to receive belimumab or placebo for 52 weeks, followed by an optional 6-month open-label extension phase. The primary efficacy endpoint was the SRI–SLEDAI-2K response rate at week 52.  Key secondary endpoints included SRI–SELENA–SLEDAI at week 52, time to first severe SLE flare, and proportion of patients with a reduction in prednisone dose. Renal and biomarker assessments were also conducted.  The study found that belimumab was effective in improving SLE disease activity and reducing renal flares in patients of Black African ancestry."
Davidson,Fifty years of peephole optimization,"Peephole optimization is a technique used in compilers to improve the performance of object programs by replacing sequences of instructions with equivalent single instructions. This article reviews the history and development of peephole optimization, including its application to various programming languages and target machines.","compilers, object programs, peephole optimization, Code generators, instruction sequences, replacement rules","Peephole optimization has been widely used in compilers to improve the performance of object programs. The technique involves replacing sequences of instructions with equivalent single instructions, and has been applied to various programming languages and target machines. The effectiveness of peephole optimization depends on several factors, including the nature of the source language, the parsing and code generation techniques used in the compiler, and the specifications of the target machine."
Deb et al.,Multi-Objective Genetic Algorithm for Optimization of Catalytic Reaction,"This paper discusses the use of a multi-objective genetic algorithm (MOGA) for the optimization of a catalytic reaction. The MOGA is used to find a set of solutions that are close to the Pareto front, well spread, and cover the whole spectrum of the Pareto front. The algorithm is applied to a competitive enzyme inhibition reaction scheme and the results are discussed.","Genetic Algorithm, Cellular Automata, Optimization, Enzyme kinetics, Pareto Front, Multi-Objective Optimization, Multi-Objective Genetic Algorithm, Catalytic Reaction","The paper presents a multi-objective genetic algorithm for the optimization of a catalytic reaction. The algorithm is used to find a set of solutions that are close to the Pareto front, well spread, and cover the whole spectrum of the Pareto front. The results of the algorithm are discussed and compared with other optimization methods."
Debarati Das,Modeling Memetics using Edge Diversity,"The study of meme propagation and the prediction of meme trajectory are emerging areas of interest in the field of complex networks research. In addition to the properties of the meme itself, the structural properties of the underlying network decides the speed and the trajectory of the propagating meme.","meme virality, information propagation, meme propagation models, meme propagation, social network analysis, complex networks research, social networks, viral marketing, influence maximisation",The paper proposes a framework for studying meme propagation patterns using a synthetic network and a spreading model based on the diversity of edges in the network. The framework is validated against the real-world spreading of the Higgs boson meme on Twitter.
Debashisha Jena,Differential Evolution: A Simple and Efficient Heuristic for Global Optimization over Continuous Spaces,"Several gradient-based approaches such as back propagation (BP) and Levenberg Marquardt (LM) methods have been developed for training the neural network (NN) based systems. But, for multimodal cost functions these procedures may lead to local minima, therefore, the evolutionary algorithms (EAs) based procedures are considered as promising alternatives. In this paper we focus on a memetic algorithm based approach for training the multilayer perceptron NN applied to nonlinear system identiﬁcation. The proposed memetic algorithm is an alternative to gradient search methods, such as back-propagation and back-propagation with momentum which has inherent limitations of many local optima. Here we have proposed the identiﬁcation of a nonlinear system using memetic differential evolution (DE) algorithm and compared the results with other six algorithms such as Back-propagation (BP), Genetic Algorithm (GA), Particle Swarm Optimization (PSO), Differential Evolution (DE), Genetic Algorithm Back-propagation (GABP), Particle Swarm Optimization combined with Back-propagation (PSOBP). In the proposed system identiﬁcation scheme, we have exploited DE to be hybridized with the back propagation algorithm, i.e. differential evolution back-propagation (DEBP) where the local search BP algorithm is used as an operator to DE. These algorithms have been tested on a standard benchmark problem for nonlinear system identiﬁcation to prove their efﬁcacy. First examples shows the comparison of different algorithms which proves that the proposed DEBP is having better identiﬁcation capability in comparison to other. In example 2 good behavior of the identiﬁcation method is tested on an one degree of freedom (1DOF) experimental aerodynamic test rig, a twin rotor multi-input–multi-output system (TRMS), ﬁnally it is applied to Box and Jenkins Gas furnace benchmark identiﬁcation problem and its efﬁcacy has been tested through correlation analysis.","Particle swarm optimization, Nonlinear system identiﬁcation, Differential evolution, Continuous Spaces, Global Optimization, Evolutionary Algorithms, Back propagation, Heuristic, Evolutionary computation",This paper proposes a memetic algorithm based approach for training the multilayer perceptron neural network applied to nonlinear system identification. The proposed memetic algorithm is an alternative to gradient search methods and has been tested on a standard benchmark problem for nonlinear system identification. The results show that the proposed differential evolution back-propagation algorithm has better identification capability compared to other algorithms.
"Deborah Friedman, MD",Cardiac Neonatal Lupus: Maternal and Fetal Risk Factors for Mortality,"Background: Cardiac neonatal lupus (CNL) is a serious complication of maternal anti-Ro/SSA and anti-La/SSB antibodies.  We sought to identify maternal and fetal risk factors for mortality in infants with CNL.

Methods and Results: We retrospectively analyzed data from 325 infants with CNL born to 297 mothers. Overall, 57 deaths (17.5%) occurred. Hydrops, carditis, and EFE were associated with increased mortality in both in utero and postnatal deaths. Maternal diagnosis of SLE and/or SS was associated with increased mortality in the overall analysis and in utero deaths.  Whites were less likely to die than minorities.

Conclusions: Hydrops, carditis, EFE, and maternal SLE and/or SS are significant risk factors for mortality in infants with CNL.","mortality, morbidity, cardiomyopathy, antibodies, heart block","This study investigates maternal and fetal risk factors for mortality in infants with cardiac neonatal lupus (CNL).  Key findings include the significant association of hydrops, carditis, EFE, and maternal SLE and/or SS with increased mortality. Additionally, white infants were found to have a lower mortality rate compared to minorities."
Deepak Kumar Sharma,Security vs. Flexibility : Striking a Balance in the Pandemic Era,"An organization’s reputation is largely dependent on the work culture it provides to its employees. This is the reason, “flexibility” is becoming an inherent part of an employer’s support to its employees. Due to the unprecedented outbreak of novel corona virus (COVID-19), most companies have adopted flexibility of working from anywhere, for their employees. This digital transformation took place almost instantaneously. Hence, neither the employees, nor the employers were fully prepared for this situation. This definitely makes our lives convenient. But there exists another side of the coin which is concerned with the security issues pertaining to use of personal networks and devices. The home network devices have not been configured to be secure in line with the employer’s requirements. That is the reason, attackers have a larger surface to get their hands dirty on. This paper exhaustively describes the holistic view of security issues and challenges faced by employees as well as employers in remote working paradigm. This paper emphasizes on the cybersecurity threats which have emerged in this pandemic era. The work presents the challenges faced by the employees as well as their employers in these tough times. Then this paper discusses the sudden rise in volumes of cyber-attacks between January 2020 to March 2020. The company’s evaluation of critical threats in the on-site working paradigm versus the remote working paradigm have also been described. Next, it describes the risks which might occur in the near future of the COVID-19 impacted world. Finally, the paper proposes some of the ways in which employers can strike an efficient balance between flexibility for employees and security of their assets.","COVID-19, cyber attacks, remote working, flexibility, cybersecurity, pandemic, attacks, threats","The COVID-19 pandemic has led to a significant increase in cyber attacks, with various types of attacks including Corona Virus themed MalSpam Emails, Spam Emails, Malware inside Interactive Map, VPN Exploitation, Credential Stuffing, Misconfiguration of Cloud Services, Vishing (or phishing) Attacks, Ransomware Attack, and Data Theft By Employees. Organizations need to work toward inculcating a strong security technological infrastructure to deal with the frequently changing cyber-attacks landscape."
Deepak Pullaguram,A Standalone BLDC Based Solar Air Cooler with MPP Tracking for Improved Efﬁciency,This article proposes the idea of using Solar Energy (SE) as a source of power for designing and developing a standalone air-cooling system. This type of application is particularly suited for rural areas that have a considerable amount of solar radiation and have no access to grid systems.,"BLDC motor, PV System, BLDC Pump, BLDC, MPP tracking, efficiency, BLDC air blower, solar air cooler","The proposed system consists of a PV array, a boost converter, a BLDC drive, and a solar air cooler. The system is designed to operate in a standalone mode, where the PV array generates power and the boost converter boosts the input voltage to the required operating quantity. The BLDC drive is used to control the speed of the BLDC motor, which drives the solar air cooler."
Deepak Puthal,Accurate Trafﬁc Flow Prediction in Heterogeneous Vehicular Networks in an Intelligent Transport System Using a Supervised Non-Parametric Classiﬁer,"Heterogeneous vehicular networks (HETVNETs) evolve from vehicular ad hoc networks (VANETs), which allow vehicles to always be connected so as to obtain safety services within intelligent transportation systems (ITSs). The services and data provided by HETVNETs should be neither interrupted nor delayed. Therefore, Quality of Service (QoS) improvement of HETVNETs is one of the topics attracting the attention of researchers and the manufacturing community.","QoS, SVM, Radial Basis Function, Prediction Accuracy, RBF, internet of vehicles, Support Vector Machines, HETVNET, Vehicular Ad Hoc Network",This paper proposes a prediction model based on support vector machines (SVMs) to improve Quality of Service (QoS) in Heterogeneous Vehicular Networks (HETVNETs). The model uses a radial basis function (RBF) kernel and outperforms other prediction methods in terms of accuracy and computational complexity.
Deepak Sinwar,Recent Developments in Plant Leaf Disease Identification and Classification,"In the modern era, deep learning techniques have emerged as powerful tools in image recognition. Convolutional Neural Networks, one of the deep learning tools, have attained an impressive outcome in this area. The effectiveness of Convolutional Neural Networks in image recognition motivates the researchers to extend its applications in the field of agriculture for recognition of plant species, yield management, weed detection, soil, and water management, fruit counting, diseases, and pest detection, evaluating the nutrient status of plants, and much more.","leaf, deep learning models, disease, survey, deep learning, machine learning models, plant leaf disease identification, agriculture, convolutional neural networks","This manuscript presents a survey of the existing literature in applying deep Convolutional Neural Networks to predict plant diseases from leaf images. It presents an exemplary comparison of the pre-processing techniques, Convolutional Neural Network models, frameworks, and optimization techniques applied to detect and classify plant diseases using leaf images as a data set."
Deepika Kukreja,Security vs. Flexibility : Striking a Balance in the Pandemic Era,"An organization’s reputation is largely dependent on the work culture it provides to its employees. This is the reason, “flexibility” is becoming an inherent part of an employer’s support to its employees. Due to the unprecedented outbreak of novel corona virus (COVID-19), most companies have adopted flexibility of working from anywhere, for their employees. This digital transformation took place almost instantaneously. Hence, neither the employees, nor the employers were fully prepared for this situation. This definitely makes our lives convenient. But there exists another side of the coin which is concerned with the security issues pertaining to use of personal networks and devices. The home network devices have not been configured to be secure in line with the employer’s requirements. That is the reason, attackers have a larger surface to get their hands dirty on. This paper exhaustively describes the holistic view of security issues and challenges faced by employees as well as employers in remote working paradigm. This paper emphasizes on the cybersecurity threats which have emerged in this pandemic era. The work presents the challenges faced by the employees as well as their employers in these tough times. Then this paper discusses the sudden rise in volumes of cyber-attacks between January 2020 to March 2020. The company’s evaluation of critical threats in the on-site working paradigm versus the remote working paradigm have also been described. Next, it describes the risks which might occur in the near future of the COVID-19 impacted world. Finally, the paper proposes some of the ways in which employers can strike an efficient balance between flexibility for employees and security of their assets.","COVID-19, cyber attacks, remote working, flexibility, cybersecurity, pandemic, attacks, threats","The COVID-19 pandemic has led to a significant increase in cyber attacks, with various types of attacks including Corona Virus themed MalSpam Emails, Spam Emails, Malware inside Interactive Map, VPN Exploitation, Credential Stuffing, Misconfiguration of Cloud Services, Vishing (or phishing) Attacks, Ransomware Attack, and Data Theft By Employees. Organizations need to work toward inculcating a strong security technological infrastructure to deal with the frequently changing cyber-attacks landscape."
Deepti Singhal,Cognitive cross-layer multipath probabilistic routing for cognitive networks ||| Doubly Cognitive Architecture Based Cognitive Wireless Sensor Network,"Mobile Ad-hoc NETworks (MANETs) is a set of mobile nodes that can move around arbitrarily, and communicate with others in a multi-hop fashion without any assistance of base stations. With recent advances in Cognitive Radio (CR) technology, it is possible to apply the Dynamic Spectrum Access model in MANETs. This introduces the concept of Cognitive Radio Ad Hoc Networks (CRAHNs). Applying CR techniques provides better throughput, even in congested spectrum along with better propagation characteristics. CRAHN is a kind of intelligent network that is aware of its surrounding environment, and adapts to the transmission or reception parameters to achieve efficient communication without interfering with primary users. Routing in CR environment is a challenging task as the availability of channel is constrained by the presence of primary user. The problem of routing in CRAHNs targets the creation and maintenance of wireless multi-hop paths among cognitive nodes by deciding both the spectrum to be used and the relay nodes of the path. This paper proposes a cognitive cross-layer multipath probabilistic routing for cognitive radio based networks. The proposed solution uses spectrum holes identified by MAC layer, decides the channel to be used and transmit power level for each hop in the path. The proposed solution is implemented in NS2, and performance of the proposed solution is compared with the existing solution from the literature. The paper also shows that the proposed solution outperforms existing solution in terms of packet delivery ratio, average end-to-end delay and energy consumed per data packet. ||| Nowadays scarcity of spectrum availability is increasing highly. Adding cognition to the existing Wireless Sensor Network (WSN) infrastructure will help in this situation. As sensor nodes in WSN are limited with some constrains like power, efforts are required to increase the lifetime and other performance measures of the network. In this paper we propose the idea of Doubly Cognitive WSN. The basic idea is to progressively allocate the sensing resources only to the most promising areas of the spectrum. This work is based on Artificial Neural Network as well as on Support Vector Machine (SVM) concept. As the load of sensing resource is reduced significantly, this approach will save the energy of the nodes, and also reduce the sensing time dramatically.","mobile communication, Routing protocols, Cross-Layer Solution, Doubly Cognitive WSN, Ad hoc networks, Spectrum Sensing, Artificial Neural Network, Spectrum Management, cognitive radio, Cognitive Radio Ad Hoc Networks, Cognitive Wireless Sensor Network, WSN, Cross layer design, Power Control, Cognitive radio, Support Vector Machine, Routing","This paper proposes a cognitive cross-layer multipath probabilistic routing for cognitive radio based networks. The proposed solution uses spectrum holes identified by MAC layer, decides the channel to be used and transmit power level for each hop in the path. The proposed solution is implemented in NS2, and performance of the proposed solution is compared with the existing solution from the literature. ||| This paper proposes the idea of Doubly Cognitive WSN, which is based on pattern recognition and two-stage spectrum sensing for cognitive radios. The underlying notion of the idea is to progressively allocate the sensing resources to only the most promising areas of the spectrum, reducing sensing resources and time needed to accurately identify spectrum holes. The proposed approach will save the energy of the spectrum sensing nodes and also reduce the sensing time dramatically."
Devam Dave,"Explainable AI (XAI): Core Ideas, Techniques and Solutions ||| Title Suppressed Due to Excessive Length","As our dependence on intelligent machines continues to grow, so does the demand for more transparent and interpretable models. In addition, the ability to explain the model generally is now the gold standard for building trust and deployment of Artificial Intelligence (AI) systems in critical domains. Explainable Artificial Intelligence (XAI) aims to provide a suite of machine learning (ML) techniques that enable human users to understand, appropriately trust, and produce more explainable models. ||| The objective of an online Mart is to match buyers and sellers, to weigh animals and to oversee their sale. A reliable pricing method can be developed by ML models that can read through historical sales data. However, when AI models suggest or recommend a price, that in itself does not reveal too much (i.e., it acts like a black box) about the qualities and the abilities of an animal. An interested buyer would like to know more about the salient features of an animal before making the right choice based on his requirements. A model capable of explaining the different factors that impact the price point is essential for the needs of the market. It can also inspire confidence in buyers and sellers about the price point offered.","Machine Learning, Software toolkits, Video Analytics, Decision Making, vision based feature extraction, Internet of Things, Bias, Interpretable AI, XAI, Explainable AI, cow, Robustness, computer vision, ML based price prediction, weight estimation, Stakeholders, machine learning, Programming framework, Explainable Artiﬁcial Intelligence","The paper presents the core ideas, techniques, and solutions of XAI, emphasizing its importance in various phases of the machine learning process. It discusses the stakeholders involved in these phases, including developers, theorists, data scientists, users, consumers, businesses, regulators, and scientists, and highlights the use cases of XAI in detecting bias, scientific understanding, building robust models, and better decision making. ||| The paper discusses a method for estimating the weight of cows using a machine learning approach. The method involves training a model to predict the weight of cows based on images of their faces. However, the paper notes that the face of a cow is not sufficient for weight estimation and that the model can get biased according to color. The paper also discusses the limitations of the approach and suggests future directions for research."
Devendra Pratap Mishra,Genetic variability and associations studies for yield and its component traits in potato (Solanum tuberosum L.),"The present investigation was conducted during growing season of 2017-18. Data collected on tuber yield and its components were subjected for analysis of variability parameters, correlation coefficient and genetic advance. The estimates of analysis of variance were significant for the all parameters. The analysis of genetic variance revealed that the sufficient variability was present in experimental material. The Phenotypic coefficient of variation (PCV) was slightly higher in magnitude than genotypic coefficient of variation (GCV) for all the parameters. The high heritability estimates in broad sense was recorded in weight of ‘C’ grade tubers per hill, number of stems per hill, yield of tubers per hill (kg plant-1), number of leaves per plant, weight of ‘A’ grade tubers per hill, weight of ‘B’ grade tubers per hill, number of ‘C’ grade tubers per hill, weight of ‘D’ grade tubers per hill. The high heritability estimates coupled with high genetic advance was recorded for the parameters number of ‘D’ grade tubers per hill, weight of ‘D’ grade tubers per hill, weight of ‘C’ grade tubers per hill, number of ‘B’ grade tubers per hill, weight of ‘B’ grade tubers per hill and yield of tubers per hill (kg plot-1).","potato, Genetic variability, Correlation coefficient, Solanum tuberosum L., Genetic advance, correlation","The study aimed to investigate the genetic variability and associations studies for yield and its component traits in potato (Solanum tuberosum L.). The results showed significant differences among genotypes for all the characters studied, with sufficient variability present in genotypes. The high heritability estimates and genetic advance were recorded for several parameters, indicating the potential for selection and breeding of high-yielding cultivars."
Devendra Pratap Singh,The Idealized Heritage Village: Surveying the Public Perception for a Sustainable Development,"A comprehensive site survey was conducted for the area under study forming the historic core, combined with a detailed photo survey of the relevant components in the rural environment. The well documented photo survey of the elevations and places of interest facilitated a better understanding of the identified patterns and their locations.","Heritage Village, Community Participation, Rural Heritage, Public Perception, Settlement pattern, Sustainable Development, Human Perception, Vernacular architecture","The study aimed to investigate the planning tools that can be used to guide new developments, while respecting rural cultural heritage, distinctive characteristics of the traditional buildings, and understanding priorities and needs of villagers related to make alterations and extensions."
Dharamvir Singh Arya,"Cardioprotection from ischemia and reperfusion injury by Withania somnifera: A hemodynamic, biochemical and histopathological assessment","The efficacy of Withania somnifera (Ws) to limit myocardial injury after ischemia and reperfusion was explored and compared to that of Vit E, a reference standard known to reduce mortality and infarct size due to myocardial infarction. Wistar rats (150–200 g) were divided into six groups and received orally saline (sham, control group), Ws-50/kg (Ws control and treated group) and Vit E-100 mg/kg (Vit E control and treated group) respectively for 1 month. On the 31st day, rats of the control, Vit E and Ws treated groups were anesthetized and subjected to 45 min occlusion of the LAD coronary artery followed by 60 min reperfusion. Hemodynamic parameters: systolic, diastolic and mean arterial pressure (SAP, DAP, MAP), heart rate (HR), left ventricular end diastolic pressure (LVEDP), left ventricular peak (+)LVdP/dt and (–)LVdP/dt were monitored. Hearts were removed and processed for histopathological and biochemical studies: Myocardial enzyme viz, creatin phosphokinase (CPK), and antioxidant parameters: malondialdehyde (MDA), glutathione (GSH), superoxide dismutase (SOD), catalase (CAT), glu-tathione peroxidase (GSHPx) were estimated. Postischemic reperfusion produced significant cardiac necrosis, depression of left ventricular functions (MAP, LVEDP, (+) and (–)LVdP/dt) and a significant fall in GSH (p < 0.01), SOD, CAT (p < 0.05), LDH and CPK (p < 0.01) as well as an increase in MDA level (p < 0.05) in the control group rats as compared to sham group. The changes in levels of protein and GPx was however, not significant. Ws and Vit E favorably modulated most of the hemo-dynamic, biochemical and histopathological parameters though no significant restoration in GSH, MAP (with Vit E) were ob-served. Ws on chronic administration markedly augmented antioxidants (GSH, GSHPx, SOD, CAT) while Vit E did not stimulate the synthesis of endogenous antioxidants compared to sham. Results indicate that Ws significantly reduced myocardial injury and emphasize the beneficial action of Ws as a cardioprotective agent.","Withania somnifera, adaptogens, Adaptogenic, myocardial infarction, Ischemia-reperfusion injury, Myocardial damage, ischemia, Vitamin E, antioxidants, reperfusion","This study investigated the cardioprotective effects of Withania somnifera (Ws) compared to Vitamin E in a rat model of ischemia and reperfusion induced myocardial injury. Ws significantly reduced myocardial injury, improved hemodynamic parameters, and enhanced antioxidant defense mechanisms. These findings suggest that Ws has potential as a cardioprotective agent."
Dharm Raj Singh,"Estimate of variability, heritability and genetic advance with respect to yield and yield contributing characters in field pea (Pisum sativum L.)","The present investigation entitled “Estimate of variability, heritability and genetic advance with respect to yield and yield contributing characters in field pea (Pisum sativum L.)” for 10 characters. The experiment comprising of 23 genotypes of pea were grown in a Randomized Block Design (RBD), with three replications at Research Farm, Department of Genetics & Plant Breeding, Post Graduate College, Ghazipur, during rabi season of 2017-2018, plant to plant and row to row distance was kept 10 cm and 45 cm, respectively.","Pisum sativum L., heritability, Genetic variability, yield contributing characters, genetic advance, field pea","The estimates of genotypic coefficient of variation (GCV) and phenotypic coefficient of variation (PCV) and environmental coefficient of variation (ECV) showed a wide range. The high estimates of genotypic coefficient of variation (GCV) were observed for plant height, biological yield per plant, number of pods per plant, seed yield per plant, number, 100 seed weight. The high estimates of phenotypic coefficient of variation (PCV) were observed for seed yield per pod, number of pods per plant, biological yield per plant, harvest index, plant height."
Dheeraj Chaudhary,Cost Effective Influence Maximisation,"In the context of virality prediction, many researchers have leveraged the existence of a core-periphery structure in a network to identify the super-spreaders of information. Topologically, the nodes in the core of a network are the most eﬃcient spreaders. However, these nodes are less susceptible, i.e., unlikely to be inﬂuenced by the periphery nodes. Consequently, large payoﬀs are required to market information (ideas, products, memes, etc.) via them. In this paper, we show the presence of several non-core nodes whose spreading power is close to that of the core nodes.","Virality, Inﬂuence maximisation, Information diﬀusion, cost-effective, Core-periphery structure, information diffusion, social networks, influence maximisation",A cost-effective information diffusion strategy has been proposed that only requires the neighborhood information (friendship connections) of a node to make a meme go viral. Digital marketing agencies with a limited advertising budget can use the proposed strategy to popularise their product.
Dheeraj Wadhwa,Predicting pattern of coronavirus using X-ray and CT scan images,Novel coronavirus is a disease that can propagate easily with very minute carelessness and with very little physical contact between people.,"CT scan, COVID-19, Convolutional Neural Networks, CXR images, Convolutional Neural Network (CNN), Deep learning, X-ray, Coronavirus, Prediction",A lightweight deep learning model is proposed to automate and analyze the diagnostic process by utilizing Convolutional Neural Network (CNN) for predicting the pattern of coronavirus using X-ray and CT scan images.
Dhiman and Kumar,Analysis of high-dimensional biomedical data using an evolutionary multi-objective emperor penguin optimizer,This paper proposes a multi-objective chaotic Emperor Penguin Optimization algorithm for gene selection and classification performance. The algorithm uses the social huddling behavior of emperor penguins to update the positions of solutions and select the optimal gene subset. The proposed method combines the Fisher score filter and mRMR filter to select relevant genes and then uses the Emperor Penguin Optimization algorithm to select the optimal gene subset.,"Kernel ridge regression, Logistic function, Multi-objective optimization, Chaotic maps, Microarray, Emperor Penguin Optimization, MOCEPO, Gene selection, mRMR, Fisher score","The proposed algorithm uses the logistic chaotic map to replace the random variables in the Emperor Penguin Optimization algorithm, which improves the diversity of the resultant solutions and boosts the performance of the population-based methods. The algorithm is tested on several datasets and shows better classification performance compared to other existing methods."
Dhou et al.,Typeface size and weight and word location inüluence on relative size judgments in tag clouds,"This paper focuses on viewers’ perception of the relative size of words presented in tag clouds. Tag clouds are a type of visualization that displays the contents of a document as a cluster (cloud) of key words (tags) with frequency (importance) indicated by tag word features such as size or color, with variation of size within a tag cloud being the most common indicator of tag importance. Prior studies have shown that word size is the most inüluential factor of tag importance and tag memory. Systematic biases in relative size perception in tag clouds are therefore likely to have important implications for viewer understanding of tag cloud visualizations.","layout, typeface size, size judgment, perception, psychophysics, perceptual biases, tag cloud, search tasks, tag clouds","The study focuses on documenting systematic biases in relative size judgment in tag clouds while varying typeface weight and the location of the target tag word pair under comparison. The results provide a first report of systematic biases in relative size judgment in tag clouds, suggest that simple power-law scaling models developed for simple displays containing 1-2 objects on a blank background, may be applicable to relative size judgments in complex tag clouds."
Diaz et al.,Deformation Adjustment with Single Real Signature Image for Biometric Verification Using CNN,"Signature verification is the widely used biometric verification method for maintaining individual privacy. It is generally used in legal documents and in financial transactions. A vast range of research has been done so far to tackle different system issues, but there are various hot issues that remain unaddressed. The scale and orientation of the signatures are some issues to address, and the deformation of the signature within the genuine examples is the most critical for the verification system.","biometric authentication, Single real signature image, soft biometrics, deep learning, hard biometrics, CNN, Signature verification, Deformation adjustment, Biometric verification, writer-independent","This work proposes a two-phase system requiring only one target signature image to verify a query signature image. It takes care of the target signature's scaling, orientation, and spatial translation in the first phase. The second phase uses this transformed sample image and verifies the given sample as the target signature with the help of another deep neural network."
Dilip Kumar Chakrabarti,A brief survey of computerized expert systems for crop protection being used in India,"In the recent years, a plethora of computerized expert systems has been developed for various sectors of agriculture in India. The availability of low-cost computers, agricultural knowledge and information technology professionals are the principal reasons for the development of so many agricultural expert systems. Among all agricultural expert systems, the expert systems for crop protection need special mention. These expert systems are meant to be used by farmers and other persons without much experience of using computers. Hence, special care must be taken while developing them. The current paper develops a taxonomy for the expert systems for crop protection and brieﬂy discusses four such expert systems for crop protection being used in India.","crop specificity, taxonomy, Computerized expert system, Crop protection, Agriculture, expert systems, Agricultural expert system, disease specificity","The paper discusses the development of expert systems for crop protection in India, the design and implementation issues, and the current trend of agricultural expert systems in India. It also provides a brief survey of four expert systems for crop protection being used in India."
Dimple Bajaj,Maximum Coverage Heuristics (MCH) for Target Coverage Problem in Wireless Sensor Network,"Wireless Sensor Network is useful in broad range of applications such as natural disaster relief, military, environmental and health monitoring. Coverage is one of the fundamental problem and an active research area in wireless sensor network. WSN is an emerging field due to its large contribution in dealing with coverage. It consist of low cost, low power, small size and multifunction sensor nodes. The critical aspect with wireless sensor network is energy conservation. In power constrained WSN, scheduling of sensors to be done effectively and efficiently so as to maximize network lifetime. In this paper we give an introduction to WSN and its fundamental problems that is target coverage problem together with energy constraint. The target coverage problem is proven to be NP-Complete problem by many researchers. We propose a new energy-efficient heuristic for target coverage problem in wireless sensor network to maximize total network lifetime.","NP-complete, Network Lifetime, Q-Coverage Requirement, Target Coverage Problem, Wireless Sensor Networks, Wireless Sensor Network, Energy-Efficiency, Target Coverage","This paper proposes an energy-efficient method of scheduling sensors activity for target coverage problem in WSN. The aim of this paper is to propose an energy-efficient method of scheduling sensors activity for target coverage problem in WSN. The coverage problem is classified into an area coverage problem and a target coverage problem. The objective of the sensor network in area coverage is to cover a given area completely by battery powered sensors and each point of the area need to be monitored to extent network lifetime. Area is divided into number of fields such that each field is covered by a subset of sensors. Area coverage problem aims at determining the sensor covers that covers the entire area collectively. In Area coverage problem, network lifetime can be extended by selecting an appropriate distributed and localized protocol to select set of active sensors. The network activity is divided into rounds such that before each round decision is made about which sensors will be in sleep mode. The target coverage problem is all about maximizing network lifetime of wireless sensor network with power scarcity by monitoring a set of targets continuously for the maximum duration. Since the sensors are battery powered, they can be in three modes: Active, Sleep, off mode. In Active mode, sensor can sense and communicate the data. Energy of sensor in active mode is consumed. In Sleep mode, energy of sensor is not consumed. In Off mode, either the sensor is turned off permanently or battery of sensor is finished. An energy-efficient method for managing the power consumption of the sensor nodes is to schedule the sensor nodes in such a way that they alternate between active and sleep mode. This can be done by organizing the sensors into set of sensors (we call these sets as sensor covers) such that every sensor cover is capable of monitoring all the targets. As only a subset of sensors is active at a time for providing coverage to all the targets, helps in reducing power consumption."
Dipankar Deb,Advances in Intelligent Systems and Computing 757,"The series “Advances in Intelligent Systems and Computing” contains publications on theory, applications, and design methods of Intelligent Systems and Intelligent Computing.","learning paradigms, soft computing, knowledge management, intelligent agents, fuzzy systems, robotics and mechatronics, interactive entertainment, computational intelligence, neural networks, recommender systems, Conference Proceedings, human-centered and human-centric computing, trust management, Mechanical Engineering, ambient intelligence, evolutionary computing, DNA and immune based systems, intelligent control, virtual worlds and society, human-machine teaming, self-organizing and adaptive systems, computational neuroscience, knowledge-based paradigms, artiﬁcial life, Perception and Vision, intelligent data analysis, e-Learning and teaching, social intelligence, cognitive science and systems, Web intelligence and multimedia, intelligent decision making and support, intelligent network security, machine ethics","This volume constitutes a part of the proceedings of ﬁrst International Conference on Innovations in Infrastructure (ICIIF) 2018, which was held on 18–19 May, 2018, in Ahmedabad, India."
Divyashikha Sethia,Early Detection of Alzheimer’s Disease using Deep Learning Models and Word Embeddings,"Alzheimer’s Disease (AD) is an irrecoverable, progressive neurodegenerative disorder that deteriorates the cognitive and linguistic abilities of a person over time. Ample research has been done on the early detection of AD; it remains a challenging task. Doctors use the patient’s history, laboratory tests, and change in behaviour to diagnose the disease. Natural Language Processing(NLP) techniques can help automate the detection of AD, as Language impairments accompany this disease. This work aims to analyze the effect of different Embedding models on the DementiaBank dataset in order to detect the disease.","Natural Language Processing, Deep Learning, Alzheimer’s Disease, early detection, Cookie theft Description task, Word Embeddings","This paper explores the effect of different embedding algorithms and neural architectures on early detection of Alzheimer’s Disease using the DementiaBank dataset. The study uses both generic and domain-specific Word Embeddings on three deep learning models - CNN, Bidirectional LSTM(BLSTM), and CNN+BLSTM. Results indicate that domain-specific Word Embeddings tend to work better for a specific picture description task like cookie theft description. The study also discusses how results are affected by the use of different Embedding models (Fasttext, Word2Vec, GloVe)."
Diwakar Tripathi,Survey on Brain-Computer Interface,"A brain-computer interface (BCI) provides a way to develop interaction between a brain and a computer. The communication is developed as a result of neural responses generated in the brain because of motor movements or cognitive activities. The means of communication here includes muscular and non-muscular actions. These actions generate brain activities or brain waves that are directed to a hardware device to perform a specific task. BCI initially was developed as the communication device for patients suffering from neuromuscular disorders. Owing to recent advancements in BCI devices—such as passive electrodes, wireless headsets, adaptive software, and decreased costs—it is also being used for developing communication between the general public. The BCI device records brain responses using various invasive and non-invasive acquisition techniques such as electrocorticography (ECoG), electroencephalography (EEG), magnetoencephalography (MEG), and magnetic resonance imaging (MRI). In this article, a survey on these techniques has been provided. The brain response needs to be translated using machine learning and pattern recognition methods to control any application. A brief review of various existing feature extraction techniques and classification algorithms applied on data recorded from the brain has been included in this article. A significant comparative analysis of popular existing BCI techniques is presented and possible future directives are provided.","fuzzy inference system, feature extraction, electrocorticography, Brain-computer interface, Brain Signal Acquisition, Neural Tissue, classification, electroencephalogram, Electrodes","This survey provides a comprehensive overview of brain-computer interface (BCI) techniques, including signal acquisition, feature extraction, and classification algorithms. It discusses the recent advancements in BCI devices and their applications in developing communication between the general public. The survey also presents a comparative analysis of popular existing BCI techniques and provides possible future directives."
Dmitry Bragin,Generation of an EDS Key Based on a Graphic Image of a Subject’s Face Using the RC4 Algorithm,"Modern facial recognition algorithms make it possible to identify system users by their appearance with a high level of accuracy. In such cases, an image of the user’s face is converted to parameters that later are used in a recognition process. On the other hand, the obtained parameters can be used as data for pseudo-random number generators. However, the closeness of the sequence generated by such a generator to a truly random one is questionable. This paper proposes a system which is able to authenticate users by their face, and generate pseudo-random values based on the facial image that will later serve to generate an encryption key. The generator of a random value was tested with the NIST Statistical Test Suite. The subsystem of image recognition was also tested under various conditions of taking the image. The test results of the random value generator show a satisfactory level of randomness, i.e., an average of 0.47 random generation (NIST test), with 95% accuracy of the system as a whole.","random number generation, digital signatures, authenticity, neural networks, digital signature, python, NIST test battery, computer vision, programming, algorithms, cryptography, facial recognition, security","This paper proposes a system for authenticating users by their face and generating pseudo-random values based on facial images. The system uses a combination of mathematical procedures for facial recognition and a pseudo-random number generator. The generator of a random value was tested with the NIST Statistical Test Suite, and the subsystem of image recognition was tested under various conditions of taking the image. The test results show a satisfactory level of randomness and 95% accuracy of the system as a whole."
Domingos and Richardson,Rumour Source Detection Using Game Theory,"Social networks have become a critical part of our lives as they enable us to interact with a lot of people. These networks have become the main sources for creating, sharing and also extracting information regarding various subjects. But all this information may not be true and may contain a lot of unverified rumours that have the potential of spreading incorrect information to the masses, which may even lead to situations of widespread panic. Thus, it is of great importance to identify those nodes and edges that play a crucial role in a network in order to find the most influential sources of rumour spreading. Generally, the basic idea is to classify the nodes and edges in a network with the highest criticality. Most of the existing work regarding the same focuses on using simple centrality measures which focus on the individual contribution of a node in a network. Game-theoretic approaches such as Shapley Value (SV) algorithms suggest that individual marginal contribution should be measured for a given player as the weighted average marginal increase in the yield of any coalition that this player might join. For our experiment, we have played five SV-based games to find the top 10 most influential nodes on three network datasets (Enron, USAir97 and Les Misérables). We have compared our results to the ones obtained by using primitive centrality measures. Our results show that SV-based approach is better at understanding the marginal contribution, and therefore the actual influence, of each node to the entire network.","influential nodes, Jaccard Similarity Coefficient, cooperative game, Rumour Source Detection (RSD), centrality measures, network analysis, Shapley Value (SV), Game-Theory, Network Centrality",This paper aims to identify the most influential nodes in a network that are the primary sources of rumour propagation. The authors propose a game-theoretic approach using the Shapley Value algorithm to find the most influential nodes. They compare their results with primitive centrality measures and show that the SV-based approach is better at understanding the marginal contribution of each node to the entire network.
Dong-Wook Lee,Endogenous IRAK-M Attenuates Postinfarction Remodeling Through Effects on Macrophages and Fibroblasts ||| TSP-1 in Diabetic Cardiomyopathy,"Quantitative polymerase chain reaction analysis demonstrated significant IRAK-M mRNA upregulation in the infarcted myocardium. The time course of IRAK-M induction showed a biphasic response (Figure 1), characterized by marked early upregulation after 6 hours of reperfusion, followed by a second peak after 7 days of reperfusion (Figure 1A). IRAK-M Is Localized in Infarct Macrophages and Myofibroblasts Dual immunofluorescence was used to study IRAK-M localization in the infarcted myocardium. IRAK-M immunoreactivity in the infarcted heart was localized in Mac2+ infarct macrophages and in spindle-shaped, α–smooth muscle actin–positive myofibroblasts (Figure 1B and 1C). Moreover, infarct myofibroblasts and CD11b+ leukocytes isolated from the infarcted heart after 72 hours of reperfusion exhibited IRAK-M expression (Figure 1D–1G). To study cell-type specific changes in the timing of IRAK-M expression, we assessed IRAK-M mRNA levels in cardiac fibroblasts and CD11b+ leukocytes harvested from the infarcted heart. Isolated fibroblasts had a 3-fold increase in IRAK-M mRNA levels after 24 hours to 72 hours of reperfusion in comparison with control cardiac fibroblasts. When compared with control CD11b+ cells harvested from normal hearts, leukocytes isolated after 6 hours of reperfusion showed a trend toward increased IRAK-M mRNA expression (Figure I in the online-only Data Supplement). IRAK-M Loss Is Associated With Enhanced Adverse Remodeling Despite the Absence of Effects on the Size of the Infarct IRAK-M−null and WT animals had comparable mortality after myocardial infarction (P=NS). Triphenyltetrazolium chloride/Evans blue staining demonstrated that IRAK-M loss does not affect the size of the infarct after 1 hour of ischemia and 24 hours of reperfusion (Figure 1H–1J). Two independent techniques, echocardiographic imaging (Figure 2A–2G; Table I in the online-only Data Supplement) and quantitative morphometry (Figure 2H–2L), demonstrated that IRAK-M loss was associated with enhanced adverse remodeling after myocardial infarction. Systolic and diastolic chamber dimensions measured through echocardiography (left ventricular end-diastolic dimension, left ventricular end-systolic dimension, left ventricular end-systolic volume, and left ventricular end-diastolic volume; Figure 2A–2G) and morphometrically-derived left ventricular end-diastolic volume and left ventricular end-diastolic dimension (Figure 2H–2L) were significantly higher in IRAK-M−null mice after 7 and 28 days of reperfusion, indicating increased chamber dilation. Left ventricular mass was also significantly higher in infarcted IRAK-M−null hearts, suggesting accentuated hypertrophic remodeling. Increased adverse remodeling in the absence of IRAK-M was associated with reduced fractional shortening (FS), reflecting worse systolic dysfunction (Figure 2D). Because acute infarct size was comparable between WT and IRAK-M−null mice (Figure 1H–1J), accentuated adverse remodeling in IRAK-M−null hearts was not a result of more extensive cardiomyocyte injury. Moreover, scar size after 7 to 28 days of reperfusion was comparable between IRAK-M−/− and WT animals (Figure 2I). IRAK-M−/− Mice Have Enhanced Postinfarction Inflammation Exhibiting Increased Myocardial Cytokine mRN ||| Diabetes mellitus is associated with cardiac fibrosis. Matricellular proteins are induced in fibrotic conditions and modulate fibrogenic and angiogenic responses by regulating growth factor signaling. Our aim was to test the hypothesis that the prototypical matricellular protein thrombospondin (TSP)-1, a potent angiostatic molecule and crucial activator of transforming growth factor-β, may play a key role in remodeling of the diabetic heart. Obese diabetic db/db mice exhibited marked myocardial TSP-1 upregulation in the interstitial and perivascular space. To study the role of TSP-1 in remodeling of the diabetic heart, we generated and characterized db/db TSP-1–/– (dbTSP) mice. TSP-1 disruption did not significantly affect weight gain and metabolic function in db/db animals. When compared with db/db animals, dbTSP mice had increased left ventricular dilation associated with mild nonprogressive systolic dysfunction. Chamber dilation in dbTSP mice was associated with decreased myocardial collagen content and accentuated matrix metalloproteinase-2 and -9 activity. TSP-1 disruption did not affect inflammatory gene expression and activation of transforming growth factor-β/small mothers against decapendaplegic signaling in the db/db myocardium. In cardiac fibroblasts populating collagen pads, TSP-1 incorporation into the matrix did not activate transforming growth factor-β responses, but inhibited leptin-induced matrix metalloproteinase-2 activation. TSP-1 disruption abrogated age-associated capillary rarefaction in db/db mice, attenuating myocardial upregulation of angiopoietin-2, a mediator that induces vascular regression. In vitro, TSP-1 stimulation increased macrophage, but not endothelial cell, angiopoietin-2 synthesis. Conclusions: TSP-1 upregulation in the diabetic heart prevents chamber dilation by exerting matrix-preserving actions on cardiac fibroblasts and mediates capillary rarefaction through effects that may involve angiopoietin-2 upregulation.","metalloproteinases, cytokines, matrix metalloproteinases, immune system, macrophages, thrombospondins, fibrosis, cardiac remodeling, ventricular remodeling, diabetic cardiomyopathies","This study investigates the role of Interleukin-1 receptor-associated kinase (IRAK)-M in myocardial infarction.  Key findings include: 

* IRAK-M mRNA is significantly upregulated in the infarcted myocardium, with a biphasic response.
* IRAK-M is localized in macrophages and myofibroblasts within the infarcted heart.
* IRAK-M loss is associated with enhanced adverse remodeling after myocardial infarction, characterized by increased chamber dilation and hypertrophy, despite no effect on infarct size.
* IRAK-M−/− mice exhibit increased postinfarction inflammation with elevated myocardial cytokine mRNA levels. ||| This study investigates the role of thrombospondin-1 (TSP-1) in diabetic cardiomyopathy. Researchers found that TSP-1 is upregulated in the hearts of diabetic mice and that its loss attenuates cardiac fibrosis and enhances myocardial protease activity. However, TSP-1 disruption also led to mild left ventricular dilation and modest nonprogressive systolic dysfunction. These findings suggest that TSP-1 plays a complex role in diabetic heart remodeling, with both beneficial and detrimental effects."
Dorko and Schmid,A New Keypoints Selection Technique for Histopathological Image Classification,"An efﬁcient classiﬁcation method to categorize histopathological images is a challenging research problem. In this paper, an improved bag-of-features approach is presented as an efﬁcient image classiﬁcation method.","Bag-of-features, Grey relational analysis, histopathological image classification, Histopathological image analysis, Keypoint selection, keypoints selection","The proposed method reduces the extracted high dimensional features by 95% and 68% from the ADL and Blue histology datasets respectively with less computational time. Moreover, the enhanced bag-of-features method increases classiﬁcation accuracy by from other considered classiﬁcation methods."
Dr Anil Kumar Dubey,Aspect Term Extraction using Domain Ontology for Sarcasm Detection ||| Fake News Detection Through ML and Deep Learning ||| Web-Based Movie Recommender System,"Various aspects or characteristic features of an entity come into interplay to create an underlying fabric upon which sentiments blossom. In multi aspect Sentiment Analysis (SA), potentially related aspects of an entity under review are discussed in a single piece of text such as an online review. In this work, we use domain ontologies for enabling multi-aspect Sentiment Analysis. Since, domain ontologies contain the entire domain knowledge, they assist in enhanced aspect identification and detection of the latent or hidden aspects in a review document. We illustrate our approach by developing a system named Ontology driven Multi Aspect Sentiment Analysis (OMASA) system. We provide hotel reviews as input to this system and identify the panorama of explicitly expressed and latent aspects in a review using hotel domain ontology. After detecting the aspects, we link them with the corresponding opinions to gauge the sentiment pertaining to the aspects extracted. OMASA first computes sentiment scores for every aspect of the hotel. It then evaluates the overall sentiment score. On comparing with the baseline, the experimental results of OMASA show a marked improvement in the aspect level evaluation metrics Δaspect2 and ρaspect after detecting the hidden aspects. This shows that OMASA has the potential to identify the latent aspects in text thereby improving the quality of SA. ||| This paper discusses the detection of fake news through machine learning and deep learning algorithms. The authors present a proposed approach for fake news detection using decision tree, XGBoost, and LSTM algorithms. The paper also discusses the preprocessing of data, feature extraction, and the training and testing of the classifiers. The results show that the decision tree algorithm achieves a prediction accuracy of 99.67% for fake news detection. ||| All content following this page was uploaded by Mala Saraswat on 24 May 2021.","Sarcasm Detection, Machine Learning, Sentiment Analysis, decision tree, Classification, Aspect Term Extraction, Sarcasm, Domain Ontology, fake news detection, TripAdvisor, Domain Ontologies, LSTM, Social media, News, Amazon, Hotel Domain, Hontology, XGBoost, Accuracy, deep learning, machine learning, Twitter, Detection","This paper proposes a novel approach for multi-aspect sentiment analysis using domain ontologies. The proposed system, OMASA, uses domain ontologies to identify and extract latent and hidden aspects in a review document. OMASA computes sentiment scores for every aspect of the hotel and evaluates the overall sentiment score, showing a marked improvement in aspect level evaluation metrics compared to the baseline. ||| The detection of fake news is an important challenge to researchers. The detection of misinformation is not an easy task for anyone, but quite is a complex for people. Here, we analyze the different fake news detection approaches followed in current scenario and compute the detection process through machine learning and deep leaning algorithms for better accuracy. ||| See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/339920629"
Dr Manju,Maximum Coverage Heuristics (MCH) for Target Coverage Problem in Wireless Sensor Network,"Wireless Sensor Network is useful in broad range of applications such as natural disaster relief, military, environmental and health monitoring. Coverage is one of the fundamental problem and an active research area in wireless sensor network. WSN is an emerging field due to its large contribution in dealing with coverage. It consist of low cost, low power, small size and multifunction sensor nodes. The critical aspect with wireless sensor network is energy conservation. In power constrained WSN, scheduling of sensors to be done effectively and efficiently so as to maximize network lifetime. In this paper we give an introduction to WSN and its fundamental problems that is target coverage problem together with energy constraint. The target coverage problem is proven to be NP-Complete problem by many researchers. We propose a new energy-efficient heuristic for target coverage problem in wireless sensor network to maximize total network lifetime.","NP-complete, Network Lifetime, Q-Coverage Requirement, Target Coverage Problem, Wireless Sensor Networks, Wireless Sensor Network, Energy-Efficiency, Target Coverage","This paper proposes an energy-efficient method of scheduling sensors activity for target coverage problem in WSN. The aim of this paper is to propose an energy-efficient method of scheduling sensors activity for target coverage problem in WSN. The coverage problem is classified into an area coverage problem and a target coverage problem. The objective of the sensor network in area coverage is to cover a given area completely by battery powered sensors and each point of the area need to be monitored to extent network lifetime. Area is divided into number of fields such that each field is covered by a subset of sensors. Area coverage problem aims at determining the sensor covers that covers the entire area collectively. In Area coverage problem, network lifetime can be extended by selecting an appropriate distributed and localized protocol to select set of active sensors. The network activity is divided into rounds such that before each round decision is made about which sensors will be in sleep mode. The target coverage problem is all about maximizing network lifetime of wireless sensor network with power scarcity by monitoring a set of targets continuously for the maximum duration. Since the sensors are battery powered, they can be in three modes: Active, Sleep, off mode. In Active mode, sensor can sense and communicate the data. Energy of sensor in active mode is consumed. In Sleep mode, energy of sensor is not consumed. In Off mode, either the sensor is turned off permanently or battery of sensor is finished. An energy-efficient method for managing the power consumption of the sensor nodes is to schedule the sensor nodes in such a way that they alternate between active and sleep mode. This can be done by organizing the sensors into set of sensors (we call these sets as sensor covers) such that every sensor cover is capable of monitoring all the targets. As only a subset of sensors is active at a time for providing coverage to all the targets, helps in reducing power consumption."
Dr. Alex Pappachen James,International Journal of Computer Science & Information Security,"The International Journal of Computer Science and Information Security is a monthly periodical on research articles in general computer science and information security which provides a distinctive technical perspective on novel technical research work, whether theoretical, applicable, or related to implementation.","Internet security, cryptography, formal methods in information security, wireless communication, web services, networking and technologies, software, intelligent systems, data mining, network security, security infrastructures, innovation technology and management, content protection, information systems, steganography, multimedia systems","The journal covers various topics in computer science and information security, including security infrastructures, network security, and multimedia systems. It provides a platform for researchers to share their work and ideas in these areas."
Dr. Gregorio Martinez Perez,International Journal of Computer Science & Information Security,"The International Journal of Computer Science and Information Security is a monthly periodical on research articles in general computer science and information security which provides a distinctive technical perspective on novel technical research work, whether theoretical, applicable, or related to implementation.","Internet security, cryptography, formal methods in information security, wireless communication, web services, networking and technologies, software, intelligent systems, data mining, network security, security infrastructures, innovation technology and management, content protection, information systems, steganography, multimedia systems","The journal covers various topics in computer science and information security, including security infrastructures, network security, and multimedia systems. It provides a platform for researchers to share their work and ideas in these areas."
Dr. K.V. Sambasiva Rao,Adaptive Privacy Policy Prediction for Images in Social Media,"Social Network is an emerging E-service for content sharing sites (CSS). It is emerging service which provides a reliable communication, through this communication a new attack ground for data hackers; they can easily misuses the data through these media.","A3P-Core, Policy Prediction, Adaptive Privacy Policy Prediction, Privacy-Aware Image Classification and Search, Policy Mining, Privacy Suites, A3P-Social, Image Classification, Adaptive Privacy Policy Prediction (A3P), Social Media, Polar Fourier Transform (PFT), Tag based access control of data","This paper proposes an Adaptive Privacy Policy Prediction (A3P) system to help users compose privacy settings for their images. The system handles user uploaded images and factors in social environment, personal characteristics, image content, and metadata to predict the best available privacy policy for each user's images."
Dr. K.V.N. Sunitha,Trusted Secure Geographic Routing Protocol for Detecting Insider Attacks in MANET,"In Mobile Ad hoc Network (MANET), the nodes are linked to one another wirelessly and are self sustaining. The member nodes of MANET are very robust and minute. The deployment and maintenance of this network is less expensive and comparatively easy when compared with the conventional networks. However, MANET is highly susceptible to attacks due to its infrastructureless topology. The possible attacks vary over a wide range and affect the network in different levels. To overcome these attacks and safeguard the network performance, in this paper we propose to develop a trusted secure geographical routing protocol for detecting insider attacks.","trust value estimation, Insider Attacks, Mobile Ad hoc Network, Trusted Secure Geographic Routing Protocol, MANET","The protocol estimates the overall trust value of neighboring nodes in two steps: initially, the agent in each node computes the trust value based on two desired functionalities at every Trust Update Interval (TUI); then, after packets are transmitted to the next hop node, the transmitting node overhears the channel to determine the number of packets forwarded and dropped by the next hop node, and computes the trust value of the next hop node based on the overheard information."
Dr. K.V.Sambasiva Rao,The Role of Commercial Websites in the Improvements of E-Business,"Electronic Business (e-Business) is revolutionizing the way of communication between internal and external stakeholders in an organization. E-business can lead to competitive advantage and at the same time, increase profitability. There are several factors resulting on the success of e-business. One of the most important factors is trust. Acquiring customers’ trust depends on many things that an e-business controls. Some relating factors for gaining customers’ trust are: appeal of the website, product/service offering, branding, quality of service, and trusted seals. The paper seeks to address industry uncertainties and consumer concerns about commercial Internet sites by developing a framework identifying factors and facilities for business-to consumer web sites.","quality of service, security, e-Business, web site evaluation, trust, website",This paper aims to address industry uncertainties and consumer concerns about commercial Internet sites by developing a framework identifying factors and facilities for business-to consumer web sites. The framework is based on a broad literature review ranging from consumer adoption of technology-based innovations to evaluations of web sites as well as a review of internationally recognized leading examples of Business to Consumer web sites.
Dr. M. Emre Celebi,International Journal of Computer Science & Information Security,"The International Journal of Computer Science and Information Security is a monthly periodical on research articles in general computer science and information security which provides a distinctive technical perspective on novel technical research work, whether theoretical, applicable, or related to implementation.","Internet security, cryptography, formal methods in information security, wireless communication, web services, networking and technologies, software, intelligent systems, data mining, network security, security infrastructures, innovation technology and management, content protection, information systems, steganography, multimedia systems","The journal covers various topics in computer science and information security, including security infrastructures, network security, and multimedia systems. It provides a platform for researchers to share their work and ideas in these areas."
Dr. Riktesh Srivastava,International Journal of Computer Science & Information Security,"The International Journal of Computer Science and Information Security is a monthly periodical on research articles in general computer science and information security which provides a distinctive technical perspective on novel technical research work, whether theoretical, applicable, or related to implementation.","Internet security, cryptography, formal methods in information security, wireless communication, web services, networking and technologies, software, intelligent systems, data mining, network security, security infrastructures, innovation technology and management, content protection, information systems, steganography, multimedia systems","The journal covers various topics in computer science and information security, including security infrastructures, network security, and multimedia systems. It provides a platform for researchers to share their work and ideas in these areas."
Dr. Roshini Rawal,Effect of Cyber Crime on Economical Development,"Internet has become household commodity in India and almost every information and data is running online. Due to this cyber crime has been rapidly increasing its footfall on Indian economy. There are various kind of cyber crimes, creating impact and threat to the economy of a nation and even disturbing peace and the security. This research paper emphasis on how cyber crime is having hazardous effect on Indian economy as it move towards the new investment, digitalization and demonetization. It is increasing the risk factor. Therefore there is need for a holistic approach to combat these crimes and try to find remedies for it. So that we can drag our Indian economy towards developing economy, not the underdeveloped economy and its effects could be more profound. And we can witness the new horizon of cyber crime free Indian economy.","Risk Factors, Cyber Crime, Cyber Espionage, Cyber Security, Economic Growth, Indian Economy, Digitalization, Demonetization","This research paper aims to comprehend how cybercrime is affecting economical development in India, study the factors or determinants related to crime that play vital roles in the development of economy of any nation, get acquainted with the above identified factors effecting cyber crime, and study and reduce the factors responsible for having effect on Indian economy."
Dr. Sanjay Jasola,International Journal of Computer Science & Information Security,"The International Journal of Computer Science and Information Security is a monthly periodical on research articles in general computer science and information security which provides a distinctive technical perspective on novel technical research work, whether theoretical, applicable, or related to implementation.","Internet security, cryptography, formal methods in information security, wireless communication, web services, networking and technologies, software, intelligent systems, data mining, network security, security infrastructures, innovation technology and management, content protection, information systems, steganography, multimedia systems","The journal covers various topics in computer science and information security, including security infrastructures, network security, and multimedia systems. It provides a platform for researchers to share their work and ideas in these areas."
Dr. Siddhivinayak Kulkarni,International Journal of Computer Science & Information Security,"The International Journal of Computer Science and Information Security is a monthly periodical on research articles in general computer science and information security which provides a distinctive technical perspective on novel technical research work, whether theoretical, applicable, or related to implementation.","Internet security, cryptography, formal methods in information security, wireless communication, web services, networking and technologies, software, intelligent systems, data mining, network security, security infrastructures, innovation technology and management, content protection, information systems, steganography, multimedia systems","The journal covers various topics in computer science and information security, including security infrastructures, network security, and multimedia systems. It provides a platform for researchers to share their work and ideas in these areas."
Dr. Vidhi Khanduja,"MACHINE LEARNING: APPLICATIONS, TECHNIQUES AND CURRENT SCENARIO","Machine Learning (ML) used in day-to-day life. ML can use data and use it for self-learning. It is widely used in many fields like finance, agriculture, education, and security, etc. This paper discusses the potential of utilizing machine learning technologies in various sector.ML categorized in mainly four Learning process. Supervised learning which contains labelled data where unsupervised learning includes unlabelled data. Semi-supervised learning is a combination of supervised and unsupervised learning. The reinforcement learning algorithm is learned by receiving feedback on the effect of modifying some parameters. We can study in detail with different techniques and different methods and also check which algorithm is more accurate in less runtime. This paper summarizes some application of machine learning such as prediction, disease detection, fraud detection and more. This paper helps in reducing the research gap for ML applications.","decision trees, SVM, ANN, Machine Learning, finance, support vector machines, education, Naïve Bayes, artificial neural networks, Detection, Prediction, KNN, security","This paper discusses the potential of utilizing machine learning technologies in various sectors. It categorizes machine learning into four main learning processes: supervised, unsupervised, semi-supervised, and reinforcement learning. The paper also summarizes some applications of machine learning such as prediction, disease detection, and fraud detection."
Dr. Yong Li,International Journal of Computer Science & Information Security,"The International Journal of Computer Science and Information Security is a monthly periodical on research articles in general computer science and information security which provides a distinctive technical perspective on novel technical research work, whether theoretical, applicable, or related to implementation.","Internet security, cryptography, formal methods in information security, wireless communication, web services, networking and technologies, software, intelligent systems, data mining, network security, security infrastructures, innovation technology and management, content protection, information systems, steganography, multimedia systems","The journal covers various topics in computer science and information security, including security infrastructures, network security, and multimedia systems. It provides a platform for researchers to share their work and ideas in these areas."
Dr.G.R.S.Murthy,Performance Evaluation of Entropy and Gini using Threaded and Non Threaded ID3 on Anaemia Dataset,"Classification is an important data mining task, and decision trees have emerged as a popular classifier due to their simplicity and relatively low computational complexity. Time required to build a decision tree becomes intractable, as datasets get extremely large. To overcome this problem we proposed a parallel mode of ID3 algorithm. Decision tree building is well-suited for thread-level parallelism as it requires a large number of independent computations. In this paper, we present the analysis and parallel implementation of the ID3 algorithm using Entropy and Gini as heuristics, along data set.","Entropy Heuristic, Threaded ID3, Parallel data mining, Gini Heuristic, Data Mining, Decision tree, ID3, Parallelism, Gini, Entropy, Anemia Database","The paper presents a parallel mode of ID3 algorithm for decision tree building, using Entropy and Gini as heuristics, and analyzes its performance on an anaemia dataset. The proposed method helps in analyzing two types of anaemia, Iron deficiency anaemia (ID) and B12 deficiency anaemia (B12), and identifies the most significant attributes for determining the transferred, number of frozen embryos, and culture days of embryo."
Dr.Vidhi Khanduja,Effect of Cyber Crime on Economical Development,"Internet has become household commodity in India and almost every information and data is running online. Due to this cyber crime has been rapidly increasing its footfall on Indian economy. There are various kind of cyber crimes, creating impact and threat to the economy of a nation and even disturbing peace and the security. This research paper emphasis on how cyber crime is having hazardous effect on Indian economy as it move towards the new investment, digitalization and demonetization. It is increasing the risk factor. Therefore there is need for a holistic approach to combat these crimes and try to find remedies for it. So that we can drag our Indian economy towards developing economy, not the underdeveloped economy and its effects could be more profound. And we can witness the new horizon of cyber crime free Indian economy.","Risk Factors, Cyber Crime, Cyber Espionage, Cyber Security, Economic Growth, Indian Economy, Digitalization, Demonetization","This research paper aims to comprehend how cybercrime is affecting economical development in India, study the factors or determinants related to crime that play vital roles in the development of economy of any nation, get acquainted with the above identified factors effecting cyber crime, and study and reduce the factors responsible for having effect on Indian economy."
"Dunn, J. C. (1973)",Quantum-inspired evolutionary approach for selection of optimal parameters of fuzzy clustering,"Recently, Fuzzy c-Means (FCM) algorithm is most widely used because of its efficiency and simplicity. However, FCM is sensitive to the initialization of fuzziness factor (m) and the number of clusters (c) due to which it easily trapped in local optima. A selection of these parameters is a critical issue because an adverse selection can blur the clusters in the data.","Fuzzy clustering, Cluster validity index, Quantum-Inspired Evolutionary Fuzzy c-Means, Fuzzy c-Means algorithm, Fuzzy c-Means, Quantum computing","This paper proposes a hybrid fuzzy clustering algorithm, Quantum-Inspired Evolutionary Fuzzy c-Means (QIE–FCM), which uses the merits of quantum computing for finding the global optimal value of m and its corresponding value of c in the FCM. The proposed approach improves the way of initialization of the fuzziness factor (m) in the FCM and provides the diversity in selecting the optimal value of m and c from a large quantum search space."
E. Suresh Babua,Alignment Free Cancellable Fingerprint Templates Using Ellipse Structure,"In this work, a new method for alignment free cancellable fingerprint templates was proposed using ellipse structure. Ellipse was formed by selecting one of the minutiae and core point of the fingerprint as focal points and the farthest minutia as the co-vertex. This method performs well because instead of storing spatial information of the fingerprints such as distance or orientation between minutia, etc., we are storing the ellipse attributes in transformed form such that even though if any stored template got leaked, the original fingerprint information will not be revealed to the attacker. This method also performs well in terms of FAR and FRR. However for the fingerprints which does not possess a core point this method will not be suitable and is the main limitation of this work.","Template protection, Discrete Fourier transform, Fingerprint, Ellipse, cancellable templates, biometric security, fingerprint templates, ellipse structure","The proposed method uses elliptical structures generated from fingerprint minutiae to secure fingerprint templates. The method involves extracting minutiae from fingerprint images, constructing ellipses and extracting feature sets, projecting the feature sets onto a 3D space, generating a binary string, and transforming the binary string into the frequency domain using DFT."
Ekarat Rattagan,Accurate Trafﬁc Flow Prediction in Heterogeneous Vehicular Networks in an Intelligent Transport System Using a Supervised Non-Parametric Classiﬁer,"Heterogeneous vehicular networks (HETVNETs) evolve from vehicular ad hoc networks (VANETs), which allow vehicles to always be connected so as to obtain safety services within intelligent transportation systems (ITSs). The services and data provided by HETVNETs should be neither interrupted nor delayed. Therefore, Quality of Service (QoS) improvement of HETVNETs is one of the topics attracting the attention of researchers and the manufacturing community.","QoS, SVM, Radial Basis Function, Prediction Accuracy, RBF, internet of vehicles, Support Vector Machines, HETVNET, Vehicular Ad Hoc Network",This paper proposes a prediction model based on support vector machines (SVMs) to improve Quality of Service (QoS) in Heterogeneous Vehicular Networks (HETVNETs). The model uses a radial basis function (RBF) kernel and outperforms other prediction methods in terms of accuracy and computational complexity.
El Emam & Madhavji,Characterizing relatedness of web and requirements engineering,"Web and Requirements Engineering have been well-recognized as two individual active areas of research in the past. Convergence between these two notable areas has been a point-of-discussion in recent years and offers new avenues of research. This paper explores this alliance from two perspectives; firstly, where Requirement Engineering can be viewed as a process for Web application development as it primarily concerns with adapting the Requirement Engineering process to the Web applications which are special in characteristics as compared to traditional software applications and secondly, where Web can be viewed as a supporting technology for improving the requirements engineering process and enabling new capabilities.","Web Applications, Web 3.0, Web 2.0, SWOT Analysis, Web application, Requirements engineering","The paper explores the relationship between Web and Requirements Engineering from two perspectives, highlighting the need for a more extensive and efficient Requirements Engineering process for Web applications, and the potential of Web technologies to support and improve the requirements engineering process."
Ellen Ginzler,BELIMUMAB IN PATIENTS OF BLACK AFRICAN ANCESTRY,"Study design. SELENA–SLEDAI = Safety of Estrogens in Lupus Erythematosus National Assessment–Systemic Lupus Erythemato-sus Disease Activity Index; IV = intravenous.

Randomization and treatment. Using an interactive voice/web response system, patients receiving standard therapy were randomized 2:1 to receive either belimumab 10 mg/kg IV or placebo, which was administered on days 0, 14, and 28 and every 28 days thereafter up to week 48, with a final evaluation at week 52. Randomization was stratified by screening SELENA–SLEDAI score (≤9 versus ≥10), region (US/Canada versus rest of world), and complement level (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]). Detailed randomization data are provided in Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Patients who successfully completed the initial 52-week double-blind phase could enter an optional 6-month open-label extension phase, during which they received belimumab 10 mg/kg IV every 28 days plus standard therapy, irrespective of their previous study assignment. The first dose was given at the week 52 (day 364) visit of the double-blind period (day 1 of the open-label extension phase). Patients who completed the 52-week double-blind phase, but did not enter the 6-month open-label extension phase, were required to return for an additional follow-up visit 8 weeks after their last dose. Patients who withdrew early were required to return for an exit visit 4 weeks after their last dose and a follow-up visit 8 weeks after their last dose.

The original protocol plan was to randomize 816 patients, providing ≥90% power to detect ≥12% absolute improvement in the SRI response rate in the belimumab group compared with the placebo group at a 5% significance level. Due to enrollment challenges, a revised sample size was calculated to include 501 patients (≥334 patients in the belimumab group and ≥167 patients in the placebo group). This sample size provided ≥90% power to detect a minimum 15.55% absolute improvement in SRI–SLEDAI-2K response rate in the belimumab group relative to the placebo group at a 5% significance level (based on the pooled data from efficacy studies BEL112341 and BEL113750) (15,21). These calculations assumed a placebo response rate of 43.95% at week 52.

Study end points and assessments. The primary efficacy end point was the SRI–SLEDAI-2K response rate (defined in the Supplementary Material) at week 52 of the double-blind phase. Unlike in the phase II and phase III studies, the SRI–SLEDAI-2K was selected because of the simplification it offers in proteinuria assessment as compared with the SELENA–SLEDAI proteinuria component; both are clinically meaningful (22). The primary efficacy end point for the open-label extension phase was SRI–SLEDAI-2K response rate at open-label extension week 24. If the open-label extension week 24 data were missing, data from the open-label extension week 28/exit visit were used. This time point is referred to as “open-label extension week 24” throughout the text. Data related to the primary efficacy end point, e.g., the response rate over time, percentage of patients with a durable SRI–SLEDAI-2K response from week 44 through week 52, time to first SRI–SLEDAI-2K response that was maintained through week 52, and duration of longest SRI–SLEDAI-2K response among patients with ≥1 SRI–SLEDAI-2K responses were summarized.

The key secondary end points were SRI–SELENA–SLEDAI at week 52 (open-label extension week 24), time to first severe SLE flare (measured by the SELENA–SLEDAI flare index [SFI]), and proportion of patients whose average prednisone dose had been reduced by ≥25% from baseline to ≤7.5 mg/day during week 40 through week 52 (open-label extension week 28/exit visit), in patients receiving >7.5 mg/day at baseline. Key renal end points included time to first renal flare over 52 weeks and over 28 weeks in the open-label extension, SELENA–SLEDAI–SLEDAI-2K renal domain improvement at week 52, SELENA–SLEDAI–SLEDAI-2K renal domain worsening at week 52, percentage reduction in proteinuria by visit and at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours, and proteinuria shift at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours. Renal flare is defined in the Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Biomarkers measured included percentage changes in serum IgG level, anti-dsDNA antibody level (in those who were anti-dsDNA positive [≥30 IU/ml] at baseline), and complement (C3 and C4) levels from baseline. Safety was evaluated by monitoring adverse events (AEs), serious AEs (SAEs), AEs of special interest, vital signs, clinical laboratory test results, and immunogenicity up to 8 weeks posttreatment and throughout the open-label extension phase.

Data analyses. For the double-blind phase, safety analyses were performed on the safety population, defined as all patients who were randomized and treated with at least 1 dose of investigational product. Data on the safety population were summarized according to the treatment the patient was randomized to receive rather than by the treatment that was received, but both were the same for this study. Efficacy analyses were performed on the modified intent-to-treat (ITT) population, defined as the safety population minus those patients who had any assessment at any of 3 study sites that were excluded from the efficacy analyses before the database lock because of potential Good Clinical Practice noncompliance.

For analysis of the primary and 3 key secondary efficacy end points, a step-down sequential testing procedure was used as described in the Supplementary Material. The following subgroup analyses were performed for the primary analysis (SRI–SLEDAI-2K response at week 52): region (US/Canada versus rest of world), baseline SELENA–SLEDAI–SLEDAI-2K score (≤9 versus ≥10), baseline anti-dsDNA antibody level (≥30 IU/ml versus <30 IU/ml), baseline complement levels (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]), and baseline complement and anti-dsDNA antibody levels (≥1 test finding showing low C3/C4 and anti-dsDNA ≥30 IU/ml versus C3/C4 other and anti-dsDNA ≥30 IU/ml). The odds of an SRI–SLEDAI-2K response with belimumab treatment versus placebo were estimated using logistic regression analysis.

For the open-label extension phase, all patients received belimumab, no formal statistical hypothesis t",,"This study investigated the efficacy and safety of belimumab in patients of Black African ancestry with systemic lupus erythematosus (SLE).  Patients were randomized to receive belimumab or placebo for 52 weeks, followed by an optional 6-month open-label extension phase. The primary efficacy endpoint was the SRI–SLEDAI-2K response rate at week 52.  Key secondary endpoints included SRI–SELENA–SLEDAI at week 52, time to first severe SLE flare, and proportion of patients with a reduction in prednisone dose. Renal and biomarker assessments were also conducted.  The study found that belimumab was effective in improving SLE disease activity and reducing renal flares in patients of Black African ancestry."
Emmanuel Chigutsa,First-­in-­Human Study of Bamlanivimab in a Randomized Trial of Hospitalized Patients With COVID-­19,"This first-in-human study in hospitalized patients with COVID-19 was supported by studies assessing in vitro viral neutralization combined with a single-dose non-human primate PK study. The nonclinical safety package to support subsequent studies included tissue cross-reactivity studies on human, rat, and monkey tissues and an in vivo toxicology study.  A complete physical examination was conducted at the screening visit, and one of three bamlanivimab doses or placebo was administered i.v. at the baseline visit (D1) with infusion rates as follows: bamlanivimab 700 mg (50 mL) administered 100 mL/hr for 30 minutes; 2,800 mg (75 mL) administered 100 mL/hr for 45 minutes; and 7,000 mg administered 100 mL/hr for 60 minutes. Placebo infusion was 0.9% normal saline, administered at the same volume and rate as the corresponding bamlanivimab dose cohort. Safety and tolerability were reviewed for sentinel participants up to 24 hours after dosing, at which point the investigators and sponsor team determined whether safety and tolerability were acceptable to continue with dosing subsequent participants. The decision to dose the next cohort was made when all participants from the previous cohort had been dosed and safety data assessed for at least 4 days after the i.v. infusion by the investigators and sponsor team in consultation with an independent safety assessment committee. Blood samples were obtained for assessment of exploratory biomarkers, serology, clinical laboratory assessments, and PD on days 1, 3, 7, 11, 15, 22, and 29, and every 7 days until discharge or day 60, if still an inpatient. Samples for the virology assay were collected using nasopharyngeal (preferred) or mid-turbinate methods. Blood samples obtained for PK analyses were assessed on days 1 (pre-infusion and just before end of infusion), 4, 15, and 29, and follow-up visits up to day 60. Symptom-related physical examinations and assessments of clinical symptoms were performed on days 1, 2, 3, 4, 7, 11, 15, 22, and 29, and the day of discharge from the hospital, with additional follow-up examinations every 7 days thereafter until day 60 if the patient was not discharged from the hospital by day 29. Participants’ clinical status and concurrent procedures of special interest were recorded, including limitation on activities due to COVID-19 and any requirements for the following procedures of special interest, such as ongoing hospital medical care, supplemental oxygen, noninvasive ventilation or a high flow oxygen device, mechanical ventilation, extracorporeal membrane oxygenation, additional organ support, or consciousness status using alert, consciousness, verbal, pain, unresponsive scale. Hospitalization events were recorded, including dates of hospital admission and discharge, admission to the intensive care unit (ICU), discharge from the ICU, and discharge location including to an extended care facility or home. Outcomes The primary objective was to assess safety and tolerability, including adverse events (AEs), serious adverse events (SAEs), and discontinuations due to AEs. Other objectives included PKs (e.g., mean concentration at day 29); PD viral load, area under the response time curve (AUC, from day 1 to day 29), and change from baseline time course; total symptom score; time to symptom resolution; duration of hospitalization; National Institute of Allergy and Infectious Diseases (NIAID), World Health Organization (WHO) scales, and National Early Warning Score (NEWS2); and analysis of viral resistance. Any hypothesis tests were conducted for treatment comparisons without adjustment for multiplicity except for the evaluation of treatment effect on endogenous antibody titers. Success for the trial was claimed using a Bayesian criterion if any of the 3 bamlanivimab doses had at least 60% probability to reduce at least 30% mean AUC (28-day viral load) over placebo.",,"This first-in-human study evaluated the safety, tolerability, pharmacokinetics, clinical course, and viral dynamics of bamlanivimab, a fully human neutralizing monoclonal antibody targeting SARS-CoV-2, in hospitalized patients with moderate to severe COVID-19.  The study found bamlanivimab to be safe and well-tolerated, with no serious adverse events or deaths reported.  Further research is needed to determine the efficacy of bamlanivimab in treating COVID-19."
Eric-Juwei Cheng,Deep Sparse Representation Classifier for Facial Recognition  and Detection System,"This paper proposes a two-layer Convolutional Neural Network (CNN) to learn the high-level features which utilizes to the face identification via sparse representation. Feature extraction plays a vital role in real-world pattern recognition and classification tasks. The details description of the given input face image, significantly improve the performance of the facial recognition system. Sparse Representation Classifier (SRC) is a popular face classifier that sparsely represents the face image by a subset of training data, which is known as insensitive to the choice of feature space. The proposed method shows the performance improvement of SRC via a precisely selected feature exactor. The experimental results show that the proposed method outperform other methods on given datasets.","Sparse Feature Extraction, Convolutional neural network, Deep learning, CNN, Sparse representation classifier, Face recognition, Support Vector Machines, Feature extraction","This paper presents a robust face recognition framework based on the combination of sparse feature extraction using Convolutional Neural Networks (CNNs) and Support Vector Machines (SVMs). The proposed framework is evaluated on four widely used face datasets, including Extended YALE B database, AR database, MIT faces database, and ORL faces database. The experimental results show that the proposed framework outperforms the state-of-the-art methods in terms of recognition rate."
Escalona & Koch,Characterizing relatedness of web and requirements engineering,"Web and Requirements Engineering have been well-recognized as two individual active areas of research in the past. Convergence between these two notable areas has been a point-of-discussion in recent years and offers new avenues of research. This paper explores this alliance from two perspectives; firstly, where Requirement Engineering can be viewed as a process for Web application development as it primarily concerns with adapting the Requirement Engineering process to the Web applications which are special in characteristics as compared to traditional software applications and secondly, where Web can be viewed as a supporting technology for improving the requirements engineering process and enabling new capabilities.","Web Applications, Web 3.0, Web 2.0, SWOT Analysis, Web application, Requirements engineering","The paper explores the relationship between Web and Requirements Engineering from two perspectives, highlighting the need for a more extensive and efficient Requirements Engineering process for Web applications, and the potential of Web technologies to support and improve the requirements engineering process."
Esha Baidya Kayal,"Development of Novel Imaging-Based Methods for Evaluating Chemotherapy Response in Osteosarcoma ||| Magnetic Resonance Materials in Physics, Biology and Medicine","Osteosarcoma is the most common bone sarcoma and the third most common malignancy in children and adolescents with high morbidity and mortality. Early evaluation of chemotherapy response may help to prevent the patients from undergoing ineffective chemotherapy regimen, reducing side-effects, saving treatment time, cost and may improve patient management through personalized therapeutic options. ||| Objective  To implement an advanced spatial penalty-based reconstruction to constrain the intravoxel incoherent motion (IVIM)–diffusion kurtosis imaging (DKI) model and investigate whether it provides a suitable alternative at 1.5 T to the traditional IVIM–DKI model at 3 T for clinical characterization of prostate cancer (PCa) and benign prostatic hyperplasia (BPH).","TV penalty function, Prostate cancer, Benign prostatic hyperplasia, Total variation penalty function, Osteosarcoma, Image Analysis, MRI, Diffusion kurtosis imaging, Intravoxel incoherent motion, Chemotherapy, IVIM, IVIM–DKI model","The goal of this PhD thesis was to investigate the role of non-invasive imaging-based markers for monitoring and evaluating early therapeutic response in patients with osteosarcoma receiving neoadjuvant chemotherapy using Intravoxel incoherent motion (IVIM) and mutli-parametric MRI analysis. ||| This study compares the use of IVIM–DKI at 1.5 T and 3 T MRI for differentiating between prostate cancer and benign prostatic hyperplasia. The results show that IVIM–DKI modeled with a novel model at 1.5 T produced parameter maps with lower coefficient of variation than the traditional model at 3 T. The novel model estimated higher D with lower D*, f, and k values at both field strengths compared to the traditional model. The study concludes that the proposed novel model can be utilized for improved detection of prostate lesions."
Eshwar kuncham,Lateral Response Reduction of Tall Buildings Using Portal Frame as TMD,"Majority of construction industries are aiming to go for taller and lighter buildings which may result in flexible and slender structures. Hence serviceability and safety become a critical issue during the occurrence of heavy winds and high magnitude earthquakes. Therefore, considerable techniques are adopted to minimize the vibrations caused by these natural responses of the structures. One of the techniques used prominently for tall structures is Tuned Mass Damper (TMD). TMD’s have been very effective in controlling structural vibrations. This study proposes a detailed analysis of a 2D frame structure with a TMD system placed at different levels of the structure in order to evaluate the behaviour of structure for given earthquake ground motions. The results obtained indicate installation of simple frames can decrease the response of the structure during an earthquake and location of TMD is also discussed in detail.","Lateral Response, damping, vibration control, Dynamic Analysis, TMD, Tall Buildings, tuned mass damper",The study presents a numerical modeling and analysis of a 15-storey structure with a TMD installed on the top. The TMD is designed to be tuned to the same natural frequency of the building and is installed on different floors of the building. The study investigates the effectiveness of the TMD in reducing the dynamic response of the building under various excitations.
Essam Said Hanandeh,Hybrid Harmony Search Algorithm to Solve the Feature Selection for Data Mining Applications,"The increasing size of all sorts text and data information on websites makes the method of text clustering (TC) a lot more complicated. The TC technique is employed to cluster an enormous variety of documents into a set of intelligible and connected clusters. Usually, TC is employed in several domains like text mining, data processing, pattern recognition, image clustering.","Hybrid Harmony Search Algorithm, Vector Space Model, Feature Selection, Text Clustering, Data Mining, Data Mining Applications","This paper proposes a hybrid harmony search algorithm to solve the feature selection problem for data mining applications. The algorithm uses the harmony search rule to select and obtain a new set of informative knowledge features, reducing the runtime of the system and decreasing the uninformative knowledge feature. The results show that the proposed modification of the harmony search rule enriched the performance value of the feature choice method in regard to the correct set, owing to its fine features."
Eung-Sun Kim,Bandwidth-Efﬁcient OFDM transmission with iterative cyclic preﬁx reconstruction,"Abstract—Orthogonal frequency division multiplexing (OFDM) systems are now a part of all major wireless standards, because of its potential to offer high data rate. Cyclic prefix (CP) in OFDM system converts a multipath channel to a flat fading channel, thus simplifies the design of equalizer. However, there is a lot of ambiguity in choosing the length of CP. In this paper, we propose a new method for calculation of length of CP using cumulant features. The merits of proposed method are verified by computer simulation.","bandwidth efﬁciency, OFDM, channel length estimation, cumulant features, Orthogonal frequency division multiplexing (OFDM), Cyclic prefix (CP), cyclic preﬁx, Blind channel length estimation","This paper proposes a novel method for blind channel length estimation in OFDM systems using cumulant features. The proposed method is well-suited for dynamic spectrum access (DSA) setups and does not require pilot or training sequences, thus saving bandwidth. The method is based on exploiting the properties of nth order cumulant features and is verified by computer simulation."
Evgeny Kostuchenko,Generation of an EDS Key Based on a Graphic Image of a Subject’s Face Using the RC4 Algorithm,"Modern facial recognition algorithms make it possible to identify system users by their appearance with a high level of accuracy. In such cases, an image of the user’s face is converted to parameters that later are used in a recognition process. On the other hand, the obtained parameters can be used as data for pseudo-random number generators. However, the closeness of the sequence generated by such a generator to a truly random one is questionable. This paper proposes a system which is able to authenticate users by their face, and generate pseudo-random values based on the facial image that will later serve to generate an encryption key. The generator of a random value was tested with the NIST Statistical Test Suite. The subsystem of image recognition was also tested under various conditions of taking the image. The test results of the random value generator show a satisfactory level of randomness, i.e., an average of 0.47 random generation (NIST test), with 95% accuracy of the system as a whole.","random number generation, digital signatures, authenticity, neural networks, digital signature, python, NIST test battery, computer vision, programming, algorithms, cryptography, facial recognition, security","This paper proposes a system for authenticating users by their face and generating pseudo-random values based on facial images. The system uses a combination of mathematical procedures for facial recognition and a pseudo-random number generator. The generator of a random value was tested with the NIST Statistical Test Suite, and the subsystem of image recognition was tested under various conditions of taking the image. The test results show a satisfactory level of randomness and 95% accuracy of the system as a whole."
F. Benevenuto,Cost Eﬀective Inﬂuence Maximisation,"In the context of virality prediction, many researchers have leveraged the existence of a core-periphery structure in a network to identify the super-spreaders of information. Topologically, the nodes in the core of a network are the most eﬃcient spreaders. However, these nodes are less susceptible, i.e., unlikely to be inﬂuenced by the periphery nodes. Consequently, large payoﬀs are required to market information (ideas, products, memes, etc.) via them. In this paper, we show the presence of several non-core nodes whose spreading power is close to that of the core nodes.","Virality, Inﬂuence maximisation, Information diﬀusion, cost-effective, Core-periphery structure, information diffusion, social networks, influence maximisation","This paper proposes a cost-eﬀective strategy to make a meme reach the super-spreaders without the need for global information. The proposed hill-climbing based strategy can be eﬀectively used with both, global as well as local characteristics of the nodes in a network. In terms of the cost metric, it outperforms the conventional independent cascade model by more than 5 times for the core and 2 times for the non-core super-spreaders."
F. Luthon,Unique Local Features in Lip Images for Recognition,"The experiments are carried out from images taken with a camera that is used for the regular use. And the color features of a lip are not explored in the proposed research. Still the recognition system exploits the grayscale local features of a lip images and eﬃciently matches it with local features of another lip image. If the color properties of a lip image is explored for recognition along with local features, the accuracy values would increase further.","grayscale features, Lip Pattern Recognition, SIFT, lip recognition, color features, Biometric, Local Feature Extraction, local features, SURF",The paper presents the results of experiments on lip recognition using local features. The recognition system exploits the grayscale local features of lip images and achieves high accuracy. The authors suggest that exploring color properties of lip images could further improve the accuracy.
FAO,Agriculture Extension System in India: A Meta-analysis,"Agriculture extension system bridges the gap between research labs to a farmer’s field. Agricultural research, education and extension are said to be the most critical for promoting farm productivity and enhancing farmer’s income. The public sector is major extension service provider and the reach of the public extension is limited in India and in addition it is burdened with non-extension responsibilities such as the distribution of subsidies and inputs, with little time left to attend to core extension activities.","Investment, Extension approaches, Farmers Producers' Organizations, India, Agriculture extension, Meta analysis, ICT, Manpower","The article reviews the agricultural extension system in India to suggest pathways for better extension system in India. The public extension services are highly skewed towards crop husbandry ignoring allied sectors in India. The growth in the High-Value Agriculture sector has been twice or sometimes even thrice that of the crop production. However, Agriculture extension services for such sectors almost nil or unorganized."
Faisal Alam,Power Optimization Strategy for Android Applications,"Energy efficiency is a critical factor in mobile systems, and a significant body of recent research efforts has focused on reducing the energy dissipation in mobile hardware and applications. The Android OS Power Manager provides programming interface routines called wakelocks for controlling the activation state of devices on a mobile system.","Data Flow Analysis, Android, Wakelock Placement, Power Optimization, Mobile Systems, Energy Optimization",This paper proposes a data flow analysis based strategy for determining the placement of wakelock statements corresponding to the uses of devices in an application. The proposed optimization strategy shows significant (up to 32%) energy savings with experimental evaluation on a set of Android applications.
Faisal Bashir,A Dynamic Congestion Control Scheme for safety applications in vehicular ad hoc networks,"In recent years, various types of applications have emerged from Vehicular Ad hoc Networks (VANETs) for safety, infotainment, rescue and security purposes. Safety applications have their own strict communication requirements, and they require reliable and timely data communication within networks. Due to a variety of network applications, safety applications have been negatively impacted by communication channel congestion issues. Channel congestion leads to packet loss, delay and unreliability issues, and has a serious impact on vehicular traffic, including road accidents, road jams, and wrong traffic decisions. In addressing these issues, this paper's authors have proposed a Dynamic Congestion Control Scheme (DCCS) as a means of reliable and timely data delivery, in safety applications. The proposed scheme is designed for communication channels, as a means of broadcasting safety messages, and to ensure the reliable and timely delivery of messages to all neighbours in a network. The DCCS scheme is designed for inter-vehicle communication, without fixed infrastructure. Comprehensive simulation is conducted, in order to evaluate the performance of a proposed scheme, and to compare it with other state of the art schemes.","Congestion Control, Mobility, Transmit Power Control, MAC Blocking, Safety, Measurement-Based Detection, Urban, VANETs, Congestion, Communication, Vehicular, Control, Broadcasting, Queue Freezing",This paper proposes a Dynamic Congestion Control Scheme (DCCS) for safety applications in Vehicular Ad hoc Networks (VANETs). The scheme detects congestion and controls it by exploiting existing network resources for road traffic safety and cum security. The main objectives of this research are to determine whether a congestion detection scheme will reduce congestion by using realistic weighting factors and whether a congestion control scheme can control congestion through message originated-based queue freezing.
Farhan Jalees Ahmad,Wound Healing Potential of Raloxifene Nanoemulsion Gel for the Management of Postmenopausal Cutaneous Wounds,"Background: Depletion in estrogen level(s) especially in postmenopausal women is reported to have delayed wound healing effects; hence we have evaluated the wound healing potential of raloxifene in rat model. Objectives: Investigating the wound healing effects of raloxifene nanoemulsion for the management of postmenopausal cutaneous wounds. Materials and Methods: The optimized nanoemulsion gel contains 0.072% raloxifene hydrochloride. Female Wistar rats were used to investigate its wound healing effects. After three months of ovariectomy, wound healing effect was observed in terms of breaking strength, tensile strength, area of wound contraction, wound closure time, hydroxyproline content and histopathological changes. Results: The nanoemulsion gel exhibited better retention (34.31%) than its nanoemulsion. The raloxifene nanoemulsion gel has no erythema and no eschar formation recorded, and it is safe for topical use. In the incision wound model in ovariectomized rats, breaking (898±25g) and tensile strengths (4.47±0.12 g/mm2) in raloxifene treated groups were found to be higher than the untreated control group. Additionally, in ovariectomized rats, wound contraction was found to be 100% in the treated group s following 20 days of post-wounding, where as in control group only 88% was contraction was observed. Also, more hydroxyproline content in raloxifene treated ovariectomized rat was observed that recommend more collagen content than the untreated ovariectomized rat but approximately similar effects to untreated non-ovariectomized rats. Histopathological studies confirmed that the raloxifene treated groups had more re-epithelialization, neo-vascularization, fibroblast proliferation, and collagen deposition than the control group. Conclusion: These results confirms that the raloxifene nanoemulsion gel has significant wound healing potential, as observed in ovariectomized rats, which will be helpful in postmenopausal cutaneous wound healing.","Raloxifene, Histopathology, Ovariectomized, Hydroxyproline, Wound contraction, Postmenopausal Cutaneous Wounds, Postmenopausal, Breaking strength, Nanoemulsion gel, Wound Healing","This study investigates the wound healing potential of raloxifene nanoemulsion gel in postmenopausal cutaneous wounds. The results show that the nanoemulsion gel has significant wound healing potential, as observed in ovariectomized rats, and is safe for topical use. The study suggests that raloxifene nanoemulsion gel can be a good alternative for wound healing in postmenopausal women."
Fariha Afsana,"Toward a Heterogeneous Mist, Fog, and Cloud-Based Framework for the Internet of Healthcare Things","Rapid developments in the fields of information and communication technology and microelectronics allowed seamless interconnection among various devices letting them to communicate with each other. This technological integration opened up new possibilities in many disciplines including healthcare and well-being. With the aim of reducing healthcare costs and providing improved and reliable services, several healthcare frameworks based on Internet of Healthcare Things (IoHT) have been developed. However, due to the critical and heterogeneous nature of healthcare data, maintaining high quality of service (QoS)—in terms of faster responsiveness and data-specific complex analytics—has always been the main challenge in designing such systems. Addressing these issues, this paper proposes a five-layered heterogeneous mist, fog, and cloud-based IoHT framework capable of efficiently handling and routing (near-)real-time as well as offline/batch mode data. Also, by employing software defined networking and link adaptation-based load balancing, the framework ensures optimal resource allocation and efficient resource utilization. The results, obtained by simulating the framework, indicate that the designed network via its various components can achieve high QoS, with reduced end-to-end latency and packet drop rate, which is essential for developing next generation e-healthcare systems.","QoS, healthcare big data, load balancing, healthcare application, healthcare, e-healthcare, IoHT, fog computing, quality of service (QoS), reduced latency, IoT, mist computing, Data fusion, cloud computing, heterogeneous framework, low power consumption, real-time computing, resource allocation","This paper proposes a five-layered heterogeneous mist, fog, and cloud-based Internet of Healthcare Things (IoHT) framework to efficiently handle and route healthcare data. The framework employs software defined networking and link adaptation-based load balancing to ensure optimal resource allocation and efficient resource utilization. The results show that the designed network can achieve high quality of service with reduced latency and packet drop rate, making it essential for developing next generation e-healthcare systems."
Fei Kang,Memetic search in artiﬁcial bee colony algorithm,"Artiﬁcial bee colony (ABC) optimization algorithm is relatively a simple and recent population based probabilistic approach for global optimization. ABC has been outperformed over some Nature Inspired Algorithms (NIAs) when tested over benchmark as well as real world optimization problems. The solution search equation of ABC is signiﬁcantly inﬂuenced by a random quantity which helps in exploration at the cost of exploitation of the search space. In the solution search equation of ABC, there is a enough chance to skip the true solution due to large step size. In order to balance between diversity and con-vergence capability of the ABC, a new local search phase is integrated with the basic ABC to exploit the search space identiﬁed by the best individual in the swarm. In the proposed phase, ABC works as a local search algorithm in which, the step size that is required to update the best solution, is controlled by Golden Section Search approach. The proposed strategy is named as Memetic ABC (MeABC). In MeABC, new solutions are generated around the best solution and it helps to enhance the exploitation capability of ABC. MeABC is established as a modiﬁed ABC algorithm through experiments over 20 test problems of different complexities and 4 well known engineering optimization problems.","Exploration-exploitation, Swarm intelligence, Memetic algorithm, Memetic Search, Honey Bees, Artiﬁcial bee colony","This paper proposes a new local search strategy, Memetic ABC (MeABC), which integrates a Golden Section Search approach with the basic Artificial Bee Colony (ABC) algorithm to balance exploration and exploitation behavior. MeABC is established as a modified ABC algorithm through experiments over 20 test problems and 4 engineering optimization problems."
Felix et al.,Typeface size and weight and word location inüluence on relative size judgments in tag clouds,"This paper focuses on viewers’ perception of the relative size of words presented in tag clouds. Tag clouds are a type of visualization that displays the contents of a document as a cluster (cloud) of key words (tags) with frequency (importance) indicated by tag word features such as size or color, with variation of size within a tag cloud being the most common indicator of tag importance. Prior studies have shown that word size is the most inüluential factor of tag importance and tag memory. Systematic biases in relative size perception in tag clouds are therefore likely to have important implications for viewer understanding of tag cloud visualizations.","layout, typeface size, size judgment, perception, psychophysics, perceptual biases, tag cloud, search tasks, tag clouds","The study focuses on documenting systematic biases in relative size judgment in tag clouds while varying typeface weight and the location of the target tag word pair under comparison. The results provide a first report of systematic biases in relative size judgment in tag clouds, suggest that simple power-law scaling models developed for simple displays containing 1-2 objects on a blank background, may be applicable to relative size judgments in complex tag clouds."
Fernando Calamante,"Magnetic Resonance Materials in Physics, Biology and Medicine",Objective  To implement an advanced spatial penalty-based reconstruction to constrain the intravoxel incoherent motion (IVIM)–diffusion kurtosis imaging (DKI) model and investigate whether it provides a suitable alternative at 1.5 T to the traditional IVIM–DKI model at 3 T for clinical characterization of prostate cancer (PCa) and benign prostatic hyperplasia (BPH).,"TV penalty function, Prostate cancer, Benign prostatic hyperplasia, Total variation penalty function, MRI, Diffusion kurtosis imaging, Intravoxel incoherent motion, IVIM–DKI model","This study compares the use of IVIM–DKI at 1.5 T and 3 T MRI for differentiating between prostate cancer and benign prostatic hyperplasia. The results show that IVIM–DKI modeled with a novel model at 1.5 T produced parameter maps with lower coefficient of variation than the traditional model at 3 T. The novel model estimated higher D with lower D*, f, and k values at both field strengths compared to the traditional model. The study concludes that the proposed novel model can be utilized for improved detection of prostate lesions."
"Flores-Sintas, J. M., et al. (1999)",Quantum-inspired evolutionary approach for selection of optimal parameters of fuzzy clustering,"Recently, Fuzzy c-Means (FCM) algorithm is most widely used because of its efficiency and simplicity. However, FCM is sensitive to the initialization of fuzziness factor (m) and the number of clusters (c) due to which it easily trapped in local optima. A selection of these parameters is a critical issue because an adverse selection can blur the clusters in the data.","Fuzzy clustering, Cluster validity index, Quantum-Inspired Evolutionary Fuzzy c-Means, Fuzzy c-Means algorithm, Fuzzy c-Means, Quantum computing","This paper proposes a hybrid fuzzy clustering algorithm, Quantum-Inspired Evolutionary Fuzzy c-Means (QIE–FCM), which uses the merits of quantum computing for finding the global optimal value of m and its corresponding value of c in the FCM. The proposed approach improves the way of initialization of the fuzziness factor (m) in the FCM and provides the diversity in selecting the optimal value of m and c from a large quantum search space."
Florian C Kurschus,Myelin-speciﬁc T cells also recognize neuronal autoantigen in a transgenic mouse model of multiple sclerosis,"We describe here the paradoxical development of spontaneous experimental autoimmune encephalomyelitis (EAE) in transgenic mice expressing a myelin oligodendrocyte glycoprotein (MOG)-speciﬁc T cell antigen receptor (TCR) in the absence of MOG. We report that in Mog-deﬁcient mice (Mog–/–), the autoimmune response by transgenic T cells is redirected to a neuronal cytoskeletal self antigen, neuroﬁlament-M (NF-M). Although components of radically different protein classes, the cross-reacting major histocompatibility complex I-Ab–restricted epitope sequences of MOG35–55 and NF-M18–30 share essential TCR contact positions. This pattern of cross-reaction is not speciﬁc to the transgenic TCR but is also commonly seen in MOG35–55–I-Ab–reactive T cells. We propose that in the C57BL/6 mouse, MOG and NF-M response components add up to overcome the general resistance of this strain to experimental induction of autoimmunity. Similar cumulative responses against more than one autoantigen may have a role in spontaneously developing human autoimmune diseases.",,"This study reports the unexpected finding that transgenic mice expressing a myelin oligodendrocyte glycoprotein (MOG)-specific T cell receptor (TCR) develop spontaneous experimental autoimmune encephalomyelitis (EAE) even in the absence of MOG. The researchers discovered that these mice redirect their autoimmune response to a neuronal cytoskeletal protein called neuroﬁlament-M (NF-M). This cross-reactivity between MOG and NF-M is mediated by shared TCR contact positions on their respective epitope sequences. The study suggests that cumulative responses against multiple autoantigens, such as MOG and NF-M, may contribute to the development of spontaneous autoimmune diseases in humans."
Foster et al,A Spectral Learning Based Model to Evaluate Semantic Textual Similarity,"Semantic Textual Similarity (STS) is a task in NLP that compares two sentences in a sentence-pair and scores the relationship between them using the degree of semantic equivalence. It has wide applicability in various fields. Consequently, the research around the task is constantly evolving. The demand for new as well as improved methods is endless. Numerous methods have been proposed that largely belong to either unsupervised or supervised learning approaches. The model proposed here is fairly simple and provides a fresh take on this classification problem using spectral learning. The model does not engage a large labeled corpus or lexical database like most STS supervised and unsupervised methods. Although, supervised STS methods achieve an accuracy that outperforms humans in some cases, but are often held back due to a lack of interpretation of the features instrumental in molding the decision-making process. The proposed model on the other hand generates features (latent knowledge) that are easy to ascertain and have a mathematical foundation. Given a sentence pair, the work focuses on finding latent states and variables from each sentence and performs classification by generating a similarity score. The latent variables are a result of projections learned by performing Canonical Correlation Analysis (CCA) amongst the sentence pair. To perform matching and determine the similarity score, Cosine similarity and Word Mover’s Distance (WMD) are employed. The performance of the proposed model does exhibit an improvement over various sophisticated supervised techniques such as LSTM and BiLSTM.","Natural Language Processing, Hidden Variables, Canonical Correlation Analysis, Word Mover’s Distance, Semantic Textual Similarity, Latent Variables, Latent State, Hidden state, Spectral Learning",This study aims to design a structure that can not only generate and evaluate latent/semantic components but also elevate their part in the learning process. The proposed model is a spectral learning based model that uses Canonical Correlation Analysis (CCA) to estimate the latent state from each sentence and employs Cosine Similarity and Word Mover’s Distance (WMD) to output a similarity score. The model does not require a large labeled dataset and is particularly suited for settings where labeled data is scarce. The process of learning the latent state from a sentence pair is transparent and has a mathematical grounding.
Frank H¨oppner,What are Clusters in High Dimensions and are they Difﬁcult to Find?,"This paper discusses clustering in high dimensions, including hierarchical clustering, prototype-based clustering, fuzzy k-means clustering, Gaussian mixture models, and subspace clustering. It also touches on the challenges of clustering high-dimensional data and provides examples of applications where high-dimensional data is relevant.","hierarchical clustering, fuzzy k-means clustering, subspace clustering, Gaussian mixture models, hubness phenomenon, cluster analysis, clustering, high dimensions, concentration of norm, prototype-based clustering, high-dimensional data","This paper investigates consequences that the special properties of high-dimensional data have for cluster analysis. We discuss questions like when clustering in high dimensions is meaningful at all, can the clusters just be artifacts and what are the algorithmic problems for clustering methods in high dimensions."
Frank Klawonn,What are Clusters in High Dimensions and are they Difﬁcult to Find?,"This paper discusses clustering in high dimensions, including hierarchical clustering, prototype-based clustering, fuzzy k-means clustering, Gaussian mixture models, and subspace clustering. It also touches on the challenges of clustering high-dimensional data and provides examples of applications where high-dimensional data is relevant.","hierarchical clustering, fuzzy k-means clustering, subspace clustering, Gaussian mixture models, hubness phenomenon, cluster analysis, clustering, high dimensions, concentration of norm, prototype-based clustering, high-dimensional data","This paper investigates consequences that the special properties of high-dimensional data have for cluster analysis. We discuss questions like when clustering in high dimensions is meaningful at all, can the clusters just be artifacts and what are the algorithmic problems for clustering methods in high dimensions."
Fraser,Fifty years of peephole optimization,"Peephole optimization is a technique used in compilers to improve the performance of object programs by replacing sequences of instructions with equivalent single instructions. This article reviews the history and development of peephole optimization, including its application to various programming languages and target machines.","compilers, object programs, peephole optimization, Code generators, instruction sequences, replacement rules","Peephole optimization has been widely used in compilers to improve the performance of object programs. The technique involves replacing sequences of instructions with equivalent single instructions, and has been applied to various programming languages and target machines. The effectiveness of peephole optimization depends on several factors, including the nature of the source language, the parsing and code generation techniques used in the compiler, and the specifications of the target machine."
Freeman,Rumour Source Detection Using Game Theory,"Social networks have become a critical part of our lives as they enable us to interact with a lot of people. These networks have become the main sources for creating, sharing and also extracting information regarding various subjects. But all this information may not be true and may contain a lot of unverified rumours that have the potential of spreading incorrect information to the masses, which may even lead to situations of widespread panic. Thus, it is of great importance to identify those nodes and edges that play a crucial role in a network in order to find the most influential sources of rumour spreading. Generally, the basic idea is to classify the nodes and edges in a network with the highest criticality. Most of the existing work regarding the same focuses on using simple centrality measures which focus on the individual contribution of a node in a network. Game-theoretic approaches such as Shapley Value (SV) algorithms suggest that individual marginal contribution should be measured for a given player as the weighted average marginal increase in the yield of any coalition that this player might join. For our experiment, we have played five SV-based games to find the top 10 most influential nodes on three network datasets (Enron, USAir97 and Les Misérables). We have compared our results to the ones obtained by using primitive centrality measures. Our results show that SV-based approach is better at understanding the marginal contribution, and therefore the actual influence, of each node to the entire network.","influential nodes, Jaccard Similarity Coefficient, cooperative game, Rumour Source Detection (RSD), centrality measures, network analysis, Shapley Value (SV), Game-Theory, Network Centrality",This paper aims to identify the most influential nodes in a network that are the primary sources of rumour propagation. The authors propose a game-theoretic approach using the Shapley Value algorithm to find the most influential nodes. They compare their results with primitive centrality measures and show that the SV-based approach is better at understanding the marginal contribution of each node to the entire network.
G. C. Reinsel,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
G. Dhanalekshmi,An efficient prefix based labelling scheme for dynamic update of XML ||| LPLX-lexicographic-based persistent labelling scheme of XML documents,"The increasing volume of XML documents and the real-world requirement to support the updations has motivated the research community to develop dynamic labelling schemes. Each of the dynamic labelling schemes proposed till date differs in characteristics and has its own advantages and limitations. They may differ in terms of the query supported, their update performance, label size, etc. In this paper, a new prefix based labelling scheme is proposed which is compact, dynamic. And it also facilitates the computation of structural relationships which is the core part of query processing. The proposed scheme can handle both static as well as dynamic XML documents. The experimentation is conducted to evaluate the performance of storage requirement, structural relationship computation and update processing. The result is compared with some of the existing labelling mechanisms. ||| The increasing number of XML documents over the internet motivated us to develop indexing techniques to retrieve the XML data efficiently. Assigning unique labels to each node and determining the structural relationships is a critical problem in XML query processing. Labelling schemes designed for static XML documents will not support dynamic updates on XML documents. Some dynamic labelling schemes provide dynamic updates but, with a high cost and complexity. In this paper we propose a labelling scheme which supports the dynamic update without relabelling the existing nodes. It also determines the structural relationships efficiently by looking at the labels. A set of performance tests is carried to compute the time required to generate unique labels.","XML, XML documents, persistent labelling scheme, dynamic updates, ancestor-descendant relationship, dynamic update, ancestor-descendant, label size, structural relationships, parent-child relationship, tree traversal, sibling relation, XPath, structural relationship, prefix-based, collision avoidance, labelling scheme, labelling time, lexicographic order, XML query processing","This paper proposes a new prefix based labelling scheme for dynamic update of XML documents. The scheme is compact, dynamic, and facilitates the computation of structural relationships. It can handle both static and dynamic XML documents and has been evaluated for its performance in storage requirement, structural relationship computation, and update processing. ||| This paper proposes a new labelling scheme, lexicographic-based persistent labelling (LPLX) scheme, which assigns a unique label in lexicographical order to each node in the XML tree with the tuple format (prefix, level, selfcode). The LPLX supports dynamic update of XML documents without relabelling the existing nodes and computes the structural relationships such as ancestor-descendant, parent-child and siblings at constant time."
G. E. Box,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
G. Karabatis,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
G. Kole,YASS: Yet Another Suﬃx Stripper,"This paper presents a set of string distance measures for clustering the lexicon. The main intuition behind defining these distances was to reward long matching prefixes, and to penalize an early mismatch.","string distance measures, morphological variants, information retrieval, resource-poor languages, clustering, lexicon clustering, Bengali language, equivalence classes, stemming","The paper proposes a set of string distance measures for clustering words into homogeneous groups, with the goal of representing an equivalence class consisting of morphological variants of a single root word."
G. M. Jenkins,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
G. Panda,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
G. Polepally,Comparison of Different Types of Pylon in Cable-Stayed Bridges,This study discusses the key design considerations for cable-stayed bridges under gravity loads and earthquake loads. A numerical model of a cable-stayed bridge is formulated for single plane of cables with global coordinates for bridges having different pylon shapes.,"Pylon shape, cable-stayed bridges, Time history analysis, Quincy Bay view bridge, Cable-stayed bridge, earthquake loads, gravity loads, numerical model",The study focuses on the design considerations for cable-stayed bridges under various loads and presents a numerical model for single plane of cables with global coordinates for bridges with different pylon shapes.
G. Raghava Rao,Detection of Financial Statement Fraud Using Data Mining Techniques,"Recently, high profile cases of financial statement fraud have been dominating the news. This paper uses data mining techniques such as Multilayer Feed Forward Neural Network (MLFF), Support Vector Machines (SVM), Genetic Programming (GP), Group Method of Data Handling (GMDH), Logistic Regression (LR), and Probabilistic Neural Network (PNN) to identify companies that resort to financial statement fraud. Each of these techniques is tested on a dataset involving 202 Chinese companies and compared with and without feature selection. PNN outperformed all the techniques without feature selection, and GP and PNN outperformed others with feature selection and with marginally equal accuracies.","Data mining, artificial intelligence, SVM, Feature selection, GP, financial statement fraud, fraud detection, Financial fraud detection, Neural networks, t-statistic","This paper uses data mining techniques to identify companies that resort to financial statement fraud. The techniques used include Multilayer Feed Forward Neural Network (MLFF), Support Vector Machines (SVM), Genetic Programming (GP), Group Method of Data Handling (GMDH), Logistic Regression (LR), and Probabilistic Neural Network (PNN). The results show that PNN outperformed all the techniques without feature selection, and GP and PNN outperformed others with feature selection and with marginally equal accuracies."
G. Sahoo,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
G. Song,Cost Eﬀective Inﬂuence Maximisation,"In the context of virality prediction, many researchers have leveraged the existence of a core-periphery structure in a network to identify the super-spreaders of information. Topologically, the nodes in the core of a network are the most eﬃcient spreaders. However, these nodes are less susceptible, i.e., unlikely to be inﬂuenced by the periphery nodes. Consequently, large payoﬀs are required to market information (ideas, products, memes, etc.) via them. In this paper, we show the presence of several non-core nodes whose spreading power is close to that of the core nodes.","Virality, Inﬂuence maximisation, Information diﬀusion, cost-effective, Core-periphery structure, information diffusion, social networks, influence maximisation","This paper proposes a cost-eﬀective strategy to make a meme reach the super-spreaders without the need for global information. The proposed hill-climbing based strategy can be eﬀectively used with both, global as well as local characteristics of the nodes in a network. In terms of the cost metric, it outperforms the conventional independent cascade model by more than 5 times for the core and 2 times for the non-core super-spreaders."
G. Sridharan Reddy,Machine Learning Techniques Applied to Profile Mobile Banking Users in India,"This paper profiles mobile banking users using machine learning techniques viz. Decision Tree, Logistic Regression, Multilayer Perceptron, and SVM to test a research model with fourteen independent variables and a dependent variable (adoption). A survey was conducted and the results were analysed using these techniques. Using Decision Trees the profile of the mobile banking adopter’s profile was identified. Comparing different machine learning techniques it was found that Decision Trees outperformed the Logistic Regression and Multilayer Perceptron and SVM. Out of all the techniques, Decision Tree is recommended for profiling studies because apart from obtaining high accurate results, it also yields ‘if–then’ classification rules. The classification rules provided here can be used to target potential customers to adopt mobile banking by offering them appropriate incentives.","Machine Learning, Logistic Regression, Multilayer Perceptron, Mobile Banking User Profiles, Decision Tree","This paper studies the various factors that affect the intention of users to adopt mobile banking. The major influential factors have been identified through literature, and a survey was conducted with two hundred respondents in the Indian context. The paper analyses the survey data through the use of machine learning techniques to arrive at the most important and critical success factors that influences the adoption of mobile."
G. Xu,Iris Detection,"For iris boundary detection, circular summation of intensity approach is used as proposed in [5]. The original grayscale image is blurred using median filter to remove external noise. After filtering, the contrast of image is enhanced to have sharp variation at image boundaries using histogram equalisation as shown in Figure 5(a). This contrast enhanced image is used for finding the outer iris boundary by drawing concentric circles (Figure 5(b) shows an example) of different radii from the pupil center and the intensities lying over the perimeter of the circle are summed up.","Adaptive Threshold, Circular Hough Transform, Spectrum Image, histogram equalisation, iris recognition, circular summation of intensity, Connected Components, Iris detection, pupil boundary, Iris Segmentation",The proposed system has been tested on two publicly available databases BATH and CASIA V3. From experimental analysis it has been observed that the system is capable of handling unconstrained scenarios as well. The system is capable of performing segmentation for unconstrained scenarios in significantly less time compared to Hough transform.
G.Krishna Kishore,An Efficient Trusted Computing Base for Routing in MANET’s,"This paper seeks a set of fixed functionality suitable for securing MANETs. We deliberately impose some restrictions on such fixed functionality to ensure that TMMs which offer such functionality can be easily verified, will consume negligible power, and thus can be simultaneously trustworthy and inexpensive to realize.","TMM, TCG, trustworthy modules, MANET, TCB, TMMs, AODE, MANETs","The paper proposes a simple and efficient TCB for MANET nodes which can be leveraged to improve the performance of MANETs by providing assurances that reduce the scope of attacks that can be launched by attackers, and by reducing the overhead required for leveraging the TCB."
G.P. Zhang,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
G.Rama Murthy,Understanding Helicoverpa armigera Pest Population Dynamics related to Chickpea Crop Using Neural Networks,Insect pests are a major cause of crop loss globally. Pest management will be effective and efficient if we can predict the occurrence of peak activities of a given pest. Research efforts are going on to understand the pest dynamics by applying analytical and other techniques on pest surveillance data sets. In this study we make an effort to understand pest population dynamics using Neural Networks by analyzing  pest surveillance data set of Helicoverpa armigera or Pod borer on chickpea (Cicer arietinum L.)  crop. The results show that neural network method successfully predicts the pest attack incidences for one week in advance.,"Climatic Data, Pest Population Dynamics, Neural Networks, Pest Surveillance Databases, Chickpea Crop, Helicoverpa armigera, Neural Network, Pest Attack Prediction","The experimental results show that it is possible to predict the pest attack with high probability for one week in advance. These predictions would help the farmers in pest management programs by avoiding the crop losses with improved environment quality, as it can avoid unnecessary sprays of chemical pesticides."
G.Rani,Biclustering Algorithm for E-Gov Services,"With the widespread and proactive participation of citizens through various e-governance applications, democracy in the modern era has acquired an entirely new dimension The shear diversity of e-governance users has spurred on a fresh interest in designing adaptable e-governance systems. The first step in meeting this challenge is to develop a fast and versatile automated technique to categorize users on the basis of a similarity in their online identities and behaviors. In this paper we employ a modified version of the Cheng and Church Biclustering algorithm, hitherto used primarily in the field of Genetics, to extend its applicability to a classification of e-governance users. Taking a different route from conventional approaches, we tap a variety of dynamically varying parameters that characterize the online behavior of users with a view to improving the cohesiveness of user clusters. These include the navigation patterns of a user, her access frequency and the interactivity level during her web experience. We adopt two strategies for clustering. A single level strategy categorizes users on all the three parameters taken together using the Cheng and Church (CC) algorithm. We also employ a two level clustering strategy that first finds biclusters on the basis of individual parameters using CC and then the uses cluster ids to classify the users at a second level by and K-Means clustering. An analysis of the granularity of clusters and execution time for different strategies and datasets reveals that the single level strategy is useful in categorizing experienced users who have attained a degree of familiarity with the portal and are able to change their behavior frequently. Such a group of users is quite variegated. On the other hand, the two level strategy provides a better way to classify beginners who show very slow changes and are more uniform in their web interactions.","E-Gov Services, Threshold, single levels strategy and two level strategy, Biclustering, Mean Square Residue, e-governance, CC Biclustering Algorithm","This paper proposes the most appropriate clustering strategies for differently evolving user bases. The users' online behavior is captured with a comprehensive set of attributes including navigation path, frequency of accessing each page and the interactivity level sustained by users during their web interaction. We present a comparative analysis of single level and two level clustering strategies by employing three techniques: Cheng and Church biclustering, K-Means clustering and a combination of the two. Our experiments investigate the impact on execution time, quality and number of clusters when the base dataset of users' web behaviors is changed with minor modifications and major modifications."
G.V.Ranga Rao,Understanding Helicoverpa armigera Pest Population Dynamics related to Chickpea Crop Using Neural Networks,Insect pests are a major cause of crop loss globally. Pest management will be effective and efficient if we can predict the occurrence of peak activities of a given pest. Research efforts are going on to understand the pest dynamics by applying analytical and other techniques on pest surveillance data sets. In this study we make an effort to understand pest population dynamics using Neural Networks by analyzing  pest surveillance data set of Helicoverpa armigera or Pod borer on chickpea (Cicer arietinum L.)  crop. The results show that neural network method successfully predicts the pest attack incidences for one week in advance.,"Climatic Data, Pest Population Dynamics, Neural Networks, Pest Surveillance Databases, Chickpea Crop, Helicoverpa armigera, Neural Network, Pest Attack Prediction","The experimental results show that it is possible to predict the pest attack with high probability for one week in advance. These predictions would help the farmers in pest management programs by avoiding the crop losses with improved environment quality, as it can avoid unnecessary sprays of chemical pesticides."
Ganga Sharma,Cardiovascular Disease Detection Model,"This paper proposes a cardiovascular disease detection model that uses a combination of techniques such as Naïve Bayes, neural network, and feature selection to achieve high accuracy rates. The model is implemented using a virtual environment in Python and uses a decision tree classifier to classify patients as infected or disinfected. The results show that the proposed model can obtain infected persons from the training data with low losses, which can help doctors in real-time to categorize patients based on certain characteristics.","cardiovascular disease detection, Machine Learning, feature selection, Classification, decision tree classifier, Coronary Artery Diseases, Optimization Techniques",The proposed model uses a combination of techniques to achieve high accuracy rates in cardiovascular disease detection. The model is implemented using a virtual environment in Python and uses a decision tree classifier to classify patients as infected or disinfected. The results show that the proposed model can obtain infected persons from the training data with low losses.
Gao et. al.,Rumour Source Detection Using Game Theory,"Social networks have become a critical part of our lives as they enable us to interact with a lot of people. These networks have become the main sources for creating, sharing and also extracting information regarding various subjects. But all this information may not be true and may contain a lot of unverified rumours that have the potential of spreading incorrect information to the masses, which may even lead to situations of widespread panic. Thus, it is of great importance to identify those nodes and edges that play a crucial role in a network in order to find the most influential sources of rumour spreading. Generally, the basic idea is to classify the nodes and edges in a network with the highest criticality. Most of the existing work regarding the same focuses on using simple centrality measures which focus on the individual contribution of a node in a network. Game-theoretic approaches such as Shapley Value (SV) algorithms suggest that individual marginal contribution should be measured for a given player as the weighted average marginal increase in the yield of any coalition that this player might join. For our experiment, we have played five SV-based games to find the top 10 most influential nodes on three network datasets (Enron, USAir97 and Les Misérables). We have compared our results to the ones obtained by using primitive centrality measures. Our results show that SV-based approach is better at understanding the marginal contribution, and therefore the actual influence, of each node to the entire network.","influential nodes, Jaccard Similarity Coefficient, cooperative game, Rumour Source Detection (RSD), centrality measures, network analysis, Shapley Value (SV), Game-Theory, Network Centrality",This paper aims to identify the most influential nodes in a network that are the primary sources of rumour propagation. The authors propose a game-theoretic approach using the Shapley Value algorithm to find the most influential nodes. They compare their results with primitive centrality measures and show that the SV-based approach is better at understanding the marginal contribution of each node to the entire network.
"Gardner, M.",A Multi-Task Approach to Open Domain Suggestion Mining,"Consumer reviews online may contain suggestions useful for improving the target products and services. Mining suggestions is challenging because the field lacks large labelled and balanced datasets. Furthermore, most prior studies have only focused on mining suggestions in a single domain. In this work, we introduce a novel up-sampling technique to address the problem of class imbalance, and propose a multi-task deep learning approach for mining suggestions from multiple domains.","Deep Learning, Suggestion Mining, Artificial Intelligence, Class Imbalance, Multi-Task Learning","This paper presents a multi-task approach to open domain suggestion mining, addressing the class imbalance problem using a novel up-sampling technique and a multi-task deep learning framework. Experimental results show that the proposed approach outperforms state-of-the-art models in terms of F-1 measure and AUC."
Garg and Konemann,Maximum Coverage First: A New Heuristic for Target Coverage Problem in Wireless Sensor Networks,"This paper proposes a new heuristic, Maximum Coverage First (MCF), to solve the target coverage problem in wireless sensor networks. MCF generates sensor covers by selecting sensors that cover the maximum number of uncovered targets, and assigns lifetime to each cover based on the minimum residual battery life of its sensors.","Maximum Coverage First, Target Coverage Problem, Wireless Sensor Networks, Network lifetime, Lifetime Assignment, Heuristic Algorithms, Heuristic, NP completeness","The paper presents a new heuristic, MCF, to solve the target coverage problem in wireless sensor networks. MCF generates sensor covers by selecting sensors that cover the maximum number of uncovered targets, and assigns lifetime to each cover based on the minimum residual battery life of its sensors. The paper also compares the performance of MCF with other existing heuristics and presents simulation results to demonstrate its effectiveness."
Garimella Ram Murthy,Training Data Compression Algorithms and Reliability in Large Wireless Sensor Networks,With the availability of low-cost sensor nodes there have been many standards developed to integrate and network these nodes to form a reliable network allowing many different types of hardware vendors to coexist.,"Probability Model, Sensor Network, Data Compression, Wireless Sensor Networks, Reliability","This paper proposes a data compression algorithm for large wireless sensor networks, which optimizes data redundancy and uses a probability model to efficiently compress data at cluster heads."
Garimella Rama Murthy,Gibbs-Shannon Entropy and Related Measures: Tsallis Entropy ||| Prediction of Willingness of Users in V-MIMO ||| Time Optimal Spectrum Sensing: Stochastic Optimization,"In this research paper, it is proved that an approximation to Gibbs-Shannon entropy measure naturally leads to Tsallis entropy for the real parameter q = 2. Several interesting measures based on the input as well as output of a discrete memoryless channel are provided and some of the properties of those measures are discussed. ||| In cellular systems, virtual multiple-input multiple-output (V-MIMO) technology promises to achieve performance gains comparable to conventional MIMO. In this paper, we propose cooperative relay selection algorithm based on machine learning techniques. Willingness of user to cooperate in V-MIMO depends on his current battery power, time and day along with incentives offered by service provider. ||| This paper presents a stochastic optimization approach for time-optimal spectrum sensing. The problem is formulated as a joint optimization of the mean and variance of the spectrum sensing time random variable.","Integer Programming, discrete memoryless channel, Artificial Neural network, SVM, ANN, Machine Learning, Stochastic Optimization, Spectrum Sensing, Virtual MIMO, Pareto Front, probability mass functions, Source Coding, time-optimal, Gibbs-Shannon entropy, Support Vector Machine, V-MIMO, Tsallis entropy, Virtual Antenna Array","The paper explores the relationship between Gibbs-Shannon Entropy measure and the Tsallis entropy (for q=2) and defines various interesting measures associated with probability mass functions. ||| This paper proposes a cooperative relay selection algorithm based on machine learning techniques for virtual MIMO systems. The algorithm predicts potential willing users in the neighborhood of the source user and reduces cooperative node discovery time. The performance of the algorithm is evaluated using metrics such as MSE, accuracy, precision, and recall. ||| The paper proposes a novel approach to solve the time-optimal spectrum sensing problem using stochastic optimization. The approach is based on the minimization of the mean and variance of the spectrum sensing time random variable."
Gaurav Chawla,"MOTIVATING CHILD DEVELOPMENT AND ERADICATION OF CHILD LABOR BY PROMPT EFFORTS BY US, SOCIETY AND GOVERNMENT ||| Upgradation Of Biogas Using Combined Method Of Alkaline Water Scrubbing And Adsoption Through Carbon Molecular Sieve","One of the menacing curses that our nation is facing today is child labor. Lack of economy and basic education has been monitored as a cause for majority of child labor activities. It is being generally realized that, child labor especially in hazardous occupation is one of the worst social evil and has to be eliminated at the earliest. Government has been taking various pro-active measures to tackle this problem. However, considering the magnitude and extent of the problem and that it is essentially a socio-economic problem inextricably linked to poverty and illiteracy, it requires concerted efforts from all sections of the society to make a dent in the problem. ||| Over the past decade there is increasing demand of energy in rural, urban areas of India. This has led to the depletion of natural resources like coal, wood and kerosene. These sources are inefficient and harmful to the environment. Thus there is an imminent need to replace them with clean, eco-friendly and efficient source of energy.","government schemes, government, water scrubbing, illiteracy, child labor, pressure swing adsorption, education, biomethane, menacing, Combined Method, Biogas, Alkaline Water Scrubbing, eradication, Adsoption Through Carbon Molecular Sieve, awareness","The paper discusses the menace of child labor in India and proposes a plan to eradicate it through education, financial support, and awareness. The plan involves collecting donations, providing financial assistance to underprivileged families, and setting up schools for primary education. The authors aim to make children skillful by imparting professional education and provide alternative employment opportunities. ||| The paper discusses the upgradation of biogas using a combined method of alkaline water scrubbing and adsorption through carbon molecular sieve. The method involves the passage of compressed biogas through a cylindrical pipe packed with carbon molecular sieves, which enriches the methane content to 88% or more. The paper also discusses the environmental advantages of biogas, including its renewable nature, ability to reduce greenhouse gas emissions, and potential to replace fossil fuels."
Gaurav Gupta,An Extended Version of WordNet Incorporating Technical Terms and Subject Specific Words/Phrases,"WordNet is a huge repository being used as a tool in various fields. With an increasing number of applications referring to WordNet as a dictionary, several attempts have been made to update it. The paper proposes to extend the huge repository by adding words and relationships derived from students’ class notes through wikidata. These terms can be phrases, technical terms or any subject specific terminology appearing in students’ notes of a specific subject. Although various WordNet enriching techniques are available, it is for the first time that subject specific terminology is being added. The resulting version of WordNet has some very common phrases and technical terms along with the generic terms. Making subject specific and generic terms available in a hierarchy can improve the accuracy of various applications like text summarization and clustering for text belonging to a specific domain.","Subject Specific Words/Phrases, English WordNet, WordNet, Hyponym enrichment, Technical Terms, Wikidata","The paper proposes a novel hyponym enrichment in WordNet by enriching the database with subject related technical terms. This is important since the database has not been updated for a long time now. To the best of our knowledge, we are the first to use wikidata for adding subject specific terms and relationships to WordNet."
Gaurav Kumar Jain,Wound Healing Potential of Raloxifene Nanoemulsion Gel for the Management of Postmenopausal Cutaneous Wounds,"Background: Depletion in estrogen level(s) especially in postmenopausal women is reported to have delayed wound healing effects; hence we have evaluated the wound healing potential of raloxifene in rat model. Objectives: Investigating the wound healing effects of raloxifene nanoemulsion for the management of postmenopausal cutaneous wounds. Materials and Methods: The optimized nanoemulsion gel contains 0.072% raloxifene hydrochloride. Female Wistar rats were used to investigate its wound healing effects. After three months of ovariectomy, wound healing effect was observed in terms of breaking strength, tensile strength, area of wound contraction, wound closure time, hydroxyproline content and histopathological changes. Results: The nanoemulsion gel exhibited better retention (34.31%) than its nanoemulsion. The raloxifene nanoemulsion gel has no erythema and no eschar formation recorded, and it is safe for topical use. In the incision wound model in ovariectomized rats, breaking (898±25g) and tensile strengths (4.47±0.12 g/mm2) in raloxifene treated groups were found to be higher than the untreated control group. Additionally, in ovariectomized rats, wound contraction was found to be 100% in the treated group s following 20 days of post-wounding, where as in control group only 88% was contraction was observed. Also, more hydroxyproline content in raloxifene treated ovariectomized rat was observed that recommend more collagen content than the untreated ovariectomized rat but approximately similar effects to untreated non-ovariectomized rats. Histopathological studies confirmed that the raloxifene treated groups had more re-epithelialization, neo-vascularization, fibroblast proliferation, and collagen deposition than the control group. Conclusion: These results confirms that the raloxifene nanoemulsion gel has significant wound healing potential, as observed in ovariectomized rats, which will be helpful in postmenopausal cutaneous wound healing.","Raloxifene, Histopathology, Ovariectomized, Hydroxyproline, Wound contraction, Postmenopausal Cutaneous Wounds, Postmenopausal, Breaking strength, Nanoemulsion gel, Wound Healing","This study investigates the wound healing potential of raloxifene nanoemulsion gel in postmenopausal cutaneous wounds. The results show that the nanoemulsion gel has significant wound healing potential, as observed in ovariectomized rats, and is safe for topical use. The study suggests that raloxifene nanoemulsion gel can be a good alternative for wound healing in postmenopausal women."
Gaurav Sharma,On the Security of Authenticated Group Key Agreement Protocols,"The group key agreement protocol enables to derive a shared session key for the remote members to communicate securely. Recently, several attempts are made to utilize group key agreement protocols for secure multicasting in Internet of Things. This paper contributes to identify the security vulnerabilities in the existing protocols, to avoid them in future constructions. The protocols presented by Gupta and Biswas have been found insecure to ephemeral secret key leakage (ESL) attack and also, malicious insiders can impersonate an honest participant. Additionally, the protocol presented by Tan is also ESL-insecure. We also present a fix to the Tan’s protocol to make it secure.","Insider security, Security Protocols, Authenticated Group Key Agreement, Authentication, Mutual authentication, Group key agreement, Elliptic Curve Cryptography","This paper discusses the security vulnerabilities in existing group key agreement protocols and presents a fix to one of the protocols to make it secure. The authors identify the security vulnerabilities in the protocols presented by Gupta and Biswas and Tan, and present a fix to the Tan’s protocol to make it secure. The paper also discusses the importance of authentication and insider security in group key agreement protocols."
Geeta Rani,A deep learning model for mass screening of COVID-19 ||| Cardiovascular Disease Detection Model ||| Range Limited Double Threshold Weighted Histogram Equalization with Dynamic Range Stretching (RLDTWHE-DRS) ||| Recent Developments in Plant Leaf Disease Identification and Classification ||| Transforming view of medical images using deep learning,"The objective of this research is to develop a convolutional neural network model ‘COVID-Screen-Net’ for multi-class classification of chest X-ray images into three classes viz. COVID-19, bacterial pneumonia, and normal. ||| This paper proposes a cardiovascular disease detection model that uses a combination of techniques such as Naïve Bayes, neural network, and feature selection to achieve high accuracy rates. The model is implemented using a virtual environment in Python and uses a decision tree classifier to classify patients as infected or disinfected. The results show that the proposed model can obtain infected persons from the training data with low losses, which can help doctors in real-time to categorize patients based on certain characteristics. ||| In the recent era, a boom was observed in the field of information retrieval from images. Digital images with high contrast are sources of abundant information. The gathered information is useful in the precise detection of an object, event, or anomaly captured in an image scene. Existing systems do uniform distribution of intensities and apply intensity histogram equalization. These improve the characteristics of an image in terms of visual appearance. The problem of over enhancement and the increase in noise level produces undesirable visual artefacts. The use of Otsu’s single threshold method in existing systems is inefficient for segmenting an image with multiple objects and complex background. Additionally, these are incapable to improve the yield of the maximum entropy and brightness preservation. The aforementioned limitations motivate us to propose an efficient statistical pipelined approach, the Range Limited Double Threshold Weighted Histogram Equalization (RLDTWHE). This approach is an integration of Otsu’s double threshold, dynamic range stretching, weighted distribution, adaptive gamma correction, and homomorphic filtering. It provides optimum contrast enhancement by selecting the best appropriate threshold value for image segmentation. The proposed approach is efficient in the enhancement of low contrast medical MRI images and digital natural scene images. It effectively preserves all essential information recorded in an image. Experimental results prove its efficacy in terms of maximum entropy preservation, brightness preservation, contrast enhancement, and retaining the natural appearance of an image. ||| In the modern era, deep learning techniques have emerged as powerful tools in image recognition. Convolutional Neural Networks, one of the deep learning tools, have attained an impressive outcome in this area. The effectiveness of Convolutional Neural Networks in image recognition motivates the researchers to extend its applications in the field of agriculture for recognition of plant species, yield management, weed detection, soil, and water management, fruit counting, diseases, and pest detection, evaluating the nutrient status of plants, and much more. ||| Since the last decade, there is a significant change in the procedure of medical diagnosis and treatment. Specifically, when internal tissues, organs such as heart, lungs, brain, kidneys and bones are the target regions, a doctor recommends ‘computerized tomography’ scan and/or magnetic resonance imaging to get a clear picture of the damaged portion of an organ or a bone. This is important for correct examination of the medical deformities such as bone fracture, arthritis, and brain tumor. It ensures prescription of the best possible treatment. But ‘computerized tomography’ scan exposes a patient to high ionizing radiation. These rays make a person more prone to cancer. Magnetic resonance imaging requires a strong magnetic field. Thus, it becomes impractical for patients with implants in their body. Moreover, the high cost makes the above-stated techniques unaffordable for low economy class of society. The above-mentioned challenges of ‘computerized tomography’ scan and magnetic resonance imaging motivate researchers to focus on developing a technique for conversion of 2-dimensional view of medical images into their corresponding multiple views. In this manuscript, the authors design and develop a deep learning model that makes an effective use of conditional generative adversarial network, an extension of generative adversarial network for the transformation of 2-dimensional views of human bone into the corresponding multiple views at different angles. The model will prove useful for both doctors and patients.","leaf, CT scan, Homomorphic Filtering, Machine Learning, Deep learning, Classification, MRI, Optimum Contrast Enhancement, dynamic range stretching, Range Stretching, 2-Dimensional, deep learning models, disease, Histogram Weighting, Adaptive Gamma Correction, DCGAN, contrast enhancement, X-ray, SRGAN, Conditional generative adversarial network, weighted distribution, CCAN, SGAN, CNN model, 3-Dimensional, Optimization Techniques, convolutional neural networks, cardiovascular disease detection, survey, ACGAN, InfoGAN, Generative Adversarial Networks, Coronary Artery Diseases, Corona, COVID-19, Automatic Threshold Selection, deep learning, feature selection, machine learning models, plant leaf disease identification, Image-to-Image Translation, decision tree classifier, agriculture, global pandemic, histogram equalization","The authors developed a deep learning model ‘COVID-Screen-Net’ for mass screening of COVID-19 from chest X-ray images. The model achieves an average accuracy of 97.71% and a maximum recall of 100%. It outperforms existing systems for screening of COVID-19 and may prove a useful tool for quick and low-cost mass screening of patients. ||| The proposed model uses a combination of techniques to achieve high accuracy rates in cardiovascular disease detection. The model is implemented using a virtual environment in Python and uses a decision tree classifier to classify patients as infected or disinfected. The results show that the proposed model can obtain infected persons from the training data with low losses. ||| This paper proposes a new approach for digital image contrast enhancement, called Range Limited Double Threshold Weighted Histogram Equalization (RLDTWHE). The approach integrates several techniques, including Otsu’s double threshold, dynamic range stretching, weighted distribution, adaptive gamma correction, and homomorphic filtering. The proposed approach is efficient in enhancing low contrast medical MRI images and digital natural scene images, and effectively preserves all essential information recorded in an image. ||| This manuscript presents a survey of the existing literature in applying deep Convolutional Neural Networks to predict plant diseases from leaf images. It presents an exemplary comparison of the pre-processing techniques, Convolutional Neural Network models, frameworks, and optimization techniques applied to detect and classify plant diseases using leaf images as a data set. ||| The paper discusses the application of GANs in image-to-image translation and presents various techniques such as InfoGAN, SGAN, SRGAN, CCAN, DCGAN, and ACGAN. The paper highlights the advantages and disadvantages of each technique and provides a clear idea about the extension of the application area of the existing work."
Geyong Min,A Cost-Efficient Communication Framework For Battery Switch Based Electric Vehicle Charging ||| A Novel EV Charging Management Scheme Considering Mobility Uncertainty,"This paper proposes a battery switch service for electric vehicles (EVs) using a publish/subscribe (P/S) communication paradigm. The system consists of road side units (RSUs), electric vehicles (EVs), and charging stations (CSs). RSUs act as brokers to bridge the information flow from CSs to EVs, while EVs and CSs interact through RSUs. The system enables efficient radio resource utilization and alleviates interference to EVs. ||| This paper proposes a novel EV charging management scheme that considers mobility uncertainty due to traffic jams in a city. The scheme uses a centralized aggregator to manage charging plans for all EVs in the network, and each EV reports its charging reservation to the aggregator, including its expected arrival time and charging time. The aggregator then makes CS-selection decisions based on the reported information and updates the reservations periodically to adjust for mobility uncertainty.","Electric Vehicles, publish/subscribe, road side units, Charging System, Smart Cities, Mobility Uncertainty, Communication Framework, Electric Vehicle Charging, CS-Selection Decision Making, Traffic Jams, Centralized Aggregator, CS-Selection, Charging Management, Battery Switch, Electric Vehicle, Driver's Trip Duration, charging stations","This article presents a cost-efﬁcient communication framework for battery switch based electric vehicle charging. The framework is provisioned to support the EV charging service and considers urban travel uncertainties, e.g., trafﬁc congestions and drivers’ preferences. Results demonstrate a guidance for the provisioning of P/S communication framework to improve EV drivers’ experience, e.g., charging waiting time and total trip duration. ||| This paper proposes an EV charging management system that considers drivers' trip duration and mobility uncertainty. The system selects charging stations based on reported EVs' reservation information and parking duration, minimizing trip duration for on-the-move EVs."
Gholamreza Ahakian,A comparative study of testing semantic web services,"Web Services provide efficient reusability mechanism, thereby reducing the development time and cost. Mostly the source code of web services is unavailable to other developers who use these services. The manual effort spent by them in testing these web services is very large in order to increase the interoperability. Thus, automated testing needs to be developed for testing these Web services. This paper reviews test cases for Web Services using reduction techniques Pair-Wise Testing (PWT) and Orthogonal Array Testing (OAT) and compares the two techniques with general method. The structure of Web Services is specified using UML diagrams. The pre and post conditions for the service rule are specified using Object Constraint Language (OCL). The framework transforms into WSDL-S specifications. These specifications are parsed and transformed into structured DOM tree. Test data set generated by this framework would satisfy the constraints of the WSDL. The test cases are then developed based on the data generated, documented in XML based test files. The number of test cases required by general testing, PWT, OAT are compared and the better testing technique for testing Web Services is determined.","Semantics, Reduction Techniques, Reduction, Test case, Web Services, Pair wise, Orthogonal Array Testing, web service, Test Cases, Pair-Wise Testing, Orthogonal Array","This paper compares Pair-Wise Testing (PWT) and Orthogonal Array Testing (OAT) for reducing the number of test cases needed for Web Services. It finds that OAT is more efficient when dealing with a large number of parameters, while PWT is suitable for smaller sets of parameters. Both techniques significantly reduce the testing effort compared to a general approach."
Gi Hong Im,Bandwidth-Efﬁcient OFDM transmission with iterative cyclic preﬁx reconstruction,"Abstract—Orthogonal frequency division multiplexing (OFDM) systems are now a part of all major wireless standards, because of its potential to offer high data rate. Cyclic prefix (CP) in OFDM system converts a multipath channel to a flat fading channel, thus simplifies the design of equalizer. However, there is a lot of ambiguity in choosing the length of CP. In this paper, we propose a new method for calculation of length of CP using cumulant features. The merits of proposed method are verified by computer simulation.","bandwidth efﬁciency, OFDM, channel length estimation, cumulant features, Orthogonal frequency division multiplexing (OFDM), Cyclic prefix (CP), cyclic preﬁx, Blind channel length estimation","This paper proposes a novel method for blind channel length estimation in OFDM systems using cumulant features. The proposed method is well-suited for dynamic spectrum access (DSA) setups and does not require pilot or training sequences, thus saving bandwidth. The method is based on exploiting the properties of nth order cumulant features and is verified by computer simulation."
Giovanni Russello,Encrypted Domain Camera Attribution,"Photo Response Non-Uniformity (PRNU) noise-based source camera attribution is a popular digital forensic method. In this method, a camera fingerprint computed from a set of known images of the camera is matched against the extracted noise of an anonymous questionable image to find out if the camera had taken the anonymous image.","PRNU-based camera attribution, Camera Fingerprinting, utility, Privacy, camera attribution, Secure computation, encrypted domain",The proposed method is based on a secure multi-party computation scheme that enables a third-party entity to perform camera attribution tasks without accessing the sensitive image data. The method uses a combination of homomorphic encryption and secure multi-party computation to ensure both utility and privacy.
Girish Nath Jha,Lecture Notes in Artificial Intelligence 6465,"This work is subject to copyright. All rights are reserved, whether the whole or part of the material is concerned, specifically the rights of translation, reprinting, re-use of illustrations, recitation, broadcasting, reproduction on microfilms or in any other way, and storage in data banks. Duplication of this publication or parts thereof is permitted only under the provisions of the German Copyright Law of September 9, 1965, in its current version, and permission for use must always be obtained from Springer. Violations are liable to prosecution under the German Copyright Law.","Artificial Intelligence, Computational Linguistics, Sanskrit","The 4th International Sanskrit Computational Linguistics Symposium (4i-SCLS) was hosted by the Jawaharlal Nehru University, the premier research University of India during (December 10–12, 2010) at the Special Center for Sanskrit Studies. The event saw excellent response from the scholars, with more than 31 papers received, which were examined by the Program Committee members to shortlist 18 papers for publication presented in this volume."
Gohel et al.,Explainable AI: Current Status and Future Directions,"This paper discusses the current status and future directions of Explainable AI (XAI). XAI is a subfield of Artificial Intelligence (AI) that focuses on making AI models more transparent, interpretable, and explainable. The paper highlights the importance of XAI in various domains such as healthcare, finance, and defense. It also discusses the challenges and limitations of XAI and proposes a classification tree to categorize XAI techniques into transparent and post-hoc methods.","Interpretable Artiﬁcial Intelligence, Explainable AI, Machine Learning, Interpretability, Transparency, Explainable Artiﬁcial Intelligence (XAI), XAI, Artificial Intelligence, Explainability","This paper provides an overview of XAI techniques from a multimedia (i.e., text, image, audio, and video) point of view. Advantages and shortcomings of these techniques have been discussed, and pointers to some future directions have also been provided."
Gourab Datta,First-­in-­Human Study of Bamlanivimab in a Randomized Trial of Hospitalized Patients With COVID-­19,"This first-in-human study in hospitalized patients with COVID-19 was supported by studies assessing in vitro viral neutralization combined with a single-dose non-human primate PK study. The nonclinical safety package to support subsequent studies included tissue cross-reactivity studies on human, rat, and monkey tissues and an in vivo toxicology study.  A complete physical examination was conducted at the screening visit, and one of three bamlanivimab doses or placebo was administered i.v. at the baseline visit (D1) with infusion rates as follows: bamlanivimab 700 mg (50 mL) administered 100 mL/hr for 30 minutes; 2,800 mg (75 mL) administered 100 mL/hr for 45 minutes; and 7,000 mg administered 100 mL/hr for 60 minutes. Placebo infusion was 0.9% normal saline, administered at the same volume and rate as the corresponding bamlanivimab dose cohort. Safety and tolerability were reviewed for sentinel participants up to 24 hours after dosing, at which point the investigators and sponsor team determined whether safety and tolerability were acceptable to continue with dosing subsequent participants. The decision to dose the next cohort was made when all participants from the previous cohort had been dosed and safety data assessed for at least 4 days after the i.v. infusion by the investigators and sponsor team in consultation with an independent safety assessment committee. Blood samples were obtained for assessment of exploratory biomarkers, serology, clinical laboratory assessments, and PD on days 1, 3, 7, 11, 15, 22, and 29, and every 7 days until discharge or day 60, if still an inpatient. Samples for the virology assay were collected using nasopharyngeal (preferred) or mid-turbinate methods. Blood samples obtained for PK analyses were assessed on days 1 (pre-infusion and just before end of infusion), 4, 15, and 29, and follow-up visits up to day 60. Symptom-related physical examinations and assessments of clinical symptoms were performed on days 1, 2, 3, 4, 7, 11, 15, 22, and 29, and the day of discharge from the hospital, with additional follow-up examinations every 7 days thereafter until day 60 if the patient was not discharged from the hospital by day 29. Participants’ clinical status and concurrent procedures of special interest were recorded, including limitation on activities due to COVID-19 and any requirements for the following procedures of special interest, such as ongoing hospital medical care, supplemental oxygen, noninvasive ventilation or a high flow oxygen device, mechanical ventilation, extracorporeal membrane oxygenation, additional organ support, or consciousness status using alert, consciousness, verbal, pain, unresponsive scale. Hospitalization events were recorded, including dates of hospital admission and discharge, admission to the intensive care unit (ICU), discharge from the ICU, and discharge location including to an extended care facility or home. Outcomes The primary objective was to assess safety and tolerability, including adverse events (AEs), serious adverse events (SAEs), and discontinuations due to AEs. Other objectives included PKs (e.g., mean concentration at day 29); PD viral load, area under the response time curve (AUC, from day 1 to day 29), and change from baseline time course; total symptom score; time to symptom resolution; duration of hospitalization; National Institute of Allergy and Infectious Diseases (NIAID), World Health Organization (WHO) scales, and National Early Warning Score (NEWS2); and analysis of viral resistance. Any hypothesis tests were conducted for treatment comparisons without adjustment for multiplicity except for the evaluation of treatment effect on endogenous antibody titers. Success for the trial was claimed using a Bayesian criterion if any of the 3 bamlanivimab doses had at least 60% probability to reduce at least 30% mean AUC (28-day viral load) over placebo.",,"This first-in-human study evaluated the safety, tolerability, pharmacokinetics, clinical course, and viral dynamics of bamlanivimab, a fully human neutralizing monoclonal antibody targeting SARS-CoV-2, in hospitalized patients with moderate to severe COVID-19.  The study found bamlanivimab to be safe and well-tolerated, with no serious adverse events or deaths reported.  Further research is needed to determine the efficacy of bamlanivimab in treating COVID-19."
Graham Morgan,"Explainable AI (XAI): Core Ideas, Techniques and Solutions","As our dependence on intelligent machines continues to grow, so does the demand for more transparent and interpretable models. In addition, the ability to explain the model generally is now the gold standard for building trust and deployment of Artificial Intelligence (AI) systems in critical domains. Explainable Artificial Intelligence (XAI) aims to provide a suite of machine learning (ML) techniques that enable human users to understand, appropriately trust, and produce more explainable models.","Explainable AI, Stakeholders, Machine Learning, Software toolkits, Programming framework, Bias, Robustness, Interpretable AI, Explainable Artiﬁcial Intelligence, XAI, Decision Making","The paper presents the core ideas, techniques, and solutions of XAI, emphasizing its importance in various phases of the machine learning process. It discusses the stakeholders involved in these phases, including developers, theorists, data scientists, users, consumers, businesses, regulators, and scientists, and highlights the use cases of XAI in detecting bias, scientific understanding, building robust models, and better decision making."
Grobler and Grubner,Automated Competitor Analysis Using Big Data and NLP,"Competitor analysis is a key component in operations management. Most business decisions are rooted in the analysis of rival products inferred from market structure. Relative to more traditional competitor analysis methods, the purpose of this paper is to provide operations managers with an innovative tool to monitor a firm’s market position and competitors in real time at higher resolution and lower cost than more traditional competitor analysis methods.","Mobile apps, Operational strategy, Naïve Bayes, Probabilistic topic modelling, NLP, competitor analysis, management theories, User segment overlapping, Big data","The paper presents an innovative tool for competitor analysis using big data analytics, which can monitor a firm’s market position and competitors in real time at higher resolution and lower cost than traditional methods. The tool combines Web Crawler, Natural Language Processing, and Machine Learning algorithms with data visualization to develop a big data competitor-analysis system."
Gu-Yeon Wei,Design of Next-Generation Low-Power Sensor Network Nodes,This paper presents the design of next-generation low-power sensor network nodes that can scavenge energy from the environment and use this energy to power the sensor network device.,"Ultra Low Power System Architecture, Fine-Grain Power Management, low-power sensor network nodes, hardware acceleration, Sensor Network Applications, event-driven system, Event-Driven Computation, energy scavenging","The paper discusses the design of next-generation low-power sensor network nodes that can scavenge energy from the environment and use this energy to power the sensor network device. The system architecture is designed to be event-driven, with hardware accelerators offloading common tasks to improve performance and power efficiency."
Guanzheng Que,A new method for rock brittleness evaluation in tight oil formation from conventional logs and petrophysical data,"Brittleness is a critical indicator for hydraulic fracturing candidate screening in unconventional reservoirs. Current rock brittleness estimation models are often inferred from mechanical parameters and mineralogical data, which primarily use empirical equations. However, the absence of shear sonic velocity data and insufficient mineral data sometimes restricts its wide application. In this article, our objective is to illustrate the application of a data-driven approach for rock brittleness estimation that employs computational intelligence technologies (multilayer perception and radial basis function models) that use conventional well logs as inputs.","Rock brittleness, Multilayer perception, production, brittleness, Computational intelligence, Hydraulic fracturing, Tight oil, oil and gas exploration, rock mechanics, Radial basis function","The paper reviews the current state of brittleness calculation methods and their limitations, highlighting the need for a universally applicable model. It discusses the importance of mineral composition, strain rate, temperature, pore pressure, saturation, and stress state in controlling rock brittleness."
Gulati,Agriculture Extension System in India: A Meta-analysis,"Agriculture extension system bridges the gap between research labs to a farmer’s field. Agricultural research, education and extension are said to be the most critical for promoting farm productivity and enhancing farmer’s income. The public sector is major extension service provider and the reach of the public extension is limited in India and in addition it is burdened with non-extension responsibilities such as the distribution of subsidies and inputs, with little time left to attend to core extension activities.","Investment, Extension approaches, Farmers Producers' Organizations, India, Agriculture extension, Meta analysis, ICT, Manpower","The article reviews the agricultural extension system in India to suggest pathways for better extension system in India. The public extension services are highly skewed towards crop husbandry ignoring allied sectors in India. The growth in the High-Value Agriculture sector has been twice or sometimes even thrice that of the crop production. However, Agriculture extension services for such sectors almost nil or unorganized."
Gulzar Alam,Study the modern biochemical analysis techniques of proteins and alkaline phasphtase enzyme system from biological sample chicken liver,"The objective of the study was the biochemical analysis of proteins and Alkaline Phosphatase enzyme system from biological sample Chicken Liver using modern biochemical analysis techniques, including protein extraction, fractionation and electrophoresis separation technique and enzyme analysis.","Amino acids, alkaline phosphatase, Enzymes, Biochemical analysis, peroxidases, acid phosphatase, Protein chains, proteases, Proteins","The paper discusses the biochemical analysis of proteins and alkaline phosphatase enzyme system from chicken liver using modern biochemical analysis techniques. It covers topics such as protein synthesis, structure, and purification, and highlights the importance of proteins in living organisms."
Guofeng Yang et al.,Deep Learning Techniques for Disease Detection in Fruits and Vegetables,"Plant Diseases are one of the leading reasons of economic shortfalls in agricultural and farming sectors worldwide. It is the most essential element since it reduces crop quantity and quality significantly. Fruits are one of the largest essential nutritional resources from plants. Unfortunately, a variety of conditions might impair both the content and outcome of fruits. As a result, an autonomous Computer Vision (CV) -based approach for reliable Fruit Disease Detection (FDD) is necessary.","Attention mechanisms, Transfer learning, Convolutional neural networks, Computer Vision, Machine Learning, Disease detection, Deep Learning, Fruits and vegetables, Fruit Disease Detection","This paper presents a detailed review of different ML and DL algorithms developed to predict and classify FDs from different fruit images. First, different FDD and classification systems designed by many researchers based on ML and DL algorithms are studied in brief. Then, a detailed analysis is carried out in order to identify the shortcomings of existing algorithms and to provide a novel strategy for properly classifying fruit pathogens."
Gupta,An Efﬁcient Encryption Algorithm for Sensitive Data Using Numeric and Alphanumeric Format,"In the contemporary world, with the growth of networking and increase in the volume of data storage capacity, a significant amount of personal information leakage accident occurs that leads to loss of personal data day by day. Hence, there arises a need to emphasize more on the security of data stored either in databases or transmitted over the web to ensure that user’s personal data is stored at a safer place. To maintain the privacy and security of data a protective layer of encryption is applied around the sensitive data items focusing on encrypting only the sensitive data. Standard encryption techniques such as AES, DES or 3DES are used to encrypt the data, but these techniques are unsuitable for encrypting personal information as they lead to various shortcomings.","database system, Database, Advanced Encryption Standard (AES), Encryption, Feistel cycle walking, Numeric and Alphanumeric Data, encryption algorithm, Format Preserving Encryption, Data Security",This paper proposes a new and efficient encryption scheme for securing numeric and alphanumeric data of databases. The proposed solution integrates with various encryption schemes such as Advanced Encryption Standard (AES) on the remote side database. Data transmission and data storage take place at the server database. The remote side and server side database will be secured with the same data formats.
Gurpuz B,Correlation and Path Analysis in Fennel (Foeniculum vulgare Mill.),"The present investigation was conducted during December, 2017 to May, 2018 at Main Experimental Station of Vegetable Science, Acharya Narendra Deva University of Agriculture & Technology, Kumarganj, Ayodhya (U.P.). The field experiment was laid out in Agumented Block Design with 60 genotypes along with four check to estimate correlation and path coefficient for ten yield contributing traits and identification of superior recombinants for their utilization in crop improvement programme.","augmented block design, correlation, path analysis, Ajwain Trachyspermum ammi L.","The study aimed to investigate the character association and path analysis in ajwain (Trachyspermum ammi L.). The experiment was conducted at Main Experimental Station of Vegetable Science, Acharya Narendra Deva University of Agriculture & Technology, Kumarganj, Ayodhya (U.P.). The results showed that germination % had a highly significant and positive correlation with yield per plant, followed by days to maturity and weight of grain per umbel. However, negative direct effect was found in days to 50% flowering and plant height on fruit yield per plant."
Gurumoorthy Krishnamoorthy,Myelin-speciﬁc T cells also recognize neuronal autoantigen in a transgenic mouse model of multiple sclerosis,"We describe here the paradoxical development of spontaneous experimental autoimmune encephalomyelitis (EAE) in transgenic mice expressing a myelin oligodendrocyte glycoprotein (MOG)-speciﬁc T cell antigen receptor (TCR) in the absence of MOG. We report that in Mog-deﬁcient mice (Mog–/–), the autoimmune response by transgenic T cells is redirected to a neuronal cytoskeletal self antigen, neuroﬁlament-M (NF-M). Although components of radically different protein classes, the cross-reacting major histocompatibility complex I-Ab–restricted epitope sequences of MOG35–55 and NF-M18–30 share essential TCR contact positions. This pattern of cross-reaction is not speciﬁc to the transgenic TCR but is also commonly seen in MOG35–55–I-Ab–reactive T cells. We propose that in the C57BL/6 mouse, MOG and NF-M response components add up to overcome the general resistance of this strain to experimental induction of autoimmunity. Similar cumulative responses against more than one autoantigen may have a role in spontaneously developing human autoimmune diseases.",,"This study reports the unexpected finding that transgenic mice expressing a myelin oligodendrocyte glycoprotein (MOG)-specific T cell receptor (TCR) develop spontaneous experimental autoimmune encephalomyelitis (EAE) even in the absence of MOG. The researchers discovered that these mice redirect their autoimmune response to a neuronal cytoskeletal protein called neuroﬁlament-M (NF-M). This cross-reactivity between MOG and NF-M is mediated by shared TCR contact positions on their respective epitope sequences. The study suggests that cumulative responses against multiple autoantigens, such as MOG and NF-M, may contribute to the development of spontaneous autoimmune diseases in humans."
H Takemotob,Evaluation of the microangiographic fluoroscope (MAF) using generalized system performance metrics,"Cone beam computed tomography (CBCT) systems with rotational gantries that have standard flat panel detectors (FPD) are widely used for the 3D rendering of vascular structures using Feldkamp cone beam reconstruction algorithms. One of the inherent limitations of these systems is limited resolution (<3 lp/mm). There are systems available with higher resolution but their small FOV limits them to small animal imaging only. In this work, we report on region-of-interest (ROI) CBCT with a high resolution CMOS detector (75 μm pixels, 600 μm HR-CsI) mounted with motorized detector changer on a commercial FPD-based C-arm angiography gantry (194 μm pixels, 600 μm HL-CsI). A cylindrical CT phantom and neuro stents were imaged with both detectors. For each detector a total of 209 images were acquired in a rotational protocol. The technique parameters chosen for the FPD by the imaging system were used for the CMOS detector. The anti-scatter grid was removed and the incident scatter was kept the same for both detectors with identical collimator settings. The FPD images were reconstructed for the 10 cm x10 cm FOV and the CMOS images were reconstructed for a 3.84 cm × 3.84 cm FOV. Although the reconstructed images from the CMOS detector demonstrated comparable contrast to the FPD images, the reconstructed 3D images of the neuro stent clearly showed that the CMOS detector improved delineation of smaller objects such as the stent struts (~70 μm) compared to the FPD. Further development and the potential for substantial clinical impact are suggested.",,"This study demonstrates the use of a high-resolution CMOS detector in region-of-interest cone beam computed tomography (ROI CBCT) for improved visualization of small vascular structures. Compared to a standard flat panel detector, the CMOS detector achieved comparable contrast but significantly enhanced spatial resolution, enabling clearer delineation of stent struts. This advancement holds promise for clinical applications requiring high-resolution imaging of vascular anatomy."
H et Naik,"Explainable AI (XAI): Core Ideas, Techniques and Solutions","As our dependence on intelligent machines continues to grow, so does the demand for more transparent and interpretable models. In addition, the ability to explain the model generally is now the gold standard for building trust and deployment of Artificial Intelligence (AI) systems in critical domains. Explainable Artificial Intelligence (XAI) aims to provide a suite of machine learning (ML) techniques that enable human users to understand, appropriately trust, and produce more explainable models.","Explainable AI, Stakeholders, Machine Learning, Software toolkits, Programming framework, Bias, Robustness, Interpretable AI, Explainable Artiﬁcial Intelligence, XAI, Decision Making","The paper presents the core ideas, techniques, and solutions of XAI, emphasizing its importance in various phases of the machine learning process. It discusses the stakeholders involved in these phases, including developers, theorists, data scientists, users, consumers, businesses, regulators, and scientists, and highlights the use cases of XAI in detecting bias, scientific understanding, building robust models, and better decision making."
H. Bansal,Trust evaluation of websites: a comprehensive study,"People rely heavily on internet to fulfil even the minuscule of their need. According to a survey, 41% of time spent on web is for finding some information from search engines or reading some information. This is majorly due to easily accessible, cost effective and perceived high value information. But, this perceived high value information can prove fatal, if consumed without any authoritarian checks; especially if related to issues like health. Some template is necessitated to measure trustworthiness of such information. This paper explores a novel approach to quantify trust in such information-led websites. Analytical data is collected for various informational websites using similarweb.com and trust is modelled for these websites using human behaviour as an aggregate. Analytical data is believed to capture actual behaviour of each and every visitor visiting the website for information; thus making the study reliable and dependable. Results have been compared with some other acceptable studies and have found to be encouraging.","user satisfaction, medical trust, online interaction, health information, web analytics, trustworthiness, search engine optimization, web trust, social networks, content trust, trust","The paper discusses the concept of trust in social networks and its application in evaluating the trustworthiness of websites. It explores various aspects of trust, including its propagative nature, aggregative nature, subjective nature, asymmetric nature, and self-reinforcing nature. The authors also examine different approaches to trust representation, information sources, and trust evaluation models. The paper concludes by highlighting the importance of trust in search engine optimization and proposes a methodology for quantifying trust using web analytical tools."
H. Bay,Unique Local Features in Lip Images for Recognition,"The experiments are carried out from images taken with a camera that is used for the regular use. And the color features of a lip are not explored in the proposed research. Still the recognition system exploits the grayscale local features of a lip images and eﬃciently matches it with local features of another lip image. If the color properties of a lip image is explored for recognition along with local features, the accuracy values would increase further.","grayscale features, Lip Pattern Recognition, SIFT, lip recognition, color features, Biometric, Local Feature Extraction, local features, SURF",The paper presents the results of experiments on lip recognition using local features. The recognition system exploits the grayscale local features of lip images and achieves high accuracy. The authors suggest that exploring color properties of lip images could further improve the accuracy.
H. Cui,Secure Robust and Imperceptible Algorithm for Watermarking Relational Databases,"This paper proposes a secure robust and imperceptible algorithm for watermarking relational databases. The algorithm divides the embedding algorithm into three phases: Watermark preparator, watermark position detector, and watermark embedder. The ownership identification issue is resolved by embedding owner's identity as watermark in Preparator phase.","imperceptible algorithm, Ownership identification, robust algorithm, Relational Database, watermarking, Watermark, Copyright protection, Proof of ownership, relational databases","The paper proposes a new robust secure and imperceptible embedding mechanism to resolve the two important concerns namely; owner identification and proof of ownership. The proposed mechanism involves encoding and decoding on numerical attribute of relational database in three phases; 1)Watermark preparator, 2)Watermark position detector and 3) Watermark Embedder or Detector."
H. El-Sayed,"Edge of Things: The Big Picture on the Integration of Edge, IoT and the Cloud in a Distributed Computing Environment","A centralized infrastructure system carries out existing data analytics and decision-making processes from our current highly virtualized platform of wireless networks and the Internet of Things (IoT) applications. There is a high possibility that these existing methods will encounter more challenges and issues in relation to network dynamics, resulting in a high overhead in the network response time, leading to latency and traffic. In order to avoid these problems in the network and achieve an optimum level of resource utilization, a new paradigm called edge computing (EC) is proposed to pave the way for the evolution of new age applications and services.","edge computing, multi-cloud, fog computing, cloud computing, IoT","This paper aims to validate the efficiency and resourcefulness of edge computing (EC) by extensively surveying edge systems and presenting a comparative study of cloud computing systems. The results show that EC systems perform better than cloud computing systems, and the research challenges in implementing an EC system and future research directions are discussed."
H. F. Hsiao,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
H. Gao,Cost Eﬀective Inﬂuence Maximisation,"In the context of virality prediction, many researchers have leveraged the existence of a core-periphery structure in a network to identify the super-spreaders of information. Topologically, the nodes in the core of a network are the most eﬃcient spreaders. However, these nodes are less susceptible, i.e., unlikely to be inﬂuenced by the periphery nodes. Consequently, large payoﬀs are required to market information (ideas, products, memes, etc.) via them. In this paper, we show the presence of several non-core nodes whose spreading power is close to that of the core nodes.","Virality, Inﬂuence maximisation, Information diﬀusion, cost-effective, Core-periphery structure, information diffusion, social networks, influence maximisation","This paper proposes a cost-eﬀective strategy to make a meme reach the super-spreaders without the need for global information. The proposed hill-climbing based strategy can be eﬀectively used with both, global as well as local characteristics of the nodes in a network. In terms of the cost metric, it outperforms the conventional independent cascade model by more than 5 times for the core and 2 times for the non-core super-spreaders."
H. Haddadi,Cost Eﬀective Inﬂuence Maximisation,"In the context of virality prediction, many researchers have leveraged the existence of a core-periphery structure in a network to identify the super-spreaders of information. Topologically, the nodes in the core of a network are the most eﬃcient spreaders. However, these nodes are less susceptible, i.e., unlikely to be inﬂuenced by the periphery nodes. Consequently, large payoﬀs are required to market information (ideas, products, memes, etc.) via them. In this paper, we show the presence of several non-core nodes whose spreading power is close to that of the core nodes.","Virality, Inﬂuence maximisation, Information diﬀusion, cost-effective, Core-periphery structure, information diffusion, social networks, influence maximisation","This paper proposes a cost-eﬀective strategy to make a meme reach the super-spreaders without the need for global information. The proposed hill-climbing based strategy can be eﬀectively used with both, global as well as local characteristics of the nodes in a network. In terms of the cost metric, it outperforms the conventional independent cascade model by more than 5 times for the core and 2 times for the non-core super-spreaders."
H.M. Joshi,Impact of Eurasian Snow Cover on Indian Summer Monsoon Rainfall over the Northwestern Himalayas,"The entire Indo-Himalayan region from northwest (Kashmir) to northeast (Assam) is facing prevalence of floods and landslides in recent years causing massive loss of property, human and animal lives, infrastructure, and eventually threatening tourist activities substantially. Extremely intense rainfall event of A.D. 2013 (between 15 and 17 June) kicked off mammoth flash floods in the Kedarnath area of Uttarakhand state, resulting in huge socioeconomic losses to the state and country.","Eurasian snow cover, extreme rainfall events, flash floods, gridded data sets, Himalayas, Arctic Oscillation, northwestern Himalayas, Indian summer monsoon rainfall","The study investigates ~100-year-long monthly rainfall and air temperature time series data for a selected grid covering most parts of Uttarakhand state. The results indicate that under warming scenario, JJ rainfall (over AS) may further increase with occasional extreme rainfall spells when AO index (March) is negative."
HESHAM EL-SAYED,IoT-Based Wireless Polysomnography Intelligent System for Sleep Monitoring,"Polysomnography (PSG) is considered the gold standard in the diagnosis of obstructive sleep apnea (OSA). The diagnosis of OSA requires an overnight sleep experiment in a laboratory. However, due to limitations in relation to the number of labs and beds available, patients often need to wait a long time before being diagnosed and eventually treated. In addition, the unfamiliar environment and restricted mobility when a patient is being tested with a polysomnogram may disturb their sleep, resulting in an incomplete or corrupted test. Therefore, it is posed that a PSG conducted in the patient’s home would be more reliable and convenient. The Internet of Things (IoT) plays a vital role in the e-Health system. In this paper, we implement an IoT-based wireless polysomnography system for sleep monitoring, which utilizes a battery-powered, miniature, wireless, portable, and multipurpose recorder. A Java-based PSG recording program in the personal computer is designed to save several bio-signals and transfer them into the European data format. These PSG records can be used to determine a patient’s sleep stages and diagnose OSA. This system is portable, lightweight, and has low power-consumption. To demonstrate the feasibility of the proposed PSG system, a comparison was made between the standard PSG-Alice 5 Diagnostic Sleep System and the proposed system. Several healthy volunteer patients participated in the PSG experiment and were monitored by both the standard PSG-Alice 5 Diagnostic Sleep System and the proposed system simultaneously, under the supervision of specialists at the Sleep Laboratory in Taipei Veteran General Hospital. A comparison of the results of the time-domain waveform and sleep stage of the two systems shows that the proposed system is reliable and can be applied in practice. The proposed system can facilitate the long-term tracing and research of personal sleep monitoring at home.","sleep monitoring, wireless, Internet of Things, wireless PSG, JAVA, Polysomnography (PSG), IoT","This paper proposes an IoT-based wireless polysomnography system for sleep monitoring, which utilizes a battery-powered, miniature, wireless, portable, and multipurpose recorder. The system is designed to save several bio-signals and transfer them into the European data format, allowing for the determination of a patient’s sleep stages and diagnosis of OSA. The proposed system is compared to the standard PSG-Alice 5 Diagnostic Sleep System and shows reliable results, making it a viable option for long-term tracing and research of personal sleep monitoring at home."
Hadi Saboohi,A comparative study of testing semantic web services,"Web Services provide efficient reusability mechanism, thereby reducing the development time and cost. Mostly the source code of web services is unavailable to other developers who use these services. The manual effort spent by them in testing these web services is very large in order to increase the interoperability. Thus, automated testing needs to be developed for testing these Web services. This paper reviews test cases for Web Services using reduction techniques Pair-Wise Testing (PWT) and Orthogonal Array Testing (OAT) and compares the two techniques with general method. The structure of Web Services is specified using UML diagrams. The pre and post conditions for the service rule are specified using Object Constraint Language (OCL). The framework transforms into WSDL-S specifications. These specifications are parsed and transformed into structured DOM tree. Test data set generated by this framework would satisfy the constraints of the WSDL. The test cases are then developed based on the data generated, documented in XML based test files. The number of test cases required by general testing, PWT, OAT are compared and the better testing technique for testing Web Services is determined.","Semantics, Reduction Techniques, Reduction, Test case, Web Services, Pair wise, Orthogonal Array Testing, web service, Test Cases, Pair-Wise Testing, Orthogonal Array","This paper compares Pair-Wise Testing (PWT) and Orthogonal Array Testing (OAT) for reducing the number of test cases needed for Web Services. It finds that OAT is more efficient when dealing with a large number of parameters, while PWT is suitable for smaller sets of parameters. Both techniques significantly reduce the testing effort compared to a general approach."
Hafemann et al.,Deformation Adjustment with Single Real Signature Image for Biometric Verification Using CNN,"Signature verification is the widely used biometric verification method for maintaining individual privacy. It is generally used in legal documents and in financial transactions. A vast range of research has been done so far to tackle different system issues, but there are various hot issues that remain unaddressed. The scale and orientation of the signatures are some issues to address, and the deformation of the signature within the genuine examples is the most critical for the verification system.","biometric authentication, Single real signature image, soft biometrics, deep learning, hard biometrics, CNN, Signature verification, Deformation adjustment, Biometric verification, writer-independent","This work proposes a two-phase system requiring only one target signature image to verify a query signature image. It takes care of the target signature's scaling, orientation, and spatial translation in the first phase. The second phase uses this transformed sample image and verifies the given sample as the target signature with the help of another deep neural network."
Hai-Jun Rong,A fast pruned-extreme learning machine for classification problem,"Extreme learning machine (ELM) represents one of the recent successful approaches in machine learning, particularly for performing pattern classification. One key strength of ELM is the significantly low computational time required for training new classifiers since the weights of the hidden and output nodes are randomly chosen and analytically determined, respectively.","Extreme learning machine (ELM), Feedforward networks, Pruned ELM, Statistical Relevance Measures, Extreme Learning Machine, Pattern classification, Generalization Ability, Hidden Node Size",This paper presents a pruned-ELM (P-ELM) algorithm as a systematic and automated approach for designing ELM classifier network. P-ELM uses statistical methods to measure the relevance of hidden nodes and provides a systematic approach for designing the network architecture of the ELM classifier.
Haitao Liu,Scalable GPs,"The vast quantity of information brought by big data as well as the evolving computer hardware encourages success stories in the machine learning community. In the meanwhile, it poses challenges for the Gaussian process (GP) regression, a well-known non-parametric and interpretable Bayesian model, which suffers from cubic complexity to data size. To improve the scalability while retaining desirable prediction quality, a variety of scalable GPs have been presented. But they have not yet been comprehensively reviewed and analyzed in order to be well understood by both academia and industry.","big data, Scalable GPs, local approximations, Gaussian Processes, Gaussian process regression, sparse approximations, scalability","This paper reviews state-of-the-art scalable GPs involving two main categories: global approximations which distillate the entire data and local approximations which divide the data for subspace learning. Recent advances for improving the scalability and capability of scalable GPs are reviewed. Finally, the extensions and open issues regarding the implementation of scalable GPs in various scenarios are reviewed and discussed to inspire novel ideas for future research avenues."
Hall et al.,Characterizing relatedness of web and requirements engineering,"Web and Requirements Engineering have been well-recognized as two individual active areas of research in the past. Convergence between these two notable areas has been a point-of-discussion in recent years and offers new avenues of research. This paper explores this alliance from two perspectives; firstly, where Requirement Engineering can be viewed as a process for Web application development as it primarily concerns with adapting the Requirement Engineering process to the Web applications which are special in characteristics as compared to traditional software applications and secondly, where Web can be viewed as a supporting technology for improving the requirements engineering process and enabling new capabilities.","Web Applications, Web 3.0, Web 2.0, SWOT Analysis, Web application, Requirements engineering","The paper explores the relationship between Web and Requirements Engineering from two perspectives, highlighting the need for a more extensive and efficient Requirements Engineering process for Web applications, and the potential of Web technologies to support and improve the requirements engineering process."
"Hall, L. O.",A Multi-Task Approach to Open Domain Suggestion Mining,"Consumer reviews online may contain suggestions useful for improving the target products and services. Mining suggestions is challenging because the field lacks large labelled and balanced datasets. Furthermore, most prior studies have only focused on mining suggestions in a single domain. In this work, we introduce a novel up-sampling technique to address the problem of class imbalance, and propose a multi-task deep learning approach for mining suggestions from multiple domains.","Deep Learning, Suggestion Mining, Artificial Intelligence, Class Imbalance, Multi-Task Learning","This paper presents a multi-task approach to open domain suggestion mining, addressing the class imbalance problem using a novel up-sampling technique and a multi-task deep learning framework. Experimental results show that the proposed approach outperforms state-of-the-art models in terms of F-1 measure and AUC."
Halvey & Keane,Typeface size and weight and word location inüluence on relative size judgments in tag clouds,"This paper focuses on viewers’ perception of the relative size of words presented in tag clouds. Tag clouds are a type of visualization that displays the contents of a document as a cluster (cloud) of key words (tags) with frequency (importance) indicated by tag word features such as size or color, with variation of size within a tag cloud being the most common indicator of tag importance. Prior studies have shown that word size is the most inüluential factor of tag importance and tag memory. Systematic biases in relative size perception in tag clouds are therefore likely to have important implications for viewer understanding of tag cloud visualizations.","layout, typeface size, size judgment, perception, psychophysics, perceptual biases, tag cloud, search tasks, tag clouds","The study focuses on documenting systematic biases in relative size judgment in tag clouds while varying typeface weight and the location of the target tag word pair under comparison. The results provide a first report of systematic biases in relative size judgment in tag clouds, suggest that simple power-law scaling models developed for simple displays containing 1-2 objects on a blank background, may be applicable to relative size judgments in complex tag clouds."
"Han, S. H., & Kim, J. H. (2004)",Quantum-inspired evolutionary approach for selection of optimal parameters of fuzzy clustering,"Recently, Fuzzy c-Means (FCM) algorithm is most widely used because of its efficiency and simplicity. However, FCM is sensitive to the initialization of fuzziness factor (m) and the number of clusters (c) due to which it easily trapped in local optima. A selection of these parameters is a critical issue because an adverse selection can blur the clusters in the data.","Fuzzy clustering, Cluster validity index, Quantum-Inspired Evolutionary Fuzzy c-Means, Fuzzy c-Means algorithm, Fuzzy c-Means, Quantum computing","This paper proposes a hybrid fuzzy clustering algorithm, Quantum-Inspired Evolutionary Fuzzy c-Means (QIE–FCM), which uses the merits of quantum computing for finding the global optimal value of m and its corresponding value of c in the FCM. The proposed approach improves the way of initialization of the fuzziness factor (m) in the FCM and provides the diversity in selecting the optimal value of m and c from a large quantum search space."
Hans India News,Agriculture Extension System in India: A Meta-analysis,"Agriculture extension system bridges the gap between research labs to a farmer’s field. Agricultural research, education and extension are said to be the most critical for promoting farm productivity and enhancing farmer’s income. The public sector is major extension service provider and the reach of the public extension is limited in India and in addition it is burdened with non-extension responsibilities such as the distribution of subsidies and inputs, with little time left to attend to core extension activities.","Investment, Extension approaches, Farmers Producers' Organizations, India, Agriculture extension, Meta analysis, ICT, Manpower","The article reviews the agricultural extension system in India to suggest pathways for better extension system in India. The public extension services are highly skewed towards crop husbandry ignoring allied sectors in India. The growth in the High-Value Agriculture sector has been twice or sometimes even thrice that of the crop production. However, Agriculture extension services for such sectors almost nil or unorganized."
Hans Lassmann,Cutting Edge: CD8 T Cell-Mediated Demyelination ||| Myelin-speciﬁc T cells also recognize neuronal autoantigen in a transgenic mouse model of multiple sclerosis,"We generated mice (DKI) in which the HA coding sequence was introduced in the ubiquitously active Rosa26 locus but where HA transcription was prevented by an upstream LoxP-flanked Stop cassette. The DKI mice were then crossed with the MOGi-Cre mice, which express Cre specifically in oligodendrocytes. The resulting DKI mice excise the Stop cassette due to MOG-controlled Cre expression, leading to restricted HA expression to oligodendrocytes.  We then decided to test whether effector CD8 T cells can mediate oligodendrocyte cell death and demyelination in vivo. Effector T cells were first generated by in vitro activation of Kd:HA512–520 pentamer-specific CD8 T cells obtained from CL4-TCR mice using HA peptide, IL-2, and IL-12. The resulting Tc1 cells produce large amounts of granzyme B (GrB) and IFN-γ and exhibit potent cytotoxicity to HA-loaded target cells in vivo. Next, we transferred these HA-specific Tc1 cells into DKI and control mice. Following i.v. injection of 3 × 107 HA-specific Tc1 cells, but not naive HA-specific CD8 T cells, ~40% of the DKI mice developed an overt monophasic disease peaking at day 8–10 and waning by 4 wk posttransfer. The clinical manifestations included weight loss and, in the more severe cases, tremors, reduced mobility, and difficulty to right when overturned without overt paralysis. Upon histological analysis, all DKI mice injected with Tc1 cells demonstrated clear CNS pathology from day 5 onwards. Inflammatory lesions were never found in control littermates injected in parallel with HA-specific Tc1 cells. ||| We describe here the paradoxical development of spontaneous experimental autoimmune encephalomyelitis (EAE) in transgenic mice expressing a myelin oligodendrocyte glycoprotein (MOG)-speciﬁc T cell antigen receptor (TCR) in the absence of MOG. We report that in Mog-deﬁcient mice (Mog–/–), the autoimmune response by transgenic T cells is redirected to a neuronal cytoskeletal self antigen, neuroﬁlament-M (NF-M). Although components of radically different protein classes, the cross-reacting major histocompatibility complex I-Ab–restricted epitope sequences of MOG35–55 and NF-M18–30 share essential TCR contact positions. This pattern of cross-reaction is not speciﬁc to the transgenic TCR but is also commonly seen in MOG35–55–I-Ab–reactive T cells. We propose that in the C57BL/6 mouse, MOG and NF-M response components add up to overcome the general resistance of this strain to experimental induction of autoimmunity. Similar cumulative responses against more than one autoantigen may have a role in spontaneously developing human autoimmune diseases.",,"This study investigates the role of CD8 T cells in multiple sclerosis (MS) pathogenesis. Researchers generated a mouse model where a model antigen (influenza hemagglutinin) is expressed specifically in oligodendrocytes, the cells responsible for producing myelin in the central nervous system. Transferring activated CD8 T cells specific for this antigen into these mice resulted in inflammatory lesions in the brain, spinal cord, and optic nerve, resembling active MS lesions. These lesions were characterized by CD8 T cell infiltration, loss of oligodendrocytes, demyelination, and microglia activation. This suggests that CD8 T cells can directly contribute to oligodendrocyte death and demyelination in MS, highlighting their potential as therapeutic targets. ||| This study reports the unexpected finding that transgenic mice expressing a myelin oligodendrocyte glycoprotein (MOG)-specific T cell receptor (TCR) develop spontaneous experimental autoimmune encephalomyelitis (EAE) even in the absence of MOG. The researchers discovered that these mice redirect their autoimmune response to a neuronal cytoskeletal protein called neuroﬁlament-M (NF-M). This cross-reactivity between MOG and NF-M is mediated by shared TCR contact positions on their respective epitope sequences. The study suggests that cumulative responses against multiple autoantigens, such as MOG and NF-M, may contribute to the development of spontaneous autoimmune diseases in humans."
Hao Yin,Chaos in fractional-order discrete neural networks with application to image encryption,"In this paper, a three-dimensional fractional-order (FO) discrete Hopfield neural network (FODHNN) in the left Caputo discrete delta’s sense is proposed, the dynamic behavior and synchronization of FODHNN are studied, and the system is applied to image encryption. First, FODHNN is shown to exhibit rich nonlinear dynamics behaviors. Phase portraits, bifurcation diagrams and Lyapunov exponents are carried out to verify chaotic dynamics in this system. Moreover, by using stability theorem of FO discrete linear systems, a suitable control scheme is designed to achieve synchronization of the FODHNN. Finally, image encryption system based on the chaotic FODHNN is presented. Some security analysis and tests are given to show the effective of the encryption system.","Fractional-order discrete Hopfield neural networks, Lyapunov exponent, Chaotic dynamics, Fractional-order discrete systems, Synchronization, Image encryption, Jacobian matrix algorithm, Neural networks","This paper presents a chaotic dynamics analysis of fractional-order discrete Hopfield neural networks (FODHNNs). The FODHNNs are derived from a 3D-neuron fractional-order continuous Hopfield-type neural networks proposed in Zhang, Qi, and Wang (2010). The dynamic behavior, synchronization, and image encryption application of FODHNNs are explored. Numerical solutions of FODHNNs are needed to be presented. The maximum Lyapunov exponent (LE) of the dynamical system is an important index that characterizes the rate of separation of infinitesimally close trajectories. The Jacobian matrix algorithm for Lyapunov exponents of the discrete fractional maps proposed in Wu and Baleanu (2015b) is employed to calculate the LE of FODHNNs."
Hardik Patel,Multifunctional HUD with Drowsy Detection and Fog Elimination Mechanism,"People are conscious of the risk of drinking and driving but don't realize the danger of drowsiness. Prior state of art reveals very little work on designing the automated system that measures the driver drowsiness. Our research lodge a system for the drivers and travelers who drive various means of transportation and alerts them when a driver is in a drowsy state. We have amalgamated the HUD (Head-up Display) facilities, drowsy detection system, and fog elimination system altogether to help the driver reach the destination safely by providing navigation, visual indication and many useful applications of mobile phones on HUD. Experimental results reveal that our proposed system is superior to existing HUDs and provide more features for the benefit of drivers.","Facial landmark detection, Fog Elimination, Head-Up Display, Drowsy detection, Drowsiness Detection, Night vision Infrared (IR) camera, Head-Up Display (HUD), OpenCV","The proposed system is a smart camera that uses machine learning algorithm to detect drowsiness in drivers. It captures the face of the driver using a Night vision Infrared (IR) camera and detects the eyes using facial landmark detection technique. The system generates an alert and alarm if the eyes are closed for more than 5 seconds, making it a safe and efficient way to detect drowsiness in drivers."
Hardin et. al.,Rumour Source Detection Using Game Theory,"Social networks have become a critical part of our lives as they enable us to interact with a lot of people. These networks have become the main sources for creating, sharing and also extracting information regarding various subjects. But all this information may not be true and may contain a lot of unverified rumours that have the potential of spreading incorrect information to the masses, which may even lead to situations of widespread panic. Thus, it is of great importance to identify those nodes and edges that play a crucial role in a network in order to find the most influential sources of rumour spreading. Generally, the basic idea is to classify the nodes and edges in a network with the highest criticality. Most of the existing work regarding the same focuses on using simple centrality measures which focus on the individual contribution of a node in a network. Game-theoretic approaches such as Shapley Value (SV) algorithms suggest that individual marginal contribution should be measured for a given player as the weighted average marginal increase in the yield of any coalition that this player might join. For our experiment, we have played five SV-based games to find the top 10 most influential nodes on three network datasets (Enron, USAir97 and Les Misérables). We have compared our results to the ones obtained by using primitive centrality measures. Our results show that SV-based approach is better at understanding the marginal contribution, and therefore the actual influence, of each node to the entire network.","influential nodes, Jaccard Similarity Coefficient, cooperative game, Rumour Source Detection (RSD), centrality measures, network analysis, Shapley Value (SV), Game-Theory, Network Centrality",This paper aims to identify the most influential nodes in a network that are the primary sources of rumour propagation. The authors propose a game-theoretic approach using the Shapley Value algorithm to find the most influential nodes. They compare their results with primitive centrality measures and show that the SV-based approach is better at understanding the marginal contribution of each node to the entire network.
Harish Sharma,Artificial Bee Colony (ABC) Algorithm ||| Opposition based lévy ﬂight artiﬁcial bee colony ||| Spider Monkey Optimization algorithm for numerical optimization,"Artificial bee colony (ABC) optimisation algorithm is a relatively simple and recent population-based probabilistic approach for global optimisation. The solution search equation of ABC is significantly influenced by a random quantity which helps in exploration at the cost of exploitation of the search space. In the ABC, there is a high chance to skip the true solution due to its large step sizes. In order to balance between diversity and convergence in the ABC, a Lévy flight inspired search strategy is proposed and integrated with ABC. The proposed strategy is named as Lévy Flight ABC (LFABC) has both the local and global search capability simultaneously and can be achieved by tuning the Lévy flight parameters and thus automatically tuning the step sizes. ||| Artiﬁcial Bee Colony (ABC) is a well known optimization approach to solve nonlinear and complex prob-lems. It is relatively a simple and recent population based probabilistic approach for global optimization. Similar to other population based algorithms, ABC is also computa-tionally expensive due to its slow nature of search process. The solution search equation of ABC is signiﬁcantly inﬂu-enced by a random quantity which helps in exploration at the cost of exploitation of the search space. In the solution search equation of ABC due to the large step size the chance of skipping the true solution is high. Therefore, in this paper, to balance the diversity and convergence capability of the ABC, Lévy Flight random walk based local search strategy is proposed and incorporated with ABC along with opposition based learning strategy. The proposed algorithm is named as Opposition Based Lévy Flight ABC. The experiments over 14 un-biased test problems of different complexities and ﬁve well known engineering optimization problems show that the proposed algorithm outperforms the basic ABC and its recent variants namely Gbest guided ABC, Best-So-Far ABC, and Modiﬁed ABC in most of the experiments. ||| Swarm intelligence is one of the most promising area for the researchers in the field of numerical optimization. Researchers have developed many algorithms by simulating the swarming behavior of various creatures like ants, honey bees, fish, birds and the findings are very motivating. In this paper, a new approach for numerical optimization is proposed by modeling the foraging behavior of spider monkeys.","ABC algorithm, numerical optimisation, Evolutionary computation, Optimisation, Lévy Flight, stochastic optimization, Fission–fusion social system, Spider Monkey Optimization algorithm, Honey bees, convergence speed, local search, Food foraging, Spider monkey optimization, Optimization, Swarm intelligence based algorithm, Memetic algorithm, computational complexity, fission-fusion social structure, Artificial Bee Colony, Lévy flight local search, Swarm intelligence, Lévy ﬂight local search, swarm intelligence, Artificial Bee Colony algorithm, foraging behavior, memetic algorithm","This paper proposes a Lévy flight inspired search strategy to balance between diversity and convergence in the artificial bee colony (ABC) optimisation algorithm. The proposed strategy, named as Lévy Flight ABC (LFABC), has both local and global search capability simultaneously and can be achieved by tuning the Lévy flight parameters. The performance of the proposed strategy is analysed over test problems and five real-world engineering optimisation problems. ||| This paper proposes a new algorithm called Opposition Based Lévy Flight ABC, which combines the Lévy Flight random walk based local search strategy with the opposition based learning strategy. The algorithm is designed to balance the diversity and convergence capability of the ABC. The experiments show that the proposed algorithm outperforms the basic ABC and its recent variants in most of the experiments. ||| This paper proposes a new swarm intelligence algorithm based on the foraging behavior of spider monkeys. The foraging behavior of spider monkeys shows that these monkeys fall in the category of fission–fusion social structure (FFSS) based animals. Thus the proposed optimization algorithm which is based on foraging behavior of spider monkeys is explained better in terms of FFSS."
Harsh Kumar,EXPERIMENTAL STUDY OF REGENERATIVE BRAKING SYSTEM (RBS),"In this era, the automobile sector is facing a major challenge to reduce consumption of fuel and greenhouse gases emission, this is often because limited fuel reserves and continuous degrade in air quality. An experimental setup is made for the current study to reduce the loss of energy by reusing it. In this present study, an alternator is connected to the driver shaft through chain and sprocket. When brakes are applied to slow the vehicle down or make it come to a halt, the alternator is activated with an electromagnetic clutch, and the energy lost during braking is utilized to generate electrical energy.","Generator, Automobile, Regenerative braking, Electromagnetic clutch, Energy recovery system","This paper presents an experimental study of regenerative braking system (RBS) to reduce energy loss during braking. An experimental setup is designed to reuse the energy lost during braking by activating an alternator with an electromagnetic clutch. The study shows that 16.32% of brake energy was recovered, and the current from the alternator increases with engine speed."
Hartmut Wekerle,Myelin-speciﬁc T cells also recognize neuronal autoantigen in a transgenic mouse model of multiple sclerosis,"We describe here the paradoxical development of spontaneous experimental autoimmune encephalomyelitis (EAE) in transgenic mice expressing a myelin oligodendrocyte glycoprotein (MOG)-speciﬁc T cell antigen receptor (TCR) in the absence of MOG. We report that in Mog-deﬁcient mice (Mog–/–), the autoimmune response by transgenic T cells is redirected to a neuronal cytoskeletal self antigen, neuroﬁlament-M (NF-M). Although components of radically different protein classes, the cross-reacting major histocompatibility complex I-Ab–restricted epitope sequences of MOG35–55 and NF-M18–30 share essential TCR contact positions. This pattern of cross-reaction is not speciﬁc to the transgenic TCR but is also commonly seen in MOG35–55–I-Ab–reactive T cells. We propose that in the C57BL/6 mouse, MOG and NF-M response components add up to overcome the general resistance of this strain to experimental induction of autoimmunity. Similar cumulative responses against more than one autoantigen may have a role in spontaneously developing human autoimmune diseases.",,"This study reports the unexpected finding that transgenic mice expressing a myelin oligodendrocyte glycoprotein (MOG)-specific T cell receptor (TCR) develop spontaneous experimental autoimmune encephalomyelitis (EAE) even in the absence of MOG. The researchers discovered that these mice redirect their autoimmune response to a neuronal cytoskeletal protein called neuroﬁlament-M (NF-M). This cross-reactivity between MOG and NF-M is mediated by shared TCR contact positions on their respective epitope sequences. The study suggests that cumulative responses against multiple autoantigens, such as MOG and NF-M, may contribute to the development of spontaneous autoimmune diseases in humans."
Heike Fassbender,Preconditioned Iterative Solves in Model Reduction,"This paper proposes the use of preconditioned iterative methods for solving linear systems in model reduction. The authors discuss the importance of preconditioning in improving the performance of iterative methods and present a new preconditioner, the Sparse Approximate Inverse (SPAI) preconditioner. They also discuss the use of SPAI preconditioner in the Adaptive Iterative Rational Global Arnoldi Algorithm (AIRGA) and present results showing the effectiveness of the proposed method.","Global Arnoldi Algorithm, Model Order Reduction, Sparse Approximate Inverse (SPAI) preconditioner, Preconditioned iterative methods, Model reduction, Preconditioner and Stability Analysis, Iterative Methods, Moment Matching, Adaptive Iterative Rational Global Arnoldi Algorithm (AIRGA), Linear systems","This paper focuses on efficiently solving linear systems arising in the model reduction process using iterative methods and preconditioners. The authors propose the use of relevant iterative algorithms and the Sparse Approximate Inverse (SPAI) preconditioner, and provide a technique to cheaply update the SPAI preconditioner in each iteration step."
Helena S Domingues,Myelin-speciﬁc T cells also recognize neuronal autoantigen in a transgenic mouse model of multiple sclerosis,"We describe here the paradoxical development of spontaneous experimental autoimmune encephalomyelitis (EAE) in transgenic mice expressing a myelin oligodendrocyte glycoprotein (MOG)-speciﬁc T cell antigen receptor (TCR) in the absence of MOG. We report that in Mog-deﬁcient mice (Mog–/–), the autoimmune response by transgenic T cells is redirected to a neuronal cytoskeletal self antigen, neuroﬁlament-M (NF-M). Although components of radically different protein classes, the cross-reacting major histocompatibility complex I-Ab–restricted epitope sequences of MOG35–55 and NF-M18–30 share essential TCR contact positions. This pattern of cross-reaction is not speciﬁc to the transgenic TCR but is also commonly seen in MOG35–55–I-Ab–reactive T cells. We propose that in the C57BL/6 mouse, MOG and NF-M response components add up to overcome the general resistance of this strain to experimental induction of autoimmunity. Similar cumulative responses against more than one autoantigen may have a role in spontaneously developing human autoimmune diseases.",,"This study reports the unexpected finding that transgenic mice expressing a myelin oligodendrocyte glycoprotein (MOG)-specific T cell receptor (TCR) develop spontaneous experimental autoimmune encephalomyelitis (EAE) even in the absence of MOG. The researchers discovered that these mice redirect their autoimmune response to a neuronal cytoskeletal protein called neuroﬁlament-M (NF-M). This cross-reactivity between MOG and NF-M is mediated by shared TCR contact positions on their respective epitope sequences. The study suggests that cumulative responses against multiple autoantigens, such as MOG and NF-M, may contribute to the development of spontaneous autoimmune diseases in humans."
Hesham El-Sayed,Accurate Trafﬁc Flow Prediction in Heterogeneous Vehicular Networks in an Intelligent Transport System Using a Supervised Non-Parametric Classiﬁer,"Heterogeneous vehicular networks (HETVNETs) evolve from vehicular ad hoc networks (VANETs), which allow vehicles to always be connected so as to obtain safety services within intelligent transportation systems (ITSs). The services and data provided by HETVNETs should be neither interrupted nor delayed. Therefore, Quality of Service (QoS) improvement of HETVNETs is one of the topics attracting the attention of researchers and the manufacturing community.","QoS, SVM, Radial Basis Function, Prediction Accuracy, RBF, internet of vehicles, Support Vector Machines, HETVNET, Vehicular Ad Hoc Network",This paper proposes a prediction model based on support vector machines (SVMs) to improve Quality of Service (QoS) in Heterogeneous Vehicular Networks (HETVNETs). The model uses a radial basis function (RBF) kernel and outperforms other prediction methods in terms of accuracy and computational complexity.
Het Naik,Title Suppressed Due to Excessive Length,"The objective of an online Mart is to match buyers and sellers, to weigh animals and to oversee their sale. A reliable pricing method can be developed by ML models that can read through historical sales data. However, when AI models suggest or recommend a price, that in itself does not reveal too much (i.e., it acts like a black box) about the qualities and the abilities of an animal. An interested buyer would like to know more about the salient features of an animal before making the right choice based on his requirements. A model capable of explaining the different factors that impact the price point is essential for the needs of the market. It can also inspire confidence in buyers and sellers about the price point offered.","Explainable AI, weight estimation, cow, vision based feature extraction, machine learning, Internet of Things, computer vision, ML based price prediction, Video Analytics","The paper discusses a method for estimating the weight of cows using a machine learning approach. The method involves training a model to predict the weight of cows based on images of their faces. However, the paper notes that the face of a cow is not sufficient for weight estimation and that the model can get biased according to color. The paper also discusses the limitations of the approach and suggests future directions for research."
"Hey, A. J. G. (1999)",Quantum-inspired evolutionary approach for selection of optimal parameters of fuzzy clustering,"Recently, Fuzzy c-Means (FCM) algorithm is most widely used because of its efficiency and simplicity. However, FCM is sensitive to the initialization of fuzziness factor (m) and the number of clusters (c) due to which it easily trapped in local optima. A selection of these parameters is a critical issue because an adverse selection can blur the clusters in the data.","Fuzzy clustering, Cluster validity index, Quantum-Inspired Evolutionary Fuzzy c-Means, Fuzzy c-Means algorithm, Fuzzy c-Means, Quantum computing","This paper proposes a hybrid fuzzy clustering algorithm, Quantum-Inspired Evolutionary Fuzzy c-Means (QIE–FCM), which uses the merits of quantum computing for finding the global optimal value of m and its corresponding value of c in the FCM. The proposed approach improves the way of initialization of the fuzziness factor (m) in the FCM and provides the diversity in selecting the optimal value of m and c from a large quantum search space."
Himani Bansal,Cloud Computing: Different Approach & Security Challenge ||| On the Security of Authenticated Group Key Agreement Protocols,"Cloud computing has generated a lot of interest and competition in the industry and it is recognize as one of the top 10 technologies of 2010. It is an internet based service delivery model which provides internet based services, computing and storage for users in all market including financial, health care & government. In this paper we did systematic review on different types of clouds and the security challenges that should be solved. Cloud security is becoming a key differentiator and competitive edge between cloud providers. This paper discusses the security issues arising in different type of clouds. ||| The group key agreement protocol enables to derive a shared session key for the remote members to communicate securely. Recently, several attempts are made to utilize group key agreement protocols for secure multicasting in Internet of Things. This paper contributes to identify the security vulnerabilities in the existing protocols, to avoid them in future constructions. The protocols presented by Gupta and Biswas have been found insecure to ephemeral secret key leakage (ESL) attack and also, malicious insiders can impersonate an honest participant. Additionally, the protocol presented by Tan is also ESL-insecure. We also present a fix to the Tan’s protocol to make it secure.","Insider security, Security Protocols, Authenticated Group Key Agreement, Cloud, Cloud computing, Security challenges, Group key agreement, Authentication, Mutual authentication, Security, Elliptic Curve Cryptography","This paper discusses the security issues arising in different types of clouds, including personal clouds, general clouds, domain-specific clouds, and hybrid clouds. It highlights the security challenges that need to be solved in each type of cloud, such as compliance and auditing, intrusion detection, access control, and anti-virus/anti-malware protection. ||| This paper discusses the security vulnerabilities in existing group key agreement protocols and presents a fix to one of the protocols to make it secure. The authors identify the security vulnerabilities in the protocols presented by Gupta and Biswas and Tan, and present a fix to the Tan’s protocol to make it secure. The paper also discusses the importance of authentication and insider security in group key agreement protocols."
Himanshu Chaudhary,Transforming view of medical images using deep learning,"Since the last decade, there is a significant change in the procedure of medical diagnosis and treatment. Specifically, when internal tissues, organs such as heart, lungs, brain, kidneys and bones are the target regions, a doctor recommends ‘computerized tomography’ scan and/or magnetic resonance imaging to get a clear picture of the damaged portion of an organ or a bone. This is important for correct examination of the medical deformities such as bone fracture, arthritis, and brain tumor. It ensures prescription of the best possible treatment. But ‘computerized tomography’ scan exposes a patient to high ionizing radiation. These rays make a person more prone to cancer. Magnetic resonance imaging requires a strong magnetic field. Thus, it becomes impractical for patients with implants in their body. Moreover, the high cost makes the above-stated techniques unaffordable for low economy class of society. The above-mentioned challenges of ‘computerized tomography’ scan and magnetic resonance imaging motivate researchers to focus on developing a technique for conversion of 2-dimensional view of medical images into their corresponding multiple views. In this manuscript, the authors design and develop a deep learning model that makes an effective use of conditional generative adversarial network, an extension of generative adversarial network for the transformation of 2-dimensional views of human bone into the corresponding multiple views at different angles. The model will prove useful for both doctors and patients.","CT scan, 2-Dimensional, DCGAN, ACGAN, Deep learning, MRI, Conditional generative adversarial network, InfoGAN, CCAN, SGAN, SRGAN, Generative Adversarial Networks, 3-Dimensional, Image-to-Image Translation","The paper discusses the application of GANs in image-to-image translation and presents various techniques such as InfoGAN, SGAN, SRGAN, CCAN, DCGAN, and ACGAN. The paper highlights the advantages and disadvantages of each technique and provides a clear idea about the extension of the application area of the existing work."
Himanshu Mittal,A New Fuzzy Cluster Validity Index for Hyperellipsoid or Hyperspherical Shape Close Clusters With Distant Centroids ||| Chaotic Kbest gravitational search algorithm (CKGSA) ||| Classiﬁcation of Histopathological Images Through Bag-of-Visual-Words ||| Difö-Hellman Based Smart-Card Multi-server Authentication Scheme ||| Improved Gravitational Search Algorithm for COVID-19 Diagnosis ||| Map-reduce-based tournament empowered whale optimization algorithm for recommendation ||| Optimal keyframe selection-based lossless video-watermarking technique using IGSA in LWT domain for copyright protection ||| Source parameters and f max in lower Siang region of Arunachal lesser Himalaya ||| Technological Advancements in Automated Crop Pest and Disease Detection: A Review & Ongoing Research,"Determining the correct number of clusters is essential for efficient clustering and cluster validity indices are widely used for the same. Generally, the effectiveness of a cluster validity index relies on two factors: (i) separation, defined by the distance between a pair of cluster centroids or a pair of data points belonging to different clusters and (ii) compactness which is determined in terms of the distance between a data point and a centroid or between a pair of data points belonging to the same cluster. ||| Gravitational search algorithm is a popular adaptive search algorithm among nature-inspired algorithms and has been successfully used for optimizing many real-world problems. Gravitational search algorithm uses the law of Newton gravity for finding the optimal solution. The performance of gravitational search algorithm is controlled by exploration and exploitation capabilities and Kbest is one of its parameters that controls this trade-off. In this paper, a novel chaotic Kbest gravitational search algorithm has been proposed that uses the chaotic model in Kbest to balance the exploration and exploitation non-linearly. The proposed algorithm shows better convergence rate at later iterations with high precision and does not trap into local optima. ||| The automated quantiﬁcation of different cell structures available in histopathological images is a challenging task due to the presence of complex back-ground structures. Moreover, the tissues of different categories, namely epithelium tissue, connective tissue, muscular tissue, and nervous tissue have heterogeneous structure which limits the applicability of an algorithm to only a single class of tissue for the quantiﬁcation analysis of histopathological images. ||| A secure smart-card multi-server authentication scheme has been proposed using Diffie-Hellman, Hash-Function and XOR. The scheme made no use of verification table, or encryption techniques, or timestamps to generate a session key to provide secure communication between user and server and resists all possible security attacks, such as Man-in-the-Middle attack, Impersonation attack, Insider attack and many more. The scheme proved to be better when compared to Xie and Chen scheme in terms of security and performance. ||| This paper presents a novel variant of the gravitational search algorithm, improved gravitational search algorithm (IGSA), to enhance the vicinity to optimal solutions. The proposed variant is employed to obtain optimal clusters in the proposed clustering method for the CoVID19 diagnosis. An extensive experimental analysis of IGSA has been conducted against 16 metaheuristic algorithms over 17 standard benchmark functions belonging to unimodal and multimodal categories. The results are studied over four different dimensional settings, i.e. 10, 30, 50, and 90. ||| In the era of Web 2.0, the data are growing immensely and is assisting E-commerce websites for better decision-making. Collaborative filtering, one of the prominent recommendation approaches, performs recommendation by finding similarity. However, this approach fails in managing large-scale datasets. To mitigate the same, an efficient map-reduce-based clustering recommendation system is presented. The proposed method uses a novel variant of the whale optimization algorithm, tournament selection empowered whale optimization algorithm, to attain the optimal clusters. ||| Video piracy is a challenging issue in the modern world. Approximately 90% of newly released films were illegally distributed around the world via the Internet. To overcome this issue, video watermarking is an effective process that integrates a logo in video frames as a watermark. Therefore, this paper presents an efficient lossless video-watermarking scheme based on optimal keyframe selection using an intelligent gravitational search algorithm in linear wavelet transform. This technique obtains color motion and motionless frames from the cover video by the histogram difference method. One-level linear wavelet transform is performed on the chrominance channel of motion frames and a low-frequency sub-band LL opts for watermark embedding. The performance of the proposed technique has been evaluated against 12 video processing attacks in terms of imperceptibility and robustness. Experiments demonstrate that the proposed technique outperforms five state-of-the-art schemes on the considered attacks. ||| A data set of 60 local events (1.9≤Mw≤3.6) collected by a temporary digital network deployed in the Siang region of Arunachal Lesser Himalaya during July 2011 to February 2012 is analysed to study the source parameters and fmax. The software EQK_SRC_PARA (Kumar et al. in Int J Geosci 3(5):1142–1149, 2012) that considers Brune’s model with a high-frequency diminution factor (Boore in Bull Seismol Soc Am 73:1865–1894, 1983) has been used to estimate the spectral parameters namely: low-frequency displacement spectral level (Ω0), corner frequency (fc) and fmax. These obtained spectral parameters are used to estimate source parameters, namely: seismic moment, source dimension and stress drop and to study the characteristics of fmax in this region. ||| Automated crop pests and disease detection have fateful effects on food safety, leading to significant deterioration in agriculture products. The effects of crop diseases and pests can be so severe that a harvest may even be ruined entirely. Therefore, automatic recognition and diagnosis of crop disease is required in the agricultural field. However, Fast and accurate crop disease detection is still a challenging and error-prone task. Earlier, traditional methods were used to detect abnormalities in crops caused by fungus, pests and nutritional deficiency. Moreover, in some cases, it is time-consuming, expensive and impractical. To overcome these issues, experimental research is being performed into the use of image processing techniques for crop disease detection using machine learning, artificial intelligence, deep learning, generative adversarial networks and the internet of things. In this study, a comprehensive literature review of current studies is performed in crop disease and pest recognition using image processing to extract the features and algorithms used in prediction studies. In particular, several models have reported better accuracy on specific data sets. In contrast, in the case of different data sets or field conditions, the performance of the models degraded significantly. Despite this, progress has been encouraging so far. Furthermore, different inputs gained from the literature indicate that the aforementioned techniques provide better accuracy in comparison with existing techniques. Additionally, a detailed study has been performed on several unresolved challenges to develop a framework for automated crop pests and disease detection to use in real field conditions.","Cluster validity index, SIFT, optimization algorithm, Deep learning, transfer learning, Clustering, Intelligent gravitational search algorithm, global optimization, Adaptive search algorithm, leaf disease recognition, centroid-based clustering, Diffie-Hellman, Metaheuristic Algorithms, Arunachal Lesser Himalaya, Clustering Method, Kbest, Machine learning, SVM, tournament empowered WOA, weaknesses, Gravitational search algorithm, Multi-server, Hash-function, authentication scheme, authentication protocols, Recommendation system, fmax, Seismicity, COVID-19 Diagnosis, Generative adversarial networks, Chaotic, Linear wavelet transform, CoVID19 diagnosis, SIFT method, hyper-ellipsoid or hyper-spherical clusters, Whale optimization algorithm, Histopathological image classiﬁcation, Video watermarking, Siang region, Chaotic Kbest Gravitational Search Algorithm, Xie and Chen scheme, Map-reduce, histopathological images, Seismometers, Accelerometers, GANs, Bag-of-visual-words, fuzzy c-means, Metaheuristic algorithm, Source parameters, Lower Siang, crop disease detection, Internet of things, Big data, map-reduce architecture","This paper proposes a new fuzzy cluster validity index for hyper-ellipsoid or hyper-spherical shape close clusters with distant centroids, generated by fuzzy c-means. The proposed index computes compactness in terms of the distance between data points and corresponding centroids, while the distance between data points of disjoint clusters defines separation. ||| This paper proposes a novel chaotic Kbest gravitational search algorithm (CKGSA) that uses the chaotic model in Kbest to balance exploration and exploitation non-linearly. The proposed algorithm shows better convergence rate at later iterations with high precision and does not trap into local optima. ||| This paper introduces a novel method for categorization of histopathological images into the respective tissue category before quantiﬁcation analysis. The proposed method uses SIFT method for feature extraction which are further processed by gravitational search algorithm to obtain optimal bag-of-visual-words. ||| The paper highlights the weaknesses of Xie and Chen scheme in authentication protocols, including insider attack, forward secrecy attack, impersonation attack, password guessing attack, replay attack, stolen-verifier attack, man-in-the-middle attack, server spoofing attack, and authentication center spoofing attack. ||| This paper presents a new clustering method for the diagnosis of CoVID19 using medical images. The method employs a novel variant of a gravitational search algorithm to obtain optimal clusters. The performance of the proposed method is compared with recent metaheuristic algorithms using benchmark functions and publicly available CoVID19 medical images. The results demonstrate that the proposed method is outperforming in terms of accuracy, precision, sensitivity, specificity, and F1-score. ||| This paper presents a novel meta-heuristic-based recommendation system for the big data environment. The proposed method uses a novel variant of the whale optimization algorithm, tournament selection empowered whale optimization algorithm, to attain the optimal clusters. The clustering efficiency of the proposed method is measured on four large-scale datasets in terms of F-measure and computation time. ||| This paper presents a lossless video-watermarking scheme based on optimal keyframe selection using an intelligent gravitational search algorithm in linear wavelet transform. The technique obtains color motion and motionless frames from the cover video and performs one-level linear wavelet transform on the chrominance channel of motion frames. The performance of the proposed technique has been evaluated against 12 video processing attacks and outperforms five state-of-the-art schemes. ||| This study investigates the source parameters and fmax in the lower Siang region of Arunachal Lesser Himalaya using a data set of 60 local events. The results show that fmax has similar behavior as fc to seismic moment, indicating that it is also due to source process. The study also finds that fmax is independent of epicentral distance and focal depth. ||| The paper presents a comprehensive review of the current state of leaf disease recognition using deep learning techniques. It discusses the use of pre-trained CNNs, transfer learning, and GANs for generating synthetic images and addressing the problem of data scarcity. The paper also presents several architectures and methods for leaf disease recognition, including the use of YOLOv3 and AlexNet for predicting bounding boxes and the use of a softmax layer and a CNN architecture for crop disease recognition."
Hongyi LI,Adaptive event-triggered control for a class of nonlinear systems with periodic disturbances,"This paper investigates the adaptive event-triggered control problem for a class of nonlinear systems subject to periodic disturbances. To reduce the communication burden, a reliable relative threshold strategy is proposed. Fourier series expansion and radial basis function neural network are combined into a function approximator to model suitable time-varying disturbed function of known periods in strict-feedback systems. By combining the Lyapunov stability theory and the backstepping technique, the proposed adaptive control approach ensures that all the signals in the closed-loop system are bounded, and the tracking error can be regulated to a compact set around zero in finite time. Finally, simulation results are presented to verify the effectiveness of the theoretical results.","periodic disturbances, event-triggered control, Fourier series expansion, nonlinear systems, finite time",This paper proposes an adaptive event-triggered control strategy for a class of nonlinear systems with periodic disturbances. The strategy combines Fourier series expansion and radial basis function neural network into a function approximator to estimate unknown nonlinear functions. The proposed control approach ensures that all signals in the closed-loop system are bounded and the tracking error converges to the origin with a small neighborhood in finite time.
Houbing Song,A Cost-Efficient Communication Framework For Battery Switch Based Electric Vehicle Charging ||| Mobile Edge Computing for Big Data-Enabled Electric Vehicle Charging,"This paper proposes a battery switch service for electric vehicles (EVs) using a publish/subscribe (P/S) communication paradigm. The system consists of road side units (RSUs), electric vehicles (EVs), and charging stations (CSs). RSUs act as brokers to bridge the information flow from CSs to EVs, while EVs and CSs interact through RSUs. The system enables efficient radio resource utilization and alleviates interference to EVs. ||| As one of the key drivers of smart grid, Electric Vehicles (EVs) are environment-friendly to alleviate CO2 pollution. Big data analytics could enable the move from Internet of EVs, to optimized EV charging in smart transportation. In this paper, we propose a Mobile Edge Computing (MEC) based system, in line with a big data-driven planning strategy on which Charging Station (CS) to charge.","Communication Technologies, Mobile Edge Computing, Network Entities, Smart Transportation, Charging Planning, Smart Grid, Battery Switch, Electric Vehicles, Big Data, Decentralized Charging Management, publish/subscribe, Big Data-Enabled Electric Vehicle Charging, charging stations, EV Charging, road side units, MEC Based System, Smart Cities, Communication Framework, Centralized Charging Management, Charging Management","This article presents a cost-efﬁcient communication framework for battery switch based electric vehicle charging. The framework is provisioned to support the EV charging service and considers urban travel uncertainties, e.g., trafﬁc congestions and drivers’ preferences. Results demonstrate a guidance for the provisioning of P/S communication framework to improve EV drivers’ experience, e.g., charging waiting time and total trip duration. ||| This paper proposes a Mobile Edge Computing (MEC) based system for big data-enabled electric vehicle charging. The system integrates big data analytics to opportunistically disseminate the outcome from a Global Controller and collect driving big data from mobile clients. The MEC servers implement big data mining and aggregation in a decentralized way, alleviating the size of data to be processed by the Global Controller."
"Ho¨ppner, F. (1999)",Quantum-inspired evolutionary approach for selection of optimal parameters of fuzzy clustering,"Recently, Fuzzy c-Means (FCM) algorithm is most widely used because of its efficiency and simplicity. However, FCM is sensitive to the initialization of fuzziness factor (m) and the number of clusters (c) due to which it easily trapped in local optima. A selection of these parameters is a critical issue because an adverse selection can blur the clusters in the data.","Fuzzy clustering, Cluster validity index, Quantum-Inspired Evolutionary Fuzzy c-Means, Fuzzy c-Means algorithm, Fuzzy c-Means, Quantum computing","This paper proposes a hybrid fuzzy clustering algorithm, Quantum-Inspired Evolutionary Fuzzy c-Means (QIE–FCM), which uses the merits of quantum computing for finding the global optimal value of m and its corresponding value of c in the FCM. The proposed approach improves the way of initialization of the fuzziness factor (m) in the FCM and provides the diversity in selecting the optimal value of m and c from a large quantum search space."
Hua Chen,Fractional-Order BP Algorithm for Training Fractional FNNs,"Fractional calculus has been found to be a promising area of research for information processing and modeling of some physical systems. In this paper, we propose a fractional gradient descent method for the backpropagation (BP) training of neural networks. In particular, the Caputo derivative is employed to evaluate the fractional-order gradient of the error defined as the traditional quadratic energy function. The monotonicity and weak (strong) convergence of the proposed approach are proved in detail. Two simulations have been implemented to illustrate the performance of presented fractional-order BP algorithm on three small datasets and one large dataset. The numerical simulations effectively verify the theoretical observations of this paper as well.","BP algorithm, Caputo derivative, fractional-order neural networks, Backpropagation, Fractional calculus, Caputo fractional-order derivative, training FNNs, Monotonicity, Convergence","This paper proposes a fractional gradient descent method for the backpropagation (BP) training of neural networks, employing the Caputo derivative to evaluate the fractional-order gradient of the error. The monotonicity and weak (strong) convergence of the proposed approach are proved in detail, and numerical simulations are implemented to illustrate its performance on various datasets."
Huai-Ning Wu,Off-policy Reinforcement Learning for H∞Control Design,"The H∞control design problem is considered for nonlinear systems with unknown internal system model. An off-policy reinforcement leaning (RL) method is introduced to learn the solution of HJI equation from real system data instead of mathematical system model, and its convergence is proved.","Reinforcement learning, Hamilton-Jacobi-Isaacs equation, Neural Network, H∞control design, Off-policy learning","The paper introduces an off-policy reinforcement learning method to solve the H∞control design problem for nonlinear systems with unknown internal system model. The method learns the solution of the Hamilton-Jacobi-Isaacs equation from real system data instead of a mathematical system model, and its convergence is proved. The paper also discusses the relationship between reinforcement learning and control communities, and reviews some existing results on reinforcement learning for optimal control problems."
Huang et al.,Robust Exponential Stability of Uncertain Delayed Neural Networks With Stochastic Perturbation and Impulse Effects,"This paper studies the robust exponential stability of uncertain delayed neural networks with impulsive effects. The system model is described by a set of differential equations with time-varying parameter uncertainties and external inputs. The stability of the system is analyzed using a Lyapunov function candidate and the Halanay inequality for stochastic systems. The main results are presented in the form of a theorem, which provides a set of sufficient conditions for the global, robust, and exponential stability of the system in the mean square sense.","uncertain delayed neural networks, Halanay inequality, impulsive effects, parameter uncertainty, Delayed neural networks (DNN), Lyapunov function, mean-square stability, exponential stability, stochastic perturbation, robust exponential stability, impulse","The paper presents a study on the robust exponential stability of uncertain delayed neural networks with impulsive effects. The system model is described by a set of differential equations with time-varying parameter uncertainties and external inputs. The stability of the system is analyzed using a Lyapunov function candidate and the Halanay inequality for stochastic systems. The main results are presented in the form of a theorem, which provides a set of sufficient conditions for the global, robust, and exponential stability of the system in the mean square sense."
Huaqing Zhang,Reservoir Characterization and Productivity Forecast Based on Knowledge Interaction Neural Network,"The reservoir characterization aims to provide the analysis and quantification of the injection-production relationship, which is the fundamental work for production management. The connectivity between injectors and producers is dominated by geological properties, especially permeability. However, the permeability parameters are very heterogenous in oil reservoirs, and expensive to collect by well logging. The commercial simulators enable to get accurate simulation but require sufficient geological properties and consume excessive computation resources.","knowledge interaction neural network, machine learning, productivity prediction, reservoir characterization, Productivity Forecast, Physical Knowledge, embedded model","The goal of this study is to improve the accuracy and stableness of the inter-well connectivity characterization and enhance the prediction precision on well productivity, by combining the physical knowledge with machine learning techniques. An innovative neural network is proposed to handle the reservoir characterization and productivity forecast problems, in which the material balance equation is embedded via three high transparent modules, thereby ensuring the physical sense of model parameters."
Hui MA,Adaptive event-triggered control for a class of nonlinear systems with periodic disturbances,"This paper investigates the adaptive event-triggered control problem for a class of nonlinear systems subject to periodic disturbances. To reduce the communication burden, a reliable relative threshold strategy is proposed. Fourier series expansion and radial basis function neural network are combined into a function approximator to model suitable time-varying disturbed function of known periods in strict-feedback systems. By combining the Lyapunov stability theory and the backstepping technique, the proposed adaptive control approach ensures that all the signals in the closed-loop system are bounded, and the tracking error can be regulated to a compact set around zero in finite time. Finally, simulation results are presented to verify the effectiveness of the theoretical results.","periodic disturbances, event-triggered control, Fourier series expansion, nonlinear systems, finite time",This paper proposes an adaptive event-triggered control strategy for a class of nonlinear systems with periodic disturbances. The strategy combines Fourier series expansion and radial basis function neural network into a function approximator to estimate unknown nonlinear functions. The proposed control approach ensures that all signals in the closed-loop system are bounded and the tracking error converges to the origin with a small neighborhood in finite time.
Hui Zhao,History Matching of Naturally Fractured Reservoirs Using a Deep Sparse Autoencoder,"This work proposes a new characterization method and a method to reduce dimensionality for history matching of naturally fractured reservoirs. The forward simulator is modeled after the EDFM given its computational efficiency. The fracture network can be represented with length, orientation, and position, including large-scale fractures and small-scale fractures.","History matching, characterization method, EDFM, Naturally fractured reservoirs, Deep sparse autoencoder, dimensionality reduction, fracture network","This paper proposes a new characterization method for the multiscale fracture network, and a powerful dimensionality-reduction method by means of an autoencoder for model parameters. The characterization method of the fracture network is dependent on the length, orientation, and position of fractures, including large-scale and small-scale fractures."
Hui-Chul Won,Bandwidth-Efﬁcient OFDM transmission with iterative cyclic preﬁx reconstruction,"Abstract—Orthogonal frequency division multiplexing (OFDM) systems are now a part of all major wireless standards, because of its potential to offer high data rate. Cyclic prefix (CP) in OFDM system converts a multipath channel to a flat fading channel, thus simplifies the design of equalizer. However, there is a lot of ambiguity in choosing the length of CP. In this paper, we propose a new method for calculation of length of CP using cumulant features. The merits of proposed method are verified by computer simulation.","bandwidth efﬁciency, OFDM, channel length estimation, cumulant features, Orthogonal frequency division multiplexing (OFDM), Cyclic prefix (CP), cyclic preﬁx, Blind channel length estimation","This paper proposes a novel method for blind channel length estimation in OFDM systems using cumulant features. The proposed method is well-suited for dynamic spectrum access (DSA) setups and does not require pilot or training sequences, thus saving bandwidth. The method is based on exploiting the properties of nth order cumulant features and is verified by computer simulation."
"Hung, C. L., et al. (2013)",Quantum-inspired evolutionary approach for selection of optimal parameters of fuzzy clustering,"Recently, Fuzzy c-Means (FCM) algorithm is most widely used because of its efficiency and simplicity. However, FCM is sensitive to the initialization of fuzziness factor (m) and the number of clusters (c) due to which it easily trapped in local optima. A selection of these parameters is a critical issue because an adverse selection can blur the clusters in the data.","Fuzzy clustering, Cluster validity index, Quantum-Inspired Evolutionary Fuzzy c-Means, Fuzzy c-Means algorithm, Fuzzy c-Means, Quantum computing","This paper proposes a hybrid fuzzy clustering algorithm, Quantum-Inspired Evolutionary Fuzzy c-Means (QIE–FCM), which uses the merits of quantum computing for finding the global optimal value of m and its corresponding value of c in the FCM. The proposed approach improves the way of initialization of the fuzziness factor (m) in the FCM and provides the diversity in selecting the optimal value of m and c from a large quantum search space."
I. Bose,Detection of Financial Statement Fraud Using Data Mining Techniques,"Recently, high profile cases of financial statement fraud have been dominating the news. This paper uses data mining techniques such as Multilayer Feed Forward Neural Network (MLFF), Support Vector Machines (SVM), Genetic Programming (GP), Group Method of Data Handling (GMDH), Logistic Regression (LR), and Probabilistic Neural Network (PNN) to identify companies that resort to financial statement fraud. Each of these techniques is tested on a dataset involving 202 Chinese companies and compared with and without feature selection. PNN outperformed all the techniques without feature selection, and GP and PNN outperformed others with feature selection and with marginally equal accuracies.","Data mining, artificial intelligence, SVM, Feature selection, GP, financial statement fraud, fraud detection, Financial fraud detection, Neural networks, t-statistic","This paper uses data mining techniques to identify companies that resort to financial statement fraud. The techniques used include Multilayer Feed Forward Neural Network (MLFF), Support Vector Machines (SVM), Genetic Programming (GP), Group Method of Data Handling (GMDH), Logistic Regression (LR), and Probabilistic Neural Network (PNN). The results show that PNN outperformed all the techniques without feature selection, and GP and PNN outperformed others with feature selection and with marginally equal accuracies."
I. Khandelwal,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
I. Perfilieva,SISO Fuzzy Relational Inference Systems based on Fuzzy Implications are Universal Approximators,"This paper deals with fuzzy relational inference mechanisms as universal approximators. We consider the implicative form of the rule base, where the antecedents of the rules are related to their consequents using a fuzzy implication. We show that fuzzy relational inference mechanisms with singleton input can be used as universal approximators, and we provide a constructive proof of their approximation capability.","T-norms, Fuzzy sets, Fuzzy relational inference mechanisms, Fuzzy Relational Inference, Universal Approximation, Fuzzy Implications",This paper explores the use of fuzzy relational inference mechanisms as universal approximators. We focus on the implicative form of the rule base and show that fuzzy relational inference mechanisms with singleton input can be used to approximate any continuous function. We provide a constructive proof of their approximation capability and discuss the implications of our results.
IET Energy Syst. Integr.,Battery super-capacitor hybrid system for electrical vehicle transportation's systems – an energy integrated approach,"This paper proposes an adaptive control law for battery and super-capacitor current dynamics. The control law is designed to track the reference current and maintain the desired output voltage. The dynamics of the battery and super-capacitor currents are modeled as uncertain systems, and the assumptions of global Lipschitz and relative degree one are satisfied. The control law is implemented using a Nussbaum function, and the convergence result is provided in the Appendix.","Hybrid energy storage system, battery and super-capacitor current dynamics, adaptive control, Battery super-capacitor, uncertain systems, Adaptive λ tracking control strategy, Nussbaum function","The proposed control strategy is to preserve battery life, while operating at transient conditions of the load. The proposed control strategy comprises of a gain adaptation algorithm, combined with a dead-zone induced feedback. The closed loop system under the influence of this feedback scheme, is proved to be is robust against variation in operating conditions, parameter uncertainties and measurement noise."
IET Power Electron.,Analysis and modelling of circulating current in two parallel-connected inverters,This paper analyzes the circulating current in parallel-connected inverters and its effects on the system. The circulating current is caused by the difference in the common-mode (CM) voltages of the inverters and is affected by the phase shift of the carrier signals. The paper focuses on the case of asymmetrical regular-sampled pulse-width modulation (RSPWM) and shows that a phase shift of 180° between the carrier signals results in a low total harmonic distortion (THD) in the ac side currents.,"circulating current, high power applications, common-mode voltages, total harmonic distortion, parallel-connected inverters, pulse-width modulation, phase shift, asymmetrical RSPWM",This paper analyzes the circulating current in parallel-connected inverters and its effects on the system. The circulating current is caused by the difference in the common-mode (CM) voltages of the inverters and is affected by the phase shift of the carrier signals. The paper focuses on the case of asymmetrical regular-sampled pulse-width modulation (RSPWM) and shows that a phase shift of 180° between the carrier signals results in a low total harmonic distortion (THD) in the ac side currents.
IET Wirel. Sens. Syst.,A Novel Meta-Heuristic for Target Coverage in Sensor Networks ||| Generic correlation model for wireless sensor network applications,"In wireless sensor networks (WSNs), network lifetime and energy consumption are two important parameters which directly impacts each other. In order to enhance the global network lifetime, one should need to utilise the available sensors’ energy in an optimise way. There are several approaches discussed in the literature to maximise the network lifetime for well-known target coverage problem in WSN. The target coverage problem is presented as a maximum network lifetime problem (MLP) and solved heuristically using various approaches. In this study, the authors propose a genetic algorithm (GA)-based meta-heuristic to solve the above said MLP. The GA is a non-linear optimisation solution method which is proven to be better as compared to the column generation or approximation schemes. ||| A generic spatial correlation model for wireless sensor networks is proposed. The model is based on the assumption that the received sensory data from reporting nodes is jointly Gaussian. The covariance between the two measured values from nodes ni and nj at location si and sj, respectively, can be expressed by Cov si, sj = s2 SKq ∥si −sj∥. The correlation function Kϑ(.) is used to model the correlation between sensor nodes. The control parameter ϑ is used to control the degree of correlation between nodes. The proposed model is a generic correlation model that can be applied to all sensor network applications.","spatial correlation, control parameter, Sensor Networks, genetic algorithm, correlation function, spatial correlation model, energy-efﬁcient methodologies, network lifetime, target coverage problem, meta-heuristic, wireless sensor networks, Target Coverage","The proposed heuristic consists of chromosome representation, initial population generation, fitness function derivation, and crossover and mutation operations. The chromosome is represented as a string of zeros and ones, where the length of each chromosome is equal to the number of sensor nodes in the network. The initial population is generated by randomly selecting chromosomes, and the fitness function is derived to maximise the total network lifetime. ||| The proposed spatial correlation model is a generic model that can be applied to all sensor network applications. It is based on the assumption that the received sensory data from reporting nodes is jointly Gaussian. The model uses the correlation function Kϑ(.) to model the correlation between sensor nodes. The control parameter ϑ is used to control the degree of correlation between nodes. The proposed model can provide guidelines for designing energy-efﬁcient communication protocols for most of the WSNs."
IMAD RIDA,Palmprint Identification Using an Ensemble of Sparse Representations,"Among various palmprint identification methods proposed in the literature, sparse representation for classification (SRC) is very attractive offering high accuracy. Although SRC has good discriminative ability, its performance strongly depends on the quality of the training data. In particular, SRC suffers from two major problems: lack of training samples per class and large intra-class variations. In fact, palmprint images not only contain identity information but they also have other information, such as illumination and geometrical distortions due to the unconstrained conditions and the movement of the hand. In this case, the sparse representation assumption may not hold well in the original space since samples from different classes may be considered from the same class. This paper aims to enhance palmprint identification performance through SRC by proposing a simple yet efficient method based on an ensemble of sparse representations through an ensemble of discriminative dictionaries satisfying SRC assumption.","sparse representations, sparse representation, ensemble learning, palmprint identification, 2D-PCA, 2D-LDA, Biometrics, palmprint",This paper proposes a new method for palmprint identification using an ensemble of sparse representations. The method aims to enhance the performance of sparse representation for classification (SRC) by proposing a simple yet efficient method based on an ensemble of discriminative dictionaries satisfying SRC assumption. The proposed method is evaluated on two publicly available palmprint data sets and shows very promising results compared with both state-of-the-art holistic and coding methods.
Ia Khmaladze,ROS deficiency enhanced mannan-induced PsA,"In and joint inflammation using B10Q.Ncf1m1j/m1j mice that have a mutation in the Ncf1 gene (m1j) (the Ncf1 protein also denoted p47phox), and hence reduced ROS production (oxidative burst) (18). As shown in Fig. 1D, Ncf1 mutated mice developed severe joint inflammation within 2 d after mannan injection, which reached the mean maximal disease severity (30 ± 6 points) within 4 d. The frequency of skin lesions was 100%, with more severe cases in B10Q.Ncf1m1j/m1j mice (Fig. 1E), whereas B10.Q mice had a significantly milder disease course. Multiple Exposures to Mannan Induced a Relapsing Disease. Next, we examined the effect of multiple mannan injections in B10Q and B10Q.Ncf1m1j/m1j mice. We boosted mice twice with mannan on days 7 and 14 after disease initiation. Repetitive injections of mannan reproduced the arthritis phenotype, which reached the maximum severity level on days 9 and 17, similar to the first injection (Fig. 1F). A more severe disease course was observed in B10Q.Ncf1m1j/m1j mice than in B10Q mice (P < 0.05 and P < 0.01, respectively). Interestingly, Ps skin scaling returned only after the second mannan injection (on day 16), but the skin peeled off even more quickly than the first time (Fig. 1G). Moreover, from day 11 onward, B10Q.Ncf1m1j/m1j mice started to develop pruritus on the body, predominantly on the back and above the eye (Fig. S1E). Pruritus was only evident in B10Q.Ncf1m1j/m1j mice, but flaky skin on the tail and alopecia all over the leg was observed in both of the mouse strains. We also observed genetic heterogeneity in disease susceptibility (Fig. Fig. 1. ROS deficiency enhanced mannan-induced PsA. The arthritic joint phenotype and Ps-like skin lesions in the front (A) and hind (B) paws of B10Q.Ncf1m1j/m1j mice are shown. (C) Ps-like skin scaling in diseased B10Q.Ncf1m1j/m1j mouse ear compared with naive mouse ear. Mean arthritis (D) and Ps lesion (E) severity in B10Q (n = 5) and B10Q.Ncf1m1j/m1j (n = 5) mice after a single i.p. mannan injection. Mean arthritis (F) and Ps lesion (G) severity in B10Q (n = 5) and B10Q.Ncf1m1j/m1j (n = 5) mice after repetitive mannan injections (days 7 and 14). (H) Mannan-induced mean maximum arthritis scores ± SEM in different mouse strains: B10Q (n = 8), B10Q.Ncf1m1j/m1j (n = 9), B10RIII (n = 10), B10RIII.Ncf1m1j/m1j (n = 9), B10P (n = 3), B10P.Ncf1m1j/m1j (n = 9), BALB/cByJ/Q (n = 10), BALB/cByJ/Q.Ncf1m1j/m1j (n = 8), BALB/cByJ (n = 5), BALB/cByJ.Ncf1m1j/m1j (n = 7), C57BL/6NJ (n = 8), and C57BL/6NJ.Ncf1m1j/m1j (n = 7). Significance was calculated by comparing the maximal disease severity of B10Q and B10Q.Ncf1m1j/m1j mice with all of the other strains in their respective groups. *P < 0.05; **P < 0.01; ***P < 0.001. E3670 | www.pnas.org/cgi/doi/10.1073/pnas.1405798111 Khmaladze et al. Downloaded from https://www.pnas.org by 122.184.65.228 on February 22, 2023 from IP address 122.184.65.228.","autoimmune disease, Ncf1, animal model","This study identifies a new mechanism for psoriasis (Ps) and psoriasis arthritis (PsA) development in mice. A single injection of mannan, a component of baker's yeast, induced Ps and PsA-like symptoms. This effect was exacerbated in mice lacking reactive oxygen species (ROS), but improved when ROS production was restored in macrophages.  Blocking IL-17A, a cytokine produced by gamma delta T cells, completely prevented disease. The study suggests that mannan activates macrophages, leading to TNF-α secretion and stimulation of IL-17A production by gamma delta T cells. This, in turn, drives neutrophil infiltration and inflammation, mimicking Ps and PsA. This new mouse model could be valuable for testing new therapies for Ps and PsA."
Iacca et al.,Memetic search in artiﬁcial bee colony algorithm,"Artiﬁcial bee colony (ABC) optimization algorithm is relatively a simple and recent population based probabilistic approach for global optimization. ABC has been outperformed over some Nature Inspired Algorithms (NIAs) when tested over benchmark as well as real world optimization problems. The solution search equation of ABC is signiﬁcantly inﬂuenced by a random quantity which helps in exploration at the cost of exploitation of the search space. In the solution search equation of ABC, there is a enough chance to skip the true solution due to large step size. In order to balance between diversity and con-vergence capability of the ABC, a new local search phase is integrated with the basic ABC to exploit the search space identiﬁed by the best individual in the swarm. In the proposed phase, ABC works as a local search algorithm in which, the step size that is required to update the best solution, is controlled by Golden Section Search approach. The proposed strategy is named as Memetic ABC (MeABC). In MeABC, new solutions are generated around the best solution and it helps to enhance the exploitation capability of ABC. MeABC is established as a modiﬁed ABC algorithm through experiments over 20 test problems of different complexities and 4 well known engineering optimization problems.","Exploration-exploitation, Swarm intelligence, Memetic algorithm, Memetic Search, Honey Bees, Artiﬁcial bee colony","This paper proposes a new local search strategy, Memetic ABC (MeABC), which integrates a Golden Section Search approach with the basic Artificial Bee Colony (ABC) algorithm to balance exploration and exploitation behavior. MeABC is established as a modified ABC algorithm through experiments over 20 test problems and 4 engineering optimization problems."
Ibrahiem M. M. El Emary,Wireless Sensor Networks: From Theory to Applications,"This book contains information obtained from authentic and highly regarded sources. Reasonable efforts have been made to publish reliable data and information, but the author and publisher cannot assume responsibility for the validity of all materials or the consequences of their use.","Quality of Services, Applications, Wireless Sensor Networks, Theory, WSNs","The book focuses on the quality of services in wireless sensor networks, covering various aspects such as data collection, aggregation, and spatial coverage, physical layer and interfacing, routing and transport protocols, and energy-saving approaches."
Ibrahim A. Elgendy,Adaptive Energy-Aware Algorithms for Minimizing Energy Consumption and SLA Violation in Cloud Computing,"In cloud computing, high energy consumption and service-level agreements (SLAs) violation are the challenging issues considering that the demand for computational power is growing rapidly, thereby requiring large-scale cloud data centers. This paper proposes three adaptive models, namely, gradient descent-based regression (Gdr), maximize correlation percentage (MCP), and bandwidth-aware selection policy (Bw), that can significantly minimize energy consumption and SLA violation.","regression method, energy-efﬁciency, service level agreements, SLA violation, host overloaded detection, energy efficiency, cloud data center, VM consolidation, Cloud computing, meta-heuristic approach, green computing","This paper proposes three adaptive models to minimize energy consumption and SLA violation in cloud computing. The models are based on gradient descent-based regression, maximize correlation percentage, and bandwidth-aware selection policy. The proposed algorithms reduce energy consumption while maintaining the required performance levels in a cloud data center."
Ikshu Bhalla,Emotion Analysis in Twitter,"The ever-increasing amount of text generated by Twitter users contains a wealth of information about the users’ state of mind. Over the years, researchers have tapped upon this resource and proposed a number of lexicons and techniques for analyzing the polarity of sentiments expressed by tweets. However, we need to delve deeper to extract the emotions conveyed by them – a research direction that had not received adequate attention so far.","Psychology, Twitter, WordNet, sentiment analysis, Lexicon, Emotion Analysis","This paper proposes a novel Emotion Analysis lexicon that was compiled by integrating information from the domain of psychology, the lexical ontology WordNet, and a set of emoticons and slangs commonly used in web jargon. The lexicon is used to find the predominant emotions carried by tweets originating from three different cities and analyzed how they evolve with time."
Ilaiah Kavatia,Alignment Free Cancellable Fingerprint Templates Using Ellipse Structure,"In this work, a new method for alignment free cancellable fingerprint templates was proposed using ellipse structure. Ellipse was formed by selecting one of the minutiae and core point of the fingerprint as focal points and the farthest minutia as the co-vertex. This method performs well because instead of storing spatial information of the fingerprints such as distance or orientation between minutia, etc., we are storing the ellipse attributes in transformed form such that even though if any stored template got leaked, the original fingerprint information will not be revealed to the attacker. This method also performs well in terms of FAR and FRR. However for the fingerprints which does not possess a core point this method will not be suitable and is the main limitation of this work.","Template protection, Discrete Fourier transform, Fingerprint, Ellipse, cancellable templates, biometric security, fingerprint templates, ellipse structure","The proposed method uses elliptical structures generated from fingerprint minutiae to secure fingerprint templates. The method involves extracting minutiae from fingerprint images, constructing ellipses and extracting feature sets, projecting the feature sets onto a 3D space, generating a binary string, and transforming the binary string into the frequency domain using DFT."
Ilaria Russo,Opposing Actions of Fibroblast and Cardiomyocyte Smad3 Signaling in the Infarcted Myocardium,"Transforming growth factor (TGF)–βs are highly pleiotropic mediators with critical roles in regulating cellular phenotype and function in embryonic development, tissue homeostasis, and disease. Normal tissues contain stores of latent TGF-β bound to the extracellular matrix through its association with a large binding protein, the latent TGF-β binding protein. Tissue injury is associated with marked induction of TGF-β isoforms and activation of TGF-β signaling cascades. Parenchymal cells, extravasated leukocytes, and platelets synthesize and release large amounts of TGF-β in the injury site. Reactive oxygen species, proteases, matricellular proteins, and integrins cooperate to trigger the release of bioactive TGF-β from the latent stores. Subsequent binding of the active TGF-β dimer to the type II TGF-β receptor, followed by transphosphorylation of the type I receptor, triggers the TGF-β signaling response. The cellular effects of TGF-β are mediated through a canonical pathway involving a series of intracellular effectors, the Smads, or through activation of noncanonical signaling cascades. Activation of TGF-β signaling induces phosphorylation of the receptor-activated Smads, Smad2 and Smad3, which can form heteromeric complexes with the common Smad, Smad4. These complexes are transported to the nucleus, where they regulate gene transcription. TGF–β receptors and Smads are ubiquitously expressed by all cell types. Thus, all cells are responsive to the actions of TGF-β. Cardiac injury is associated with the marked induction of TGF-β and activation of TGF-β cascades. Our laboratory and other investigators have documented activation of Smad2 and Smad3 signaling in the infarcted myocardium, localized in both cardiomyocytes and interstitial cells. In isolated cardiac fibroblasts, Smad3 signaling accentuates myofibroblast transdifferentiation and stimulates a matrix-preserving program. In a model of reperfused infarction, global loss of Smad3 attenuated remodeling after infarction. However, considering the ubiquitous expression of Smad3 in all cell types, the cell biological basis for the actions of Smad3 in the infarcted heart remains unknown. Our study dissects the cell-specific actions of Smad3 signaling in the infarcted myocardium by developing and studying mice with cell-specific loss of Smad3 in activated fibroblasts and cardiomyocytes. It is surprising that fibroblast-specific loss of Smad3 worsened remodeling after infarction, resulting in accentuated chamber dilation. The deleterious consequences of fibroblast-specific Smad3 loss reflected unrestrained fibroblast proliferation, defective scar remodeling, and perturbed organization of myofibroblast arrays in the border zone. Smad3 signaling regulated fibroblast function, activating integrin-mediated nicotinamide adenine dinucleotide phosphate (NADPH) oxidase (NOX)–2 expression. In contrast, cardiomyocyte-specific loss of Smad3 protected the infarcted heart from dysfunction after infarction. The protective effects of cardiomyocyte-specific Smad3 loss were associated with attenuated cardiomyocyte apoptosis in remodeling myocardium and accompanied by decreased NOX2 levels, reduced nitrosative stress, and decreased matrix metalloproteinase (MMP)–2 expression.","SMAD, fibroblast, heart failure, cardiomyocyte, remodeling","This study investigates the role of Smad3 in cardiac fibroblasts following myocardial infarction. Using a mouse model with fibroblast-specific Smad3 deletion (FS3KO), the researchers found that loss of Smad3 in fibroblasts exacerbated dilative remodeling and worsened systolic dysfunction after both reperfused and nonreperfused infarction.  While acute infarct size was not affected, FS3KO mice exhibited larger scars, increased myofibroblast density, and enhanced myofibroblast proliferation. These findings suggest that Smad3 plays a protective role in cardiac fibroblasts and its loss contributes to adverse cardiac remodeling after infarction."
Inder Khatri,An Emotion-Based Multi-Task Approach to Fake News Detection,"Social media, blogs, and online articles are instant sources of news for internet users globally. But due to their unmoderated nature, a significant percentage of these texts are fake news or rumors. Their deceptive nature and ability to propagate instantly can have an adverse effect on society. In this work, we hypothesize that legitimacy of news has a correlation with its emotion, and propose a multi-task framework predicting both the emotion and legitimacy of news. Experimental results verify that our multi-task models outperform their single-task counterparts in terms of accuracy.","social media, legitimacy of news, rumors, fake news detection, emotion-based multi-task approach","This paper proposes an emotion-based multi-task approach to fake news detection, which predicts both the emotion and legitimacy of news. The approach uses a multi-task framework and outperforms single-task models in terms of accuracy. The results show that there is a correlation between the legitimacy of news and its emotion, and that the proposed approach can effectively detect fake news and rumors."
International Journal of Trend in Scientific Research and Development (IJTSRD),Design and Construction of a Shredding Machine for Recycling and Management of Organic Waste,This research work accounts for the study of the significant problems of organic wastes management which is an issue utmost concern in developing Countries like India. Principally our aim is to minimize the jolt caused by organic Waste produced in agricultural fields as residue which is commonly burned causing pollution. We seek to reuse this valuable resource and turning into good quality compost for agricultural use.,"recycling, compost, composting, organic waste, machine, design, shredding machine, organic waste shredder, development, agriculture, management","The paper discusses the design and construction of a shredding machine for recycling and management of organic waste. The machine is designed to convert larger particle size of collected organic waste into desired size, making it easier to treat other chemical and biological processes to convert it into compost in the least amount of time possible."
Interscience Management Review (IMR),Survey of E-Governance Systems with focus on Development Approaches and Interface Quality,"There has been a significant growth of e-governance systems in general and online voting systems in particular. Various models have been proposed to conceptualise and develop these systems. Attention is currently on developing adaptive interfaces that respond intelligently to changes in user profiles. These models differ in many aspects, but no formal classification or comparative study is available as yet which may be used as a reference for researchers engaged in this area. This paper surveys the plethora of existing approaches and models for e-governance and presents a comparative evaluation based on certain qualitative parameters. These parameters have been selected based upon their criticality in e-governance applications. They include security, interoperability, authentication, flexibility, extensibility, privacy, adaptability, transparency, verifiability and robustness. The classification provides a common platform to glean knowledge about the strengths and weaknesses of different models, gain a quality-based comparative evaluation and build upon specific research directions.","online voting, Interface Quality, fraud detection, Development Approaches, verifiability, authentication, security, E-Governance, anonymity","The paper provides a comprehensive survey of e-governance systems, highlighting the importance of security, anonymity, and verifiability in online voting systems. It also reviews different e-governance models and discusses the need for classification and review of these models."
Ipseeta Mohanty,"Cardioprotection from ischemia and reperfusion injury by Withania somnifera: A hemodynamic, biochemical and histopathological assessment","The efficacy of Withania somnifera (Ws) to limit myocardial injury after ischemia and reperfusion was explored and compared to that of Vit E, a reference standard known to reduce mortality and infarct size due to myocardial infarction. Wistar rats (150–200 g) were divided into six groups and received orally saline (sham, control group), Ws-50/kg (Ws control and treated group) and Vit E-100 mg/kg (Vit E control and treated group) respectively for 1 month. On the 31st day, rats of the control, Vit E and Ws treated groups were anesthetized and subjected to 45 min occlusion of the LAD coronary artery followed by 60 min reperfusion. Hemodynamic parameters: systolic, diastolic and mean arterial pressure (SAP, DAP, MAP), heart rate (HR), left ventricular end diastolic pressure (LVEDP), left ventricular peak (+)LVdP/dt and (–)LVdP/dt were monitored. Hearts were removed and processed for histopathological and biochemical studies: Myocardial enzyme viz, creatin phosphokinase (CPK), and antioxidant parameters: malondialdehyde (MDA), glutathione (GSH), superoxide dismutase (SOD), catalase (CAT), glu-tathione peroxidase (GSHPx) were estimated. Postischemic reperfusion produced significant cardiac necrosis, depression of left ventricular functions (MAP, LVEDP, (+) and (–)LVdP/dt) and a significant fall in GSH (p < 0.01), SOD, CAT (p < 0.05), LDH and CPK (p < 0.01) as well as an increase in MDA level (p < 0.05) in the control group rats as compared to sham group. The changes in levels of protein and GPx was however, not significant. Ws and Vit E favorably modulated most of the hemo-dynamic, biochemical and histopathological parameters though no significant restoration in GSH, MAP (with Vit E) were ob-served. Ws on chronic administration markedly augmented antioxidants (GSH, GSHPx, SOD, CAT) while Vit E did not stimulate the synthesis of endogenous antioxidants compared to sham. Results indicate that Ws significantly reduced myocardial injury and emphasize the beneficial action of Ws as a cardioprotective agent.","Withania somnifera, adaptogens, Adaptogenic, myocardial infarction, Ischemia-reperfusion injury, Myocardial damage, ischemia, Vitamin E, antioxidants, reperfusion","This study investigated the cardioprotective effects of Withania somnifera (Ws) compared to Vitamin E in a rat model of ischemia and reperfusion induced myocardial injury. Ws significantly reduced myocardial injury, improved hemodynamic parameters, and enhanced antioxidant defense mechanisms. These findings suggest that Ws has potential as a cardioprotective agent."
Ipshita Chatterjee,An Analysis of ICT Tools in Medical Education During the COVID-19 Pandemic,"The COVID-19 pandemic has disrupted life and all forms of education. However, the impact on medical education is unique since the need for continuity of training medical students is urgent and traditionally calls for hands-on training and a physical presence.","COVID-19, e-learning, information and communication technology, COVID-19 pandemic, medical education, live streamed lecture, ICT tools","The COVID-19 pandemic has accelerated the adoption of ICT tools in medical education, enabling real-time collaboration, virtual classroom lectures, and online conferences. Various tools such as videoconferencing, teleconferencing, prerecorded videos, social media, live streaming applications, and web-based learning tools are being used to ensure educational continuity."
Ishani Khurana,Adsorption and Photodegradation of Dyes Using Graphene Composites: A Review,"Water contamination has reached an alarming state due to industrialization and urbanization and has become a worldwide issue. Dyes contaminate water and are addressed extensively by researchers. Various technologies and materials have been developed for the treatment of contaminated water. Among them, adsorption has attracted great attention due to its ease and cost-effective nature. In recent years, graphene-based composites have shown great potential for the removal of contaminants from water. The literature reveals the usefulness of composites of graphene with metal oxides, carbon derivatives, metal hybrids and polymers for the removal of organic dyes from contaminated water. In this review, efforts have been made to compile the studies on the removal of cationic and anionic dyes from water using graphene-based composites.","Graphene, Dye removal, Photodegradation, Graphene composites, Degradation, Water treatment, Composites, Contaminated water, Adsorption, Dyes","Graphene composites are emerging as promising materials for the removal of dyes from wastewater due to their high surface area, excellent electrical conductivity, and tunable properties. This review summarizes the recent progress in using graphene composites for both adsorption and photodegradation of dyes. It discusses the mechanisms involved, key factors affecting dye removal efficiency, and the advantages of graphene-based materials over conventional methods. The review also highlights the potential of graphene composites for sustainable and efficient dye remediation in the future."
"Iyyer, M.",A Multi-Task Approach to Open Domain Suggestion Mining,"Consumer reviews online may contain suggestions useful for improving the target products and services. Mining suggestions is challenging because the field lacks large labelled and balanced datasets. Furthermore, most prior studies have only focused on mining suggestions in a single domain. In this work, we introduce a novel up-sampling technique to address the problem of class imbalance, and propose a multi-task deep learning approach for mining suggestions from multiple domains.","Deep Learning, Suggestion Mining, Artificial Intelligence, Class Imbalance, Multi-Task Learning","This paper presents a multi-task approach to open domain suggestion mining, addressing the class imbalance problem using a novel up-sampling technique and a multi-task deep learning framework. Experimental results show that the proposed approach outperforms state-of-the-art models in terms of F-1 measure and AUC."
J. Balasubramaniam,Non-Vanishing but Filling Negation ||| On the Distributivity of F-Generated Implications Jf over T-Norms and T-Conorms ||| On the Distributivity of Implication Operators Over T and S Norms,"Contrapositive symmetry (CPS) is a tautology in classical logic. In fuzzy logic, not all fuzzy implications have CPS with respect to a given strong negation. Given a fuzzy implication J, towards imparting contrapositive symmetry to J with respect to a strong negation N two techniques, viz., upper and lower contrapositivisation, have been proposed by Bandler and Kohout [Semantics of implication operators and fuzzy relational products, Internat. J. Man Machine Stud. 12 (1980) 89–116]. In this work we investigate the N-compatibility of these contrapositivisation techniques, i.e., conditions under which the natural negation of the contrapositivised implication is equal to the strong negation employed. ||| Recently, Yager [R. Yager, On some new classes of implication operators and their role in approximate reasoning, Information Sciences 167 (2004) 193–216] has introduced a new class of fuzzy implications, denoted Jf, called the f-generated implications and has discussed some of their desirable properties, such as neutrality, exchange principle, etc. In this work, we discuss the class of Jf implications with respect to three classical logic tautologies, viz., distributivity, law of importation and contrapositive symmetry. ||| It may be noted that a fuzzy implication will be of the form “If X is A, then Y is B,” where X and Y are the variables and A and B are fuzzy sets on the domain of X and Y, respectively. The implication is represented as and often as . It is common in fuzzy control to have two different antecedents (observations) leading to the same consequent (action). The two rules may be joined by “else” or “and.” These lead to the RHS of (1) and (2) respectively. The the left-hand side of these equations reduce these to a single rule. Similarly, in the case of fuzzy expert systems, it is possible that one antecedent (symptom) may lead to different consequents (diseases). These lead to the right-hand side of (3) and (4). The left-hand side of these equations once again enable reduction in number of rules. The advantage of this rule reduction is lossless inferencing, i.e., the inferences drawn from the original system and the reduced system are the same. It is quite satisfying to note that all S-implications and R-implications have this property. The requirement on any binary operator to satisfy these equations is also not too stringent. The discussion in this work is on the framework of single-input–single-output fuzzy systems, but can be extended in an obvious way to multiple-input–single-output systems.","Law of importation, rule reduction, fuzzy systems, fuzzy control, f-Generated implications, Sugeno (S)-norms, fuzzy logic, Yager’s Implications, fuzzy expert systems, S-implications, fuzzy implications, Contrapositive symmetry, implication operators, Residuated implications, Takagi (T)-norms, fuzzy implication, natural negations, t-norms, Distributivity of fuzzy implications, Contrapositivisation, Distributivity, distributivity, N-compatibility, t-conorms, properties, h-Generated implications","This paper investigates the conditions under which two contrapositivisation techniques, upper and lower contrapositivisation, are N-compatible. It also proposes a new contrapositivisation technique, M-contrapositivisation, which is N-compatible independent of any ordering between N and NJ. ||| This paper discusses the class of Jf implications with respect to three classical logic tautologies, viz., distributivity, law of importation and contrapositive symmetry. Necessary and sufficient conditions under which Jf implications are distributive over t-norms and t-conorms and satisfy the law of importation with respect to a t-norm have been presented. ||| The authors discuss the distributivity of implication operators in fuzzy systems and their application to rule reduction. They show that all S-implications and R-implications have the property of lossless inferencing and that the requirement on any binary operator to satisfy these equations is not too stringent."
J. C. Shim,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
J. Daugman,Iris Detection,"For iris boundary detection, circular summation of intensity approach is used as proposed in [5]. The original grayscale image is blurred using median filter to remove external noise. After filtering, the contrast of image is enhanced to have sharp variation at image boundaries using histogram equalisation as shown in Figure 5(a). This contrast enhanced image is used for finding the outer iris boundary by drawing concentric circles (Figure 5(b) shows an example) of different radii from the pupil center and the intensities lying over the perimeter of the circle are summed up.","Adaptive Threshold, Circular Hough Transform, Spectrum Image, histogram equalisation, iris recognition, circular summation of intensity, Connected Components, Iris detection, pupil boundary, Iris Segmentation",The proposed system has been tested on two publicly available databases BATH and CASIA V3. From experimental analysis it has been observed that the system is capable of handling unconstrained scenarios as well. The system is capable of performing segmentation for unconstrained scenarios in significantly less time compared to Hough transform.
J. G. De Gooijer,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
J. Gadge,Secure Robust and Imperceptible Algorithm for Watermarking Relational Databases,"This paper proposes a secure robust and imperceptible algorithm for watermarking relational databases. The algorithm divides the embedding algorithm into three phases: Watermark preparator, watermark position detector, and watermark embedder. The ownership identification issue is resolved by embedding owner's identity as watermark in Preparator phase.","imperceptible algorithm, Ownership identification, robust algorithm, Relational Database, watermarking, Watermark, Copyright protection, Proof of ownership, relational databases","The paper proposes a new robust secure and imperceptible embedding mechanism to resolve the two important concerns namely; owner identification and proof of ownership. The proposed mechanism involves encoding and decoding on numerical attribute of relational database in three phases; 1)Watermark preparator, 2)Watermark position detector and 3) Watermark Embedder or Detector."
J. Kasprzak,Unique Local Features in Lip Images for Recognition,"The experiments are carried out from images taken with a camera that is used for the regular use. And the color features of a lip are not explored in the proposed research. Still the recognition system exploits the grayscale local features of a lip images and eﬃciently matches it with local features of another lip image. If the color properties of a lip image is explored for recognition along with local features, the accuracy values would increase further.","grayscale features, Lip Pattern Recognition, SIFT, lip recognition, color features, Biometric, Local Feature Extraction, local features, SURF",The paper presents the results of experiments on lip recognition using local features. The recognition system exploits the grayscale local features of lip images and achieves high accuracy. The authors suggest that exploring color properties of lip images could further improve the accuracy.
J. Siekmann,Lecture Notes in Artificial Intelligence 6465,"This work is subject to copyright. All rights are reserved, whether the whole or part of the material is concerned, specifically the rights of translation, reprinting, re-use of illustrations, recitation, broadcasting, reproduction on microfilms or in any other way, and storage in data banks. Duplication of this publication or parts thereof is permitted only under the provisions of the German Copyright Law of September 9, 1965, in its current version, and permission for use must always be obtained from Springer. Violations are liable to prosecution under the German Copyright Law.","Artificial Intelligence, Computational Linguistics, Sanskrit","The 4th International Sanskrit Computational Linguistics Symposium (4i-SCLS) was hosted by the Jawaharlal Nehru University, the premier research University of India during (December 10–12, 2010) at the Special Center for Sanskrit Studies. The event saw excellent response from the scholars, with more than 31 papers received, which were examined by the Program Committee members to shortlist 18 papers for publication presented in this volume."
J. Singh,Impact of Eurasian Snow Cover on Indian Summer Monsoon Rainfall over the Northwestern Himalayas,"The entire Indo-Himalayan region from northwest (Kashmir) to northeast (Assam) is facing prevalence of floods and landslides in recent years causing massive loss of property, human and animal lives, infrastructure, and eventually threatening tourist activities substantially. Extremely intense rainfall event of A.D. 2013 (between 15 and 17 June) kicked off mammoth flash floods in the Kedarnath area of Uttarakhand state, resulting in huge socioeconomic losses to the state and country.","Eurasian snow cover, extreme rainfall events, flash floods, gridded data sets, Himalayas, Arctic Oscillation, northwestern Himalayas, Indian summer monsoon rainfall","The study investigates ~100-year-long monthly rainfall and air temperature time series data for a selected grid covering most parts of Uttarakhand state. The results indicate that under warming scenario, JJ rainfall (over AS) may further increase with occasional extreme rainfall spells when AO index (March) is negative."
J. Sun,Secure Robust and Imperceptible Algorithm for Watermarking Relational Databases,"This paper proposes a secure robust and imperceptible algorithm for watermarking relational databases. The algorithm divides the embedding algorithm into three phases: Watermark preparator, watermark position detector, and watermark embedder. The ownership identification issue is resolved by embedding owner's identity as watermark in Preparator phase.","imperceptible algorithm, Ownership identification, robust algorithm, Relational Database, watermarking, Watermark, Copyright protection, Proof of ownership, relational databases","The paper proposes a new robust secure and imperceptible embedding mechanism to resolve the two important concerns namely; owner identification and proof of ownership. The proposed mechanism involves encoding and decoding on numerical attribute of relational database in three phases; 1)Watermark preparator, 2)Watermark position detector and 3) Watermark Embedder or Detector."
J. Wu,High-Energy-First (HEF) Heuristic for Energy-Efficient Target Coverage Problem,"Target coverage problem in wireless sensor networks is concerned with maximizing the lifetime of the network while continuously monitoring a set of targets. A sensor covers targets which are within the sensing range. For a set of sensors and a set of targets, the sensor-target coverage relationship is assumed to be known. A sensor cover is a set of sensors that covers all the targets. The target coverage problem is to determine a set of sensor covers with maximum aggregated lifetime while constraining the life of each sensor by its initial battery life. The problem is proved to be NP-complete and heuristic algorithms to solve this problem are proposed. In the present study, we give a unified interpretation of earlier algorithms and propose a new and efficient algorithm. We show that all known algorithms are based on a common reasoning though they seem to be derived from different algorithmic paradigms.  We also show that though some algorithms guarantee bound on the quality of the solution, this bound is not meaningful and not practical too.  Our interpretation provides a better insight to the solution techniques. We propose a new greedy heuristic which prioritizes sensors on residual battery life. We show empirically that the proposed algorithm outperforms all other heuristics in terms of quality of solution. Our experimental study over a large set of randomly generated problem instances also reveals that a very naïve greedy approach yields solutions which is reasonably (appx. 10%) close to the actual optimal solutions.","Network Lifetime, QoS constraints, connected coverage, sensing ranges, Target Coverage Problem, Greedy Heuristic, Wireless Sensor Networks, Energy-Efficiency, target coverage",The paper proposes a new heuristic algorithm for the energy-efficient target coverage problem in wireless sensor networks. The algorithm prioritizes sensors based on their residual battery life and is shown to outperform other heuristics in terms of quality of solution. The paper also provides a unified interpretation of earlier algorithms and shows that they are based on a common reasoning. The experimental study reveals that a naïve greedy approach yields solutions close to the actual optimal solutions.
J. technol. behav. sci.,Emotion Analysis of Frequent Twitter Users During Lockdown,"This study analyzed the emotions of frequent Twitter users during the COVID-19 lockdown in India. The authors collected 7688 emotion-based tweets and 1690 situation-based tweets, and identified 222 frequent users who posted a total of 45,710 tweets during the lockdown period. The k-means clustering algorithm grouped the users into four clusters based on their daily usage pattern, and the authors found that the overall emotion of users varied significantly across the clusters.","COVID-19, k-means clustering, Twitter users, COVID-19 lockdown, Social media addiction, Emotion analysis, Lockdown, Twitter","This study analyzed the social media usage pattern of people during the COVID-19 imposed lockdown in India and the effects of emotion on the same. The study found that 13.5% of users were found to be addicted to Twitter and posted 13.67 tweets daily on an average, while 3.2% were found to be highly addicted and posted 40.71 tweets daily on an average. The overall emotion of 40.1% of the users was happiness throughout the study period. However, it was also observed that users who tweeted more frequently were typically angry, disgusted, or sad about the prevailing situation."
J.-M. Wan,Secure Robust and Imperceptible Algorithm for Watermarking Relational Databases,"This paper proposes a secure robust and imperceptible algorithm for watermarking relational databases. The algorithm divides the embedding algorithm into three phases: Watermark preparator, watermark position detector, and watermark embedder. The ownership identification issue is resolved by embedding owner's identity as watermark in Preparator phase.","imperceptible algorithm, Ownership identification, robust algorithm, Relational Database, watermarking, Watermark, Copyright protection, Proof of ownership, relational databases","The paper proposes a new robust secure and imperceptible embedding mechanism to resolve the two important concerns namely; owner identification and proof of ownership. The proposed mechanism involves encoding and decoding on numerical attribute of relational database in three phases; 1)Watermark preparator, 2)Watermark position detector and 3) Watermark Embedder or Detector."
J.C. Bansal,A Modiﬁed Binary Particle Swarm Optimization for Knapsack Problems ||| Mean particle swarm optimisation for function optimisation,"The Knapsack Problems (KPs) are classical NP-hard problems in Operations Research having a number of engineering applications. Several traditional as well as population based search algorithms are available in literature for the solution of these problems. In this paper, a new Modiﬁed Binary Particle Swarm Optimization (MBPSO) algorithm is proposed for solving KPs, particularly 0–1 Knapsack Problem (KP) and Multidimensional Knapsack Problem (MKP). ||| In this paper, a new particle swarm optimisation algorithm, called MeanPSO, is presented, based on a novel philosophy by modifying the velocity update equation. This is done by replacing two terms of original velocity update equation by two new terms based on the linear combination of pbest and gbest. Its performance is compared with the standard PSO (SPSO) by testing it on a set of 15 scalable and 15 nonscalable test problems. Based on the numerical and graphical analyses of results it is shown that the MeanPSO outperforms the SPSO, in terms of efficiency, reliability, accuracy and stability.","Function Optimisation, Binary Particle Swarm Optimization, Knapsack Problems, velocity update equation, particle swarm optimisation, MeanPSO, Particle Swarm Optimization, PSO, global optimisation, Benchmark Problems, Knapsack Problem, Sigmoid function","The paper introduces a new Modiﬁed Binary Particle Swarm Optimization method (MBPSO) and its application to 0–1 KP and MKP. The proposed method allows for better exploration and efficiency in the search process. ||| This paper proposes a new particle swarm optimisation algorithm, called MeanPSO, which modifies the velocity update equation by replacing two terms with a linear combination of pbest and gbest. The performance of MeanPSO is compared with the standard PSO (SPSO) on 30 benchmark test problems, and it is shown that MeanPSO outperforms SPSO in terms of efficiency, reliability, accuracy, and stability."
J.Kiernan,Secure Robust and Imperceptible Algorithm for Watermarking Relational Databases,"This paper proposes a secure robust and imperceptible algorithm for watermarking relational databases. The algorithm divides the embedding algorithm into three phases: Watermark preparator, watermark position detector, and watermark embedder. The ownership identification issue is resolved by embedding owner's identity as watermark in Preparator phase.","imperceptible algorithm, Ownership identification, robust algorithm, Relational Database, watermarking, Watermark, Copyright protection, Proof of ownership, relational databases","The paper proposes a new robust secure and imperceptible embedding mechanism to resolve the two important concerns namely; owner identification and proof of ownership. The proposed mechanism involves encoding and decoding on numerical attribute of relational database in three phases; 1)Watermark preparator, 2)Watermark position detector and 3) Watermark Embedder or Detector."
J.N. Mishra,Study the modern biochemical analysis techniques of proteins and alkaline phasphtase enzyme system from biological sample chicken liver,"The objective of the study was the biochemical analysis of proteins and Alkaline Phosphatase enzyme system from biological sample Chicken Liver using modern biochemical analysis techniques, including protein extraction, fractionation and electrophoresis separation technique and enzyme analysis.","Amino acids, alkaline phosphatase, Enzymes, Biochemical analysis, peroxidases, acid phosphatase, Protein chains, proteases, Proteins","The paper discusses the biochemical analysis of proteins and alkaline phosphatase enzyme system from chicken liver using modern biochemical analysis techniques. It covers topics such as protein synthesis, structure, and purification, and highlights the importance of proteins in living organisms."
JAGENDRA SINGH,IoT-Based Wireless Polysomnography Intelligent System for Sleep Monitoring,"Polysomnography (PSG) is considered the gold standard in the diagnosis of obstructive sleep apnea (OSA). The diagnosis of OSA requires an overnight sleep experiment in a laboratory. However, due to limitations in relation to the number of labs and beds available, patients often need to wait a long time before being diagnosed and eventually treated. In addition, the unfamiliar environment and restricted mobility when a patient is being tested with a polysomnogram may disturb their sleep, resulting in an incomplete or corrupted test. Therefore, it is posed that a PSG conducted in the patient’s home would be more reliable and convenient. The Internet of Things (IoT) plays a vital role in the e-Health system. In this paper, we implement an IoT-based wireless polysomnography system for sleep monitoring, which utilizes a battery-powered, miniature, wireless, portable, and multipurpose recorder. A Java-based PSG recording program in the personal computer is designed to save several bio-signals and transfer them into the European data format. These PSG records can be used to determine a patient’s sleep stages and diagnose OSA. This system is portable, lightweight, and has low power-consumption. To demonstrate the feasibility of the proposed PSG system, a comparison was made between the standard PSG-Alice 5 Diagnostic Sleep System and the proposed system. Several healthy volunteer patients participated in the PSG experiment and were monitored by both the standard PSG-Alice 5 Diagnostic Sleep System and the proposed system simultaneously, under the supervision of specialists at the Sleep Laboratory in Taipei Veteran General Hospital. A comparison of the results of the time-domain waveform and sleep stage of the two systems shows that the proposed system is reliable and can be applied in practice. The proposed system can facilitate the long-term tracing and research of personal sleep monitoring at home.","sleep monitoring, wireless, Internet of Things, wireless PSG, JAVA, Polysomnography (PSG), IoT","This paper proposes an IoT-based wireless polysomnography system for sleep monitoring, which utilizes a battery-powered, miniature, wireless, portable, and multipurpose recorder. The system is designed to save several bio-signals and transfer them into the European data format, allowing for the determination of a patient’s sleep stages and diagnosis of OSA. The proposed system is compared to the standard PSG-Alice 5 Diagnostic Sleep System and shows reliable results, making it a viable option for long-term tracing and research of personal sleep monitoring at home."
JAYARAM,DISTRIBUTIVITY OF FUZZY IMPLICATIONS OVER NILPOTENT OR STRICT TRIANGULAR CONORMS,"Recently, many works have appeared in this very journal dealing with the distributivity of fuzzy implications over t-norms and t-conorms. These equations have a very important role to play in efficient inferencing in approximate reasoning, especially fuzzy control systems.","nilpotent conorms, fuzzy implication, t-norm, R-implication, t-conorm, fuzzy implications, triangular conorms, functional equations, strict conorms, Combs methods","This paper characterizes functions I that satisfy the functional equation when S1, S2 are either both strict or nilpotent t-conorms. Then, using these characterizations, it investigates the conditions under which the equation holds when I is an R-implication obtained from a strict t-norm."
Jacek M. Zurada,Review and performance comparison of SVM- and ELM- based classiﬁers,"This paper presents how commonly used machine learning classiﬁers can be analyzed using a common framework of convex optimization. Four clas-siﬁer models, the Support Vector Machine (SVM), the Least-Squares SVM (LSSVM), the Extreme Learning Machine (ELM), and the Margin Loss ELM (MLELM) are discussed to demonstrate how speciﬁc parametrizations of a general problem statement aﬀect the classiﬁer design and performance, and how ideas from the four diﬀerent classiﬁers can be mixed and used together.","ELM, SVM, MLELM, randomization, Classiﬁers, LSSVM, convex quadratic programming","The paper discusses the analysis of commonly used machine learning classiﬁers using a common framework of convex optimization. It compares the performance of four classiﬁer models: SVM, LSSVM, ELM, and MLELM, and highlights the differences in their formulations and properties."
Jacek M. Zuradad,Convergence Analyses on Sparse Feedforward Neural Networks via Group Lasso Regularization,"In this paper, a new variant of feedforward neural networks has been proposed for a class of nonsmooth optimization problems. The penalty term of the presented neural networks stems from the Group Lasso method which selects hidden variables in a grouped manner.","Feedforward neural networks, Clarke gradient, Non-differentiability, Group Lasso, Convergence",The paper proposes a new variant of feedforward neural networks for nonsmooth optimization problems using Group Lasso regularization. The convergence analysis shows that the gradient of the smoothing error function approaches zero and the weight sequence converges to a fixed point.
Jacques Zappulla,Cutting Edge: CD8 T Cell-Mediated Demyelination,"We generated mice (DKI) in which the HA coding sequence was introduced in the ubiquitously active Rosa26 locus but where HA transcription was prevented by an upstream LoxP-flanked Stop cassette. The DKI mice were then crossed with the MOGi-Cre mice, which express Cre specifically in oligodendrocytes. The resulting DKI mice excise the Stop cassette due to MOG-controlled Cre expression, leading to restricted HA expression to oligodendrocytes.  We then decided to test whether effector CD8 T cells can mediate oligodendrocyte cell death and demyelination in vivo. Effector T cells were first generated by in vitro activation of Kd:HA512–520 pentamer-specific CD8 T cells obtained from CL4-TCR mice using HA peptide, IL-2, and IL-12. The resulting Tc1 cells produce large amounts of granzyme B (GrB) and IFN-γ and exhibit potent cytotoxicity to HA-loaded target cells in vivo. Next, we transferred these HA-specific Tc1 cells into DKI and control mice. Following i.v. injection of 3 × 107 HA-specific Tc1 cells, but not naive HA-specific CD8 T cells, ~40% of the DKI mice developed an overt monophasic disease peaking at day 8–10 and waning by 4 wk posttransfer. The clinical manifestations included weight loss and, in the more severe cases, tremors, reduced mobility, and difficulty to right when overturned without overt paralysis. Upon histological analysis, all DKI mice injected with Tc1 cells demonstrated clear CNS pathology from day 5 onwards. Inflammatory lesions were never found in control littermates injected in parallel with HA-specific Tc1 cells.",,"This study investigates the role of CD8 T cells in multiple sclerosis (MS) pathogenesis. Researchers generated a mouse model where a model antigen (influenza hemagglutinin) is expressed specifically in oligodendrocytes, the cells responsible for producing myelin in the central nervous system. Transferring activated CD8 T cells specific for this antigen into these mice resulted in inflammatory lesions in the brain, spinal cord, and optic nerve, resembling active MS lesions. These lesions were characterized by CD8 T cell infiltration, loss of oligodendrocytes, demyelination, and microglia activation. This suggests that CD8 T cells can directly contribute to oligodendrocyte death and demyelination in MS, highlighting their potential as therapeutic targets."
Jagdish Chand Bansal,Artificial Bee Colony (ABC) Algorithm ||| Opposition based lévy ﬂight artiﬁcial bee colony ||| Particle Swarm Optimization ||| Spider Monkey Optimization algorithm for numerical optimization,"Artificial bee colony (ABC) optimisation algorithm is a relatively simple and recent population-based probabilistic approach for global optimisation. The solution search equation of ABC is significantly influenced by a random quantity which helps in exploration at the cost of exploitation of the search space. In the ABC, there is a high chance to skip the true solution due to its large step sizes. In order to balance between diversity and convergence in the ABC, a Lévy flight inspired search strategy is proposed and integrated with ABC. The proposed strategy is named as Lévy Flight ABC (LFABC) has both the local and global search capability simultaneously and can be achieved by tuning the Lévy flight parameters and thus automatically tuning the step sizes. ||| Artiﬁcial Bee Colony (ABC) is a well known optimization approach to solve nonlinear and complex prob-lems. It is relatively a simple and recent population based probabilistic approach for global optimization. Similar to other population based algorithms, ABC is also computa-tionally expensive due to its slow nature of search process. The solution search equation of ABC is signiﬁcantly inﬂu-enced by a random quantity which helps in exploration at the cost of exploitation of the search space. In the solution search equation of ABC due to the large step size the chance of skipping the true solution is high. Therefore, in this paper, to balance the diversity and convergence capability of the ABC, Lévy Flight random walk based local search strategy is proposed and incorporated with ABC along with opposition based learning strategy. The proposed algorithm is named as Opposition Based Lévy Flight ABC. The experiments over 14 un-biased test problems of different complexities and ﬁve well known engineering optimization problems show that the proposed algorithm outperforms the basic ABC and its recent variants namely Gbest guided ABC, Best-So-Far ABC, and Modiﬁed ABC in most of the experiments. ||| This chapter discusses the basic version of Particle Swarm Optimization (PSO) algorithm, its parameters, and its working. The PSO algorithm is a population-based search algorithm that uses a swarm of particles to search for the optimal solution. The algorithm is based on the movement of particles in a D-dimensional space, where each particle has a position and a velocity. The position of each particle is updated using the velocity update equation, which is based on the particle's previous position, its personal best position, and the global best position. The algorithm is explained in detail, including the velocity update equation, the position update equation, and the basic principles of PSO. The chapter also discusses the parameters of PSO, including the swarm size, scaling factors, and stopping criterion. A numerical example is provided to illustrate the working of PSO. ||| Swarm intelligence is one of the most promising area for the researchers in the field of numerical optimization. Researchers have developed many algorithms by simulating the swarming behavior of various creatures like ants, honey bees, fish, birds and the findings are very motivating. In this paper, a new approach for numerical optimization is proposed by modeling the foraging behavior of spider monkeys.","ABC algorithm, Metaheuristics, numerical optimisation, Particle Swarm Optimization, Evolutionary computation, Optimisation, Lévy Flight, stochastic optimization, Fission–fusion social system, Spider Monkey Optimization algorithm, Honey bees, convergence speed, local search, Food foraging, Spider monkey optimization, Optimization, numerical optimization algorithm, Swarm intelligence based algorithm, Memetic algorithm, computational complexity, fission-fusion social structure, Artificial Bee Colony, Lévy flight local search, Swarm intelligence, Lévy ﬂight local search, swarm intelligence, Artificial Bee Colony algorithm, foraging behavior, memetic algorithm, PSO","This paper proposes a Lévy flight inspired search strategy to balance between diversity and convergence in the artificial bee colony (ABC) optimisation algorithm. The proposed strategy, named as Lévy Flight ABC (LFABC), has both local and global search capability simultaneously and can be achieved by tuning the Lévy flight parameters. The performance of the proposed strategy is analysed over test problems and five real-world engineering optimisation problems. ||| This paper proposes a new algorithm called Opposition Based Lévy Flight ABC, which combines the Lévy Flight random walk based local search strategy with the opposition based learning strategy. The algorithm is designed to balance the diversity and convergence capability of the ABC. The experiments show that the proposed algorithm outperforms the basic ABC and its recent variants in most of the experiments. ||| This chapter provides an in-depth explanation of the basic version of Particle Swarm Optimization (PSO) algorithm, its parameters, and its working. The PSO algorithm is a population-based search algorithm that uses a swarm of particles to search for the optimal solution. The chapter discusses the velocity update equation, the position update equation, and the basic principles of PSO, as well as the parameters of PSO, including the swarm size, scaling factors, and stopping criterion. A numerical example is provided to illustrate the working of PSO. ||| This paper proposes a new swarm intelligence algorithm based on the foraging behavior of spider monkeys. The foraging behavior of spider monkeys shows that these monkeys fall in the category of fission–fusion social structure (FFSS) based animals. Thus the proposed optimization algorithm which is based on foraging behavior of spider monkeys is explained better in terms of FFSS."
Jaime Lloret,Towards Video Streaming in IoT Environments: Vehicular Communication Perspective ||| Virtualization in Wireless Sensor Networks: Fault Tolerant Embedding for Internet of Things,"Multimedia oriented Internet of Things (IoT) enables pervasive and real-time communication of video, audio and image data among devices in immediate surroundings. Today’s vehicles have the capability of supporting real time multimedia acquisition. Vehicles with high illuminating infrared cameras and customized sensors can communicate with other on-road devices using dedicated short-range communication (DSRC) and 5G enabled communication technologies. Real time incidence of both urban and highway vehicular traffic environment can be captured and transmitted using vehicle-to-vehicle and vehicle-to-infrastructure communication modes. Video streaming in vehicular IoT (VSV-IoT) environments is in growing stage with several challenges that need to be addressed ranging from limited resources in IoT devices, intermittent connection in vehicular networks, heterogeneous devices, dynamism and scalability in video encoding, bandwidth underutilization in video delivery, and attaining application-precise quality of service in video streaming. In this context, this paper presents a comprehensive review on video streaming in IoT environments focusing on vehicular communication perspective. Specifically, the significance of video streaming in vehicular IoT environments is highlighted focusing on the integration of vehicular communication with 5G enabled IoT technologies, and smart city oriented application areas for VSV-IoT. A taxonomy is presented for the classification of related literature on video streaming in vehicular network environments. Following the taxonomy, critical review of literature is performed focusing on major functional model, strengths and weaknesses. Metrics for video streaming in vehicular IoT environments are derived and comparatively analyzed in terms of their usage and evaluation capabilities. Open research challenges in VSV-IoT are identified as future directions of research in the area. The survey would benefit both IoT and vehicle industry practitioners and researchers, in terms of augmenting understanding of vehicular video streaming and its IoT related trends and issues. ||| Recently, virtualization in wireless sensor networks (WSNs) has witnessed significant attention due to the growing service domain for IoT. Related literature on virtualization in WSNs explored resource optimization without considering communication failure in WSNs environments. The failure of a communication link in WSNs impacts many virtual networks running IoT services. In this context, this paper proposes a framework for optimizing fault tolerance in virtualization in WSNs, focusing on heterogeneous networks for service-oriented IoT applications.","Video streaming, Internet of vehicles, traffic safety, vehicular ad-hoc networks, Fault Tolerant Embedding, Vehicular Communication, Intelligent transportation system, Internet of Things, Virtualization, Internet of things, IoT, Wireless sensor networks","The paper discusses the significance of video streaming in vehicular IoT environments, presents a taxonomy for the classification of literature on video streaming over vehicular ad-hoc networks, derives performance metrics for video streaming in vehicular IoT environments, and identifies open research issues and challenges in vehicular video streaming under IoT environments. ||| The paper discusses the importance of virtualization in WSNs for IoT applications, focusing on fault-tolerant embedding. It reviews existing proposals on virtualization in WSNs, highlighting their limitations and proposing a new approach to enhance fault tolerance."
Jain,An Efﬁcient Encryption Algorithm for Sensitive Data Using Numeric and Alphanumeric Format,"In the contemporary world, with the growth of networking and increase in the volume of data storage capacity, a significant amount of personal information leakage accident occurs that leads to loss of personal data day by day. Hence, there arises a need to emphasize more on the security of data stored either in databases or transmitted over the web to ensure that user’s personal data is stored at a safer place. To maintain the privacy and security of data a protective layer of encryption is applied around the sensitive data items focusing on encrypting only the sensitive data. Standard encryption techniques such as AES, DES or 3DES are used to encrypt the data, but these techniques are unsuitable for encrypting personal information as they lead to various shortcomings.","database system, Database, Advanced Encryption Standard (AES), Encryption, Feistel cycle walking, Numeric and Alphanumeric Data, encryption algorithm, Format Preserving Encryption, Data Security",This paper proposes a new and efficient encryption scheme for securing numeric and alphanumeric data of databases. The proposed solution integrates with various encryption schemes such as Advanced Encryption Standard (AES) on the remote side database. Data transmission and data storage take place at the server database. The remote side and server side database will be secured with the same data formats.
James Blanchard,"Seroprevalence of SARS-CoV-2 Antibodies in Uttar Pradesh, India: A Cross-Sectional Study","Population-based serological antibody test for SARS-CoV-2 infection helps in estimating the exposure in the community. We present the findings of the first district representative seroepidemiological survey conducted between 4 and 10 September 2020 among the population aged 5 years and above in the state of Uttar Pradesh, India. Multi-stage cluster sampling was used to select participants from 495 primary sampling units (villages in rural areas and wards in urban areas) across 11 selected districts to provide district-level seroprevalence disaggregated by place of residence (rural/urban), age (5–17 years/aged 18 +) and gender. A venous blood sample was collected to determine seroprevalence. Of 16,012 individuals enrolled in the study, 22.2% [95% CI 21.5–22.9] equating to about 10.4 million population in 11 districts were already exposed to SARS-CoV-2 infection by mid-September 2020. The overall seroprevalence was significantly higher in urban areas (30.6%, 95% CI 29.4–31.7) compared to rural areas (14.7%, 95% CI 13.9–15.6), and among aged 18 + years (23.2%, 95% CI 22.4–24.0) compared to aged 5–17 years (18.4%, 95% CI 17.0–19.9). No differences were observed by gender. Individuals exposed to a COVID confirmed case or residing in a COVID containment zone had higher seroprevalence (34.5% and 26.0%, respectively). There was also a wide variation (10.7–33.0%) in seropositivity across 11 districts indicating that population exposed to COVID was not uniform at the time of the study. Since about 78% of the population (36.5 million) in these districts were still susceptible to infection, public health measures remain essential to reduce further spread.","COVID-19, Seroprevalence, India, SARS-CoV-2, Heterogeneity, Uttar Pradesh","This study presents the first district-level seroprevalence survey of SARS-CoV-2 infection in Uttar Pradesh, India. Conducted in September 2020, the survey found that 22.2% of the population had been exposed to the virus by that time. Seroprevalence was significantly higher in urban areas and among individuals aged 18 and older. The findings highlight the importance of continued public health measures to reduce further spread of the virus."
James G. Groark,BELIMUMAB IN PATIENTS OF BLACK AFRICAN ANCESTRY,"Study design. SELENA–SLEDAI = Safety of Estrogens in Lupus Erythematosus National Assessment–Systemic Lupus Erythemato-sus Disease Activity Index; IV = intravenous.

Randomization and treatment. Using an interactive voice/web response system, patients receiving standard therapy were randomized 2:1 to receive either belimumab 10 mg/kg IV or placebo, which was administered on days 0, 14, and 28 and every 28 days thereafter up to week 48, with a final evaluation at week 52. Randomization was stratified by screening SELENA–SLEDAI score (≤9 versus ≥10), region (US/Canada versus rest of world), and complement level (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]). Detailed randomization data are provided in Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Patients who successfully completed the initial 52-week double-blind phase could enter an optional 6-month open-label extension phase, during which they received belimumab 10 mg/kg IV every 28 days plus standard therapy, irrespective of their previous study assignment. The first dose was given at the week 52 (day 364) visit of the double-blind period (day 1 of the open-label extension phase). Patients who completed the 52-week double-blind phase, but did not enter the 6-month open-label extension phase, were required to return for an additional follow-up visit 8 weeks after their last dose. Patients who withdrew early were required to return for an exit visit 4 weeks after their last dose and a follow-up visit 8 weeks after their last dose.

The original protocol plan was to randomize 816 patients, providing ≥90% power to detect ≥12% absolute improvement in the SRI response rate in the belimumab group compared with the placebo group at a 5% significance level. Due to enrollment challenges, a revised sample size was calculated to include 501 patients (≥334 patients in the belimumab group and ≥167 patients in the placebo group). This sample size provided ≥90% power to detect a minimum 15.55% absolute improvement in SRI–SLEDAI-2K response rate in the belimumab group relative to the placebo group at a 5% significance level (based on the pooled data from efficacy studies BEL112341 and BEL113750) (15,21). These calculations assumed a placebo response rate of 43.95% at week 52.

Study end points and assessments. The primary efficacy end point was the SRI–SLEDAI-2K response rate (defined in the Supplementary Material) at week 52 of the double-blind phase. Unlike in the phase II and phase III studies, the SRI–SLEDAI-2K was selected because of the simplification it offers in proteinuria assessment as compared with the SELENA–SLEDAI proteinuria component; both are clinically meaningful (22). The primary efficacy end point for the open-label extension phase was SRI–SLEDAI-2K response rate at open-label extension week 24. If the open-label extension week 24 data were missing, data from the open-label extension week 28/exit visit were used. This time point is referred to as “open-label extension week 24” throughout the text. Data related to the primary efficacy end point, e.g., the response rate over time, percentage of patients with a durable SRI–SLEDAI-2K response from week 44 through week 52, time to first SRI–SLEDAI-2K response that was maintained through week 52, and duration of longest SRI–SLEDAI-2K response among patients with ≥1 SRI–SLEDAI-2K responses were summarized.

The key secondary end points were SRI–SELENA–SLEDAI at week 52 (open-label extension week 24), time to first severe SLE flare (measured by the SELENA–SLEDAI flare index [SFI]), and proportion of patients whose average prednisone dose had been reduced by ≥25% from baseline to ≤7.5 mg/day during week 40 through week 52 (open-label extension week 28/exit visit), in patients receiving >7.5 mg/day at baseline. Key renal end points included time to first renal flare over 52 weeks and over 28 weeks in the open-label extension, SELENA–SLEDAI–SLEDAI-2K renal domain improvement at week 52, SELENA–SLEDAI–SLEDAI-2K renal domain worsening at week 52, percentage reduction in proteinuria by visit and at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours, and proteinuria shift at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours. Renal flare is defined in the Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Biomarkers measured included percentage changes in serum IgG level, anti-dsDNA antibody level (in those who were anti-dsDNA positive [≥30 IU/ml] at baseline), and complement (C3 and C4) levels from baseline. Safety was evaluated by monitoring adverse events (AEs), serious AEs (SAEs), AEs of special interest, vital signs, clinical laboratory test results, and immunogenicity up to 8 weeks posttreatment and throughout the open-label extension phase.

Data analyses. For the double-blind phase, safety analyses were performed on the safety population, defined as all patients who were randomized and treated with at least 1 dose of investigational product. Data on the safety population were summarized according to the treatment the patient was randomized to receive rather than by the treatment that was received, but both were the same for this study. Efficacy analyses were performed on the modified intent-to-treat (ITT) population, defined as the safety population minus those patients who had any assessment at any of 3 study sites that were excluded from the efficacy analyses before the database lock because of potential Good Clinical Practice noncompliance.

For analysis of the primary and 3 key secondary efficacy end points, a step-down sequential testing procedure was used as described in the Supplementary Material. The following subgroup analyses were performed for the primary analysis (SRI–SLEDAI-2K response at week 52): region (US/Canada versus rest of world), baseline SELENA–SLEDAI–SLEDAI-2K score (≤9 versus ≥10), baseline anti-dsDNA antibody level (≥30 IU/ml versus <30 IU/ml), baseline complement levels (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]), and baseline complement and anti-dsDNA antibody levels (≥1 test finding showing low C3/C4 and anti-dsDNA ≥30 IU/ml versus C3/C4 other and anti-dsDNA ≥30 IU/ml). The odds of an SRI–SLEDAI-2K response with belimumab treatment versus placebo were estimated using logistic regression analysis.

For the open-label extension phase, all patients received belimumab, no formal statistical hypothesis t",,"This study investigated the efficacy and safety of belimumab in patients of Black African ancestry with systemic lupus erythematosus (SLE).  Patients were randomized to receive belimumab or placebo for 52 weeks, followed by an optional 6-month open-label extension phase. The primary efficacy endpoint was the SRI–SLEDAI-2K response rate at week 52.  Key secondary endpoints included SRI–SELENA–SLEDAI at week 52, time to first severe SLE flare, and proportion of patients with a reduction in prednisone dose. Renal and biomarker assessments were also conducted.  The study found that belimumab was effective in improving SLE disease activity and reducing renal flares in patients of Black African ancestry."
James Oates,BELIMUMAB IN PATIENTS OF BLACK AFRICAN ANCESTRY,"Study design. SELENA–SLEDAI = Safety of Estrogens in Lupus Erythematosus National Assessment–Systemic Lupus Erythemato-sus Disease Activity Index; IV = intravenous.

Randomization and treatment. Using an interactive voice/web response system, patients receiving standard therapy were randomized 2:1 to receive either belimumab 10 mg/kg IV or placebo, which was administered on days 0, 14, and 28 and every 28 days thereafter up to week 48, with a final evaluation at week 52. Randomization was stratified by screening SELENA–SLEDAI score (≤9 versus ≥10), region (US/Canada versus rest of world), and complement level (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]). Detailed randomization data are provided in Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Patients who successfully completed the initial 52-week double-blind phase could enter an optional 6-month open-label extension phase, during which they received belimumab 10 mg/kg IV every 28 days plus standard therapy, irrespective of their previous study assignment. The first dose was given at the week 52 (day 364) visit of the double-blind period (day 1 of the open-label extension phase). Patients who completed the 52-week double-blind phase, but did not enter the 6-month open-label extension phase, were required to return for an additional follow-up visit 8 weeks after their last dose. Patients who withdrew early were required to return for an exit visit 4 weeks after their last dose and a follow-up visit 8 weeks after their last dose.

The original protocol plan was to randomize 816 patients, providing ≥90% power to detect ≥12% absolute improvement in the SRI response rate in the belimumab group compared with the placebo group at a 5% significance level. Due to enrollment challenges, a revised sample size was calculated to include 501 patients (≥334 patients in the belimumab group and ≥167 patients in the placebo group). This sample size provided ≥90% power to detect a minimum 15.55% absolute improvement in SRI–SLEDAI-2K response rate in the belimumab group relative to the placebo group at a 5% significance level (based on the pooled data from efficacy studies BEL112341 and BEL113750) (15,21). These calculations assumed a placebo response rate of 43.95% at week 52.

Study end points and assessments. The primary efficacy end point was the SRI–SLEDAI-2K response rate (defined in the Supplementary Material) at week 52 of the double-blind phase. Unlike in the phase II and phase III studies, the SRI–SLEDAI-2K was selected because of the simplification it offers in proteinuria assessment as compared with the SELENA–SLEDAI proteinuria component; both are clinically meaningful (22). The primary efficacy end point for the open-label extension phase was SRI–SLEDAI-2K response rate at open-label extension week 24. If the open-label extension week 24 data were missing, data from the open-label extension week 28/exit visit were used. This time point is referred to as “open-label extension week 24” throughout the text. Data related to the primary efficacy end point, e.g., the response rate over time, percentage of patients with a durable SRI–SLEDAI-2K response from week 44 through week 52, time to first SRI–SLEDAI-2K response that was maintained through week 52, and duration of longest SRI–SLEDAI-2K response among patients with ≥1 SRI–SLEDAI-2K responses were summarized.

The key secondary end points were SRI–SELENA–SLEDAI at week 52 (open-label extension week 24), time to first severe SLE flare (measured by the SELENA–SLEDAI flare index [SFI]), and proportion of patients whose average prednisone dose had been reduced by ≥25% from baseline to ≤7.5 mg/day during week 40 through week 52 (open-label extension week 28/exit visit), in patients receiving >7.5 mg/day at baseline. Key renal end points included time to first renal flare over 52 weeks and over 28 weeks in the open-label extension, SELENA–SLEDAI–SLEDAI-2K renal domain improvement at week 52, SELENA–SLEDAI–SLEDAI-2K renal domain worsening at week 52, percentage reduction in proteinuria by visit and at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours, and proteinuria shift at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours. Renal flare is defined in the Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Biomarkers measured included percentage changes in serum IgG level, anti-dsDNA antibody level (in those who were anti-dsDNA positive [≥30 IU/ml] at baseline), and complement (C3 and C4) levels from baseline. Safety was evaluated by monitoring adverse events (AEs), serious AEs (SAEs), AEs of special interest, vital signs, clinical laboratory test results, and immunogenicity up to 8 weeks posttreatment and throughout the open-label extension phase.

Data analyses. For the double-blind phase, safety analyses were performed on the safety population, defined as all patients who were randomized and treated with at least 1 dose of investigational product. Data on the safety population were summarized according to the treatment the patient was randomized to receive rather than by the treatment that was received, but both were the same for this study. Efficacy analyses were performed on the modified intent-to-treat (ITT) population, defined as the safety population minus those patients who had any assessment at any of 3 study sites that were excluded from the efficacy analyses before the database lock because of potential Good Clinical Practice noncompliance.

For analysis of the primary and 3 key secondary efficacy end points, a step-down sequential testing procedure was used as described in the Supplementary Material. The following subgroup analyses were performed for the primary analysis (SRI–SLEDAI-2K response at week 52): region (US/Canada versus rest of world), baseline SELENA–SLEDAI–SLEDAI-2K score (≤9 versus ≥10), baseline anti-dsDNA antibody level (≥30 IU/ml versus <30 IU/ml), baseline complement levels (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]), and baseline complement and anti-dsDNA antibody levels (≥1 test finding showing low C3/C4 and anti-dsDNA ≥30 IU/ml versus C3/C4 other and anti-dsDNA ≥30 IU/ml). The odds of an SRI–SLEDAI-2K response with belimumab treatment versus placebo were estimated using logistic regression analysis.

For the open-label extension phase, all patients received belimumab, no formal statistical hypothesis t",,"This study investigated the efficacy and safety of belimumab in patients of Black African ancestry with systemic lupus erythematosus (SLE).  Patients were randomized to receive belimumab or placebo for 52 weeks, followed by an optional 6-month open-label extension phase. The primary efficacy endpoint was the SRI–SLEDAI-2K response rate at week 52.  Key secondary endpoints included SRI–SELENA–SLEDAI at week 52, time to first severe SLE flare, and proportion of patients with a reduction in prednisone dose. Renal and biomarker assessments were also conducted.  The study found that belimumab was effective in improving SLE disease activity and reducing renal flares in patients of Black African ancestry."
Jamil Ahmad et al.,Deep Learning Techniques for Disease Detection in Fruits and Vegetables,"Plant Diseases are one of the leading reasons of economic shortfalls in agricultural and farming sectors worldwide. It is the most essential element since it reduces crop quantity and quality significantly. Fruits are one of the largest essential nutritional resources from plants. Unfortunately, a variety of conditions might impair both the content and outcome of fruits. As a result, an autonomous Computer Vision (CV) -based approach for reliable Fruit Disease Detection (FDD) is necessary.","Attention mechanisms, Transfer learning, Convolutional neural networks, Computer Vision, Machine Learning, Disease detection, Deep Learning, Fruits and vegetables, Fruit Disease Detection","This paper presents a detailed review of different ML and DL algorithms developed to predict and classify FDs from different fruit images. First, different FDD and classification systems designed by many researchers based on ML and DL algorithms are studied in brief. Then, a detailed analysis is carried out in order to identify the shortcomings of existing algorithms and to provide a novel strategy for properly classifying fruit pathogens."
Jan Bauer,Cutting Edge: CD8 T Cell-Mediated Demyelination,"We generated mice (DKI) in which the HA coding sequence was introduced in the ubiquitously active Rosa26 locus but where HA transcription was prevented by an upstream LoxP-flanked Stop cassette. The DKI mice were then crossed with the MOGi-Cre mice, which express Cre specifically in oligodendrocytes. The resulting DKI mice excise the Stop cassette due to MOG-controlled Cre expression, leading to restricted HA expression to oligodendrocytes.  We then decided to test whether effector CD8 T cells can mediate oligodendrocyte cell death and demyelination in vivo. Effector T cells were first generated by in vitro activation of Kd:HA512–520 pentamer-specific CD8 T cells obtained from CL4-TCR mice using HA peptide, IL-2, and IL-12. The resulting Tc1 cells produce large amounts of granzyme B (GrB) and IFN-γ and exhibit potent cytotoxicity to HA-loaded target cells in vivo. Next, we transferred these HA-specific Tc1 cells into DKI and control mice. Following i.v. injection of 3 × 107 HA-specific Tc1 cells, but not naive HA-specific CD8 T cells, ~40% of the DKI mice developed an overt monophasic disease peaking at day 8–10 and waning by 4 wk posttransfer. The clinical manifestations included weight loss and, in the more severe cases, tremors, reduced mobility, and difficulty to right when overturned without overt paralysis. Upon histological analysis, all DKI mice injected with Tc1 cells demonstrated clear CNS pathology from day 5 onwards. Inflammatory lesions were never found in control littermates injected in parallel with HA-specific Tc1 cells.",,"This study investigates the role of CD8 T cells in multiple sclerosis (MS) pathogenesis. Researchers generated a mouse model where a model antigen (influenza hemagglutinin) is expressed specifically in oligodendrocytes, the cells responsible for producing myelin in the central nervous system. Transferring activated CD8 T cells specific for this antigen into these mice resulted in inflammatory lesions in the brain, spinal cord, and optic nerve, resembling active MS lesions. These lesions were characterized by CD8 T cell infiltration, loss of oligodendrocytes, demyelination, and microglia activation. This suggests that CD8 T cells can directly contribute to oligodendrocyte death and demyelination in MS, highlighting their potential as therapeutic targets."
Jan Chorowski,Review and performance comparison of SVM- and ELM- based classiﬁers,"This paper presents how commonly used machine learning classiﬁers can be analyzed using a common framework of convex optimization. Four clas-siﬁer models, the Support Vector Machine (SVM), the Least-Squares SVM (LSSVM), the Extreme Learning Machine (ELM), and the Margin Loss ELM (MLELM) are discussed to demonstrate how speciﬁc parametrizations of a general problem statement aﬀect the classiﬁer design and performance, and how ideas from the four diﬀerent classiﬁers can be mixed and used together.","ELM, SVM, MLELM, randomization, Classiﬁers, LSSVM, convex quadratic programming","The paper discusses the analysis of commonly used machine learning classiﬁers using a common framework of convex optimization. It compares the performance of four classiﬁer models: SVM, LSSVM, ELM, and MLELM, and highlights the differences in their formulations and properties."
Jaspal Singh Saini,Shifting Behaviour of Users: Towards Understanding the Fundamental Law of Social Networks,"Social Networking Sites (SNSs) are powerful marketing and communication tools. There are hundreds of SNSs that have entered and exited the market over time. The coexistence of multiple SNSs is a rarely observed phenomenon. Most coexisting SNSs either serve different purposes for its users or have cultural differences among them. The introduction of a new SNS with a better set of features can lead to the demise of an existing SNS, as observed in the transition from Orkut to Facebook. The paper proposes a model for analyzing the transition of users from one SNS to another, when a new SNS is introduced in the system. The game theoretic model proposed considers two major factors in determining the success of a new SNS. The first being time that an old SNS gets to stabilise. We study whether the time that a SNS like Facebook received to monopolize its reach had a distinguishable effect. The second factor is the set of features showcased by the new SNS. The results of the model are also experimentally verified with data collected by means of a survey.","game theory, Game Theoretic Model, Diffusive Shift, Social Networking Sites, modeling, social networking, Cascading Pattern",This paper proposes a model for analyzing the transition of users from one Social Networking Site (SNS) to another when a new SNS is introduced in the system. The model considers two major factors in determining the success of a new SNS: the time an old SNS gets to stabilize and the set of features showcased by the new SNS. The results of the model are experimentally verified with data collected by means of a survey.
Jeffrey Fill,First-­in-­Human Study of Bamlanivimab in a Randomized Trial of Hospitalized Patients With COVID-­19,"This first-in-human study in hospitalized patients with COVID-19 was supported by studies assessing in vitro viral neutralization combined with a single-dose non-human primate PK study. The nonclinical safety package to support subsequent studies included tissue cross-reactivity studies on human, rat, and monkey tissues and an in vivo toxicology study.  A complete physical examination was conducted at the screening visit, and one of three bamlanivimab doses or placebo was administered i.v. at the baseline visit (D1) with infusion rates as follows: bamlanivimab 700 mg (50 mL) administered 100 mL/hr for 30 minutes; 2,800 mg (75 mL) administered 100 mL/hr for 45 minutes; and 7,000 mg administered 100 mL/hr for 60 minutes. Placebo infusion was 0.9% normal saline, administered at the same volume and rate as the corresponding bamlanivimab dose cohort. Safety and tolerability were reviewed for sentinel participants up to 24 hours after dosing, at which point the investigators and sponsor team determined whether safety and tolerability were acceptable to continue with dosing subsequent participants. The decision to dose the next cohort was made when all participants from the previous cohort had been dosed and safety data assessed for at least 4 days after the i.v. infusion by the investigators and sponsor team in consultation with an independent safety assessment committee. Blood samples were obtained for assessment of exploratory biomarkers, serology, clinical laboratory assessments, and PD on days 1, 3, 7, 11, 15, 22, and 29, and every 7 days until discharge or day 60, if still an inpatient. Samples for the virology assay were collected using nasopharyngeal (preferred) or mid-turbinate methods. Blood samples obtained for PK analyses were assessed on days 1 (pre-infusion and just before end of infusion), 4, 15, and 29, and follow-up visits up to day 60. Symptom-related physical examinations and assessments of clinical symptoms were performed on days 1, 2, 3, 4, 7, 11, 15, 22, and 29, and the day of discharge from the hospital, with additional follow-up examinations every 7 days thereafter until day 60 if the patient was not discharged from the hospital by day 29. Participants’ clinical status and concurrent procedures of special interest were recorded, including limitation on activities due to COVID-19 and any requirements for the following procedures of special interest, such as ongoing hospital medical care, supplemental oxygen, noninvasive ventilation or a high flow oxygen device, mechanical ventilation, extracorporeal membrane oxygenation, additional organ support, or consciousness status using alert, consciousness, verbal, pain, unresponsive scale. Hospitalization events were recorded, including dates of hospital admission and discharge, admission to the intensive care unit (ICU), discharge from the ICU, and discharge location including to an extended care facility or home. Outcomes The primary objective was to assess safety and tolerability, including adverse events (AEs), serious adverse events (SAEs), and discontinuations due to AEs. Other objectives included PKs (e.g., mean concentration at day 29); PD viral load, area under the response time curve (AUC, from day 1 to day 29), and change from baseline time course; total symptom score; time to symptom resolution; duration of hospitalization; National Institute of Allergy and Infectious Diseases (NIAID), World Health Organization (WHO) scales, and National Early Warning Score (NEWS2); and analysis of viral resistance. Any hypothesis tests were conducted for treatment comparisons without adjustment for multiplicity except for the evaluation of treatment effect on endogenous antibody titers. Success for the trial was claimed using a Bayesian criterion if any of the 3 bamlanivimab doses had at least 60% probability to reduce at least 30% mean AUC (28-day viral load) over placebo.",,"This first-in-human study evaluated the safety, tolerability, pharmacokinetics, clinical course, and viral dynamics of bamlanivimab, a fully human neutralizing monoclonal antibody targeting SARS-CoV-2, in hospitalized patients with moderate to severe COVID-19.  The study found bamlanivimab to be safe and well-tolerated, with no serious adverse events or deaths reported.  Further research is needed to determine the efficacy of bamlanivimab in treating COVID-19."
"Jena, D.",A New MPPT Design Using Grey Wolf Optimization Technique for Photovoltaic System Under Partial Shading Conditions,"A new maximum power point tracking (MPPT) design using grey wolf optimization (GWO) technique is proposed in this paper. The proposed GWO-based MPPT algorithm is compared with improved particle swarm optimization (IPSO) and perturb and observe (P&O) algorithms. The simulation results show that the proposed GWO-based MPPT outperforms the other two methods in terms of faster convergence to the global peak (GP), tracking speed, reduced steady-state oscillations, and higher tracking efficiency.","Grey wolf optimization, Grey wolf optimization (GWO), Partial shading, MPPT algorithm, maximum power point tracking (MPPT), Maximum power point tracking, GWO-based MPPT, partial shading conditions (PSCs), photovoltaic (PV)","The proposed GWO-based MPPT algorithm is compared with IPSO and P&O algorithms in terms of convergence speed, tracking efficiency, and oscillations. The simulation results show that the proposed GWO-based MPPT outperforms the other two methods."
Jennifer A. Gilbride,BELIMUMAB IN PATIENTS OF BLACK AFRICAN ANCESTRY,"Study design. SELENA–SLEDAI = Safety of Estrogens in Lupus Erythematosus National Assessment–Systemic Lupus Erythemato-sus Disease Activity Index; IV = intravenous.

Randomization and treatment. Using an interactive voice/web response system, patients receiving standard therapy were randomized 2:1 to receive either belimumab 10 mg/kg IV or placebo, which was administered on days 0, 14, and 28 and every 28 days thereafter up to week 48, with a final evaluation at week 52. Randomization was stratified by screening SELENA–SLEDAI score (≤9 versus ≥10), region (US/Canada versus rest of world), and complement level (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]). Detailed randomization data are provided in Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Patients who successfully completed the initial 52-week double-blind phase could enter an optional 6-month open-label extension phase, during which they received belimumab 10 mg/kg IV every 28 days plus standard therapy, irrespective of their previous study assignment. The first dose was given at the week 52 (day 364) visit of the double-blind period (day 1 of the open-label extension phase). Patients who completed the 52-week double-blind phase, but did not enter the 6-month open-label extension phase, were required to return for an additional follow-up visit 8 weeks after their last dose. Patients who withdrew early were required to return for an exit visit 4 weeks after their last dose and a follow-up visit 8 weeks after their last dose.

The original protocol plan was to randomize 816 patients, providing ≥90% power to detect ≥12% absolute improvement in the SRI response rate in the belimumab group compared with the placebo group at a 5% significance level. Due to enrollment challenges, a revised sample size was calculated to include 501 patients (≥334 patients in the belimumab group and ≥167 patients in the placebo group). This sample size provided ≥90% power to detect a minimum 15.55% absolute improvement in SRI–SLEDAI-2K response rate in the belimumab group relative to the placebo group at a 5% significance level (based on the pooled data from efficacy studies BEL112341 and BEL113750) (15,21). These calculations assumed a placebo response rate of 43.95% at week 52.

Study end points and assessments. The primary efficacy end point was the SRI–SLEDAI-2K response rate (defined in the Supplementary Material) at week 52 of the double-blind phase. Unlike in the phase II and phase III studies, the SRI–SLEDAI-2K was selected because of the simplification it offers in proteinuria assessment as compared with the SELENA–SLEDAI proteinuria component; both are clinically meaningful (22). The primary efficacy end point for the open-label extension phase was SRI–SLEDAI-2K response rate at open-label extension week 24. If the open-label extension week 24 data were missing, data from the open-label extension week 28/exit visit were used. This time point is referred to as “open-label extension week 24” throughout the text. Data related to the primary efficacy end point, e.g., the response rate over time, percentage of patients with a durable SRI–SLEDAI-2K response from week 44 through week 52, time to first SRI–SLEDAI-2K response that was maintained through week 52, and duration of longest SRI–SLEDAI-2K response among patients with ≥1 SRI–SLEDAI-2K responses were summarized.

The key secondary end points were SRI–SELENA–SLEDAI at week 52 (open-label extension week 24), time to first severe SLE flare (measured by the SELENA–SLEDAI flare index [SFI]), and proportion of patients whose average prednisone dose had been reduced by ≥25% from baseline to ≤7.5 mg/day during week 40 through week 52 (open-label extension week 28/exit visit), in patients receiving >7.5 mg/day at baseline. Key renal end points included time to first renal flare over 52 weeks and over 28 weeks in the open-label extension, SELENA–SLEDAI–SLEDAI-2K renal domain improvement at week 52, SELENA–SLEDAI–SLEDAI-2K renal domain worsening at week 52, percentage reduction in proteinuria by visit and at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours, and proteinuria shift at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours. Renal flare is defined in the Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Biomarkers measured included percentage changes in serum IgG level, anti-dsDNA antibody level (in those who were anti-dsDNA positive [≥30 IU/ml] at baseline), and complement (C3 and C4) levels from baseline. Safety was evaluated by monitoring adverse events (AEs), serious AEs (SAEs), AEs of special interest, vital signs, clinical laboratory test results, and immunogenicity up to 8 weeks posttreatment and throughout the open-label extension phase.

Data analyses. For the double-blind phase, safety analyses were performed on the safety population, defined as all patients who were randomized and treated with at least 1 dose of investigational product. Data on the safety population were summarized according to the treatment the patient was randomized to receive rather than by the treatment that was received, but both were the same for this study. Efficacy analyses were performed on the modified intent-to-treat (ITT) population, defined as the safety population minus those patients who had any assessment at any of 3 study sites that were excluded from the efficacy analyses before the database lock because of potential Good Clinical Practice noncompliance.

For analysis of the primary and 3 key secondary efficacy end points, a step-down sequential testing procedure was used as described in the Supplementary Material. The following subgroup analyses were performed for the primary analysis (SRI–SLEDAI-2K response at week 52): region (US/Canada versus rest of world), baseline SELENA–SLEDAI–SLEDAI-2K score (≤9 versus ≥10), baseline anti-dsDNA antibody level (≥30 IU/ml versus <30 IU/ml), baseline complement levels (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]), and baseline complement and anti-dsDNA antibody levels (≥1 test finding showing low C3/C4 and anti-dsDNA ≥30 IU/ml versus C3/C4 other and anti-dsDNA ≥30 IU/ml). The odds of an SRI–SLEDAI-2K response with belimumab treatment versus placebo were estimated using logistic regression analysis.

For the open-label extension phase, all patients received belimumab, no formal statistical hypothesis t",,"This study investigated the efficacy and safety of belimumab in patients of Black African ancestry with systemic lupus erythematosus (SLE).  Patients were randomized to receive belimumab or placebo for 52 weeks, followed by an optional 6-month open-label extension phase. The primary efficacy endpoint was the SRI–SLEDAI-2K response rate at week 52.  Key secondary endpoints included SRI–SELENA–SLEDAI at week 52, time to first severe SLE flare, and proportion of patients with a reduction in prednisone dose. Renal and biomarker assessments were also conducted.  The study found that belimumab was effective in improving SLE disease activity and reducing renal flares in patients of Black African ancestry."
Jenny Chien,First-­in-­Human Study of Bamlanivimab in a Randomized Trial of Hospitalized Patients With COVID-­19,"This first-in-human study in hospitalized patients with COVID-19 was supported by studies assessing in vitro viral neutralization combined with a single-dose non-human primate PK study. The nonclinical safety package to support subsequent studies included tissue cross-reactivity studies on human, rat, and monkey tissues and an in vivo toxicology study.  A complete physical examination was conducted at the screening visit, and one of three bamlanivimab doses or placebo was administered i.v. at the baseline visit (D1) with infusion rates as follows: bamlanivimab 700 mg (50 mL) administered 100 mL/hr for 30 minutes; 2,800 mg (75 mL) administered 100 mL/hr for 45 minutes; and 7,000 mg administered 100 mL/hr for 60 minutes. Placebo infusion was 0.9% normal saline, administered at the same volume and rate as the corresponding bamlanivimab dose cohort. Safety and tolerability were reviewed for sentinel participants up to 24 hours after dosing, at which point the investigators and sponsor team determined whether safety and tolerability were acceptable to continue with dosing subsequent participants. The decision to dose the next cohort was made when all participants from the previous cohort had been dosed and safety data assessed for at least 4 days after the i.v. infusion by the investigators and sponsor team in consultation with an independent safety assessment committee. Blood samples were obtained for assessment of exploratory biomarkers, serology, clinical laboratory assessments, and PD on days 1, 3, 7, 11, 15, 22, and 29, and every 7 days until discharge or day 60, if still an inpatient. Samples for the virology assay were collected using nasopharyngeal (preferred) or mid-turbinate methods. Blood samples obtained for PK analyses were assessed on days 1 (pre-infusion and just before end of infusion), 4, 15, and 29, and follow-up visits up to day 60. Symptom-related physical examinations and assessments of clinical symptoms were performed on days 1, 2, 3, 4, 7, 11, 15, 22, and 29, and the day of discharge from the hospital, with additional follow-up examinations every 7 days thereafter until day 60 if the patient was not discharged from the hospital by day 29. Participants’ clinical status and concurrent procedures of special interest were recorded, including limitation on activities due to COVID-19 and any requirements for the following procedures of special interest, such as ongoing hospital medical care, supplemental oxygen, noninvasive ventilation or a high flow oxygen device, mechanical ventilation, extracorporeal membrane oxygenation, additional organ support, or consciousness status using alert, consciousness, verbal, pain, unresponsive scale. Hospitalization events were recorded, including dates of hospital admission and discharge, admission to the intensive care unit (ICU), discharge from the ICU, and discharge location including to an extended care facility or home. Outcomes The primary objective was to assess safety and tolerability, including adverse events (AEs), serious adverse events (SAEs), and discontinuations due to AEs. Other objectives included PKs (e.g., mean concentration at day 29); PD viral load, area under the response time curve (AUC, from day 1 to day 29), and change from baseline time course; total symptom score; time to symptom resolution; duration of hospitalization; National Institute of Allergy and Infectious Diseases (NIAID), World Health Organization (WHO) scales, and National Early Warning Score (NEWS2); and analysis of viral resistance. Any hypothesis tests were conducted for treatment comparisons without adjustment for multiplicity except for the evaluation of treatment effect on endogenous antibody titers. Success for the trial was claimed using a Bayesian criterion if any of the 3 bamlanivimab doses had at least 60% probability to reduce at least 30% mean AUC (28-day viral load) over placebo.",,"This first-in-human study evaluated the safety, tolerability, pharmacokinetics, clinical course, and viral dynamics of bamlanivimab, a fully human neutralizing monoclonal antibody targeting SARS-CoV-2, in hospitalized patients with moderate to severe COVID-19.  The study found bamlanivimab to be safe and well-tolerated, with no serious adverse events or deaths reported.  Further research is needed to determine the efficacy of bamlanivimab in treating COVID-19."
Jian Wang,A new method for rock brittleness evaluation in tight oil formation from conventional logs and petrophysical data ||| Convergence Analysis of Online Gradient Methods for Feedforward Neural Networks ||| Fractional-Order BP Algorithm for Training Fractional FNNs ||| History Matching of Naturally Fractured Reservoirs Using a Deep Sparse Autoencoder ||| Reservoir Characterization and Productivity Forecast Based on Knowledge Interaction Neural Network ||| Review and performance comparison of SVM- and ELM- based classiﬁers,"Brittleness is a critical indicator for hydraulic fracturing candidate screening in unconventional reservoirs. Current rock brittleness estimation models are often inferred from mechanical parameters and mineralogical data, which primarily use empirical equations. However, the absence of shear sonic velocity data and insufficient mineral data sometimes restricts its wide application. In this article, our objective is to illustrate the application of a data-driven approach for rock brittleness estimation that employs computational intelligence technologies (multilayer perception and radial basis function models) that use conventional well logs as inputs. ||| This paper considers a class of online gradient learning methods for backpropagation (BP) neural networks with a single hidden layer. We assume that in each training cycle, each sample in the training set is supplied in a stochastic order to the network exactly once. It is interesting that these stochastic learning methods can be shown to be deterministically convergent. This paper presents some weak and strong convergence results for the learning methods, indicating that the gradient of the error function goes to zero and the weight sequence goes to a fixed point, respectively. The conditions on the activation function and the learning rate to guarantee the convergence are relaxed compared with the existing results. Our convergence results are valid for not only S–S type neural networks (both the output and hidden neurons are Sigmoid functions), but also for P–P, P–S and S–P type neural networks, where S and P represent Sigmoid and polynomial functions, respectively. ||| Fractional calculus has been found to be a promising area of research for information processing and modeling of some physical systems. In this paper, we propose a fractional gradient descent method for the backpropagation (BP) training of neural networks. In particular, the Caputo derivative is employed to evaluate the fractional-order gradient of the error defined as the traditional quadratic energy function. The monotonicity and weak (strong) convergence of the proposed approach are proved in detail. Two simulations have been implemented to illustrate the performance of presented fractional-order BP algorithm on three small datasets and one large dataset. The numerical simulations effectively verify the theoretical observations of this paper as well. ||| This work proposes a new characterization method and a method to reduce dimensionality for history matching of naturally fractured reservoirs. The forward simulator is modeled after the EDFM given its computational efficiency. The fracture network can be represented with length, orientation, and position, including large-scale fractures and small-scale fractures. ||| The reservoir characterization aims to provide the analysis and quantification of the injection-production relationship, which is the fundamental work for production management. The connectivity between injectors and producers is dominated by geological properties, especially permeability. However, the permeability parameters are very heterogenous in oil reservoirs, and expensive to collect by well logging. The commercial simulators enable to get accurate simulation but require sufficient geological properties and consume excessive computation resources. ||| This paper presents how commonly used machine learning classiﬁers can be analyzed using a common framework of convex optimization. Four clas-siﬁer models, the Support Vector Machine (SVM), the Least-Squares SVM (LSSVM), the Extreme Learning Machine (ELM), and the Margin Loss ELM (MLELM) are discussed to demonstrate how speciﬁc parametrizations of a general problem statement aﬀect the classiﬁer design and performance, and how ideas from the four diﬀerent classiﬁers can be mixed and used together.","History matching, Naturally fractured reservoirs, MLELM, reservoir characterization, Caputo fractional-order derivative, fracture network, LSSVM, Rock brittleness, SVM, characterization method, feedforward neural networks, convergence analysis, OGM-SS, productivity prediction, randomization, Productivity Forecast, rock mechanics, online gradient methods, BP algorithm, Multilayer perception, Backpropagation learning, Backpropagation, Strong convergence, Online gradient method, Deep sparse autoencoder, oil and gas exploration, Physical Knowledge, Classiﬁers, Monotonicity, embedded model, Neural networks, Radial basis function, OGM-F, convex quadratic programming, Caputo derivative, fractional-order neural networks, ELM, production, brittleness, EDFM, knowledge interaction neural network, Computational intelligence, Hydraulic fracturing, Tight oil, Fractional calculus, machine learning, dimensionality reduction, Weak convergence, training FNNs, Convergence","The paper reviews the current state of brittleness calculation methods and their limitations, highlighting the need for a universally applicable model. It discusses the importance of mineral composition, strain rate, temperature, pore pressure, saturation, and stress state in controlling rock brittleness. ||| This paper presents a comprehensive study on the weak and strong convergence for OGM-F and OGM-SS, indicating that the gradient of the error function goes to zero and the weight sequence goes to a fixed point, respectively. The conditions on the activation function and the learning rate to guarantee the convergence are much relaxed compared with the existing results. ||| This paper proposes a fractional gradient descent method for the backpropagation (BP) training of neural networks, employing the Caputo derivative to evaluate the fractional-order gradient of the error. The monotonicity and weak (strong) convergence of the proposed approach are proved in detail, and numerical simulations are implemented to illustrate its performance on various datasets. ||| This paper proposes a new characterization method for the multiscale fracture network, and a powerful dimensionality-reduction method by means of an autoencoder for model parameters. The characterization method of the fracture network is dependent on the length, orientation, and position of fractures, including large-scale and small-scale fractures. ||| The goal of this study is to improve the accuracy and stableness of the inter-well connectivity characterization and enhance the prediction precision on well productivity, by combining the physical knowledge with machine learning techniques. An innovative neural network is proposed to handle the reservoir characterization and productivity forecast problems, in which the material balance equation is embedded via three high transparent modules, thereby ensuring the physical sense of model parameters. ||| The paper discusses the analysis of commonly used machine learning classiﬁers using a common framework of convex optimization. It compares the performance of four classiﬁer models: SVM, LSSVM, ELM, and MLELM, and highlights the differences in their formulations and properties."
Jian Wanga,Convergence Analyses on Sparse Feedforward Neural Networks via Group Lasso Regularization,"In this paper, a new variant of feedforward neural networks has been proposed for a class of nonsmooth optimization problems. The penalty term of the presented neural networks stems from the Group Lasso method which selects hidden variables in a grouped manner.","Feedforward neural networks, Clarke gradient, Non-differentiability, Group Lasso, Convergence",The paper proposes a new variant of feedforward neural networks for nonsmooth optimization problems using Group Lasso regularization. The convergence analysis shows that the gradient of the smoothing error function approaches zero and the weight sequence converges to a fixed point.
Jiandong Wang,A Layered-Coevolution-Based Attribute-Boosted Reduction Using Adaptive Quantum Behavior PSO and Its Consistent Segmentation for Neonates Brain Tissue,"The main challenge of attribute reduction in large data applications is to develop a new algorithm to deal with large, noisy, and uncertain large data linking multiple relevant data sources, structured or unstructured. This paper proposes a new and efficient layered-coevolution-based attribute-boosted reduction algorithm (LCQ-ABR*) using adaptive quantum behavior particle swarm optimization (PSO).","Layered Co-Evolutionary Model, Quantum-Behavior PSO, adaptive quantum behavior PSO, Attribute-boosted reduction, Multi-Agent Interaction, Neonatal Brain Tissue 3D-MRI, sulci and gyrus estimate, consistent segmentation for neonates brain tissue, Self-Adaptive Memeplexes, layered-coevolution with multi-agent interaction","This paper proposes a new attribute reduction algorithm using quantum behavior PSO, which aims to choose attribute subsets for large-scale, noisy, and uncertain datasets. The algorithm is evaluated on several benchmark datasets and compared with other representative algorithms. The results show that the proposed algorithm has better feasibility and effectiveness than the compared algorithms."
Jianfa Han,Reservoir Characterization and Productivity Forecast Based on Knowledge Interaction Neural Network,"The reservoir characterization aims to provide the analysis and quantification of the injection-production relationship, which is the fundamental work for production management. The connectivity between injectors and producers is dominated by geological properties, especially permeability. However, the permeability parameters are very heterogenous in oil reservoirs, and expensive to collect by well logging. The commercial simulators enable to get accurate simulation but require sufficient geological properties and consume excessive computation resources.","knowledge interaction neural network, machine learning, productivity prediction, reservoir characterization, Productivity Forecast, Physical Knowledge, embedded model","The goal of this study is to improve the accuracy and stableness of the inter-well connectivity characterization and enhance the prediction precision on well productivity, by combining the physical knowledge with machine learning techniques. An innovative neural network is proposed to handle the reservoir characterization and productivity forecast problems, in which the material balance equation is embedded via three high transparent modules, thereby ensuring the physical sense of model parameters."
Jianfei Cai,Scalable GPs,"The vast quantity of information brought by big data as well as the evolving computer hardware encourages success stories in the machine learning community. In the meanwhile, it poses challenges for the Gaussian process (GP) regression, a well-known non-parametric and interpretable Bayesian model, which suffers from cubic complexity to data size. To improve the scalability while retaining desirable prediction quality, a variety of scalable GPs have been presented. But they have not yet been comprehensively reviewed and analyzed in order to be well understood by both academia and industry.","big data, Scalable GPs, local approximations, Gaussian Processes, Gaussian process regression, sparse approximations, scalability","This paper reviews state-of-the-art scalable GPs involving two main categories: global approximations which distillate the entire data and local approximations which divide the data for subspace learning. Recent advances for improving the scalability and capability of scalable GPs are reviewed. Finally, the extensions and open issues regarding the implementation of scalable GPs in various scenarios are reviewed and discussed to inspire novel ideas for future research avenues."
Jie Zhang,Consistencies and Contradictions of Performance Metrics in Multiobjective Optimization,"An important consideration of Multiobjective Optimization (MOO) is the quantitative metrics used for defining the optimality of different solution sets, which is also the basic principle for the design and evaluation of MOO algorithms.","Diversity, Capacity, Multiobjective Optimization, Hypervolume, Performance Metrics, Convergence","This paper investigates the relationships among representative group metrics in Multiobjective Optimization, including Generational Distance (GD), ϵ-indicator (I1ϵ+), Spread (∆), Generalized Spread (∆∗), Inverted Generational Distance (IGD) and Hypervolume (HV). Experimental results indicated that these six metrics show high consistencies when Pareto fronts (PFs) are convex, whereas they show certain contradictions on concave PFs."
"Jill P. Buyon, MD",Cardiac Neonatal Lupus: Maternal and Fetal Risk Factors for Mortality,"Background: Cardiac neonatal lupus (CNL) is a serious complication of maternal anti-Ro/SSA and anti-La/SSB antibodies.  We sought to identify maternal and fetal risk factors for mortality in infants with CNL.

Methods and Results: We retrospectively analyzed data from 325 infants with CNL born to 297 mothers. Overall, 57 deaths (17.5%) occurred. Hydrops, carditis, and EFE were associated with increased mortality in both in utero and postnatal deaths. Maternal diagnosis of SLE and/or SS was associated with increased mortality in the overall analysis and in utero deaths.  Whites were less likely to die than minorities.

Conclusions: Hydrops, carditis, EFE, and maternal SLE and/or SS are significant risk factors for mortality in infants with CNL.","mortality, morbidity, cardiomyopathy, antibodies, heart block","This study investigates maternal and fetal risk factors for mortality in infants with cardiac neonatal lupus (CNL).  Key findings include the significant association of hydrops, carditis, EFE, and maternal SLE and/or SS with increased mortality. Additionally, white infants were found to have a lower mortality rate compared to minorities."
Jinding Zhang,History Matching of Naturally Fractured Reservoirs Using a Deep Sparse Autoencoder,"This work proposes a new characterization method and a method to reduce dimensionality for history matching of naturally fractured reservoirs. The forward simulator is modeled after the EDFM given its computational efficiency. The fracture network can be represented with length, orientation, and position, including large-scale fractures and small-scale fractures.","History matching, characterization method, EDFM, Naturally fractured reservoirs, Deep sparse autoencoder, dimensionality reduction, fracture network","This paper proposes a new characterization method for the multiscale fracture network, and a powerful dimensionality-reduction method by means of an autoencoder for model parameters. The characterization method of the fracture network is dependent on the length, orientation, and position of fractures, including large-scale and small-scale fractures."
Jinyu Sun,Endogenous IRAK-M Attenuates Postinfarction Remodeling Through Effects on Macrophages and Fibroblasts,"Quantitative polymerase chain reaction analysis demonstrated significant IRAK-M mRNA upregulation in the infarcted myocardium. The time course of IRAK-M induction showed a biphasic response (Figure 1), characterized by marked early upregulation after 6 hours of reperfusion, followed by a second peak after 7 days of reperfusion (Figure 1A). IRAK-M Is Localized in Infarct Macrophages and Myofibroblasts Dual immunofluorescence was used to study IRAK-M localization in the infarcted myocardium. IRAK-M immunoreactivity in the infarcted heart was localized in Mac2+ infarct macrophages and in spindle-shaped, α–smooth muscle actin–positive myofibroblasts (Figure 1B and 1C). Moreover, infarct myofibroblasts and CD11b+ leukocytes isolated from the infarcted heart after 72 hours of reperfusion exhibited IRAK-M expression (Figure 1D–1G). To study cell-type specific changes in the timing of IRAK-M expression, we assessed IRAK-M mRNA levels in cardiac fibroblasts and CD11b+ leukocytes harvested from the infarcted heart. Isolated fibroblasts had a 3-fold increase in IRAK-M mRNA levels after 24 hours to 72 hours of reperfusion in comparison with control cardiac fibroblasts. When compared with control CD11b+ cells harvested from normal hearts, leukocytes isolated after 6 hours of reperfusion showed a trend toward increased IRAK-M mRNA expression (Figure I in the online-only Data Supplement). IRAK-M Loss Is Associated With Enhanced Adverse Remodeling Despite the Absence of Effects on the Size of the Infarct IRAK-M−null and WT animals had comparable mortality after myocardial infarction (P=NS). Triphenyltetrazolium chloride/Evans blue staining demonstrated that IRAK-M loss does not affect the size of the infarct after 1 hour of ischemia and 24 hours of reperfusion (Figure 1H–1J). Two independent techniques, echocardiographic imaging (Figure 2A–2G; Table I in the online-only Data Supplement) and quantitative morphometry (Figure 2H–2L), demonstrated that IRAK-M loss was associated with enhanced adverse remodeling after myocardial infarction. Systolic and diastolic chamber dimensions measured through echocardiography (left ventricular end-diastolic dimension, left ventricular end-systolic dimension, left ventricular end-systolic volume, and left ventricular end-diastolic volume; Figure 2A–2G) and morphometrically-derived left ventricular end-diastolic volume and left ventricular end-diastolic dimension (Figure 2H–2L) were significantly higher in IRAK-M−null mice after 7 and 28 days of reperfusion, indicating increased chamber dilation. Left ventricular mass was also significantly higher in infarcted IRAK-M−null hearts, suggesting accentuated hypertrophic remodeling. Increased adverse remodeling in the absence of IRAK-M was associated with reduced fractional shortening (FS), reflecting worse systolic dysfunction (Figure 2D). Because acute infarct size was comparable between WT and IRAK-M−null mice (Figure 1H–1J), accentuated adverse remodeling in IRAK-M−null hearts was not a result of more extensive cardiomyocyte injury. Moreover, scar size after 7 to 28 days of reperfusion was comparable between IRAK-M−/− and WT animals (Figure 2I). IRAK-M−/− Mice Have Enhanced Postinfarction Inflammation Exhibiting Increased Myocardial Cytokine mRN","metalloproteinases, cytokines, immune system, macrophages, cardiac remodeling","This study investigates the role of Interleukin-1 receptor-associated kinase (IRAK)-M in myocardial infarction.  Key findings include: 

* IRAK-M mRNA is significantly upregulated in the infarcted myocardium, with a biphasic response.
* IRAK-M is localized in macrophages and myofibroblasts within the infarcted heart.
* IRAK-M loss is associated with enhanced adverse remodeling after myocardial infarction, characterized by increased chamber dilation and hypertrophy, despite no effect on infarct size.
* IRAK-M−/− mice exhibit increased postinfarction inflammation with elevated myocardial cytokine mRNA levels."
Jitender M. Khurana,Adsorption and Photodegradation of Dyes Using Graphene Composites: A Review,"Water contamination has reached an alarming state due to industrialization and urbanization and has become a worldwide issue. Dyes contaminate water and are addressed extensively by researchers. Various technologies and materials have been developed for the treatment of contaminated water. Among them, adsorption has attracted great attention due to its ease and cost-effective nature. In recent years, graphene-based composites have shown great potential for the removal of contaminants from water. The literature reveals the usefulness of composites of graphene with metal oxides, carbon derivatives, metal hybrids and polymers for the removal of organic dyes from contaminated water. In this review, efforts have been made to compile the studies on the removal of cationic and anionic dyes from water using graphene-based composites.","Graphene, Dye removal, Photodegradation, Graphene composites, Degradation, Water treatment, Composites, Contaminated water, Adsorption, Dyes","Graphene composites are emerging as promising materials for the removal of dyes from wastewater due to their high surface area, excellent electrical conductivity, and tunable properties. This review summarizes the recent progress in using graphene composites for both adsorption and photodegradation of dyes. It discusses the mechanisms involved, key factors affecting dye removal efficiency, and the advantages of graphene-based materials over conventional methods. The review also highlights the potential of graphene composites for sustainable and efficient dye remediation in the future."
Jitschin et al,Determination of CK Yield for L Subshells in the Region 66≤Z≤83,"L subshell fluorescent X-rays in Dy, Ho, Er, Lu, Ta, W, Pt, Au, Hg, Pb and Bi have been measured using synchrotron with selective creation of electron vacancies in individual subshells. Coster–Kronig (CK) yields were derived from the measured intensities. Present measurements have been made at photon energies above the edges where differences between measured and theoretical attenuation coefficients are almost negligible.","photoionization cross-section, CK yield, L subshell fluorescent X-rays, synchrotron photon source, Coster–Kronig yields, L subshells, fluorescent yield, selective excitation, synchrotron photons",The paper discusses the measurement of L subshell fluorescent X-rays in various elements using synchrotron radiation and selective excitation technique. The Coster–Kronig yields were derived from the measured intensities and parametric trends for the results with Z were developed to cover all Zs in the range of 66–83.
Jonathan M. Graff,Opposing Actions of Fibroblast and Cardiomyocyte Smad3 Signaling in the Infarcted Myocardium,"Transforming growth factor (TGF)–βs are highly pleiotropic mediators with critical roles in regulating cellular phenotype and function in embryonic development, tissue homeostasis, and disease. Normal tissues contain stores of latent TGF-β bound to the extracellular matrix through its association with a large binding protein, the latent TGF-β binding protein. Tissue injury is associated with marked induction of TGF-β isoforms and activation of TGF-β signaling cascades. Parenchymal cells, extravasated leukocytes, and platelets synthesize and release large amounts of TGF-β in the injury site. Reactive oxygen species, proteases, matricellular proteins, and integrins cooperate to trigger the release of bioactive TGF-β from the latent stores. Subsequent binding of the active TGF-β dimer to the type II TGF-β receptor, followed by transphosphorylation of the type I receptor, triggers the TGF-β signaling response. The cellular effects of TGF-β are mediated through a canonical pathway involving a series of intracellular effectors, the Smads, or through activation of noncanonical signaling cascades. Activation of TGF-β signaling induces phosphorylation of the receptor-activated Smads, Smad2 and Smad3, which can form heteromeric complexes with the common Smad, Smad4. These complexes are transported to the nucleus, where they regulate gene transcription. TGF–β receptors and Smads are ubiquitously expressed by all cell types. Thus, all cells are responsive to the actions of TGF-β. Cardiac injury is associated with the marked induction of TGF-β and activation of TGF-β cascades. Our laboratory and other investigators have documented activation of Smad2 and Smad3 signaling in the infarcted myocardium, localized in both cardiomyocytes and interstitial cells. In isolated cardiac fibroblasts, Smad3 signaling accentuates myofibroblast transdifferentiation and stimulates a matrix-preserving program. In a model of reperfused infarction, global loss of Smad3 attenuated remodeling after infarction. However, considering the ubiquitous expression of Smad3 in all cell types, the cell biological basis for the actions of Smad3 in the infarcted heart remains unknown. Our study dissects the cell-specific actions of Smad3 signaling in the infarcted myocardium by developing and studying mice with cell-specific loss of Smad3 in activated fibroblasts and cardiomyocytes. It is surprising that fibroblast-specific loss of Smad3 worsened remodeling after infarction, resulting in accentuated chamber dilation. The deleterious consequences of fibroblast-specific Smad3 loss reflected unrestrained fibroblast proliferation, defective scar remodeling, and perturbed organization of myofibroblast arrays in the border zone. Smad3 signaling regulated fibroblast function, activating integrin-mediated nicotinamide adenine dinucleotide phosphate (NADPH) oxidase (NOX)–2 expression. In contrast, cardiomyocyte-specific loss of Smad3 protected the infarcted heart from dysfunction after infarction. The protective effects of cardiomyocyte-specific Smad3 loss were associated with attenuated cardiomyocyte apoptosis in remodeling myocardium and accompanied by decreased NOX2 levels, reduced nitrosative stress, and decreased matrix metalloproteinase (MMP)–2 expression.","SMAD, fibroblast, heart failure, cardiomyocyte, remodeling","This study investigates the role of Smad3 in cardiac fibroblasts following myocardial infarction. Using a mouse model with fibroblast-specific Smad3 deletion (FS3KO), the researchers found that loss of Smad3 in fibroblasts exacerbated dilative remodeling and worsened systolic dysfunction after both reperfused and nonreperfused infarction.  While acute infarct size was not affected, FS3KO mice exhibited larger scars, increased myofibroblast density, and enhanced myofibroblast proliferation. These findings suggest that Smad3 plays a protective role in cardiac fibroblasts and its loss contributes to adverse cardiac remodeling after infarction."
Jong-Bu Lim,Bandwidth-Efﬁcient OFDM transmission with iterative cyclic preﬁx reconstruction,"Abstract—Orthogonal frequency division multiplexing (OFDM) systems are now a part of all major wireless standards, because of its potential to offer high data rate. Cyclic prefix (CP) in OFDM system converts a multipath channel to a flat fading channel, thus simplifies the design of equalizer. However, there is a lot of ambiguity in choosing the length of CP. In this paper, we propose a new method for calculation of length of CP using cumulant features. The merits of proposed method are verified by computer simulation.","bandwidth efﬁciency, OFDM, channel length estimation, cumulant features, Orthogonal frequency division multiplexing (OFDM), Cyclic prefix (CP), cyclic preﬁx, Blind channel length estimation","This paper proposes a novel method for blind channel length estimation in OFDM systems using cumulant features. The proposed method is well-suited for dynamic spectrum access (DSA) setups and does not require pilot or training sequences, thus saving bandwidth. The method is based on exploiting the properties of nth order cumulant features and is verified by computer simulation."
Josep M. Guerrero,Double Deadbeat Plus Repetitive Control Scheme for Microgrid System,"Parallel connection of converters is a convenient choice when system capacity is to be increased. Parallel-connected voltage source converters, especially neutral point clamped converters, are one of the best choices for its range. However, with the parallel connectivity, the converter possesses a circulating current in its legs, which consequently threatens the safe operation of the system.","Microgrid systems, parallel converters, Repetitive control, repetitive control scheme, Deadbeat control (DB) scheme, microgrids, Circulating currents, Deadbeat control, Parallel-connected inverters",This paper proposes a double deadbeat plus repetitive control scheme to mitigate circulating currents in parallel-connected voltage source converters. The proposed scheme combines the advantages of deadbeat control and repetitive control to achieve high operating bandwidth and stability.
Josh Poorbaugh,First-­in-­Human Study of Bamlanivimab in a Randomized Trial of Hospitalized Patients With COVID-­19,"This first-in-human study in hospitalized patients with COVID-19 was supported by studies assessing in vitro viral neutralization combined with a single-dose non-human primate PK study. The nonclinical safety package to support subsequent studies included tissue cross-reactivity studies on human, rat, and monkey tissues and an in vivo toxicology study.  A complete physical examination was conducted at the screening visit, and one of three bamlanivimab doses or placebo was administered i.v. at the baseline visit (D1) with infusion rates as follows: bamlanivimab 700 mg (50 mL) administered 100 mL/hr for 30 minutes; 2,800 mg (75 mL) administered 100 mL/hr for 45 minutes; and 7,000 mg administered 100 mL/hr for 60 minutes. Placebo infusion was 0.9% normal saline, administered at the same volume and rate as the corresponding bamlanivimab dose cohort. Safety and tolerability were reviewed for sentinel participants up to 24 hours after dosing, at which point the investigators and sponsor team determined whether safety and tolerability were acceptable to continue with dosing subsequent participants. The decision to dose the next cohort was made when all participants from the previous cohort had been dosed and safety data assessed for at least 4 days after the i.v. infusion by the investigators and sponsor team in consultation with an independent safety assessment committee. Blood samples were obtained for assessment of exploratory biomarkers, serology, clinical laboratory assessments, and PD on days 1, 3, 7, 11, 15, 22, and 29, and every 7 days until discharge or day 60, if still an inpatient. Samples for the virology assay were collected using nasopharyngeal (preferred) or mid-turbinate methods. Blood samples obtained for PK analyses were assessed on days 1 (pre-infusion and just before end of infusion), 4, 15, and 29, and follow-up visits up to day 60. Symptom-related physical examinations and assessments of clinical symptoms were performed on days 1, 2, 3, 4, 7, 11, 15, 22, and 29, and the day of discharge from the hospital, with additional follow-up examinations every 7 days thereafter until day 60 if the patient was not discharged from the hospital by day 29. Participants’ clinical status and concurrent procedures of special interest were recorded, including limitation on activities due to COVID-19 and any requirements for the following procedures of special interest, such as ongoing hospital medical care, supplemental oxygen, noninvasive ventilation or a high flow oxygen device, mechanical ventilation, extracorporeal membrane oxygenation, additional organ support, or consciousness status using alert, consciousness, verbal, pain, unresponsive scale. Hospitalization events were recorded, including dates of hospital admission and discharge, admission to the intensive care unit (ICU), discharge from the ICU, and discharge location including to an extended care facility or home. Outcomes The primary objective was to assess safety and tolerability, including adverse events (AEs), serious adverse events (SAEs), and discontinuations due to AEs. Other objectives included PKs (e.g., mean concentration at day 29); PD viral load, area under the response time curve (AUC, from day 1 to day 29), and change from baseline time course; total symptom score; time to symptom resolution; duration of hospitalization; National Institute of Allergy and Infectious Diseases (NIAID), World Health Organization (WHO) scales, and National Early Warning Score (NEWS2); and analysis of viral resistance. Any hypothesis tests were conducted for treatment comparisons without adjustment for multiplicity except for the evaluation of treatment effect on endogenous antibody titers. Success for the trial was claimed using a Bayesian criterion if any of the 3 bamlanivimab doses had at least 60% probability to reduce at least 30% mean AUC (28-day viral load) over placebo.",,"This first-in-human study evaluated the safety, tolerability, pharmacokinetics, clinical course, and viral dynamics of bamlanivimab, a fully human neutralizing monoclonal antibody targeting SARS-CoV-2, in hospitalized patients with moderate to severe COVID-19.  The study found bamlanivimab to be safe and well-tolerated, with no serious adverse events or deaths reported.  Further research is needed to determine the efficacy of bamlanivimab in treating COVID-19."
Jubin Sebastian E,Energy-Efficient Routing Algorithm for Wireless Sensor Networks,"Wireless Sensor Network (WSN) is a collection of sensor nodes. A sensor node covers all information which is present in its sensing range. To access the information present in some other sensor range, the networks use a process called Routing. Routing problem in wireless sensor network (WSN) concerned with maximizing the sensor network lifetime while continuously routing the collected data (information) to the base station (central server).","Network Lifetime, Energy –Efficiency, Energy-Efficient Routing, Sensor Networks, Routes, Wireless Sensor Networks, Wireless Sensor Networks (WSN), Energy Consumption, Routing problem, Routing Algorithm",The paper presents a new energy-efficient routing algorithm for wireless sensor networks. The algorithm prioritizes sensors according to their remaining battery life and selects the shortest path to maximize the total network lifetime.
Jun Yao,History Matching of Naturally Fractured Reservoirs Using a Deep Sparse Autoencoder ||| Reservoir Characterization and Productivity Forecast Based on Knowledge Interaction Neural Network,"This work proposes a new characterization method and a method to reduce dimensionality for history matching of naturally fractured reservoirs. The forward simulator is modeled after the EDFM given its computational efficiency. The fracture network can be represented with length, orientation, and position, including large-scale fractures and small-scale fractures. ||| The reservoir characterization aims to provide the analysis and quantification of the injection-production relationship, which is the fundamental work for production management. The connectivity between injectors and producers is dominated by geological properties, especially permeability. However, the permeability parameters are very heterogenous in oil reservoirs, and expensive to collect by well logging. The commercial simulators enable to get accurate simulation but require sufficient geological properties and consume excessive computation resources.","History matching, characterization method, EDFM, knowledge interaction neural network, Naturally fractured reservoirs, Deep sparse autoencoder, machine learning, productivity prediction, reservoir characterization, Productivity Forecast, Physical Knowledge, dimensionality reduction, fracture network, embedded model","This paper proposes a new characterization method for the multiscale fracture network, and a powerful dimensionality-reduction method by means of an autoencoder for model parameters. The characterization method of the fracture network is dependent on the length, orientation, and position of fractures, including large-scale and small-scale fractures. ||| The goal of this study is to improve the accuracy and stableness of the inter-well connectivity characterization and enhance the prediction precision on well productivity, by combining the physical knowledge with machine learning techniques. An innovative neural network is proposed to handle the reservoir characterization and productivity forecast problems, in which the material balance equation is embedded via three high transparent modules, thereby ensuring the physical sense of model parameters."
K. Allocca,Cost Eﬀective Inﬂuence Maximisation,"In the context of virality prediction, many researchers have leveraged the existence of a core-periphery structure in a network to identify the super-spreaders of information. Topologically, the nodes in the core of a network are the most eﬃcient spreaders. However, these nodes are less susceptible, i.e., unlikely to be inﬂuenced by the periphery nodes. Consequently, large payoﬀs are required to market information (ideas, products, memes, etc.) via them. In this paper, we show the presence of several non-core nodes whose spreading power is close to that of the core nodes.","Virality, Inﬂuence maximisation, Information diﬀusion, cost-effective, Core-periphery structure, information diffusion, social networks, influence maximisation","This paper proposes a cost-eﬀective strategy to make a meme reach the super-spreaders without the need for global information. The proposed hill-climbing based strategy can be eﬀectively used with both, global as well as local characteristics of the nodes in a network. In terms of the cost metric, it outperforms the conventional independent cascade model by more than 5 times for the core and 2 times for the non-core super-spreaders."
K. Asawa,An efficient prefix based labelling scheme for dynamic update of XML ||| New Path Based Index Structure for Processing CAS Queries Over XML Database,"The increasing volume of XML documents and the real-world requirement to support the updations has motivated the research community to develop dynamic labelling schemes. Each of the dynamic labelling schemes proposed till date differs in characteristics and has its own advantages and limitations. They may differ in terms of the query supported, their update performance, label size, etc. In this paper, a new prefix based labelling scheme is proposed which is compact, dynamic. And it also facilitates the computation of structural relationships which is the core part of query processing. The proposed scheme can handle both static as well as dynamic XML documents. The experimentation is conducted to evaluate the performance of storage requirement, structural relationship computation and update processing. The result is compared with some of the existing labelling mechanisms. ||| Querying nested data has become one of the most challenging issues for retrieving desired information from the Web. Today diverse applications generate a tremendous amount of data in different formats. These data and information exchanged on the Web are commonly expressed as nested representation such as XML, JSON, etc. Unlike the traditional database system, they do not possess a rigid schema. In general, the nested data is managed by storing data and its structures separately which significantly reduces the performance of data retrieving. Ensuring efficiency of processing queries which locates the exact positions of the elements has become a big challenging issue.","XML, WWW, query evaluation engine, index, database storage, CAS query, CAS queries, index engine, dynamic update, path-based index structure, ancestor-descendant, label size, query processing, parent-child relationship, tree traversal, XML databases, XPath, structural relationship, prefix-based, labelling scheme, labelling time, lexicographic order, XML query processing","This paper proposes a new prefix based labelling scheme for dynamic update of XML documents. The scheme is compact, dynamic, and facilitates the computation of structural relationships. It can handle both static and dynamic XML documents and has been evaluated for its performance in storage requirement, structural relationship computation, and update processing. ||| The proposed system uses integration of data structures B+ Tree and HashMap to construct the indices. The Hash Map stores the structural component of the XML document and an offset to the B+ Tree. The B+ tree stores the content information in the XML document. The path combined index (pc_index) is constructed by combining the terminal siblings with same ancestor paths into a single path."
K. Datta,YASS: Yet Another Suﬃx Stripper,"This paper presents a set of string distance measures for clustering the lexicon. The main intuition behind defining these distances was to reward long matching prefixes, and to penalize an early mismatch.","string distance measures, morphological variants, information retrieval, resource-poor languages, clustering, lexicon clustering, Bengali language, equivalence classes, stemming","The paper proposes a set of string distance measures for clustering words into homogeneous groups, with the goal of representing an equivalence class consisting of morphological variants of a single root word."
K. Deep,A Modiﬁed Binary Particle Swarm Optimization for Knapsack Problems ||| Mean particle swarm optimisation for function optimisation,"The Knapsack Problems (KPs) are classical NP-hard problems in Operations Research having a number of engineering applications. Several traditional as well as population based search algorithms are available in literature for the solution of these problems. In this paper, a new Modiﬁed Binary Particle Swarm Optimization (MBPSO) algorithm is proposed for solving KPs, particularly 0–1 Knapsack Problem (KP) and Multidimensional Knapsack Problem (MKP). ||| In this paper, a new particle swarm optimisation algorithm, called MeanPSO, is presented, based on a novel philosophy by modifying the velocity update equation. This is done by replacing two terms of original velocity update equation by two new terms based on the linear combination of pbest and gbest. Its performance is compared with the standard PSO (SPSO) by testing it on a set of 15 scalable and 15 nonscalable test problems. Based on the numerical and graphical analyses of results it is shown that the MeanPSO outperforms the SPSO, in terms of efficiency, reliability, accuracy and stability.","Function Optimisation, Binary Particle Swarm Optimization, Knapsack Problems, velocity update equation, particle swarm optimisation, MeanPSO, Particle Swarm Optimization, PSO, global optimisation, Benchmark Problems, Knapsack Problem, Sigmoid function","The paper introduces a new Modiﬁed Binary Particle Swarm Optimization method (MBPSO) and its application to 0–1 KP and MKP. The proposed method allows for better exploration and efficiency in the search process. ||| This paper proposes a new particle swarm optimisation algorithm, called MeanPSO, which modifies the velocity update equation by replacing two terms with a linear combination of pbest and gbest. The performance of MeanPSO is compared with the standard PSO (SPSO) on 30 benchmark test problems, and it is shown that MeanPSO outperforms SPSO in terms of efficiency, reliability, accuracy, and stability."
K. F. Au,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
K. Mehta,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
K. P. Gummadi,Cost Eﬀective Inﬂuence Maximisation,"In the context of virality prediction, many researchers have leveraged the existence of a core-periphery structure in a network to identify the super-spreaders of information. Topologically, the nodes in the core of a network are the most eﬃcient spreaders. However, these nodes are less susceptible, i.e., unlikely to be inﬂuenced by the periphery nodes. Consequently, large payoﬀs are required to market information (ideas, products, memes, etc.) via them. In this paper, we show the presence of several non-core nodes whose spreading power is close to that of the core nodes.","Virality, Inﬂuence maximisation, Information diﬀusion, cost-effective, Core-periphery structure, information diffusion, social networks, influence maximisation","This paper proposes a cost-eﬀective strategy to make a meme reach the super-spreaders without the need for global information. The proposed hill-climbing based strategy can be eﬀectively used with both, global as well as local characteristics of the nodes in a network. In terms of the cost metric, it outperforms the conventional independent cascade model by more than 5 times for the core and 2 times for the non-core super-spreaders."
K. P. N. Murthy,Liquid crystal films on curved surfaces: An entropic sampling study,"We report a Monte Carlo study of the phase transition in liquid crystals using the Wang-Landau algorithm. We compute the representative density of states of the film under consideration and make the system perform an energy-uniform random walk by biasing the walk against its own density of states. We then extract the canonical ensembles by simultaneously applying two biasing probabilities to the microstates, one according to the density of states and the other due to the assumed statistical distribution corresponding to the temperature under consideration. We adopt this procedure in reporting the following equilibrium properties of the film under different boundary conditions.","curved substrates, Monte Carlo simulation, Monte Carlo study, phase transition, liquid crystals, nematic thin film, Wang-Landau algorithm","We study the phase transition in liquid crystals using the Wang-Landau algorithm and report the equilibrium properties of the film under different boundary conditions. We find that the temperature at which the transition takes place is not the same as the temperature near which the uniaxial phase actually forms, and that the surface anchoring seems to be too strong for the elastic response of the nematic medium to force a uniaxial order above a certain threshold value."
K. S. Karimb,Quantitative Comparison of a High Resolution Micro-Angiographic Fluoroscopic (MAF) Detector with a Standard Flat Panel Detector (FPD) Using the New Metric of Generalized Measured Relative Object Detectability (GM-ROD),"A novel amorphous selenium (a-Se) direct detector with CMOS readout has been designed, and relative detector performance investigated. The detector features include a 25μm pixel pitch, and 1000μm thick a-Se layer operating at 10V/μm bias field. A simulated detector DQE was determined, and used in comparative calculations of the Relative Object Detectability (ROD) family of prewhitening matched-filter (PWMF) observer and non-prewhitening matched filter (NPWMF) observer model metrics to gauge a-Se detector performance against existing high resolution micro-angiographic fluoroscopic (MAF) detectors and a standard flat panel detector (FPD). The PWMF-ROD or ROD metric compares two x-ray imaging detectors in their relative abilities in imaging a given object by taking the integral over spatial frequencies of the Fourier transform of the detector DQE weighted by an object function, divided by the comparable integral for a different detector. The generalized-ROD (G-ROD) metric incorporates clinically relevant parameters (focal-spot size, magnification, and scatter) to show the degradation in imaging performance for detectors that are part of an imaging chain. Preliminary ROD calculations using simulated spheres as the object predicted superior imaging performance by the a-Se detector as compared to existing detectors. New PWMF-G-ROD and NPWMF-G-ROD results still indicate better performance by the a-Se detector in an imaging chain over all sphere sizes for various focal spot sizes and magnifications, although a-Se performance advantages were degraded by focal spot blurring. Nevertheless, the a-Se technology has great potential to provide breakthrough abilities such as visualization of fine details including of neuro-vascular perforator vessels and of small vascular devices.","Comparative metrics, generalized metrics, micro-angiography, DQE, Detector Performance, relative object detectability, Microangiography, CMOS, Flat Panel Detector, amorphous selenium","This paper presents a comparative study of a novel amorphous selenium (a-Se) direct detector with existing high resolution micro-angiographic fluoroscopic (MAF) detectors and a standard flat panel detector (FPD). The study utilizes the Relative Object Detectability (ROD) family of metrics, including the generalized-ROD (G-ROD) metric, to assess the performance of these detectors in imaging small objects.  The results indicate that the a-Se detector exhibits superior imaging performance compared to existing detectors, particularly in terms of resolving fine details.  While focal spot blurring can degrade the performance advantage of the a-Se detector, its potential for breakthrough imaging capabilities in neuro-vascular applications is highlighted."
K. S. Rao,Parameter Extraction of Photovoltaic Module Using BFO Algorithm,"This paper presents a new parameter extraction method for photovoltaic modules exploiting Bacterial Foraging Optimization (BFO) technique. In a PV system, validation of the model of a PV module with correctly chosen parameters is essential. An efficient parameter extraction method is required to estimate the parameters of PV module.","evolutionary techniques, BFO, PV module parameters, photovoltaic module, Newton-Raphson method, parameter extraction, PSO, BFO algorithm","The proposed BFO based parameter extraction method has been tested for different types of PV modules at different test conditions. Analyzing both the simulation and experimental results obtained using BFO; it is found that the module parameters are more accurate compared to that of Newton-Raphson, Particle Swarm Optimization and Enhanced Simulated Annealing methods."
K. Sudheer Reddyc,Alignment Free Cancellable Fingerprint Templates Using Ellipse Structure,"In this work, a new method for alignment free cancellable fingerprint templates was proposed using ellipse structure. Ellipse was formed by selecting one of the minutiae and core point of the fingerprint as focal points and the farthest minutia as the co-vertex. This method performs well because instead of storing spatial information of the fingerprints such as distance or orientation between minutia, etc., we are storing the ellipse attributes in transformed form such that even though if any stored template got leaked, the original fingerprint information will not be revealed to the attacker. This method also performs well in terms of FAR and FRR. However for the fingerprints which does not possess a core point this method will not be suitable and is the main limitation of this work.","Template protection, Discrete Fourier transform, Fingerprint, Ellipse, cancellable templates, biometric security, fingerprint templates, ellipse structure","The proposed method uses elliptical structures generated from fingerprint minutiae to secure fingerprint templates. The method involves extracting minutiae from fingerprint images, constructing ellipses and extracting feature sets, projecting the feature sets onto a 3D space, generating a binary string, and transforming the binary string into the frequency domain using DFT."
K. V. Arya,Artificial Bee Colony (ABC) Algorithm ||| Opposition based lévy ﬂight artiﬁcial bee colony,"Artificial bee colony (ABC) optimisation algorithm is a relatively simple and recent population-based probabilistic approach for global optimisation. The solution search equation of ABC is significantly influenced by a random quantity which helps in exploration at the cost of exploitation of the search space. In the ABC, there is a high chance to skip the true solution due to its large step sizes. In order to balance between diversity and convergence in the ABC, a Lévy flight inspired search strategy is proposed and integrated with ABC. The proposed strategy is named as Lévy Flight ABC (LFABC) has both the local and global search capability simultaneously and can be achieved by tuning the Lévy flight parameters and thus automatically tuning the step sizes. ||| Artiﬁcial Bee Colony (ABC) is a well known optimization approach to solve nonlinear and complex prob-lems. It is relatively a simple and recent population based probabilistic approach for global optimization. Similar to other population based algorithms, ABC is also computa-tionally expensive due to its slow nature of search process. The solution search equation of ABC is signiﬁcantly inﬂu-enced by a random quantity which helps in exploration at the cost of exploitation of the search space. In the solution search equation of ABC due to the large step size the chance of skipping the true solution is high. Therefore, in this paper, to balance the diversity and convergence capability of the ABC, Lévy Flight random walk based local search strategy is proposed and incorporated with ABC along with opposition based learning strategy. The proposed algorithm is named as Opposition Based Lévy Flight ABC. The experiments over 14 un-biased test problems of different complexities and ﬁve well known engineering optimization problems show that the proposed algorithm outperforms the basic ABC and its recent variants namely Gbest guided ABC, Best-So-Far ABC, and Modiﬁed ABC in most of the experiments.","Lévy Flight, Swarm intelligence, ABC algorithm, Lévy ﬂight local search, Honey bees, convergence speed, swarm intelligence, Artificial Bee Colony algorithm, numerical optimisation, local search, Food foraging, Memetic algorithm, computational complexity, memetic algorithm, Artificial Bee Colony, Evolutionary computation, Lévy flight local search, Optimisation","This paper proposes a Lévy flight inspired search strategy to balance between diversity and convergence in the artificial bee colony (ABC) optimisation algorithm. The proposed strategy, named as Lévy Flight ABC (LFABC), has both local and global search capability simultaneously and can be achieved by tuning the Lévy flight parameters. The performance of the proposed strategy is analysed over test problems and five real-world engineering optimisation problems. ||| This paper proposes a new algorithm called Opposition Based Lévy Flight ABC, which combines the Lévy Flight random walk based local search strategy with the opposition based learning strategy. The algorithm is designed to balance the diversity and convergence capability of the ABC. The experiments show that the proposed algorithm outperforms the basic ABC and its recent variants in most of the experiments."
K.NageswaraReddy,Efficient Conjunctive Cooperative Routing Schemes In Divergent Sensor Networks,"Wireless sensor networks are faced by challenges not present in wired networks. Mobility of nodes or lack of fixed infra in wireless sensor networks gives rise to issues like route changes, link failures, and need for change of IP addresses. These reasons require changes at various layers of protocol stack. In such a situation, their lifetime is expected to be extended by cooperative packet forwarding. Albeit a few scientists have learned about collaboration in different WSNs, the greater part of them don't consider the heterogeneity in the qualities of each WSN, for example, battery limit, activity begin time, the quantity of hubs, hubs areas, vitality utilization, parcel measure or potentially information transmission timing, etc. In a heterogeneous situation, gullible lifetime enhancement with participation may not be reasonable. In this paper, we propose a reasonable helpful steering strategy for heterogeneous covered WSNs. It acquaints a vitality pool with keep up the aggregate sum of vitality utilization by helpful sending. The vitality pool assumes a job of merchant for reasonable participation. At last, reenactment results demonstrate the great execution of the proposed strategy.","lifetime improvement, heterogeneous networks, cooperative routing, Wireless Sensor Networks, Fair Routing Overlapped","This paper proposes a cooperative routing scheme for heterogeneous wireless sensor networks. The scheme introduces a power pool to maintain the total amount of power utilization by cooperative forwarding. The power pool acts as a merchant for fair participation. The scheme is evaluated through simulation results, which demonstrate its good performance."
K.Prasada Rao,Performance Evaluation of Entropy and Gini using Threaded and Non Threaded ID3 on Anaemia Dataset,"Classification is an important data mining task, and decision trees have emerged as a popular classifier due to their simplicity and relatively low computational complexity. Time required to build a decision tree becomes intractable, as datasets get extremely large. To overcome this problem we proposed a parallel mode of ID3 algorithm. Decision tree building is well-suited for thread-level parallelism as it requires a large number of independent computations. In this paper, we present the analysis and parallel implementation of the ID3 algorithm using Entropy and Gini as heuristics, along data set.","Entropy Heuristic, Threaded ID3, Parallel data mining, Gini Heuristic, Data Mining, Decision tree, ID3, Parallelism, Gini, Entropy, Anemia Database","The paper presents a parallel mode of ID3 algorithm for decision tree building, using Entropy and Gini as heuristics, and analyzes its performance on an anaemia dataset. The proposed method helps in analyzing two types of anaemia, Iron deficiency anaemia (ID) and B12 deficiency anaemia (B12), and identifies the most significant attributes for determining the transferred, number of frozen embryos, and culture days of embryo."
K.V.Sambasiva Rao,An Efficient Trusted Computing Base for Routing in MANET’s,"This paper seeks a set of fixed functionality suitable for securing MANETs. We deliberately impose some restrictions on such fixed functionality to ensure that TMMs which offer such functionality can be easily verified, will consume negligible power, and thus can be simultaneously trustworthy and inexpensive to realize.","TMM, TCG, trustworthy modules, MANET, TCB, TMMs, AODE, MANETs","The paper proposes a simple and efficient TCB for MANET nodes which can be leveraged to improve the performance of MANETs by providing assurances that reduce the scope of attacks that can be launched by attackers, and by reducing the overhead required for leveraging the TCB."
KANIIKA ET AL.,VISTA: A teaching aid to enhance contextual teaching,"In this study, an innovative tool for enabling contextual teaching based on visual inputs, named Visual Stimuli-based Teaching Aid (VISTA), was developed. This system establishes the meaning and significance of concepts that are taught in the classroom within different environmental contexts.","mobile phone camera, computer science, mobile learning, pedagogical tool, contextual teaching, contextual teaching and learning, computer science education","VISTA is a system that uses a mobile phone camera to gather information from the environment and provide personalized knowledge awareness maps to assist in learning. It captures images of the teacher's notes and the physical environment, and uses optical character recognition (OCR) to convert the notes into a textual format. The system then extracts the fundamental concepts embedded within the notes by selecting informative words and searching the entries in the index of an e-book."
KUANG-PEN CHOU,Robust Feature-Based Automated Multi-View Human Action Recognition System,"Automated human action recognition has the potential to play an important role in public security, for example, in relation to the multiview surveillance videos taken in public places, such as train stations or airports. This paper compares three practical, reliable, and generic systems for multiview video-based human action recognition, namely, the nearest neighbor classiﬁer, Gaussian mixture model classiﬁer, and the nearest mean classiﬁer. To describe the different actions performed in different views, view-invariant features are proposed to address multiview action recognition. These features are obtained by extracting the holistic features from different temporal scales which are modeled as points of interest which represent the global spatial-temporal distribution. Experiments and cross-data testing are conducted on the KTH, WEIZMANN, and MuHAVi datasets. The system does not need to be retrained when scenarios are changed which means the trained database can be applied in a wide variety of environments, such as view angle or background changes. The experiment results show that the proposed approach outperforms the existing methods on the KTH and WEIZMANN datasets.","feature extraction, points of interest extraction, background subtraction, machine learning, moving object localization, multi-view human action recognition, action recognition, Multi-view video, classiﬁcation","This paper proposes a robust feature-based automated multi-view human action recognition system. The system uses view-invariant features to address multi-view action recognition from a range of perspectives. The proposed approach labels the beginning and end of an action sequence in a video stream automatically and captures sequence motions and occlusions at a low computational cost. The system is evaluated using the KTH, WEIZMAN, and MuHAVi datasets and outperforms existing methods on the KTH and WEIZMANN datasets."
Kai Zhang,History Matching of Naturally Fractured Reservoirs Using a Deep Sparse Autoencoder ||| Reservoir Characterization and Productivity Forecast Based on Knowledge Interaction Neural Network,"This work proposes a new characterization method and a method to reduce dimensionality for history matching of naturally fractured reservoirs. The forward simulator is modeled after the EDFM given its computational efficiency. The fracture network can be represented with length, orientation, and position, including large-scale fractures and small-scale fractures. ||| The reservoir characterization aims to provide the analysis and quantification of the injection-production relationship, which is the fundamental work for production management. The connectivity between injectors and producers is dominated by geological properties, especially permeability. However, the permeability parameters are very heterogenous in oil reservoirs, and expensive to collect by well logging. The commercial simulators enable to get accurate simulation but require sufficient geological properties and consume excessive computation resources.","History matching, characterization method, EDFM, knowledge interaction neural network, Naturally fractured reservoirs, Deep sparse autoencoder, machine learning, productivity prediction, reservoir characterization, Productivity Forecast, Physical Knowledge, dimensionality reduction, fracture network, embedded model","This paper proposes a new characterization method for the multiscale fracture network, and a powerful dimensionality-reduction method by means of an autoencoder for model parameters. The characterization method of the fracture network is dependent on the length, orientation, and position of fractures, including large-scale and small-scale fractures. ||| The goal of this study is to improve the accuracy and stableness of the inter-well connectivity characterization and enhance the prediction precision on well productivity, by combining the physical knowledge with machine learning techniques. An innovative neural network is proposed to handle the reservoir characterization and productivity forecast problems, in which the material balance equation is embedded via three high transparent modules, thereby ensuring the physical sense of model parameters."
Kajsa Winga,ROS deficiency enhanced mannan-induced PsA,"In and joint inflammation using B10Q.Ncf1m1j/m1j mice that have a mutation in the Ncf1 gene (m1j) (the Ncf1 protein also denoted p47phox), and hence reduced ROS production (oxidative burst) (18). As shown in Fig. 1D, Ncf1 mutated mice developed severe joint inflammation within 2 d after mannan injection, which reached the mean maximal disease severity (30 ± 6 points) within 4 d. The frequency of skin lesions was 100%, with more severe cases in B10Q.Ncf1m1j/m1j mice (Fig. 1E), whereas B10.Q mice had a significantly milder disease course. Multiple Exposures to Mannan Induced a Relapsing Disease. Next, we examined the effect of multiple mannan injections in B10Q and B10Q.Ncf1m1j/m1j mice. We boosted mice twice with mannan on days 7 and 14 after disease initiation. Repetitive injections of mannan reproduced the arthritis phenotype, which reached the maximum severity level on days 9 and 17, similar to the first injection (Fig. 1F). A more severe disease course was observed in B10Q.Ncf1m1j/m1j mice than in B10Q mice (P < 0.05 and P < 0.01, respectively). Interestingly, Ps skin scaling returned only after the second mannan injection (on day 16), but the skin peeled off even more quickly than the first time (Fig. 1G). Moreover, from day 11 onward, B10Q.Ncf1m1j/m1j mice started to develop pruritus on the body, predominantly on the back and above the eye (Fig. S1E). Pruritus was only evident in B10Q.Ncf1m1j/m1j mice, but flaky skin on the tail and alopecia all over the leg was observed in both of the mouse strains. We also observed genetic heterogeneity in disease susceptibility (Fig. Fig. 1. ROS deficiency enhanced mannan-induced PsA. The arthritic joint phenotype and Ps-like skin lesions in the front (A) and hind (B) paws of B10Q.Ncf1m1j/m1j mice are shown. (C) Ps-like skin scaling in diseased B10Q.Ncf1m1j/m1j mouse ear compared with naive mouse ear. Mean arthritis (D) and Ps lesion (E) severity in B10Q (n = 5) and B10Q.Ncf1m1j/m1j (n = 5) mice after a single i.p. mannan injection. Mean arthritis (F) and Ps lesion (G) severity in B10Q (n = 5) and B10Q.Ncf1m1j/m1j (n = 5) mice after repetitive mannan injections (days 7 and 14). (H) Mannan-induced mean maximum arthritis scores ± SEM in different mouse strains: B10Q (n = 8), B10Q.Ncf1m1j/m1j (n = 9), B10RIII (n = 10), B10RIII.Ncf1m1j/m1j (n = 9), B10P (n = 3), B10P.Ncf1m1j/m1j (n = 9), BALB/cByJ/Q (n = 10), BALB/cByJ/Q.Ncf1m1j/m1j (n = 8), BALB/cByJ (n = 5), BALB/cByJ.Ncf1m1j/m1j (n = 7), C57BL/6NJ (n = 8), and C57BL/6NJ.Ncf1m1j/m1j (n = 7). Significance was calculated by comparing the maximal disease severity of B10Q and B10Q.Ncf1m1j/m1j mice with all of the other strains in their respective groups. *P < 0.05; **P < 0.01; ***P < 0.001. E3670 | www.pnas.org/cgi/doi/10.1073/pnas.1405798111 Khmaladze et al. Downloaded from https://www.pnas.org by 122.184.65.228 on February 22, 2023 from IP address 122.184.65.228.","autoimmune disease, Ncf1, animal model","This study identifies a new mechanism for psoriasis (Ps) and psoriasis arthritis (PsA) development in mice. A single injection of mannan, a component of baker's yeast, induced Ps and PsA-like symptoms. This effect was exacerbated in mice lacking reactive oxygen species (ROS), but improved when ROS production was restored in macrophages.  Blocking IL-17A, a cytokine produced by gamma delta T cells, completely prevented disease. The study suggests that mannan activates macrophages, leading to TNF-α secretion and stimulation of IL-17A production by gamma delta T cells. This, in turn, drives neutrophil infiltration and inflammation, mimicking Ps and PsA. This new mouse model could be valuable for testing new therapies for Ps and PsA."
Kakarla V.V.D.L. Narayana,A Novel Fuzzy Rule Based Inference System for Contrast Enhancement,"In this work, we propose a fuzzy inference system based contrast enhancement of gray level images. We propose a new method of generating the fuzzy if-then rules specific to a given image based on the local information available to be used by a fuzzy inference system.","Fuzzy Partition, Histogram Equalisation, partial histogram, contrast enhancement, Fuzzy Inference Systems, fuzzy rule based inference system, Mamdani fuzzy inference system, Image Enhancement, Contrast Stretching, Histogram Matching, Gray level transformations",The paper proposes a fuzzy inference system based contrast enhancement of gray level images. It presents a new method of generating fuzzy if-then rules specific to a given image based on local information available. The method generates a partial histogram and saves on computational costs. The enhanced images from the proposed algorithm are comparable or even better than those obtained from histogram equalization.
Kalavala Revanth Harsha,Visual Sentiment Analysis of Customer Complaints using SOM,"With the widespread use of social media, companies now have access to a wealth of customer feedback data which has valuable applications to Customer Relationship Management (CRM). Analyzing customer grievances data, is paramount as their speedy non-redressal would lead to customer churn resulting in lower profitability. In this paper, we propose a descriptive analytics framework using Self-organizing feature map (SOM), for Visual Sentiment Analysis of customer complaints. The network learns the inherent grouping of the complaints automatically which can then be visualized too using various techniques. Analytical Customer Relationship Management (ACRM) executives can draw useful business insights from the maps and take timely remedial action. We also propose a high-performance version of the algorithm CUDASOM (CUDA based Self Organizing feature Map) implemented using NVIDIA parallel computing platform, CUDA, which speeds up the processing of high-dimensional text data and generates fast results. The efficacy of the proposed model has been demonstrated on the customer complaints data regarding the products and services of four leading Indian banks. CUDASOM achieved an average speed up of 44 times. Our approach can expand research into intelligent grievance redressal system to provide rapid solutions to the complaining customers.","CUDA, Grievance Redressal, Self-Organizing Map, Visual Sentiment Analysis, Customer Complaints, Self-Organizing Maps, Analytical CRM, SOM","This paper proposes a descriptive analytics framework using Self-organizing feature map (SOM) for Visual Sentiment Analysis of customer complaints. The framework learns the inherent grouping of complaints automatically and can be visualized using various techniques. A high-performance version of the algorithm CUDASOM is also proposed, which speeds up the processing of high-dimensional text data and generates fast results."
Kamal Tiwari,Mining Quantitative Association Rules in Protein Sequences,"Lot of research has gone into understanding the composition and nature of proteins, still many things remain to be understood satisfactorily. It is now generally believed that amino acid sequences of proteins are not random, and thus the patterns of amino acids that we observe in the protein sequences are also non-random.","Data mining, protein sequences, amino acids, protein composition, quantitative association rule mining",This study attempts to decipher the nature of associations between different amino acids that are present in a protein. The authors have attempted to find out rules that can tell that occurrence of one amino-acid is more likely when another amino-acid is present or absent.
Kamaruddin Sk,Digital Banking Dimensions and Analytics,"Of late, the financial services industry is fast moving away from the traditional paradigm to the sophisticated digital way of dealing and the customer. Both the facets of the financial service industry, viz., the financial service provider and the customer are going through a digital evolution. In particular, banking industry has evolved from just journal and ledger entry paradigm to data and analytics driven banking operations, which subsumes online as well as offline customer behavior. This paper discusses various scenarios in baking, finance services and insurance (BFSI) areas, where big data analytics is turning out to be paramount. The paper also highlights the potential benefits, of the new-age technologies viz., Internet of Things (IoT), Blockchain, Chatbots and robotics.","Big Data Analytics, fraud analytics, Chat-bot, Insurance, operational analytics, Digital Banking, customer analytics, Financial Services, Hadoop, risk analytics, IoT, Spark","The paper explores the eight dimensions of a digital bank, including customer/sales/services, regulator/other banks, internal, technology, data, business process reengineering, analytics, and people. It also discusses the role of analytics in digital banking, including customer analytics, fraud analytics, risk analytics, operational analytics, security analytics, and HR analytics."
Kancherla Jonah Nishanth,A Computational Intelligence Based Online Data Imputation Method: An Application For Banking,"All the imputation techniques proposed so far in literature for data imputation are offline techniques as they require a number of iterations to learn the characteristics of data during training and they also consume a lot of computational time. Hence, these techniques are not suitable for applications that require the imputation to be performed on demand and near real-time. The paper proposes a computational intelligence based architecture for online data imputation and extended versions of an existing offline data imputation method as well.","computational intelligence, K-Means clustering, Evolving Clustering Method (ECM), banking, K-Medoids clustering, General Regression Neural Network (GRNN), GRNN, Imputation, MLP, online data imputation, Data Imputation","The proposed online imputation technique has 2 stages. In stage 1, Evolving Clustering Method (ECM) is used to replace the missing values with cluster centers, as part of the local learning strategy. Stage 2 refines the resultant approximate values using a General Regression Neural Network (GRNN) as part of the global approximation strategy."
Kanika,Evaluating the Learning Perspectives of Students on the Basis of Class Notes,This paper aims to evaluate the learning perspectives of students on the basis of class notes taken while the teacher is teaching in class. Homogenous and heterogeneous groups are formed on the basis of learning perspectives.,"Class Notes, Collaborative learning environments, Learning Perspectives, Collaborative Learning, Homogenous Grouping, heterogeneous grouping, homogeneous grouping",The study evaluates the learning perspectives of students on the basis of class notes taken while the teacher is teaching in class. The study uses a quasi-experimental design and involves 194 undergraduate students from the seventh semester of the computer engineering department. The study finds that homogenous and heterogeneous grouping methods have different effects on student learning outcomes.
Kanika Kanika,An Extended Version of WordNet Incorporating Technical Terms and Subject Specific Words/Phrases ||| KELDEC: A System for Mining Knowledge Sources from Images ||| Visual Tools for Teaching Programming,"WordNet is a huge repository being used as a tool in various fields. With an increasing number of applications referring to WordNet as a dictionary, several attempts have been made to update it. The paper proposes to extend the huge repository by adding words and relationships derived from students’ class notes through wikidata. These terms can be phrases, technical terms or any subject specific terminology appearing in students’ notes of a specific subject. Although various WordNet enriching techniques are available, it is for the first time that subject specific terminology is being added. The resulting version of WordNet has some very common phrases and technical terms along with the generic terms. Making subject specific and generic terms available in a hierarchy can improve the accuracy of various applications like text summarization and clustering for text belonging to a specific domain. ||| KELDEC is a system that mines knowledge sources from images by extracting technical phrases and using them to scout for relevant websites. The system uses a combination of natural language processing and machine learning techniques to identify relevant websites and rank them based on their semantic similarity to the image and the class notes. ||| Courses on computer programming are included in the curricula of almost all engineering disciplines. We surveyed the research literature and identified the techniques that are commonly used by instructors for teaching these courses. We observed that visual programming and game-based learning can enhance computational thinking and problem-solving skills in students and may be used to introduce them to programming. Robot programming may be used to attract students to programming, but the success of this technique is subjected to the availability of robots. Pair and collaborative programming allows students to learn from one another and write efficient programs. Assessment systems help instructors in evaluating programs written by students and provide them with timely feedback. Furthermore, an analysis of citations showed that Scratch is the most researched tool for teaching programming.","pair and collaborative programming, Web content mining, programming, Subject Specific Words/Phrases, knowledge source, pair programming, visual tools, game-based learning, English WordNet, WordNet, Hyponym enrichment, Technical Terms, collaborative learning, computer science education, teaching, robot programming, Personalized mobile learning, Educational recommender system, visual programming, assessment system, Image analysis, KELDEC, Classroom learning points, image mining, Wikidata, semantic similarity, technical phrases","The paper proposes a novel hyponym enrichment in WordNet by enriching the database with subject related technical terms. This is important since the database has not been updated for a long time now. To the best of our knowledge, we are the first to use wikidata for adding subject specific terms and relationships to WordNet. ||| The KELDEC system is designed to extract technical phrases from images and use them to recommend relevant websites to users. The system uses a combination of natural language processing and machine learning techniques to identify relevant websites and rank them based on their semantic similarity to the image and the class notes. ||| The paper reviews the use of visual tools for teaching programming, including the development of various visual tools and their widespread use in teaching programming courses. It also discusses the use of game-based approaches and pair and collaborative programming for teaching programming."
Kanika Tehlan,Genetic Algorithm-Based Approach for Teaching Programming,"Pair programming is an approach where two programmers work to solve one programming problem sitting shoulder to shoulder on a computer. Several studies indicating numerous benefits of using pair programming as a teaching strategy exist. However, only a few of them take into consideration the mechanism followed for pair formation. With an aim to study the impact of pair programming on undergraduate students, we try to make the pairs compatible with a genetic algorithm‐based approach. Using a genetic algorithm, the system ensures that every pair in the class gets a particular combination of skills and personality traits. We also developed a desktop application to assign programming exercises to students dynamically. To assess the efficacy of pair programming in introductory programming course, a formal pair programming experiment was run at Netaji Subhas University of Technology. The pair programming experiment involved a total 171 undergraduate students from a computer engineering course. At the end of the program, we assessed the programming abilities of every student. We also analyzed the impact of a genetic algorithm‐based pairing mechanism. On the basis of assessments, it is observed that pair programming is a successful pedagogical tool for facilitating active learning of introductory programming courses. Responses to survey garnered from undergraduate students hint that the genetic algorithm approach leads to compatible pairs.","introductory programming, pair programming, genetic algorithm, Pair Formation, collaborative learning, Programming Exercises","This paper studies the usefulness of pair programming as a method to teach an introductory programming course. The contributions of the study are the following: Keeping in mind the role of personality traits in determining the success of pair programming, we use a blend of skills and personality‐based pairing mechanism. A five‐factor model comprising of skill levels of students, personality type, and attitude toward programming is considered for pairing students. To minimize conflicts and automate the pair formation, we propose a novel genetic algorithm‐based approach. The experiment was conducted for one semester covering the entire course syllabus to analyze the effects of pair programming better."
Kapil Ahuja,Cube Sampled K-Prototype Algorithm for Clustering ||| Preconditioned Iterative Solves in Model Reduction ||| Reusing Preconditioners in Projection Based Model Order Reduction Algorithms,"This paper proposes a novel algorithm called Cube Sampled K-Prototype for clustering mixed data types. The algorithm integrates the K-Means and K-Modes algorithms and uses cube sampling to reduce the computational complexity. The proposed algorithm is compared with other clustering algorithms and shows better performance in terms of clustering accuracy. ||| This paper proposes the use of preconditioned iterative methods for solving linear systems in model reduction. The authors discuss the importance of preconditioning in improving the performance of iterative methods and present a new preconditioner, the Sparse Approximate Inverse (SPAI) preconditioner. They also discuss the use of SPAI preconditioner in the Adaptive Iterative Rational Global Arnoldi Algorithm (AIRGA) and present results showing the effectiveness of the proposed method. ||| Dynamical systems are pervasive in almost all engineering and scientific applications. Simulating such systems is computationally very intensive. Hence, Model Order Reduction (MOR) is used to reduce them to a lower dimension. Most of the MOR algorithms require solving large sparse sequences of linear systems. Since using direct methods for solving such systems does not scale well in time with respect to the increase in the input dimension, efficient preconditioned iterative methods are commonly used. In one of our previous works, we have shown substantial improvements by reusing preconditioners for the parametric MOR (Singh et al. 2019). Here, we had proposed techniques for both, the non-parametric and the parametric cases, but had applied them only to the latter. We have three main contributions here. First, we demonstrate that preconditioners can be reused more effectively in the non-parametric case as compared to the parametric one. Second, we show that reusing preconditioners is an art via detailed algorithmic implementations in multiple MOR algorithms. Third and final, we demonstrate that reusing preconditioners for reducing a real-life industrial problem (of size 1.2 million), leads to relative savings of up to 64% in the total computation time (in absolute terms a saving of 5 days).","Mixed Data Types, Sparse Approximate Inverse (SPAI) preconditioner, Sampling, Clustering, reusing preconditioners, Adaptive Iterative Rational Global Arnoldi Algorithm (AIRGA), Cube Sampling, Global Arnoldi Algorithm, Model reduction, preconditioners, K-Prototype, K-Prototype Clustering, Model order reduction, moment matching, iterative methods, Iterative Methods, Principal Component Analysis, Model Order Reduction, Clustering Accuracy, Preconditioned iterative methods, Preconditioner and Stability Analysis, Moment Matching, Linear systems","This paper proposes a probabilistic sampling technique called cube sampling along with K-Prototype clustering. Cube sampling is used because of its accurate sample selection. The novelty of this work is in obtaining the crucial inclusion probabilities for cube sampling using Principal Component Analysis (PCA). ||| This paper focuses on efficiently solving linear systems arising in the model reduction process using iterative methods and preconditioners. The authors propose the use of relevant iterative algorithms and the Sparse Approximate Inverse (SPAI) preconditioner, and provide a technique to cheaply update the SPAI preconditioner in each iteration step. ||| This paper demonstrates the reuse of preconditioners in projection-based model order reduction algorithms for non-parametric dynamical systems. The authors have three main contributions: (i) they demonstrate that preconditioners can be reused more effectively in the non-parametric case, (ii) they show that reusing preconditioners is an art via detailed algorithmic implementations in multiple MOR algorithms, and (iii) they demonstrate that reusing preconditioners leads to relative savings of up to 64% in the total computation time for a real-life industrial problem."
Karamitros,3D FE MODELLING OF BURIED CONTINUOUS PIPELINE EXPOSED TO FAULT MOTION WITH MATERIAL NONLINEARITY AND LARGE DEFORMATION,"Pipeline generally extends over long distances traversing through wide variety of different soils, geological conditions and regions with different seismicity. Majority of the past works in the area of pipeline subjected to fault motion is restricted in several ways. There were many analytical models developed in the past for pipeline fault crossing, however, they are of limited usage, for example analytical model developed for pipeline fault crossing can be useful for strike slip fault crossing only. Likewise incorporating the large geometric changes in analytical study is a tricky task; however pipeline subjected to the fault motion itself is a phenomenon of large geometric changes. Especially when pipeline subjected to compression, where in addition to material deformation it also undergoes general as well as local buckling with bending, contradictorily past work mostly assumed that pipeline is under tension. With day by day increasing capacity of computation and advancement in numerical modeling, one can find more facts for pipeline subjected fault motions including cases of pipe under compression as well. In this paper, past work is reviewed for pipeline subjected to large fault motion. A three dimensional FE based numerical model is suggested to carry out pipeline performance of buried pipeline subjected to fault motion. A proposed model includes material nonlinearity, as well as effect of the large geometric changes. For this purpose, three dimensional FE program is developed in MATLAB. Displacement controlled Arc-length technique is implemented to solve the nonlinear behavior. To reduce the computation time of analysis here parallelization tool kit of MATLAB is utilized.","pipeline performance, Displacement controlled Arc-length technique, material nonlinearity, finite element method, Fault motion, Buried continuous pipeline, Nonlinear-large deformation FEM, large deformation","This paper presents a three-dimensional finite element model for buried continuous pipelines exposed to fault motion with material nonlinearity and large deformation. The model is developed using isoparametric brick elements and is validated by comparing the load-deflection curve with the results obtained from the commercially available finite element package ANSYS-12. The performance of the pipeline is evaluated for various fault offset, pipeline-fault crossing angle, wall thickness to diameter ratio, and depth of the buried pipeline."
Karen Price,First-­in-­Human Study of Bamlanivimab in a Randomized Trial of Hospitalized Patients With COVID-­19,"This first-in-human study in hospitalized patients with COVID-19 was supported by studies assessing in vitro viral neutralization combined with a single-dose non-human primate PK study. The nonclinical safety package to support subsequent studies included tissue cross-reactivity studies on human, rat, and monkey tissues and an in vivo toxicology study.  A complete physical examination was conducted at the screening visit, and one of three bamlanivimab doses or placebo was administered i.v. at the baseline visit (D1) with infusion rates as follows: bamlanivimab 700 mg (50 mL) administered 100 mL/hr for 30 minutes; 2,800 mg (75 mL) administered 100 mL/hr for 45 minutes; and 7,000 mg administered 100 mL/hr for 60 minutes. Placebo infusion was 0.9% normal saline, administered at the same volume and rate as the corresponding bamlanivimab dose cohort. Safety and tolerability were reviewed for sentinel participants up to 24 hours after dosing, at which point the investigators and sponsor team determined whether safety and tolerability were acceptable to continue with dosing subsequent participants. The decision to dose the next cohort was made when all participants from the previous cohort had been dosed and safety data assessed for at least 4 days after the i.v. infusion by the investigators and sponsor team in consultation with an independent safety assessment committee. Blood samples were obtained for assessment of exploratory biomarkers, serology, clinical laboratory assessments, and PD on days 1, 3, 7, 11, 15, 22, and 29, and every 7 days until discharge or day 60, if still an inpatient. Samples for the virology assay were collected using nasopharyngeal (preferred) or mid-turbinate methods. Blood samples obtained for PK analyses were assessed on days 1 (pre-infusion and just before end of infusion), 4, 15, and 29, and follow-up visits up to day 60. Symptom-related physical examinations and assessments of clinical symptoms were performed on days 1, 2, 3, 4, 7, 11, 15, 22, and 29, and the day of discharge from the hospital, with additional follow-up examinations every 7 days thereafter until day 60 if the patient was not discharged from the hospital by day 29. Participants’ clinical status and concurrent procedures of special interest were recorded, including limitation on activities due to COVID-19 and any requirements for the following procedures of special interest, such as ongoing hospital medical care, supplemental oxygen, noninvasive ventilation or a high flow oxygen device, mechanical ventilation, extracorporeal membrane oxygenation, additional organ support, or consciousness status using alert, consciousness, verbal, pain, unresponsive scale. Hospitalization events were recorded, including dates of hospital admission and discharge, admission to the intensive care unit (ICU), discharge from the ICU, and discharge location including to an extended care facility or home. Outcomes The primary objective was to assess safety and tolerability, including adverse events (AEs), serious adverse events (SAEs), and discontinuations due to AEs. Other objectives included PKs (e.g., mean concentration at day 29); PD viral load, area under the response time curve (AUC, from day 1 to day 29), and change from baseline time course; total symptom score; time to symptom resolution; duration of hospitalization; National Institute of Allergy and Infectious Diseases (NIAID), World Health Organization (WHO) scales, and National Early Warning Score (NEWS2); and analysis of viral resistance. Any hypothesis tests were conducted for treatment comparisons without adjustment for multiplicity except for the evaluation of treatment effect on endogenous antibody titers. Success for the trial was claimed using a Bayesian criterion if any of the 3 bamlanivimab doses had at least 60% probability to reduce at least 30% mean AUC (28-day viral load) over placebo.",,"This first-in-human study evaluated the safety, tolerability, pharmacokinetics, clinical course, and viral dynamics of bamlanivimab, a fully human neutralizing monoclonal antibody targeting SARS-CoV-2, in hospitalized patients with moderate to severe COVID-19.  The study found bamlanivimab to be safe and well-tolerated, with no serious adverse events or deaths reported.  Further research is needed to determine the efficacy of bamlanivimab in treating COVID-19."
Kashif Naseer Qureshi,A Dynamic Congestion Control Scheme for safety applications in vehicular ad hoc networks,"In recent years, various types of applications have emerged from Vehicular Ad hoc Networks (VANETs) for safety, infotainment, rescue and security purposes. Safety applications have their own strict communication requirements, and they require reliable and timely data communication within networks. Due to a variety of network applications, safety applications have been negatively impacted by communication channel congestion issues. Channel congestion leads to packet loss, delay and unreliability issues, and has a serious impact on vehicular traffic, including road accidents, road jams, and wrong traffic decisions. In addressing these issues, this paper's authors have proposed a Dynamic Congestion Control Scheme (DCCS) as a means of reliable and timely data delivery, in safety applications. The proposed scheme is designed for communication channels, as a means of broadcasting safety messages, and to ensure the reliable and timely delivery of messages to all neighbours in a network. The DCCS scheme is designed for inter-vehicle communication, without fixed infrastructure. Comprehensive simulation is conducted, in order to evaluate the performance of a proposed scheme, and to compare it with other state of the art schemes.","Congestion Control, Mobility, Transmit Power Control, MAC Blocking, Safety, Measurement-Based Detection, Urban, VANETs, Congestion, Communication, Vehicular, Control, Broadcasting, Queue Freezing",This paper proposes a Dynamic Congestion Control Scheme (DCCS) for safety applications in Vehicular Ad hoc Networks (VANETs). The scheme detects congestion and controls it by exploiting existing network resources for road traffic safety and cum security. The main objectives of this research are to determine whether a congestion detection scheme will reduce congestion by using realistic weighting factors and whether a congestion control scheme can control congestion through message originated-based queue freezing.
Katarina Lundqvist,ROS deficiency enhanced mannan-induced PsA,"In and joint inflammation using B10Q.Ncf1m1j/m1j mice that have a mutation in the Ncf1 gene (m1j) (the Ncf1 protein also denoted p47phox), and hence reduced ROS production (oxidative burst) (18). As shown in Fig. 1D, Ncf1 mutated mice developed severe joint inflammation within 2 d after mannan injection, which reached the mean maximal disease severity (30 ± 6 points) within 4 d. The frequency of skin lesions was 100%, with more severe cases in B10Q.Ncf1m1j/m1j mice (Fig. 1E), whereas B10.Q mice had a significantly milder disease course. Multiple Exposures to Mannan Induced a Relapsing Disease. Next, we examined the effect of multiple mannan injections in B10Q and B10Q.Ncf1m1j/m1j mice. We boosted mice twice with mannan on days 7 and 14 after disease initiation. Repetitive injections of mannan reproduced the arthritis phenotype, which reached the maximum severity level on days 9 and 17, similar to the first injection (Fig. 1F). A more severe disease course was observed in B10Q.Ncf1m1j/m1j mice than in B10Q mice (P < 0.05 and P < 0.01, respectively). Interestingly, Ps skin scaling returned only after the second mannan injection (on day 16), but the skin peeled off even more quickly than the first time (Fig. 1G). Moreover, from day 11 onward, B10Q.Ncf1m1j/m1j mice started to develop pruritus on the body, predominantly on the back and above the eye (Fig. S1E). Pruritus was only evident in B10Q.Ncf1m1j/m1j mice, but flaky skin on the tail and alopecia all over the leg was observed in both of the mouse strains. We also observed genetic heterogeneity in disease susceptibility (Fig. Fig. 1. ROS deficiency enhanced mannan-induced PsA. The arthritic joint phenotype and Ps-like skin lesions in the front (A) and hind (B) paws of B10Q.Ncf1m1j/m1j mice are shown. (C) Ps-like skin scaling in diseased B10Q.Ncf1m1j/m1j mouse ear compared with naive mouse ear. Mean arthritis (D) and Ps lesion (E) severity in B10Q (n = 5) and B10Q.Ncf1m1j/m1j (n = 5) mice after a single i.p. mannan injection. Mean arthritis (F) and Ps lesion (G) severity in B10Q (n = 5) and B10Q.Ncf1m1j/m1j (n = 5) mice after repetitive mannan injections (days 7 and 14). (H) Mannan-induced mean maximum arthritis scores ± SEM in different mouse strains: B10Q (n = 8), B10Q.Ncf1m1j/m1j (n = 9), B10RIII (n = 10), B10RIII.Ncf1m1j/m1j (n = 9), B10P (n = 3), B10P.Ncf1m1j/m1j (n = 9), BALB/cByJ/Q (n = 10), BALB/cByJ/Q.Ncf1m1j/m1j (n = 8), BALB/cByJ (n = 5), BALB/cByJ.Ncf1m1j/m1j (n = 7), C57BL/6NJ (n = 8), and C57BL/6NJ.Ncf1m1j/m1j (n = 7). Significance was calculated by comparing the maximal disease severity of B10Q and B10Q.Ncf1m1j/m1j mice with all of the other strains in their respective groups. *P < 0.05; **P < 0.01; ***P < 0.001. E3670 | www.pnas.org/cgi/doi/10.1073/pnas.1405798111 Khmaladze et al. Downloaded from https://www.pnas.org by 122.184.65.228 on February 22, 2023 from IP address 122.184.65.228.","autoimmune disease, Ncf1, animal model","This study identifies a new mechanism for psoriasis (Ps) and psoriasis arthritis (PsA) development in mice. A single injection of mannan, a component of baker's yeast, induced Ps and PsA-like symptoms. This effect was exacerbated in mice lacking reactive oxygen species (ROS), but improved when ROS production was restored in macrophages.  Blocking IL-17A, a cytokine produced by gamma delta T cells, completely prevented disease. The study suggests that mannan activates macrophages, leading to TNF-α secretion and stimulation of IL-17A production by gamma delta T cells. This, in turn, drives neutrophil infiltration and inflammation, mimicking Ps and PsA. This new mouse model could be valuable for testing new therapies for Ps and PsA."
Kathleen Maksimowicz-McKinnon,BELIMUMAB IN PATIENTS OF BLACK AFRICAN ANCESTRY,"Study design. SELENA–SLEDAI = Safety of Estrogens in Lupus Erythematosus National Assessment–Systemic Lupus Erythemato-sus Disease Activity Index; IV = intravenous.

Randomization and treatment. Using an interactive voice/web response system, patients receiving standard therapy were randomized 2:1 to receive either belimumab 10 mg/kg IV or placebo, which was administered on days 0, 14, and 28 and every 28 days thereafter up to week 48, with a final evaluation at week 52. Randomization was stratified by screening SELENA–SLEDAI score (≤9 versus ≥10), region (US/Canada versus rest of world), and complement level (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]). Detailed randomization data are provided in Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Patients who successfully completed the initial 52-week double-blind phase could enter an optional 6-month open-label extension phase, during which they received belimumab 10 mg/kg IV every 28 days plus standard therapy, irrespective of their previous study assignment. The first dose was given at the week 52 (day 364) visit of the double-blind period (day 1 of the open-label extension phase). Patients who completed the 52-week double-blind phase, but did not enter the 6-month open-label extension phase, were required to return for an additional follow-up visit 8 weeks after their last dose. Patients who withdrew early were required to return for an exit visit 4 weeks after their last dose and a follow-up visit 8 weeks after their last dose.

The original protocol plan was to randomize 816 patients, providing ≥90% power to detect ≥12% absolute improvement in the SRI response rate in the belimumab group compared with the placebo group at a 5% significance level. Due to enrollment challenges, a revised sample size was calculated to include 501 patients (≥334 patients in the belimumab group and ≥167 patients in the placebo group). This sample size provided ≥90% power to detect a minimum 15.55% absolute improvement in SRI–SLEDAI-2K response rate in the belimumab group relative to the placebo group at a 5% significance level (based on the pooled data from efficacy studies BEL112341 and BEL113750) (15,21). These calculations assumed a placebo response rate of 43.95% at week 52.

Study end points and assessments. The primary efficacy end point was the SRI–SLEDAI-2K response rate (defined in the Supplementary Material) at week 52 of the double-blind phase. Unlike in the phase II and phase III studies, the SRI–SLEDAI-2K was selected because of the simplification it offers in proteinuria assessment as compared with the SELENA–SLEDAI proteinuria component; both are clinically meaningful (22). The primary efficacy end point for the open-label extension phase was SRI–SLEDAI-2K response rate at open-label extension week 24. If the open-label extension week 24 data were missing, data from the open-label extension week 28/exit visit were used. This time point is referred to as “open-label extension week 24” throughout the text. Data related to the primary efficacy end point, e.g., the response rate over time, percentage of patients with a durable SRI–SLEDAI-2K response from week 44 through week 52, time to first SRI–SLEDAI-2K response that was maintained through week 52, and duration of longest SRI–SLEDAI-2K response among patients with ≥1 SRI–SLEDAI-2K responses were summarized.

The key secondary end points were SRI–SELENA–SLEDAI at week 52 (open-label extension week 24), time to first severe SLE flare (measured by the SELENA–SLEDAI flare index [SFI]), and proportion of patients whose average prednisone dose had been reduced by ≥25% from baseline to ≤7.5 mg/day during week 40 through week 52 (open-label extension week 28/exit visit), in patients receiving >7.5 mg/day at baseline. Key renal end points included time to first renal flare over 52 weeks and over 28 weeks in the open-label extension, SELENA–SLEDAI–SLEDAI-2K renal domain improvement at week 52, SELENA–SLEDAI–SLEDAI-2K renal domain worsening at week 52, percentage reduction in proteinuria by visit and at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours, and proteinuria shift at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours. Renal flare is defined in the Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Biomarkers measured included percentage changes in serum IgG level, anti-dsDNA antibody level (in those who were anti-dsDNA positive [≥30 IU/ml] at baseline), and complement (C3 and C4) levels from baseline. Safety was evaluated by monitoring adverse events (AEs), serious AEs (SAEs), AEs of special interest, vital signs, clinical laboratory test results, and immunogenicity up to 8 weeks posttreatment and throughout the open-label extension phase.

Data analyses. For the double-blind phase, safety analyses were performed on the safety population, defined as all patients who were randomized and treated with at least 1 dose of investigational product. Data on the safety population were summarized according to the treatment the patient was randomized to receive rather than by the treatment that was received, but both were the same for this study. Efficacy analyses were performed on the modified intent-to-treat (ITT) population, defined as the safety population minus those patients who had any assessment at any of 3 study sites that were excluded from the efficacy analyses before the database lock because of potential Good Clinical Practice noncompliance.

For analysis of the primary and 3 key secondary efficacy end points, a step-down sequential testing procedure was used as described in the Supplementary Material. The following subgroup analyses were performed for the primary analysis (SRI–SLEDAI-2K response at week 52): region (US/Canada versus rest of world), baseline SELENA–SLEDAI–SLEDAI-2K score (≤9 versus ≥10), baseline anti-dsDNA antibody level (≥30 IU/ml versus <30 IU/ml), baseline complement levels (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]), and baseline complement and anti-dsDNA antibody levels (≥1 test finding showing low C3/C4 and anti-dsDNA ≥30 IU/ml versus C3/C4 other and anti-dsDNA ≥30 IU/ml). The odds of an SRI–SLEDAI-2K response with belimumab treatment versus placebo were estimated using logistic regression analysis.

For the open-label extension phase, all patients received belimumab, no formal statistical hypothesis t",,"This study investigated the efficacy and safety of belimumab in patients of Black African ancestry with systemic lupus erythematosus (SLE).  Patients were randomized to receive belimumab or placebo for 52 weeks, followed by an optional 6-month open-label extension phase. The primary efficacy endpoint was the SRI–SLEDAI-2K response rate at week 52.  Key secondary endpoints included SRI–SELENA–SLEDAI at week 52, time to first severe SLE flare, and proportion of patients with a reduction in prednisone dose. Renal and biomarker assessments were also conducted.  The study found that belimumab was effective in improving SLE disease activity and reducing renal flares in patients of Black African ancestry."
Kaustuv Nag,Robust Consensus: A New Measure for Multicriteria Robust Group Decision Making Problems Using Evolutionary Approach,"In fuzzy group decision making problems, we often use multi-objective evolutionary optimization. The optimizers search through the whole search space and provide a set of nondominated solutions. But, sometimes the decision makers express their prior preferences using fuzzy numbers. In this case, the optimizers search in the preferred soft region and provide solutions with higher consensus. If perturbation in the decision variable space is unavoidable, we also need to search for robust solutions. Again, this perturbation aﬀects the degree of consensus of the solutions. This leads to search for solutions those are robust to their degree of consensus. In this work, we address these issues by redeﬁning consensus and proposing a new measure called robust consensus. We also provide a reformulation mechanism for multiobjective optimization problems. Our experimental results show that the proposed method is capable of ﬁnding robust solutions having robust consensus in the speciﬁed soft region.","robustness, evolutionary algorithms, fuzzy group decision making, multiobjective optimization, Consensus",This paper proposes a new measure called robust consensus for multicriteria robust group decision making problems using evolutionary approach. The proposed method addresses the issues of prior preferences using fuzzy numbers and perturbation in the decision variable space. Experimental results show that the proposed method is capable of finding robust solutions having robust consensus in the specified soft region.
Kavita,Recent Developments in Plant Leaf Disease Identification and Classification,"In the modern era, deep learning techniques have emerged as powerful tools in image recognition. Convolutional Neural Networks, one of the deep learning tools, have attained an impressive outcome in this area. The effectiveness of Convolutional Neural Networks in image recognition motivates the researchers to extend its applications in the field of agriculture for recognition of plant species, yield management, weed detection, soil, and water management, fruit counting, diseases, and pest detection, evaluating the nutrient status of plants, and much more.","leaf, deep learning models, disease, survey, deep learning, machine learning models, plant leaf disease identification, agriculture, convolutional neural networks","This manuscript presents a survey of the existing literature in applying deep Convolutional Neural Networks to predict plant diseases from leaf images. It presents an exemplary comparison of the pre-processing techniques, Convolutional Neural Network models, frameworks, and optimization techniques applied to detect and classify plant diseases using leaf images as a data set."
Ke Rong,h-value touch points between IoT mobile Apps and their users,"Business models help firms to set a right path to create, grow and retain their business value. While previous research shows that business model affects the performance of entrepreneurial firms, there is still limited understanding about how likely different business model selections of Internet of Things (IoT) startup firms retain their value and whether the venture capital investment intensity does play any role in the business model’s value retention process.","Instrumental variable regression, Business model, Value retention, Mobile application, venture capital, mobile Apps, China, Internet of things, IoT","This study investigates the impact of e-business models on value retention for start-ups in the Internet of Things (IoT) and Mobile Applications (Apps) business. The study finds that e-efficiency-centred and complementarities-centred e-business models increase value retention, while lock-in centred e-business model reduces value retention. The study also finds that venture capitalist’s involvement moderates the relationship between e-business models and value retention."
"Keane, A. J.",Local Surrogate Modeling for Parallel Evolutionary Optimization of Computationally Expensive Problems,This paper presents a local surrogate modeling algorithm for parallel evolutionary optimization of computationally expensive problems. The algorithm uses radial basis function networks to construct local surrogate models in the spirit of transductive inference. The proposed algorithm can be efficiently parallelized on grid computing architectures and does not compromise on the intrinsic parallelism offered by evolutionary algorithms.,"Radial basis function networks, evolutionary optimization, Transductive inference, Local surrogate modeling, surrogate modeling, Parallel evolutionary optimization, computationally expensive problems",The paper presents a parallel evolutionary optimization algorithm that uses surrogate models to solve computationally expensive design problems with general constraints on a limited computational budget. The algorithm combines an evolutionary algorithm with a feasible sequential quadratic programming solver and uses a trust-region approach to leverage exact and surrogate models during local search.
Kedar Khare,"Magnetic Resonance Materials in Physics, Biology and Medicine",Objective  To implement an advanced spatial penalty-based reconstruction to constrain the intravoxel incoherent motion (IVIM)–diffusion kurtosis imaging (DKI) model and investigate whether it provides a suitable alternative at 1.5 T to the traditional IVIM–DKI model at 3 T for clinical characterization of prostate cancer (PCa) and benign prostatic hyperplasia (BPH).,"TV penalty function, Prostate cancer, Benign prostatic hyperplasia, Total variation penalty function, MRI, Diffusion kurtosis imaging, Intravoxel incoherent motion, IVIM–DKI model","This study compares the use of IVIM–DKI at 1.5 T and 3 T MRI for differentiating between prostate cancer and benign prostatic hyperplasia. The results show that IVIM–DKI modeled with a novel model at 1.5 T produced parameter maps with lower coefficient of variation than the traditional model at 3 T. The novel model estimated higher D with lower D*, f, and k values at both field strengths compared to the traditional model. The study concludes that the proposed novel model can be utilized for improved detection of prostate lesions."
"Kegelmeyer, W. P.",A Multi-Task Approach to Open Domain Suggestion Mining,"Consumer reviews online may contain suggestions useful for improving the target products and services. Mining suggestions is challenging because the field lacks large labelled and balanced datasets. Furthermore, most prior studies have only focused on mining suggestions in a single domain. In this work, we introduce a novel up-sampling technique to address the problem of class imbalance, and propose a multi-task deep learning approach for mining suggestions from multiple domains.","Deep Learning, Suggestion Mining, Artificial Intelligence, Class Imbalance, Multi-Task Learning","This paper presents a multi-task approach to open domain suggestion mining, addressing the class imbalance problem using a novel up-sampling technique and a multi-task deep learning framework. Experimental results show that the proposed approach outperforms state-of-the-art models in terms of F-1 measure and AUC."
Kessler,Fifty years of peephole optimization,"Peephole optimization is a technique used in compilers to improve the performance of object programs by replacing sequences of instructions with equivalent single instructions. This article reviews the history and development of peephole optimization, including its application to various programming languages and target machines.","compilers, object programs, peephole optimization, Code generators, instruction sequences, replacement rules","Peephole optimization has been widely used in compilers to improve the performance of object programs. The technique involves replacing sequences of instructions with equivalent single instructions, and has been applied to various programming languages and target machines. The effectiveness of peephole optimization depends on several factors, including the nature of the source language, the parsing and code generation techniques used in the compiler, and the specifications of the target machine."
Ketema Adere,Directional Antenna MAC Protocols for Wireless Sensor Networks,"This paper proposes a directional antenna MAC protocol to overcome the MAC-deadlock, hidden and exposed terminal problem in wireless sensor networks. The proposed protocol uses directional antennas to receive/sending packets only from/to one side at the same time, reducing energy dissipation and increasing throughput.","Directional-Antenna, Energy efficiency, Medium Access Control protocol, MAC-deadlock, hidden terminal problem, directional antenna, exposed terminal problem, wireless sensor networks","This paper explores various aspects of medium access control (MAC) protocols in wireless sensor networks. The MAC protocols in wireless sensor network must achieve two main goals at minimum: the creation of sensor network infrastructure and the establishing communication links for data transfer between them, and fairly and efficiently share communication resources between each sensor nodes."
Keval Krishan Talwar,"Cardioprotection from ischemia and reperfusion injury by Withania somnifera: A hemodynamic, biochemical and histopathological assessment","The efficacy of Withania somnifera (Ws) to limit myocardial injury after ischemia and reperfusion was explored and compared to that of Vit E, a reference standard known to reduce mortality and infarct size due to myocardial infarction. Wistar rats (150–200 g) were divided into six groups and received orally saline (sham, control group), Ws-50/kg (Ws control and treated group) and Vit E-100 mg/kg (Vit E control and treated group) respectively for 1 month. On the 31st day, rats of the control, Vit E and Ws treated groups were anesthetized and subjected to 45 min occlusion of the LAD coronary artery followed by 60 min reperfusion. Hemodynamic parameters: systolic, diastolic and mean arterial pressure (SAP, DAP, MAP), heart rate (HR), left ventricular end diastolic pressure (LVEDP), left ventricular peak (+)LVdP/dt and (–)LVdP/dt were monitored. Hearts were removed and processed for histopathological and biochemical studies: Myocardial enzyme viz, creatin phosphokinase (CPK), and antioxidant parameters: malondialdehyde (MDA), glutathione (GSH), superoxide dismutase (SOD), catalase (CAT), glu-tathione peroxidase (GSHPx) were estimated. Postischemic reperfusion produced significant cardiac necrosis, depression of left ventricular functions (MAP, LVEDP, (+) and (–)LVdP/dt) and a significant fall in GSH (p < 0.01), SOD, CAT (p < 0.05), LDH and CPK (p < 0.01) as well as an increase in MDA level (p < 0.05) in the control group rats as compared to sham group. The changes in levels of protein and GPx was however, not significant. Ws and Vit E favorably modulated most of the hemo-dynamic, biochemical and histopathological parameters though no significant restoration in GSH, MAP (with Vit E) were ob-served. Ws on chronic administration markedly augmented antioxidants (GSH, GSHPx, SOD, CAT) while Vit E did not stimulate the synthesis of endogenous antioxidants compared to sham. Results indicate that Ws significantly reduced myocardial injury and emphasize the beneficial action of Ws as a cardioprotective agent.","Withania somnifera, adaptogens, Adaptogenic, myocardial infarction, Ischemia-reperfusion injury, Myocardial damage, ischemia, Vitamin E, antioxidants, reperfusion","This study investigated the cardioprotective effects of Withania somnifera (Ws) compared to Vitamin E in a rat model of ischemia and reperfusion induced myocardial injury. Ws significantly reduced myocardial injury, improved hemodynamic parameters, and enhanced antioxidant defense mechanisms. These findings suggest that Ws has potential as a cardioprotective agent."
Khaldoon Dhou,"An Exploratory Study on the Impact of Chess Personalities of Virtual Chess Players on the Outcome of Chess Games ||| An innovative employment of the NetLogo AIDS model in developing a new chain code for compression ||| A Novel Agent-based Modeling Approach for Image Coding and Lossless Compression Based on the Wolf-Sheep Predation Model ||| A Novel Algorithm for Bi-Level Image Coding and Lossless Compression based on Virtual Ant Colonies ||| A Novel Investigation of Attack Strategies via the Involvement of Virtual Humans: A User Study of Josh Waitzkin, a Virtual Chess Grandmaster ||| Employing Virtual Humans to Explore Competition Against Kasparov ||| Hybrid Harmony Search Algorithm to Solve the Feature Selection for Data Mining Applications ||| Personality in AR gaming: the case of Pokémon GO ||| The Effects of Tag Cloud Design on Size Judgment","Virtual humans emerged as a topic of research in HCI and they have been used for various purposes. This paper explores the behavior of chess players in a virtual chess environment to gain more understanding about chess personalities. In particular, the focus of this research is investigating attack and defense strategies used by virtual chess grandmasters against different virtual class-B personalities who vary in their strength in the different stages of a game. ||| In this paper, we utilize the NetLogo HIV model in constructing an environment for bi-level image encoding and employ it in compression. Our model considers converting an image into a virtual environment that comprises female agents testing positive and negative for HIV. Female agents are scattered according to the allocation of the pixels in the original images to be tested. The simulation considers introducing male agents that test positive for HIV, the purpose of which is to track their movements while infecting other HIV- female agents. The progressions of the HIV+ male agents within the simulation take advantage of the relative encoding approach previously used by other image processing and agent-based modeling researchers. That is to say, the simulation allows generating a high proportion of similar movement forms that are similarly encoded regardless of the movements of agents. This is followed up by applying Huffman coding to the obtained chains of movement strings for further reduction. The ultimate results reveal that our product could outperform existing benchmarks using all the images we employed in testing. ||| In this article, the researcher develops an image coding technique which is based on the wolf-sheep predation model. In the design, images are converted to virtual worlds of sheep, routes and wolves. Wolves in this model wander around searching for sheep while the algorithm tracks their movement. A wolf has seven movements which capture all the directions of the wolf. In addition, the researcher introduces one extra move of the wolf the purpose of which is to provide a shorter string of movements and to enhance the compression ratio. The first coordinates and the movements of the wolf are tracked and recorded. Then, arithmetic coding is applied on the string of movements to further compress it. The algorithm was applied on a set of images and the results were compared with other algorithms in the research community. The experimental results reveal that the size of the compressed string of wolf movements offer a higher reduction in space and the compression ratio is higher than those of many existing compression algorithms including G3, G4, JBIG1, JBIG2 and the recent agent-based model of ant colonies. ||| This paper presents a novel method for image compression using ant colony optimization. The algorithm works by representing the image as a virtual world where ants move and collect food. The coordinates of the ants and their movements are recorded and used to reconstruct the image. The algorithm consists of eight steps, including converting the image to a food-route representation, determining the coordinates of the image, dropping ants randomly, and recording the movements of the ants. The algorithm uses arithmetic coding to compress the string resulting from the movement of ants. ||| A growing body of evidence suggests that attack is a significant concept that has been explored by researchers from various disciplines such as marketing, psychology, and computing. Additionally, there has been substantial research undertaken on the role of attack in chess, which brought significant contributions to different fields of research. In this paper, the researcher investigates the attack concept in chess, as a strategic game by exploring virtual chess players of different strategies. ||| Exploring chess players of different personalities, including the strengths and weaknesses of each remains an essential component in designing new chess applications. Research shows that virtual players play an essential role in helping researchers to explore chess personalities of different classes and playing styles. ||| The increasing size of all sorts text and data information on websites makes the method of text clustering (TC) a lot more complicated. The TC technique is employed to cluster an enormous variety of documents into a set of intelligible and connected clusters. Usually, TC is employed in several domains like text mining, data processing, pattern recognition, image clustering. ||| The latest business reports showed that Augmented Real-ity (AR) and Artiﬁcial Intelligence (AI) are ranked among the top 10 strategic trends for 2018. For these reasons, in this paper, we provide an interdisciplinary focus on design and personality issues, trying to discuss the interplay between games with personality and Artiﬁcial Intelligence. ||| This dissertation focuses on viewers' perception of the relative size of words presented in tag clouds. A tag cloud is a representation of the word content of a source document where the relative frequency, or importance, of the keywords (i.e., tags) is depicted by presenting the most important tag words in a cluster called a tag cloud and varying visual characteristics of the tag words such as color, saturation, location and size.","chess personality, virtual chess players, AIDS, image encoding, size judgment, Pokémon GO, Text Clustering, agreeableness, conscientiousness, neuroticism, HIV transmission, games, outcome of chess games, wolf-sheep predation model, competition, agent-based modeling, NetLogo, Pheromone, tag clouds, AR gaming, Hybrid Harmony Search Algorithm, extraversion, binary image, Josh Waitzkin, Kasparov, chess personalities, tag cloud, binary image coding, Arithmetic Coding, Huffman coding, Augmented Reality, relative size judgment, virtual humans, compression, Ant Colonies, defense, ant colony optimization, Binary Images, agent-based model, Data Mining, attack, personality, Proximity, attack strategies, image compression, Data Mining Applications, grandmasters, chess, viewers' perception, grandmaster, chess software, Vector Space Model, Feature Selection, image coding, arithmetic coding, chain code, openness, gaming, typeface size ratio","This paper explores the behavior of chess players in a virtual chess environment to gain more understanding about chess personalities. The focus of this research is investigating attack and defense strategies used by virtual chess grandmasters against different virtual class-B personalities who vary in their strength in the different stages of a game. ||| The authors designed and implemented an agent-based model of HIV transmission within a social society to encode bi-level image information and compress the new chains. The results showed that the current model outperformed well-known standardized benchmarks in bi-level compression. ||| This paper presents a novel agent-based modeling approach for image coding and lossless compression based on the wolf-sheep predation model. The proposed model converts images to virtual worlds of sheep, routes, and wolves, where wolves wander around searching for sheep while the algorithm tracks their movement. The model introduces a new wolf movement, which is captured via a total of eight possible directions, and applies arithmetic coding to further compress the string of movements. The experimental results show that the proposed model outperforms existing compression algorithms, including JBIG1, JBIG2, and the ant colonies model. ||| The paper proposes a novel method for image compression using ant colony optimization. The algorithm works by representing the image as a virtual world where ants move and collect food. The algorithm consists of eight steps and uses arithmetic coding to compress the string resulting from the movement of ants. ||| This paper explores the attack concept in chess by investigating virtual chess players of different strategies. The researcher collected data from four virtual chess players: a grandmaster and three class-A players. The selected grandmaster is Josh Waitzkin, who is known for his fearless attacking style and deep endgame understanding. The class-A players have different personalities: (1) a player who strongly controls the center of the board; (2) a player who ignores the center; and (3) a player who offers traps to control his opponent. ||| This study investigates the personality of Kasparov by analyzing the games between Kasparov and three class-A players: Rand, Dobie, and Sunny. The study examines the inﬂuences of Kasparov’s personality on diﬀerent class-A players and uses three measurements for chess personalities: number of moves in a game, error of a chess player, and the Chessmaster agreement percentage. ||| This paper proposes a hybrid harmony search algorithm to solve the feature selection problem for data mining applications. The algorithm uses the harmony search rule to select and obtain a new set of informative knowledge features, reducing the runtime of the system and decreasing the uninformative knowledge feature. The results show that the proposed modification of the harmony search rule enriched the performance value of the feature choice method in regard to the correct set, owing to its fine features. ||| The authors conclude that personality traits play a significant role in shaping player behavior in Pokémon GO, with extraversion, agreeableness, and conscientiousness being particularly relevant. They also highlight the importance of considering the role of virtual humans in exploring personalities in chess games. ||| The dissertation looks at how viewers estimate the relative size of words given different characteristics such as decorations, appearance of the words, typeface style, and location in the tag cloud. Significant under- and over-perception of the relative size of tag words were observed, primarily varying with the size of the target tag word."
Khanuja et al.,Hate Speech Detection in Code Switched Text,"This paper proposes a novel approach to hate speech detection in code switched text, which preserves the semantic sense and syntactic structure of the text. The proposed MoH pipeline ensures that the words in code switched text are transliterated to their original languages without compromising on the semantic sense and syntactic structure of the text while ensuring the correct spelling of each word.","Semantic Sense, social media, Code Switched Text, Transliteration, MuRIL, Hate Speech Detection, Bert, transfer learning, machine learning, text classification, MoH Pipeline, data simulations, cyber hate, Syntactic Structure","The paper presents a novel approach to hate speech detection in code switched text, which preserves the semantic sense and syntactic structure of the text. The proposed MoH pipeline ensures that the words in code switched text are transliterated to their original languages without compromising on the semantic sense and syntactic structure of the text while ensuring the correct spelling of each word."
Ki-Ho Kim,Bandwidth-Efﬁcient OFDM transmission with iterative cyclic preﬁx reconstruction,"Abstract—Orthogonal frequency division multiplexing (OFDM) systems are now a part of all major wireless standards, because of its potential to offer high data rate. Cyclic prefix (CP) in OFDM system converts a multipath channel to a flat fading channel, thus simplifies the design of equalizer. However, there is a lot of ambiguity in choosing the length of CP. In this paper, we propose a new method for calculation of length of CP using cumulant features. The merits of proposed method are verified by computer simulation.","bandwidth efﬁciency, OFDM, channel length estimation, cumulant features, Orthogonal frequency division multiplexing (OFDM), Cyclic prefix (CP), cyclic preﬁx, Blind channel length estimation","This paper proposes a novel method for blind channel length estimation in OFDM systems using cumulant features. The proposed method is well-suited for dynamic spectrum access (DSA) setups and does not require pilot or training sequences, thus saving bandwidth. The method is based on exploiting the properties of nth order cumulant features and is verified by computer simulation."
Kihyun Kim,Energy-Efficient Routing Algorithm for Wireless Sensor Networks,"Wireless Sensor Network (WSN) is a collection of sensor nodes. A sensor node covers all information which is present in its sensing range. To access the information present in some other sensor range, the networks use a process called Routing. Routing problem in wireless sensor network (WSN) concerned with maximizing the sensor network lifetime while continuously routing the collected data (information) to the base station (central server).","Network Lifetime, Energy –Efficiency, Energy-Efficient Routing, Sensor Networks, Routes, Wireless Sensor Networks, Wireless Sensor Networks (WSN), Energy Consumption, Routing problem, Routing Algorithm",The paper presents a new energy-efficient routing algorithm for wireless sensor networks. The algorithm prioritizes sensors according to their remaining battery life and selects the shortest path to maximize the total network lifetime.
Kitsak et al.,Pseudo-Cores: The Terminus of an Intelligent Viral Meme's Trajectory,"Comprehending the virality of a meme can help scientists address problems pertaining to disciplines like epidemiology and digital marketing. Therefore, it does not come as a surprise that meme virality stands out as an integral component of research in complex networks, today. In this paper, we explore the possibility of artificially inducing virality in a meme by intelligently directing a meme’s trajectory in the network.","meme virality, hill climbing algorithms, complex networks, artificially inducing virality, Pseudo-Cores, Meme Propagation, Network Structure, core-periphery structure, K-Shell Decomposition",The authors propose a new approach to decompose a network into multiple shells of inﬂuence and investigate the properties of all the shells in a network. They observe that the core is the shell with the least diameter and that the high density of the core is one of the reason for the high spreading power of the core.
Klaus Dornmair,Myelin-speciﬁc T cells also recognize neuronal autoantigen in a transgenic mouse model of multiple sclerosis,"We describe here the paradoxical development of spontaneous experimental autoimmune encephalomyelitis (EAE) in transgenic mice expressing a myelin oligodendrocyte glycoprotein (MOG)-speciﬁc T cell antigen receptor (TCR) in the absence of MOG. We report that in Mog-deﬁcient mice (Mog–/–), the autoimmune response by transgenic T cells is redirected to a neuronal cytoskeletal self antigen, neuroﬁlament-M (NF-M). Although components of radically different protein classes, the cross-reacting major histocompatibility complex I-Ab–restricted epitope sequences of MOG35–55 and NF-M18–30 share essential TCR contact positions. This pattern of cross-reaction is not speciﬁc to the transgenic TCR but is also commonly seen in MOG35–55–I-Ab–reactive T cells. We propose that in the C57BL/6 mouse, MOG and NF-M response components add up to overcome the general resistance of this strain to experimental induction of autoimmunity. Similar cumulative responses against more than one autoantigen may have a role in spontaneously developing human autoimmune diseases.",,"This study reports the unexpected finding that transgenic mice expressing a myelin oligodendrocyte glycoprotein (MOG)-specific T cell receptor (TCR) develop spontaneous experimental autoimmune encephalomyelitis (EAE) even in the absence of MOG. The researchers discovered that these mice redirect their autoimmune response to a neuronal cytoskeletal protein called neuroﬁlament-M (NF-M). This cross-reactivity between MOG and NF-M is mediated by shared TCR contact positions on their respective epitope sequences. The study suggests that cumulative responses against multiple autoantigens, such as MOG and NF-M, may contribute to the development of spontaneous autoimmune diseases in humans."
Koukias & Kiritsis,Ontology Driven Software Development for Automated Documentation,"Recent outsourcing /off-shoring software development practices testify that any development done without a proper sharing mechanism leads to the generation of inconsistent information, which further results in an undesired, error-prone software. Further, with the business process automation, a significant way to minimize human effort involves various development, support and maintenance activities to reuse available information. Thus, reusing and sharing information in a standardized way is the key operative challenges which foster the need to identify and exploit novel knowledge-based frameworks. The proposed research provides a tool-based solution to automate the software documentation process using ontologies. This multi-phase framework has overall six phases where each phase output contributes to the final automated documentation. To evaluate the extent of automated documentation it is compared using free and open source software known as WCopyfind to the existing manual documentation for a Result Management System case study. Preliminary results show a highest automation of 60 percent, which is clearly noteworthy.","Ontology driven, Ontology, software architecture documentation, Software’s documentation, Automatic documentation, technical documentation, ontology driven software development, Semantic Web, automated documentation, Software engineering","The paper presents a framework for ontology driven software development for automated documentation, which is divided into six phases. The framework is designed to capture key concepts of the domain under consideration and generate documentation in both human and machine-understandable forms. The paper also discusses the related work in the field of ontology driven software development and automated documentation."
Koukias et al.,Ontology Driven Software Development for Automated Documentation,"Recent outsourcing /off-shoring software development practices testify that any development done without a proper sharing mechanism leads to the generation of inconsistent information, which further results in an undesired, error-prone software. Further, with the business process automation, a significant way to minimize human effort involves various development, support and maintenance activities to reuse available information. Thus, reusing and sharing information in a standardized way is the key operative challenges which foster the need to identify and exploit novel knowledge-based frameworks. The proposed research provides a tool-based solution to automate the software documentation process using ontologies. This multi-phase framework has overall six phases where each phase output contributes to the final automated documentation. To evaluate the extent of automated documentation it is compared using free and open source software known as WCopyfind to the existing manual documentation for a Result Management System case study. Preliminary results show a highest automation of 60 percent, which is clearly noteworthy.","Ontology driven, Ontology, software architecture documentation, Software’s documentation, Automatic documentation, technical documentation, ontology driven software development, Semantic Web, automated documentation, Software engineering","The paper presents a framework for ontology driven software development for automated documentation, which is divided into six phases. The framework is designed to capture key concepts of the domain under consideration and generate documentation in both human and machine-understandable forms. The paper also discusses the related work in the field of ontology driven software development and automated documentation."
Krishna Asawa,Bimodal Energy Based Fusion Model for Emotion Recognition ||| EMIA: Emotion Model for Intelligent Agent ||| Event Perception and Appraisal Process and Its Formalization ||| IPv6 Address Spoofing in 6LoWPANs ||| Stylometric Analysis for Authorship Attribution on Twitter,"Multi-sensor information fusion is a rapidly developing research area which forms the backbone of numerous essential technologies such as intelligent robotic control, sensor networks, video and image processing and many more. In this paper, we have developed a novel technique to analyze and correlate human emotions expressed in voice tone & facial expression. ||| Emotions play a significant role in human cognitive processes such as attention, motivation, learning, memory, and decision making. Many researchers have worked in the field of incorporating emotions in a cognitive agent. However, each model has its own merits and demerits. Moreover, most studies on emotion focus on steady-state emotions than emotion switching. Thus, in this article, a domain-independent computational model of emotions for intelligent agent is proposed that have modules for emotion elicitation, emotion regulation, and emotion transition. ||| This paper presents a formalization of the event perception and appraisal process in an artificial intelligence system. The system uses a set of fuzzy sets to represent the appraisal variables, which are used to elicit emotions in response to events. The paper describes the architecture of the system, the event perception and appraisal process, and the formalization of the appraisal process. It also presents an example of how the system can be used to determine the linguistic values of the appraisal variables. ||| An attacker can disrupt the network operations in the 6LoWPANs by spoofing the IPv6 address while evading the detection. Despite many existing spoofing prevention techniques, spoofing threat still persists. Thus, it becomes necessary to devise a method which can offer resilience against spoofing by reducing the attack disruption time. This study aims at reducing IPv6 spoofing attack disruption time in 6LoWPANs. Hence, it provides the resiliency against IPv6 spoofing threat. The time complexity analysis of the attack tree for the spoofing attack is performed to analyze the attack disruption time. The analytical results show that attack disruption window is directly proportional to the lifetime of the node addresses. The lower lifetime of node addresses ensure the reduction of the attack disruption window. Thus, the use of temporary node addresses can be a solution for reducing the spoofing attack disruption window. Node’s IPv6 address can be changed periodically to dissociate a node from its permanent identity. Hence, an attacker has to re-perform the attack to gain significant benefits. Corrupted routing table as a result of spoofing attack and its countermeasure is simulated in Cooja running Contiki operating system. The length of the attack window depends upon the periodicity of the address change. The higher frequency of address change decreases the attack disruption time with an increase in the communication cost. Simulations have been performed to compare the optimum value of address change periodicity concerning the communication cost for two private addressing schemes proposed in the literature. ||| Authorship Attribution (AA), the science of inferring an author for a given piece of text based on its characteristics is a problem with a long history. In this paper, we study the problem of authorship attribution for forensic purposes and present machine learning techniques and stylometric features of the authors that enable authorship to be determined at rates significantly better than chance for texts of 140 characters or less.","Energy Mapping, artificial intelligence, Emotion, Machine Learning, Event Perception, Privacy addressing, Time-To-Live, 6LoWPAN-ND, TTL parameter, Scherer theory, temporal analysis, Bimodal Fusion, spoofing attack, emotion transition, Emotion Recognition, emotion regulation, Feature Level Linear Weighted Fusion, IPv6 address spoofing, Twitter streaming API, EMIA, author-classiﬁed tweets, Event Appraisal, Emotions, emotion modeling, emotion elicitation, IPv6 spoofing, RPL, Authorship Attribution, Twitter client application, experiential learning, Machine Learning Classiﬁer, stylometric analysis, Support Vector Machine Classifier, Online Social Media, Emotion modeling, Intelligent Systems, appraisal process, Attack disruption window, Audio and Video Features, Stylometry Analysis, fuzzy sets, 6LoWPANs, Twitter, Bimodal Energy Based Fusion Model, 6LoWPAN, OCC theory","The paper presents a novel approach to fuse heterogeneous datasets obtained from multiple sensors with the aim of analyzing the human’s emotional behavior. The technique uses energy based mapping to overcome the inherent heterogeneity of the recorded bi-modal signal and recognizes the overall emotional component using Support Vector Machine (SVM) classifier with the accuracy 93.06%. ||| The article proposes a domain-independent computational model of emotion modeling for intelligent agent (EMIA) situated in a virtual environment. It uses the concept of a fuzzy classifier to model more flexible and adaptive emotional behavior of an agent. The model addresses the computation of the type of emotion as well as its level of intensity. It also has an emotion transition module that takes into consideration the elicitation of emotions based on a previous emotional state. ||| The paper presents a formalization of the event perception and appraisal process in an artificial intelligence system, using fuzzy sets to represent the appraisal variables and elicit emotions in response to events. ||| This study aims to reduce the attack disruption time due to spoofing in 6LoWPAN networks by periodically changing the node’s addresses. The attack disruption time can be reduced by incorporating parameters like Attack Disruption Window (ADW) and Time-To-Live (TTL) to the attack tree. The use of temporary node addresses can be a solution for reducing the spoofing attack disruption window. Simulations have been performed to compare the optimum value of address change periodicity concerning the communication cost for two private addressing schemes proposed in the literature. ||| This paper focuses on the problem of identification of the original author for a given tweet from a list of suspected authors for it using stylometric information. Various stylometric features have been taken into consideration for the training and later testing purposes of the machine learning algorithms such as Support Vector Machine (SVM) classiﬁer."
Ku-Young Young,Deep Sparse Representation Classifier for Facial Recognition  and Detection System,"This paper proposes a two-layer Convolutional Neural Network (CNN) to learn the high-level features which utilizes to the face identification via sparse representation. Feature extraction plays a vital role in real-world pattern recognition and classification tasks. The details description of the given input face image, significantly improve the performance of the facial recognition system. Sparse Representation Classifier (SRC) is a popular face classifier that sparsely represents the face image by a subset of training data, which is known as insensitive to the choice of feature space. The proposed method shows the performance improvement of SRC via a precisely selected feature exactor. The experimental results show that the proposed method outperform other methods on given datasets.","Sparse Feature Extraction, Convolutional neural network, Deep learning, CNN, Sparse representation classifier, Face recognition, Support Vector Machines, Feature extraction","This paper presents a robust face recognition framework based on the combination of sparse feature extraction using Convolutional Neural Networks (CNNs) and Support Vector Machines (SVMs). The proposed framework is evaluated on four widely used face datasets, including Extended YALE B database, AR database, MIT faces database, and ORL faces database. The experimental results show that the proposed framework outperforms the state-of-the-art methods in terms of recognition rate."
Kuang-Pen Chou,Deep Sparse Representation Classifier for Facial Recognition  and Detection System,"This paper proposes a two-layer Convolutional Neural Network (CNN) to learn the high-level features which utilizes to the face identification via sparse representation. Feature extraction plays a vital role in real-world pattern recognition and classification tasks. The details description of the given input face image, significantly improve the performance of the facial recognition system. Sparse Representation Classifier (SRC) is a popular face classifier that sparsely represents the face image by a subset of training data, which is known as insensitive to the choice of feature space. The proposed method shows the performance improvement of SRC via a precisely selected feature exactor. The experimental results show that the proposed method outperform other methods on given datasets.","Sparse Feature Extraction, Convolutional neural network, Deep learning, CNN, Sparse representation classifier, Face recognition, Support Vector Machines, Feature extraction","This paper presents a robust face recognition framework based on the combination of sparse feature extraction using Convolutional Neural Networks (CNNs) and Support Vector Machines (SVMs). The proposed framework is evaluated on four widely used face datasets, including Extended YALE B database, AR database, MIT faces database, and ORL faces database. The experimental results show that the proposed framework outperforms the state-of-the-art methods in terms of recognition rate."
Kumar & Sharma,Characterizing relatedness of web and requirements engineering,"Web and Requirements Engineering have been well-recognized as two individual active areas of research in the past. Convergence between these two notable areas has been a point-of-discussion in recent years and offers new avenues of research. This paper explores this alliance from two perspectives; firstly, where Requirement Engineering can be viewed as a process for Web application development as it primarily concerns with adapting the Requirement Engineering process to the Web applications which are special in characteristics as compared to traditional software applications and secondly, where Web can be viewed as a supporting technology for improving the requirements engineering process and enabling new capabilities.","Web Applications, Web 3.0, Web 2.0, SWOT Analysis, Web application, Requirements engineering","The paper explores the relationship between Web and Requirements Engineering from two perspectives, highlighting the need for a more extensive and efficient Requirements Engineering process for Web applications, and the potential of Web technologies to support and improve the requirements engineering process."
Kumar Ravi,Applications of machine learning techniques to predict filariasis using socio-economic factors ||| Visual Sentiment Analysis of Customer Complaints using SOM,"Filariasis is one of the major public health concerns in India. Approximately 600 million people spread across 250 districts of India are at risk of filariasis. To predict this disease, a pilot scale study was carried out in 30 villages of Karimnagar district of Telangana from 2004 to 2007 to collect epidemiological and socio-economic data. The collected data are analysed by employing various machine learning techniques such as Naïve Bayes (NB), logistic model tree, probabilistic neural network, J48 (C4.5), classification and regression tree, JRip and gradient boosting machine. The performances of these algorithms are reported using sensitivity, specificity, accuracy and area under ROC curve (AUC). Among all employed classification methods, NB yielded the best AUC of 64% and was equally statistically significant with the rest of the classifiers. Similarly, the J48 algorithm generated 23 decision rules that help in developing an early warning system to implement better prevention and control efforts in the management of filariasis. ||| With the widespread use of social media, companies now have access to a wealth of customer feedback data which has valuable applications to Customer Relationship Management (CRM). Analyzing customer grievances data, is paramount as their speedy non-redressal would lead to customer churn resulting in lower profitability. In this paper, we propose a descriptive analytics framework using Self-organizing feature map (SOM), for Visual Sentiment Analysis of customer complaints. The network learns the inherent grouping of the complaints automatically which can then be visualized too using various techniques. Analytical Customer Relationship Management (ACRM) executives can draw useful business insights from the maps and take timely remedial action. We also propose a high-performance version of the algorithm CUDASOM (CUDA based Self Organizing feature Map) implemented using NVIDIA parallel computing platform, CUDA, which speeds up the processing of high-dimensional text data and generates fast results. The efficacy of the proposed model has been demonstrated on the customer complaints data regarding the products and services of four leading Indian banks. CUDASOM achieved an average speed up of 44 times. Our approach can expand research into intelligent grievance redressal system to provide rapid solutions to the complaining customers.","Filariasis, mosquito, socio-economic factors, Self-Organizing Map, CUDA, Visual Sentiment Analysis, Socio-economic conditions, Grievance Redressal, Machine learning techniques, Customer Complaints, Predictive classification modelling, Data balancing, Feature subset selection, Self-Organizing Maps, Analytical CRM, SOM","This study aims to predict filariasis using socio-economic factors and machine learning techniques. A pilot scale study was conducted in 30 villages of Karimnagar district of Telangana from 2004 to 2007 to collect epidemiological and socio-economic data. Various machine learning techniques were employed to analyse the data and predict filariasis. The study found that Naïve Bayes yielded the best AUC of 64% and generated 23 decision rules that help in developing an early warning system to implement better prevention and control efforts in the management of filariasis. ||| This paper proposes a descriptive analytics framework using Self-organizing feature map (SOM) for Visual Sentiment Analysis of customer complaints. The framework learns the inherent grouping of complaints automatically and can be visualized using various techniques. A high-performance version of the algorithm CUDASOM is also proposed, which speeds up the processing of high-dimensional text data and generates fast results."
Kunal Sankhe,Prediction of Willingness of Users in V-MIMO,"In cellular systems, virtual multiple-input multiple-output (V-MIMO) technology promises to achieve performance gains comparable to conventional MIMO. In this paper, we propose cooperative relay selection algorithm based on machine learning techniques. Willingness of user to cooperate in V-MIMO depends on his current battery power, time and day along with incentives offered by service provider.","Artificial Neural network, SVM, ANN, Machine Learning, Virtual MIMO, Support Vector Machine, V-MIMO, Virtual Antenna Array","This paper proposes a cooperative relay selection algorithm based on machine learning techniques for virtual MIMO systems. The algorithm predicts potential willing users in the neighborhood of the source user and reduces cooperative node discovery time. The performance of the algorithm is evaluated using metrics such as MSE, accuracy, precision, and recall."
Kutty Selva Nandakumar,ROS deficiency enhanced mannan-induced PsA,"In and joint inflammation using B10Q.Ncf1m1j/m1j mice that have a mutation in the Ncf1 gene (m1j) (the Ncf1 protein also denoted p47phox), and hence reduced ROS production (oxidative burst) (18). As shown in Fig. 1D, Ncf1 mutated mice developed severe joint inflammation within 2 d after mannan injection, which reached the mean maximal disease severity (30 ± 6 points) within 4 d. The frequency of skin lesions was 100%, with more severe cases in B10Q.Ncf1m1j/m1j mice (Fig. 1E), whereas B10.Q mice had a significantly milder disease course. Multiple Exposures to Mannan Induced a Relapsing Disease. Next, we examined the effect of multiple mannan injections in B10Q and B10Q.Ncf1m1j/m1j mice. We boosted mice twice with mannan on days 7 and 14 after disease initiation. Repetitive injections of mannan reproduced the arthritis phenotype, which reached the maximum severity level on days 9 and 17, similar to the first injection (Fig. 1F). A more severe disease course was observed in B10Q.Ncf1m1j/m1j mice than in B10Q mice (P < 0.05 and P < 0.01, respectively). Interestingly, Ps skin scaling returned only after the second mannan injection (on day 16), but the skin peeled off even more quickly than the first time (Fig. 1G). Moreover, from day 11 onward, B10Q.Ncf1m1j/m1j mice started to develop pruritus on the body, predominantly on the back and above the eye (Fig. S1E). Pruritus was only evident in B10Q.Ncf1m1j/m1j mice, but flaky skin on the tail and alopecia all over the leg was observed in both of the mouse strains. We also observed genetic heterogeneity in disease susceptibility (Fig. Fig. 1. ROS deficiency enhanced mannan-induced PsA. The arthritic joint phenotype and Ps-like skin lesions in the front (A) and hind (B) paws of B10Q.Ncf1m1j/m1j mice are shown. (C) Ps-like skin scaling in diseased B10Q.Ncf1m1j/m1j mouse ear compared with naive mouse ear. Mean arthritis (D) and Ps lesion (E) severity in B10Q (n = 5) and B10Q.Ncf1m1j/m1j (n = 5) mice after a single i.p. mannan injection. Mean arthritis (F) and Ps lesion (G) severity in B10Q (n = 5) and B10Q.Ncf1m1j/m1j (n = 5) mice after repetitive mannan injections (days 7 and 14). (H) Mannan-induced mean maximum arthritis scores ± SEM in different mouse strains: B10Q (n = 8), B10Q.Ncf1m1j/m1j (n = 9), B10RIII (n = 10), B10RIII.Ncf1m1j/m1j (n = 9), B10P (n = 3), B10P.Ncf1m1j/m1j (n = 9), BALB/cByJ/Q (n = 10), BALB/cByJ/Q.Ncf1m1j/m1j (n = 8), BALB/cByJ (n = 5), BALB/cByJ.Ncf1m1j/m1j (n = 7), C57BL/6NJ (n = 8), and C57BL/6NJ.Ncf1m1j/m1j (n = 7). Significance was calculated by comparing the maximal disease severity of B10Q and B10Q.Ncf1m1j/m1j mice with all of the other strains in their respective groups. *P < 0.05; **P < 0.01; ***P < 0.001. E3670 | www.pnas.org/cgi/doi/10.1073/pnas.1405798111 Khmaladze et al. Downloaded from https://www.pnas.org by 122.184.65.228 on February 22, 2023 from IP address 122.184.65.228.","autoimmune disease, Ncf1, animal model","This study identifies a new mechanism for psoriasis (Ps) and psoriasis arthritis (PsA) development in mice. A single injection of mannan, a component of baker's yeast, induced Ps and PsA-like symptoms. This effect was exacerbated in mice lacking reactive oxygen species (ROS), but improved when ROS production was restored in macrophages.  Blocking IL-17A, a cytokine produced by gamma delta T cells, completely prevented disease. The study suggests that mannan activates macrophages, leading to TNF-α secretion and stimulation of IL-17A production by gamma delta T cells. This, in turn, drives neutrophil infiltration and inflammation, mimicking Ps and PsA. This new mouse model could be valuable for testing new therapies for Ps and PsA."
L. Lee,Sentiment Analysis of Training Programmes,"Sentiment analysis found various applications in banking, financial, service, and insurance sector. In order to increase return on investment, services industry needs to improve customer satisfaction at any cost.  In this regard, we proposed to analyze customer reviews on the basis of sentiment score. We analyzed a set of credible text reviews collected on 270 training programmes posted by 2688 participants in an organization. In order to evaluate the efficacy of the proposed approach, we computed correlation coefficient between sentiment score obtained from the unstructured reviews and the overall numerical rating assigned by all participants. Further, we employed visualization techniques to visualize different aspects of the programmes.","programme rating, Text Mining, Visualization, Training Programmes, participants' feedback, Customer Reviews, Sentiment analysis","The paper proposes a sentiment analysis approach to analyze customer reviews on the basis of sentiment score. The approach is divided into five sections: data collection, text preprocessing, sentiment score computation, evaluation, and visualization. The paper presents the results of the proposed approach and discusses the future directions of work."
L. Löu,Cost Eﬀective Inﬂuence Maximisation,"In the context of virality prediction, many researchers have leveraged the existence of a core-periphery structure in a network to identify the super-spreaders of information. Topologically, the nodes in the core of a network are the most eﬃcient spreaders. However, these nodes are less susceptible, i.e., unlikely to be inﬂuenced by the periphery nodes. Consequently, large payoﬀs are required to market information (ideas, products, memes, etc.) via them. In this paper, we show the presence of several non-core nodes whose spreading power is close to that of the core nodes.","Virality, Inﬂuence maximisation, Information diﬀusion, cost-effective, Core-periphery structure, information diffusion, social networks, influence maximisation","This paper proposes a cost-eﬀective strategy to make a meme reach the super-spreaders without the need for global information. The proposed hill-climbing based strategy can be eﬀectively used with both, global as well as local characteristics of the nodes in a network. In terms of the cost metric, it outperforms the conventional independent cascade model by more than 5 times for the core and 2 times for the non-core super-spreaders."
L. Ma,Iris Detection,"For iris boundary detection, circular summation of intensity approach is used as proposed in [5]. The original grayscale image is blurred using median filter to remove external noise. After filtering, the contrast of image is enhanced to have sharp variation at image boundaries using histogram equalisation as shown in Figure 5(a). This contrast enhanced image is used for finding the outer iris boundary by drawing concentric circles (Figure 5(b) shows an example) of different radii from the pupil center and the intensities lying over the perimeter of the circle are summed up.","Adaptive Threshold, Circular Hough Transform, Spectrum Image, histogram equalisation, iris recognition, circular summation of intensity, Connected Components, Iris detection, pupil boundary, Iris Segmentation",The proposed system has been tested on two publicly available databases BATH and CASIA V3. From experimental analysis it has been observed that the system is capable of handling unconstrained scenarios as well. The system is capable of performing segmentation for unconstrained scenarios in significantly less time compared to Hough transform.
L. Van Gool,Unique Local Features in Lip Images for Recognition,"The experiments are carried out from images taken with a camera that is used for the regular use. And the color features of a lip are not explored in the proposed research. Still the recognition system exploits the grayscale local features of a lip images and eﬃciently matches it with local features of another lip image. If the color properties of a lip image is explored for recognition along with local features, the accuracy values would increase further.","grayscale features, Lip Pattern Recognition, SIFT, lip recognition, color features, Biometric, Local Feature Extraction, local features, SURF",The paper presents the results of experiments on lip recognition using local features. The recognition system exploits the grayscale local features of lip images and achieves high accuracy. The authors suggest that exploring color properties of lip images could further improve the accuracy.
LIM et al.,Generalizing Surrogate-Assisted Evolutionary Computation,Using surrogate models in evolutionary search provides an efficient means of handling today’s complex applications plagued with increasing high-computational needs. Recent surrogate-assisted evolutionary frameworks have relied on the use of a variety of different modeling approaches to approximate the complex problem landscape.,"optimization, evolutionary search, surrogate-assisted evolutionary algorithms, Approximation models, approximation techniques, surrogate-assisted evolutionary computation, metamodels, surrogate models, multidisciplinary optimization, memetic algorithms, computationally expensive problems",This paper describes a generalization of surrogate-assisted evolutionary frameworks for optimization of problems with objectives and constraints that are computationally expensive to evaluate. The generalized evolutionary framework unifies diverse surrogate models synergistically in the evolutionary search.
Laith Mohammad Abualigah,Hybrid Harmony Search Algorithm to Solve the Feature Selection for Data Mining Applications,"The increasing size of all sorts text and data information on websites makes the method of text clustering (TC) a lot more complicated. The TC technique is employed to cluster an enormous variety of documents into a set of intelligible and connected clusters. Usually, TC is employed in several domains like text mining, data processing, pattern recognition, image clustering.","Hybrid Harmony Search Algorithm, Vector Space Model, Feature Selection, Text Clustering, Data Mining, Data Mining Applications","This paper proposes a hybrid harmony search algorithm to solve the feature selection problem for data mining applications. The algorithm uses the harmony search rule to select and obtain a new set of informative knowledge features, reducing the runtime of the system and decreasing the uninformative knowledge feature. The results show that the proposed modification of the harmony search rule enriched the performance value of the feature choice method in regard to the correct set, owing to its fine features."
Lamb,Fifty years of peephole optimization,"Peephole optimization is a technique used in compilers to improve the performance of object programs by replacing sequences of instructions with equivalent single instructions. This article reviews the history and development of peephole optimization, including its application to various programming languages and target machines.","compilers, object programs, peephole optimization, Code generators, instruction sequences, replacement rules","Peephole optimization has been widely used in compilers to improve the performance of object programs. The technique involves replacing sequences of instructions with equivalent single instructions, and has been applied to various programming languages and target machines. The effectiveness of peephole optimization depends on several factors, including the nature of the source language, the parsing and code generation techniques used in the compiler, and the specifications of the target machine."
"Lee, K.",A Multi-Task Approach to Open Domain Suggestion Mining,"Consumer reviews online may contain suggestions useful for improving the target products and services. Mining suggestions is challenging because the field lacks large labelled and balanced datasets. Furthermore, most prior studies have only focused on mining suggestions in a single domain. In this work, we introduce a novel up-sampling technique to address the problem of class imbalance, and propose a multi-task deep learning approach for mining suggestions from multiple domains.","Deep Learning, Suggestion Mining, Artificial Intelligence, Class Imbalance, Multi-Task Learning","This paper presents a multi-task approach to open domain suggestion mining, addressing the class imbalance problem using a novel up-sampling technique and a multi-task deep learning framework. Experimental results show that the proposed approach outperforms state-of-the-art models in terms of F-1 measure and AUC."
Lennart T Mars,Myelin-speciﬁc T cells also recognize neuronal autoantigen in a transgenic mouse model of multiple sclerosis,"We describe here the paradoxical development of spontaneous experimental autoimmune encephalomyelitis (EAE) in transgenic mice expressing a myelin oligodendrocyte glycoprotein (MOG)-speciﬁc T cell antigen receptor (TCR) in the absence of MOG. We report that in Mog-deﬁcient mice (Mog–/–), the autoimmune response by transgenic T cells is redirected to a neuronal cytoskeletal self antigen, neuroﬁlament-M (NF-M). Although components of radically different protein classes, the cross-reacting major histocompatibility complex I-Ab–restricted epitope sequences of MOG35–55 and NF-M18–30 share essential TCR contact positions. This pattern of cross-reaction is not speciﬁc to the transgenic TCR but is also commonly seen in MOG35–55–I-Ab–reactive T cells. We propose that in the C57BL/6 mouse, MOG and NF-M response components add up to overcome the general resistance of this strain to experimental induction of autoimmunity. Similar cumulative responses against more than one autoantigen may have a role in spontaneously developing human autoimmune diseases.",,"This study reports the unexpected finding that transgenic mice expressing a myelin oligodendrocyte glycoprotein (MOG)-specific T cell receptor (TCR) develop spontaneous experimental autoimmune encephalomyelitis (EAE) even in the absence of MOG. The researchers discovered that these mice redirect their autoimmune response to a neuronal cytoskeletal protein called neuroﬁlament-M (NF-M). This cross-reactivity between MOG and NF-M is mediated by shared TCR contact positions on their respective epitope sequences. The study suggests that cumulative responses against multiple autoantigens, such as MOG and NF-M, may contribute to the development of spontaneous autoimmune diseases in humans."
Lennart T. Mars,Cutting Edge: CD8 T Cell-Mediated Demyelination,"We generated mice (DKI) in which the HA coding sequence was introduced in the ubiquitously active Rosa26 locus but where HA transcription was prevented by an upstream LoxP-flanked Stop cassette. The DKI mice were then crossed with the MOGi-Cre mice, which express Cre specifically in oligodendrocytes. The resulting DKI mice excise the Stop cassette due to MOG-controlled Cre expression, leading to restricted HA expression to oligodendrocytes.  We then decided to test whether effector CD8 T cells can mediate oligodendrocyte cell death and demyelination in vivo. Effector T cells were first generated by in vitro activation of Kd:HA512–520 pentamer-specific CD8 T cells obtained from CL4-TCR mice using HA peptide, IL-2, and IL-12. The resulting Tc1 cells produce large amounts of granzyme B (GrB) and IFN-γ and exhibit potent cytotoxicity to HA-loaded target cells in vivo. Next, we transferred these HA-specific Tc1 cells into DKI and control mice. Following i.v. injection of 3 × 107 HA-specific Tc1 cells, but not naive HA-specific CD8 T cells, ~40% of the DKI mice developed an overt monophasic disease peaking at day 8–10 and waning by 4 wk posttransfer. The clinical manifestations included weight loss and, in the more severe cases, tremors, reduced mobility, and difficulty to right when overturned without overt paralysis. Upon histological analysis, all DKI mice injected with Tc1 cells demonstrated clear CNS pathology from day 5 onwards. Inflammatory lesions were never found in control littermates injected in parallel with HA-specific Tc1 cells.",,"This study investigates the role of CD8 T cells in multiple sclerosis (MS) pathogenesis. Researchers generated a mouse model where a model antigen (influenza hemagglutinin) is expressed specifically in oligodendrocytes, the cells responsible for producing myelin in the central nervous system. Transferring activated CD8 T cells specific for this antigen into these mice resulted in inflammatory lesions in the brain, spinal cord, and optic nerve, resembling active MS lesions. These lesions were characterized by CD8 T cell infiltration, loss of oligodendrocytes, demyelination, and microglia activation. This suggests that CD8 T cells can directly contribute to oligodendrocyte death and demyelination in MS, highlighting their potential as therapeutic targets."
Li Ma et al.,Deep Learning Techniques for Disease Detection in Fruits and Vegetables,"Plant Diseases are one of the leading reasons of economic shortfalls in agricultural and farming sectors worldwide. It is the most essential element since it reduces crop quantity and quality significantly. Fruits are one of the largest essential nutritional resources from plants. Unfortunately, a variety of conditions might impair both the content and outcome of fruits. As a result, an autonomous Computer Vision (CV) -based approach for reliable Fruit Disease Detection (FDD) is necessary.","Attention mechanisms, Transfer learning, Convolutional neural networks, Computer Vision, Machine Learning, Disease detection, Deep Learning, Fruits and vegetables, Fruit Disease Detection","This paper presents a detailed review of different ML and DL algorithms developed to predict and classify FDs from different fruit images. First, different FDD and classification systems designed by many researchers based on ML and DL algorithms are studied in brief. Then, a detailed analysis is carried out in order to identify the shortcomings of existing algorithms and to provide a novel strategy for properly classifying fruit pathogens."
"Li et al., 2014",Supervised Heterogeneous Domain Adaptation via Random Forests,This paper proposes a novel approach to heterogeneous domain adaptation using random forests. The algorithm leverages the common label information between the source and target domains as the pivot for knowledge transfer. The proposed algorithm determines the mapping PS between source and target features based on the estimate of the contribution of the features towards creating data partitions having similar label distributions.,"Label Information, Supervised Heterogeneous Domain Adaptation, Feature Mapping, Heterogeneous Domain Adaptation, Random Forests, Knowledge Transfer, Feature Transfer, Domain Adaptation",The paper proposes a novel supervised domain adaptation algorithm (SHDA-RF) that learns the mapping between heterogeneous features of different dimensions. The algorithm uses the shared label distributions present across the domains as pivots for learning a sparse feature transformation. The shared label distributions and the relationship between the feature spaces and the label distributions are estimated in a supervised manner using random forests.
Liang Feng,Consistencies and Contradictions of Performance Metrics in Multiobjective Optimization,"An important consideration of Multiobjective Optimization (MOO) is the quantitative metrics used for defining the optimality of different solution sets, which is also the basic principle for the design and evaluation of MOO algorithms.","Diversity, Capacity, Multiobjective Optimization, Hypervolume, Performance Metrics, Convergence","This paper investigates the relationships among representative group metrics in Multiobjective Optimization, including Generational Distance (GD), ϵ-indicator (I1ϵ+), Spread (∆), Generalized Spread (∆∗), Inverted Generational Distance (IGD) and Hypervolume (HV). Experimental results indicated that these six metrics show high consistencies when Pareto fronts (PFs) are convex, whereas they show certain contradictions on concave PFs."
Liang Guo,h-value touch points between IoT mobile Apps and their users,"Business models help firms to set a right path to create, grow and retain their business value. While previous research shows that business model affects the performance of entrepreneurial firms, there is still limited understanding about how likely different business model selections of Internet of Things (IoT) startup firms retain their value and whether the venture capital investment intensity does play any role in the business model’s value retention process.","Instrumental variable regression, Business model, Value retention, Mobile application, venture capital, mobile Apps, China, Internet of things, IoT","This study investigates the impact of e-business models on value retention for start-ups in the Internet of Things (IoT) and Mobile Applications (Apps) business. The study finds that e-efficiency-centred and complementarities-centred e-business models increase value retention, while lock-in centred e-business model reduces value retention. The study also finds that venture capitalist’s involvement moderates the relationship between e-business models and value retention."
"Lichman, M. (2015)",Quantum-inspired evolutionary approach for selection of optimal parameters of fuzzy clustering,"Recently, Fuzzy c-Means (FCM) algorithm is most widely used because of its efficiency and simplicity. However, FCM is sensitive to the initialization of fuzziness factor (m) and the number of clusters (c) due to which it easily trapped in local optima. A selection of these parameters is a critical issue because an adverse selection can blur the clusters in the data.","Fuzzy clustering, Cluster validity index, Quantum-Inspired Evolutionary Fuzzy c-Means, Fuzzy c-Means algorithm, Fuzzy c-Means, Quantum computing","This paper proposes a hybrid fuzzy clustering algorithm, Quantum-Inspired Evolutionary Fuzzy c-Means (QIE–FCM), which uses the merits of quantum computing for finding the global optimal value of m and its corresponding value of c in the FCM. The proposed approach improves the way of initialization of the fuzziness factor (m) in the FCM and provides the diversity in selecting the optimal value of m and c from a large quantum search space."
Liguo Yuan,Chaos in fractional-order discrete neural networks with application to image encryption,"In this paper, a three-dimensional fractional-order (FO) discrete Hopfield neural network (FODHNN) in the left Caputo discrete delta’s sense is proposed, the dynamic behavior and synchronization of FODHNN are studied, and the system is applied to image encryption. First, FODHNN is shown to exhibit rich nonlinear dynamics behaviors. Phase portraits, bifurcation diagrams and Lyapunov exponents are carried out to verify chaotic dynamics in this system. Moreover, by using stability theorem of FO discrete linear systems, a suitable control scheme is designed to achieve synchronization of the FODHNN. Finally, image encryption system based on the chaotic FODHNN is presented. Some security analysis and tests are given to show the effective of the encryption system.","Fractional-order discrete Hopfield neural networks, Lyapunov exponent, Chaotic dynamics, Fractional-order discrete systems, Synchronization, Image encryption, Jacobian matrix algorithm, Neural networks","This paper presents a chaotic dynamics analysis of fractional-order discrete Hopfield neural networks (FODHNNs). The FODHNNs are derived from a 3D-neuron fractional-order continuous Hopfield-type neural networks proposed in Zhang, Qi, and Wang (2010). The dynamic behavior, synchronization, and image encryption application of FODHNNs are explored. Numerical solutions of FODHNNs are needed to be presented. The maximum Lyapunov exponent (LE) of the dynamical system is an important index that characterizes the rate of separation of infinitesimally close trajectories. The Jacobian matrix algorithm for Lyapunov exponents of the discrete fractional maps proposed in Wu and Baleanu (2015b) is employed to calculate the LE of FODHNNs."
Liming Zhang,History Matching of Naturally Fractured Reservoirs Using a Deep Sparse Autoencoder ||| Reservoir Characterization and Productivity Forecast Based on Knowledge Interaction Neural Network,"This work proposes a new characterization method and a method to reduce dimensionality for history matching of naturally fractured reservoirs. The forward simulator is modeled after the EDFM given its computational efficiency. The fracture network can be represented with length, orientation, and position, including large-scale fractures and small-scale fractures. ||| The reservoir characterization aims to provide the analysis and quantification of the injection-production relationship, which is the fundamental work for production management. The connectivity between injectors and producers is dominated by geological properties, especially permeability. However, the permeability parameters are very heterogenous in oil reservoirs, and expensive to collect by well logging. The commercial simulators enable to get accurate simulation but require sufficient geological properties and consume excessive computation resources.","History matching, characterization method, EDFM, knowledge interaction neural network, Naturally fractured reservoirs, Deep sparse autoencoder, machine learning, productivity prediction, reservoir characterization, Productivity Forecast, Physical Knowledge, dimensionality reduction, fracture network, embedded model","This paper proposes a new characterization method for the multiscale fracture network, and a powerful dimensionality-reduction method by means of an autoencoder for model parameters. The characterization method of the fracture network is dependent on the length, orientation, and position of fractures, including large-scale and small-scale fractures. ||| The goal of this study is to improve the accuracy and stableness of the inter-well connectivity characterization and enhance the prediction precision on well productivity, by combining the physical knowledge with machine learning techniques. An innovative neural network is proposed to handle the reservoir characterization and productivity forecast problems, in which the material balance equation is embedded via three high transparent modules, thereby ensuring the physical sense of model parameters."
Lin et al.,A New Keypoints Selection Technique for Histopathological Image Classification,"An efﬁcient classiﬁcation method to categorize histopathological images is a challenging research problem. In this paper, an improved bag-of-features approach is presented as an efﬁcient image classiﬁcation method.","Bag-of-features, Grey relational analysis, histopathological image classification, Histopathological image analysis, Keypoint selection, keypoints selection","The proposed method reduces the extracted high dimensional features by 95% and 68% from the ADL and Blue histology datasets respectively with less computational time. Moreover, the enhanced bag-of-features method increases classiﬁcation accuracy by from other considered classiﬁcation methods."
Liping Chen,Chaos in fractional-order discrete neural networks with application to image encryption,"In this paper, a three-dimensional fractional-order (FO) discrete Hopfield neural network (FODHNN) in the left Caputo discrete delta’s sense is proposed, the dynamic behavior and synchronization of FODHNN are studied, and the system is applied to image encryption. First, FODHNN is shown to exhibit rich nonlinear dynamics behaviors. Phase portraits, bifurcation diagrams and Lyapunov exponents are carried out to verify chaotic dynamics in this system. Moreover, by using stability theorem of FO discrete linear systems, a suitable control scheme is designed to achieve synchronization of the FODHNN. Finally, image encryption system based on the chaotic FODHNN is presented. Some security analysis and tests are given to show the effective of the encryption system.","Fractional-order discrete Hopfield neural networks, Lyapunov exponent, Chaotic dynamics, Fractional-order discrete systems, Synchronization, Image encryption, Jacobian matrix algorithm, Neural networks","This paper presents a chaotic dynamics analysis of fractional-order discrete Hopfield neural networks (FODHNNs). The FODHNNs are derived from a 3D-neuron fractional-order continuous Hopfield-type neural networks proposed in Zhang, Qi, and Wang (2010). The dynamic behavior, synchronization, and image encryption application of FODHNNs are explored. Numerical solutions of FODHNNs are needed to be presented. The maximum Lyapunov exponent (LE) of the dynamical system is an important index that characterizes the rate of separation of infinitesimally close trajectories. The Jacobian matrix algorithm for Lyapunov exponents of the discrete fractional maps proposed in Wu and Baleanu (2015b) is employed to calculate the LE of FODHNNs."
Lisheng Yin,Chaos in fractional-order discrete neural networks with application to image encryption,"In this paper, a three-dimensional fractional-order (FO) discrete Hopfield neural network (FODHNN) in the left Caputo discrete delta’s sense is proposed, the dynamic behavior and synchronization of FODHNN are studied, and the system is applied to image encryption. First, FODHNN is shown to exhibit rich nonlinear dynamics behaviors. Phase portraits, bifurcation diagrams and Lyapunov exponents are carried out to verify chaotic dynamics in this system. Moreover, by using stability theorem of FO discrete linear systems, a suitable control scheme is designed to achieve synchronization of the FODHNN. Finally, image encryption system based on the chaotic FODHNN is presented. Some security analysis and tests are given to show the effective of the encryption system.","Fractional-order discrete Hopfield neural networks, Lyapunov exponent, Chaotic dynamics, Fractional-order discrete systems, Synchronization, Image encryption, Jacobian matrix algorithm, Neural networks","This paper presents a chaotic dynamics analysis of fractional-order discrete Hopfield neural networks (FODHNNs). The FODHNNs are derived from a 3D-neuron fractional-order continuous Hopfield-type neural networks proposed in Zhang, Qi, and Wang (2010). The dynamic behavior, synchronization, and image encryption application of FODHNNs are explored. Numerical solutions of FODHNNs are needed to be presented. The maximum Lyapunov exponent (LE) of the dynamical system is an important index that characterizes the rate of separation of infinitesimally close trajectories. The Jacobian matrix algorithm for Lyapunov exponents of the discrete fractional maps proposed in Wu and Baleanu (2015b) is employed to calculate the LE of FODHNNs."
Lohmann et al.,Typeface size and weight and word location inüluence on relative size judgments in tag clouds,"This paper focuses on viewers’ perception of the relative size of words presented in tag clouds. Tag clouds are a type of visualization that displays the contents of a document as a cluster (cloud) of key words (tags) with frequency (importance) indicated by tag word features such as size or color, with variation of size within a tag cloud being the most common indicator of tag importance. Prior studies have shown that word size is the most inüluential factor of tag importance and tag memory. Systematic biases in relative size perception in tag clouds are therefore likely to have important implications for viewer understanding of tag cloud visualizations.","layout, typeface size, size judgment, perception, psychophysics, perceptual biases, tag cloud, search tasks, tag clouds","The study focuses on documenting systematic biases in relative size judgment in tag clouds while varying typeface weight and the location of the target tag word pair under comparison. The results provide a first report of systematic biases in relative size judgment in tag clouds, suggest that simple power-law scaling models developed for simple displays containing 1-2 objects on a blank background, may be applicable to relative size judgments in complex tag clouds."
Luiz Sergio Guedes Barbosa,BELIMUMAB IN PATIENTS OF BLACK AFRICAN ANCESTRY,"Study design. SELENA–SLEDAI = Safety of Estrogens in Lupus Erythematosus National Assessment–Systemic Lupus Erythemato-sus Disease Activity Index; IV = intravenous.

Randomization and treatment. Using an interactive voice/web response system, patients receiving standard therapy were randomized 2:1 to receive either belimumab 10 mg/kg IV or placebo, which was administered on days 0, 14, and 28 and every 28 days thereafter up to week 48, with a final evaluation at week 52. Randomization was stratified by screening SELENA–SLEDAI score (≤9 versus ≥10), region (US/Canada versus rest of world), and complement level (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]). Detailed randomization data are provided in Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Patients who successfully completed the initial 52-week double-blind phase could enter an optional 6-month open-label extension phase, during which they received belimumab 10 mg/kg IV every 28 days plus standard therapy, irrespective of their previous study assignment. The first dose was given at the week 52 (day 364) visit of the double-blind period (day 1 of the open-label extension phase). Patients who completed the 52-week double-blind phase, but did not enter the 6-month open-label extension phase, were required to return for an additional follow-up visit 8 weeks after their last dose. Patients who withdrew early were required to return for an exit visit 4 weeks after their last dose and a follow-up visit 8 weeks after their last dose.

The original protocol plan was to randomize 816 patients, providing ≥90% power to detect ≥12% absolute improvement in the SRI response rate in the belimumab group compared with the placebo group at a 5% significance level. Due to enrollment challenges, a revised sample size was calculated to include 501 patients (≥334 patients in the belimumab group and ≥167 patients in the placebo group). This sample size provided ≥90% power to detect a minimum 15.55% absolute improvement in SRI–SLEDAI-2K response rate in the belimumab group relative to the placebo group at a 5% significance level (based on the pooled data from efficacy studies BEL112341 and BEL113750) (15,21). These calculations assumed a placebo response rate of 43.95% at week 52.

Study end points and assessments. The primary efficacy end point was the SRI–SLEDAI-2K response rate (defined in the Supplementary Material) at week 52 of the double-blind phase. Unlike in the phase II and phase III studies, the SRI–SLEDAI-2K was selected because of the simplification it offers in proteinuria assessment as compared with the SELENA–SLEDAI proteinuria component; both are clinically meaningful (22). The primary efficacy end point for the open-label extension phase was SRI–SLEDAI-2K response rate at open-label extension week 24. If the open-label extension week 24 data were missing, data from the open-label extension week 28/exit visit were used. This time point is referred to as “open-label extension week 24” throughout the text. Data related to the primary efficacy end point, e.g., the response rate over time, percentage of patients with a durable SRI–SLEDAI-2K response from week 44 through week 52, time to first SRI–SLEDAI-2K response that was maintained through week 52, and duration of longest SRI–SLEDAI-2K response among patients with ≥1 SRI–SLEDAI-2K responses were summarized.

The key secondary end points were SRI–SELENA–SLEDAI at week 52 (open-label extension week 24), time to first severe SLE flare (measured by the SELENA–SLEDAI flare index [SFI]), and proportion of patients whose average prednisone dose had been reduced by ≥25% from baseline to ≤7.5 mg/day during week 40 through week 52 (open-label extension week 28/exit visit), in patients receiving >7.5 mg/day at baseline. Key renal end points included time to first renal flare over 52 weeks and over 28 weeks in the open-label extension, SELENA–SLEDAI–SLEDAI-2K renal domain improvement at week 52, SELENA–SLEDAI–SLEDAI-2K renal domain worsening at week 52, percentage reduction in proteinuria by visit and at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours, and proteinuria shift at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours. Renal flare is defined in the Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Biomarkers measured included percentage changes in serum IgG level, anti-dsDNA antibody level (in those who were anti-dsDNA positive [≥30 IU/ml] at baseline), and complement (C3 and C4) levels from baseline. Safety was evaluated by monitoring adverse events (AEs), serious AEs (SAEs), AEs of special interest, vital signs, clinical laboratory test results, and immunogenicity up to 8 weeks posttreatment and throughout the open-label extension phase.

Data analyses. For the double-blind phase, safety analyses were performed on the safety population, defined as all patients who were randomized and treated with at least 1 dose of investigational product. Data on the safety population were summarized according to the treatment the patient was randomized to receive rather than by the treatment that was received, but both were the same for this study. Efficacy analyses were performed on the modified intent-to-treat (ITT) population, defined as the safety population minus those patients who had any assessment at any of 3 study sites that were excluded from the efficacy analyses before the database lock because of potential Good Clinical Practice noncompliance.

For analysis of the primary and 3 key secondary efficacy end points, a step-down sequential testing procedure was used as described in the Supplementary Material. The following subgroup analyses were performed for the primary analysis (SRI–SLEDAI-2K response at week 52): region (US/Canada versus rest of world), baseline SELENA–SLEDAI–SLEDAI-2K score (≤9 versus ≥10), baseline anti-dsDNA antibody level (≥30 IU/ml versus <30 IU/ml), baseline complement levels (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]), and baseline complement and anti-dsDNA antibody levels (≥1 test finding showing low C3/C4 and anti-dsDNA ≥30 IU/ml versus C3/C4 other and anti-dsDNA ≥30 IU/ml). The odds of an SRI–SLEDAI-2K response with belimumab treatment versus placebo were estimated using logistic regression analysis.

For the open-label extension phase, all patients received belimumab, no formal statistical hypothesis t",,"This study investigated the efficacy and safety of belimumab in patients of Black African ancestry with systemic lupus erythematosus (SLE).  Patients were randomized to receive belimumab or placebo for 52 weeks, followed by an optional 6-month open-label extension phase. The primary efficacy endpoint was the SRI–SLEDAI-2K response rate at week 52.  Key secondary endpoints included SRI–SELENA–SLEDAI at week 52, time to first severe SLE flare, and proportion of patients with a reduction in prednisone dose. Renal and biomarker assessments were also conducted.  The study found that belimumab was effective in improving SLE disease activity and reducing renal flares in patients of Black African ancestry."
López et al.,Ontology Driven Software Development for Automated Documentation,"Recent outsourcing /off-shoring software development practices testify that any development done without a proper sharing mechanism leads to the generation of inconsistent information, which further results in an undesired, error-prone software. Further, with the business process automation, a significant way to minimize human effort involves various development, support and maintenance activities to reuse available information. Thus, reusing and sharing information in a standardized way is the key operative challenges which foster the need to identify and exploit novel knowledge-based frameworks. The proposed research provides a tool-based solution to automate the software documentation process using ontologies. This multi-phase framework has overall six phases where each phase output contributes to the final automated documentation. To evaluate the extent of automated documentation it is compared using free and open source software known as WCopyfind to the existing manual documentation for a Result Management System case study. Preliminary results show a highest automation of 60 percent, which is clearly noteworthy.","Ontology driven, Ontology, software architecture documentation, Software’s documentation, Automatic documentation, technical documentation, ontology driven software development, Semantic Web, automated documentation, Software engineering","The paper presents a framework for ontology driven software development for automated documentation, which is divided into six phases. The framework is designed to capture key concepts of the domain under consideration and generate documentation in both human and machine-understandable forms. The paper also discusses the related work in the field of ontology driven software development and automated documentation."
M D Silverc,Evaluation of the microangiographic fluoroscope (MAF) using generalized system performance metrics,"Cone beam computed tomography (CBCT) systems with rotational gantries that have standard flat panel detectors (FPD) are widely used for the 3D rendering of vascular structures using Feldkamp cone beam reconstruction algorithms. One of the inherent limitations of these systems is limited resolution (<3 lp/mm). There are systems available with higher resolution but their small FOV limits them to small animal imaging only. In this work, we report on region-of-interest (ROI) CBCT with a high resolution CMOS detector (75 μm pixels, 600 μm HR-CsI) mounted with motorized detector changer on a commercial FPD-based C-arm angiography gantry (194 μm pixels, 600 μm HL-CsI). A cylindrical CT phantom and neuro stents were imaged with both detectors. For each detector a total of 209 images were acquired in a rotational protocol. The technique parameters chosen for the FPD by the imaging system were used for the CMOS detector. The anti-scatter grid was removed and the incident scatter was kept the same for both detectors with identical collimator settings. The FPD images were reconstructed for the 10 cm x10 cm FOV and the CMOS images were reconstructed for a 3.84 cm × 3.84 cm FOV. Although the reconstructed images from the CMOS detector demonstrated comparable contrast to the FPD images, the reconstructed 3D images of the neuro stent clearly showed that the CMOS detector improved delineation of smaller objects such as the stent struts (~70 μm) compared to the FPD. Further development and the potential for substantial clinical impact are suggested.",,"This study demonstrates the use of a high-resolution CMOS detector in region-of-interest cone beam computed tomography (ROI CBCT) for improved visualization of small vascular structures. Compared to a standard flat panel detector, the CMOS detector achieved comparable contrast but significantly enhanced spatial resolution, enabling clearer delineation of stent struts. This advancement holds promise for clinical applications requiring high-resolution imaging of vascular anatomy."
M. A. Plazas,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
M. Baczyński,QL-implications: Some properties and intersections,"In this paper, we attempt a systematic study of QL-implications. Towards this end, firstly, we investigate the conditions under which a QL-operation becomes a fuzzy implication without imposing any conditions on the underlying operations. Following this, we discuss the conditions under which this family satisfies some desirable algebraic properties. Based on the obtained results and existing characterization results, the intersections between QL-implications and the two most established families of fuzzy implications, viz., (S,N)- and R-implications are determined.","S-implication, fuzzy logic, R-implication, (S,N)-implication, t-norms, fuzzy sets, Fuzzy implication, QL-implication, t-conorms","This paper studies the family of QL-implications in fuzzy logic, without any restrictions on the underlying operations. Necessary and/or sufficient conditions on the underlying operations under which QL-implications satisfy some of the most desirable algebraic properties are proposed. A partial characterization of the intersections that exist between the family of QL-implications and the families of (S,N)- and R-implications is given."
M. Bozkurt,Diabetes Classiﬁcation using Radial Basis Function Network by Combining Cluster Validity Index and BAT Optimization with Novel Fitness Function,This paper discusses the use of cluster validity indices for diabetes diagnosis. The authors present a literature survey related to the problem and propose a methodology for identifying the optimal number of clusters. The experimental outcomes confirm the performance of the proposed methodology. The paper also reviews the performance of various neural network-based classifiers on the Pima Indians data set.,"diabetes diagnosis, Optimal number of clusters, Medical Diagnosis, Classiﬁcation, methodology, Diabetes, literature survey, Bat Algorithm, Radial Basis Function Networks, cluster validity indices, neural network-based classifiers","This paper presents a new model based on cluster validity index with radial basis neural network for classiﬁcation of diabetic patients data. The proposed model is tested on Pima Indians Diabetes data set and synthetic data sets, and experimental results proved that our approach performs better in terms of accuracy, sensitivity, speciﬁcity, classiﬁcation time, training time, network complexity and computational time compared to conventional radial basis function neural network."
M. C. Rodriguez-Sanchez,A Peer-Assessment Based Approach for Teaching Microprogramming,"The course on microprocessors introduces undergraduate computer science students to hardware-level programming. The course was taught by the authors to 130 students in context of the 8085 and 8086 microprocessors in the Spring semester of 2019. The students executed their programs on hardware kits, and participated in a double-blind peer-assessment exercise in which they assessed and rated programs written by their peers and also advised them on improving the efficiency and readability of their programs.","Computer science education, microprocessor, undergraduate students, computer science, microprocessors, microprogramming, peer-assessment, performance","This paper presents a study on the utility of peer-assessment in teaching microprogramming to undergraduate computer science students attending a course on microprocessors. The study found that the peer-assessment exercise helped the students to perform better in examination, with a 6.97% increase in marks in the post-intervention test compared to the pre-intervention test."
M. Cardei,High-Energy-First (HEF) Heuristic for Energy-Efficient Target Coverage Problem,"Target coverage problem in wireless sensor networks is concerned with maximizing the lifetime of the network while continuously monitoring a set of targets. A sensor covers targets which are within the sensing range. For a set of sensors and a set of targets, the sensor-target coverage relationship is assumed to be known. A sensor cover is a set of sensors that covers all the targets. The target coverage problem is to determine a set of sensor covers with maximum aggregated lifetime while constraining the life of each sensor by its initial battery life. The problem is proved to be NP-complete and heuristic algorithms to solve this problem are proposed. In the present study, we give a unified interpretation of earlier algorithms and propose a new and efficient algorithm. We show that all known algorithms are based on a common reasoning though they seem to be derived from different algorithmic paradigms.  We also show that though some algorithms guarantee bound on the quality of the solution, this bound is not meaningful and not practical too.  Our interpretation provides a better insight to the solution techniques. We propose a new greedy heuristic which prioritizes sensors on residual battery life. We show empirically that the proposed algorithm outperforms all other heuristics in terms of quality of solution. Our experimental study over a large set of randomly generated problem instances also reveals that a very naïve greedy approach yields solutions which is reasonably (appx. 10%) close to the actual optimal solutions.","Network Lifetime, QoS constraints, connected coverage, sensing ranges, Target Coverage Problem, Greedy Heuristic, Wireless Sensor Networks, Energy-Efficiency, target coverage",The paper proposes a new heuristic algorithm for the energy-efficient target coverage problem in wireless sensor networks. The algorithm prioritizes sensors based on their residual battery life and is shown to outperform other heuristics in terms of quality of solution. The paper also provides a unified interpretation of earlier algorithms and shows that they are based on a common reasoning. The experimental study reveals that a naïve greedy approach yields solutions close to the actual optimal solutions.
M. Cardei et. al,Energy-Efficient Routing Algorithm for Wireless Sensor Networks,"Wireless Sensor Network (WSN) is a collection of sensor nodes. A sensor node covers all information which is present in its sensing range. To access the information present in some other sensor range, the networks use a process called Routing. Routing problem in wireless sensor network (WSN) concerned with maximizing the sensor network lifetime while continuously routing the collected data (information) to the base station (central server).","Network Lifetime, Energy –Efficiency, Energy-Efficient Routing, Sensor Networks, Routes, Wireless Sensor Networks, Wireless Sensor Networks (WSN), Energy Consumption, Routing problem, Routing Algorithm",The paper presents a new energy-efficient routing algorithm for wireless sensor networks. The algorithm prioritizes sensors according to their remaining battery life and selects the shortest path to maximize the total network lifetime.
M. Carr,Machine Learning Techniques Applied to Profile Mobile Banking Users in India,"This paper profiles mobile banking users using machine learning techniques viz. Decision Tree, Logistic Regression, Multilayer Perceptron, and SVM to test a research model with fourteen independent variables and a dependent variable (adoption). A survey was conducted and the results were analysed using these techniques. Using Decision Trees the profile of the mobile banking adopter’s profile was identified. Comparing different machine learning techniques it was found that Decision Trees outperformed the Logistic Regression and Multilayer Perceptron and SVM. Out of all the techniques, Decision Tree is recommended for profiling studies because apart from obtaining high accurate results, it also yields ‘if–then’ classification rules. The classification rules provided here can be used to target potential customers to adopt mobile banking by offering them appropriate incentives.","Machine Learning, Logistic Regression, Multilayer Perceptron, Mobile Banking User Profiles, Decision Tree","This paper studies the various factors that affect the intention of users to adopt mobile banking. The major influential factors have been identified through literature, and a survey was conducted with two hundred respondents in the Indian context. The paper analyses the survey data through the use of machine learning techniques to arrive at the most important and critical success factors that influences the adoption of mobile."
M. Cha,Cost Eﬀective Inﬂuence Maximisation,"In the context of virality prediction, many researchers have leveraged the existence of a core-periphery structure in a network to identify the super-spreaders of information. Topologically, the nodes in the core of a network are the most eﬃcient spreaders. However, these nodes are less susceptible, i.e., unlikely to be inﬂuenced by the periphery nodes. Consequently, large payoﬀs are required to market information (ideas, products, memes, etc.) via them. In this paper, we show the presence of several non-core nodes whose spreading power is close to that of the core nodes.","Virality, Inﬂuence maximisation, Information diﬀusion, cost-effective, Core-periphery structure, information diffusion, social networks, influence maximisation","This paper proposes a cost-eﬀective strategy to make a meme reach the super-spreaders without the need for global information. The proposed hill-climbing based strategy can be eﬀectively used with both, global as well as local characteristics of the nodes in a network. In terms of the cost metric, it outperforms the conventional independent cascade model by more than 5 times for the core and 2 times for the non-core super-spreaders."
M. Choras,Unique Local Features in Lip Images for Recognition,"The experiments are carried out from images taken with a camera that is used for the regular use. And the color features of a lip are not explored in the proposed research. Still the recognition system exploits the grayscale local features of a lip images and eﬃciently matches it with local features of another lip image. If the color properties of a lip image is explored for recognition along with local features, the accuracy values would increase further.","grayscale features, Lip Pattern Recognition, SIFT, lip recognition, color features, Biometric, Local Feature Extraction, local features, SURF",The paper presents the results of experiments on lip recognition using local features. The recognition system exploits the grayscale local features of lip images and achieves high accuracy. The authors suggest that exploring color properties of lip images could further improve the accuracy.
M. Fiuzy,Diabetes Classiﬁcation using Radial Basis Function Network by Combining Cluster Validity Index and BAT Optimization with Novel Fitness Function,This paper discusses the use of cluster validity indices for diabetes diagnosis. The authors present a literature survey related to the problem and propose a methodology for identifying the optimal number of clusters. The experimental outcomes confirm the performance of the proposed methodology. The paper also reviews the performance of various neural network-based classifiers on the Pima Indians data set.,"diabetes diagnosis, Optimal number of clusters, Medical Diagnosis, Classiﬁcation, methodology, Diabetes, literature survey, Bat Algorithm, Radial Basis Function Networks, cluster validity indices, neural network-based classifiers","This paper presents a new model based on cluster validity index with radial basis neural network for classiﬁcation of diabetic patients data. The proposed model is tested on Pima Indians Diabetes data set and synthetic data sets, and experimental results proved that our approach performs better in terms of accuracy, sensitivity, speciﬁcity, classiﬁcation time, training time, network complexity and computational time compared to conventional radial basis function neural network."
M. G. Everett,Cost Eﬀective Inﬂuence Maximisation,"In the context of virality prediction, many researchers have leveraged the existence of a core-periphery structure in a network to identify the super-spreaders of information. Topologically, the nodes in the core of a network are the most eﬃcient spreaders. However, these nodes are less susceptible, i.e., unlikely to be inﬂuenced by the periphery nodes. Consequently, large payoﬀs are required to market information (ideas, products, memes, etc.) via them. In this paper, we show the presence of several non-core nodes whose spreading power is close to that of the core nodes.","Virality, Inﬂuence maximisation, Information diﬀusion, cost-effective, Core-periphery structure, information diffusion, social networks, influence maximisation","This paper proposes a cost-eﬀective strategy to make a meme reach the super-spreaders without the need for global information. The proposed hill-climbing based strategy can be eﬀectively used with both, global as well as local characteristics of the nodes in a network. In terms of the cost metric, it outperforms the conventional independent cascade model by more than 5 times for the core and 2 times for the non-core super-spreaders."
M. J. PIRAN,A Novel Routing Algorithm for Vehicular Sensor Networks,"Recent advances in wireless communications are diffusing into many new applications. The tiny sensor node, which consists of sensing, data processing and communicating components, led to the idea of sensor networks. A sensor network composed of a large number of sensor nodes that are densely deployed either inside the phenomenon or very close to it. The applications envisioned for sensor networks vary from monitoring inhospitable habitats and disaster areas to operating indoors for intrusion detection and equipment monitoring. In most cases the network designer would have little control over the exact deployment of the network. Nowadays Vehicular Networks are drawing lots of attention due to the wide variety of applications that they can provide. These applications include traffic monitoring, positioning, security etc. A lot of research work is being conducted to define the standard for vehicular communication. These include frequency allocation, standards for physical and link layers, routing algorithms, security issues and new applications. In this paper we discuss the disadvantages of the traffic monitoring by traditional methods and by using GPS equipped sensors. Then we propose a new routing protocol for a fixed topology containing both stationary and mobile nodes. We also try to optimize the energy of the sensor nodes. We simulate our routing algorithm in MATLAB and evaluate it for different possible cases.","Network Lifetime, Vehicular Sensor Networks, fixed topology, Routing, routing algorithm, energy efficiency, Wireless Sensor Networks, VANETS, Global Positioning System (GPS)","This paper discusses the disadvantages of traditional traffic monitoring methods and GPS equipped sensors. It proposes a new routing protocol for a fixed topology containing both stationary and mobile nodes, and optimizes the energy of sensor nodes. The routing algorithm is simulated in MATLAB and evaluated for different possible cases."
M. Khashei,Diabetes Classiﬁcation using Radial Basis Function Network by Combining Cluster Validity Index and BAT Optimization with Novel Fitness Function,This paper discusses the use of cluster validity indices for diabetes diagnosis. The authors present a literature survey related to the problem and propose a methodology for identifying the optimal number of clusters. The experimental outcomes confirm the performance of the proposed methodology. The paper also reviews the performance of various neural network-based classifiers on the Pima Indians data set.,"diabetes diagnosis, Optimal number of clusters, Medical Diagnosis, Classiﬁcation, methodology, Diabetes, literature survey, Bat Algorithm, Radial Basis Function Networks, cluster validity indices, neural network-based classifiers","This paper presents a new model based on cluster validity index with radial basis neural network for classiﬁcation of diabetic patients data. The proposed model is tested on Pima Indians Diabetes data set and synthetic data sets, and experimental results proved that our approach performs better in terms of accuracy, sensitivity, speciﬁcity, classiﬁcation time, training time, network complexity and computational time compared to conventional radial basis function neural network."
M. Koklu,Diabetes Classiﬁcation using Radial Basis Function Network by Combining Cluster Validity Index and BAT Optimization with Novel Fitness Function,This paper discusses the use of cluster validity indices for diabetes diagnosis. The authors present a literature survey related to the problem and propose a methodology for identifying the optimal number of clusters. The experimental outcomes confirm the performance of the proposed methodology. The paper also reviews the performance of various neural network-based classifiers on the Pima Indians data set.,"diabetes diagnosis, Optimal number of clusters, Medical Diagnosis, Classiﬁcation, methodology, Diabetes, literature survey, Bat Algorithm, Radial Basis Function Networks, cluster validity indices, neural network-based classifiers","This paper presents a new model based on cluster validity index with radial basis neural network for classiﬁcation of diabetic patients data. The proposed model is tested on Pima Indians Diabetes data set and synthetic data sets, and experimental results proved that our approach performs better in terms of accuracy, sensitivity, speciﬁcity, classiﬁcation time, training time, network complexity and computational time compared to conventional radial basis function neural network."
M. Lievin,Unique Local Features in Lip Images for Recognition,"The experiments are carried out from images taken with a camera that is used for the regular use. And the color features of a lip are not explored in the proposed research. Still the recognition system exploits the grayscale local features of a lip images and eﬃciently matches it with local features of another lip image. If the color properties of a lip image is explored for recognition along with local features, the accuracy values would increase further.","grayscale features, Lip Pattern Recognition, SIFT, lip recognition, color features, Biometric, Local Feature Extraction, local features, SURF",The paper presents the results of experiments on lip recognition using local features. The recognition system exploits the grayscale local features of lip images and achieves high accuracy. The authors suggest that exploring color properties of lip images could further improve the accuracy.
M. Meng,Secure Robust and Imperceptible Algorithm for Watermarking Relational Databases,"This paper proposes a secure robust and imperceptible algorithm for watermarking relational databases. The algorithm divides the embedding algorithm into three phases: Watermark preparator, watermark position detector, and watermark embedder. The ownership identification issue is resolved by embedding owner's identity as watermark in Preparator phase.","imperceptible algorithm, Ownership identification, robust algorithm, Relational Database, watermarking, Watermark, Copyright protection, Proof of ownership, relational databases","The paper proposes a new robust secure and imperceptible embedding mechanism to resolve the two important concerns namely; owner identification and proof of ownership. The proposed mechanism involves encoding and decoding on numerical attribute of relational database in three phases; 1)Watermark preparator, 2)Watermark position detector and 3) Watermark Embedder or Detector."
M. Mitra,YASS: Yet Another Suﬃx Stripper,"This paper presents a set of string distance measures for clustering the lexicon. The main intuition behind defining these distances was to reward long matching prefixes, and to penalize an early mismatch.","string distance measures, morphological variants, information retrieval, resource-poor languages, clustering, lexicon clustering, Bengali language, equivalence classes, stemming","The paper proposes a set of string distance measures for clustering words into homogeneous groups, with the goal of representing an equivalence class consisting of morphological variants of a single root word."
M. O. Pervaiz,High-Energy-First (HEF) Heuristic for Energy-Efficient Target Coverage Problem,"Target coverage problem in wireless sensor networks is concerned with maximizing the lifetime of the network while continuously monitoring a set of targets. A sensor covers targets which are within the sensing range. For a set of sensors and a set of targets, the sensor-target coverage relationship is assumed to be known. A sensor cover is a set of sensors that covers all the targets. The target coverage problem is to determine a set of sensor covers with maximum aggregated lifetime while constraining the life of each sensor by its initial battery life. The problem is proved to be NP-complete and heuristic algorithms to solve this problem are proposed. In the present study, we give a unified interpretation of earlier algorithms and propose a new and efficient algorithm. We show that all known algorithms are based on a common reasoning though they seem to be derived from different algorithmic paradigms.  We also show that though some algorithms guarantee bound on the quality of the solution, this bound is not meaningful and not practical too.  Our interpretation provides a better insight to the solution techniques. We propose a new greedy heuristic which prioritizes sensors on residual battery life. We show empirically that the proposed algorithm outperforms all other heuristics in terms of quality of solution. Our experimental study over a large set of randomly generated problem instances also reveals that a very naïve greedy approach yields solutions which is reasonably (appx. 10%) close to the actual optimal solutions.","Network Lifetime, QoS constraints, connected coverage, sensing ranges, Target Coverage Problem, Greedy Heuristic, Wireless Sensor Networks, Energy-Efficiency, target coverage",The paper proposes a new heuristic algorithm for the energy-efficient target coverage problem in wireless sensor networks. The algorithm prioritizes sensors based on their residual battery life and is shown to outperform other heuristics in terms of quality of solution. The paper also provides a unified interpretation of earlier algorithms and shows that they are based on a common reasoning. The experimental study reveals that a naïve greedy approach yields solutions close to the actual optimal solutions.
M. P. S Bhatia,Anomaly Detection in Multiplex Networks,"This paper presents an approach for detecting anomalies in multiplex networks. The proposed algorithm is applied to two datasets, Danio-Rerio and Florentine Marriage, and the results show that the algorithm is effective in detecting anomalies in the networks.","Page Rank Centrality, Anomaly Detection, Gaussian Model, cross-layer anomaly detection, Centrality Measure, Multiplex Network, multiplex networks","The paper proposes a novel approach for detecting anomalies in multiplex networks. The approach is based on computing centrality measures for each node in the network and then using a Gaussian model to compute the probability of each node being anomalous. The algorithm is applied to two datasets, Danio-Rerio and Florentine Marriage, and the results show that the algorithm is effective in detecting anomalies in the networks."
M. P. S. Bhatia,SWOT Analysis of Ontology Driven Software Engineering,"In the past decade offshoring and outsourcing the software development phenomenon has been undeniably a key software engineering practice. The need to adapt to this new reality is obvious and is bound to have a long lasting influence on the software industry. This fosters the industry and researchers to look for intelligent supporting technologies and tools that can help interconnect and exchange Software Engineering knowledge. A rising trend to exploit ontologies for sharing and reusing information across web is well recognized. We examine the strategic alignment of ontologies to Software Engineering where the former can be used to improve and assist in intelligent software development process. The SWOT (Strengths, Weaknesses, Opportunities, and Threats) analysis is presented giving an insight to the use of ontologies to enrich and enhance Software Engineering processes.","Ontology, Ontology Driven, information sharing, distributed development environments, Software Engineering, Semantic Web, communication, SWOT Analysis, intelligent support tools","The purpose of this study is to utilize the SWOT analysis framework to determine the benefits, impact, challenges, and risks of using ontologies for Software Engineering. This will help in providing an insight to short-term and long-term practical recommendations that can enhance the Software Engineering process and impact businesses/ individuals/ organizations/ groups in a prolific and strategic manner."
M. Pradhan,Grey Wolf Optimization Algorithm for Economic Load Dispatch,"This article presents a new evolutionary optimization approach named grey wolf optimization (GWO), which is based on the behaviour of grey wolves, for the optimal operating strategy of economic load dispatch (ELD). Nonlinear characteristics of generators like ramp rate limits, valve point discontinuities and prohibited operating zones are considered in the problem. GWO method does not require any information about the gradient of the objective function, while searching for an optimum solution. The GWO algorithm concept, appears to be a robust and reliable optimization algorithm is applied to the nonlinear ELD problems. The proposed algorithm is implemented and tested on four test systems having 10, 40, 80 and 140 units. The results confirm the potential and effectiveness of the proposed algorithm compared to various other methods available in the literature. The outcome is very encouraging and proves that the GWO is a very effective optimization technique for solving various ELD problems.","Grey wolf optimization, Economic load dispatch, Evolutionary algorithm, Valve point loading, Prohibited zone, Power Systems",The article presents a new evolutionary optimization approach named grey wolf optimization (GWO) for the optimal operating strategy of economic load dispatch (ELD). The GWO algorithm concept is applied to the nonlinear ELD problems and tested on four test systems. The results confirm the potential and effectiveness of the proposed algorithm compared to various other methods available in the literature.
M. Prasad,Machine learning techniques for the diagnosis of Alzheimer’s disease: A review,"Alzheimer’s disease is an incurable neurodegenerative disease primarily affecting the elderly population. Efficient automated techniques are needed for early diagnosis of Alzheimers. Many novel approaches are proposed by researchers for classification of Alzheimer’s disease. However, to develop more efficient learning techniques, better understanding of the work done on Alzheimers is needed. Here, we provide a review on 165 papers from 2005-2019 using various feature extraction and machine learning techniques. The machine learning techniques are surveyed under three main categories: support vector machine (SVM), artificial neural network (ANN), and deep learning (DL) and ensemble methods.","Ensemble methods, Support vector machine, Deep learning, Alzheimer’s disease, classification, Artificial neural network, Machine learning","This paper provides a review of 165 papers on machine learning techniques for the diagnosis of Alzheimer’s disease from 2005-2019. The review covers three main categories: support vector machine (SVM), artificial neural network (ANN), and deep learning (DL) and ensemble methods. The paper discusses the importance of efficient automated techniques for early diagnosis of Alzheimers and the need for better understanding of the work done on Alzheimers to develop more efficient learning techniques."
M. Rout,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
M. Russa,Quantitative Comparison of a High Resolution Micro-Angiographic Fluoroscopic (MAF) Detector with a Standard Flat Panel Detector (FPD) Using the New Metric of Generalized Measured Relative Object Detectability (GM-ROD),"A novel amorphous selenium (a-Se) direct detector with CMOS readout has been designed, and relative detector performance investigated. The detector features include a 25μm pixel pitch, and 1000μm thick a-Se layer operating at 10V/μm bias field. A simulated detector DQE was determined, and used in comparative calculations of the Relative Object Detectability (ROD) family of prewhitening matched-filter (PWMF) observer and non-prewhitening matched filter (NPWMF) observer model metrics to gauge a-Se detector performance against existing high resolution micro-angiographic fluoroscopic (MAF) detectors and a standard flat panel detector (FPD). The PWMF-ROD or ROD metric compares two x-ray imaging detectors in their relative abilities in imaging a given object by taking the integral over spatial frequencies of the Fourier transform of the detector DQE weighted by an object function, divided by the comparable integral for a different detector. The generalized-ROD (G-ROD) metric incorporates clinically relevant parameters (focal-spot size, magnification, and scatter) to show the degradation in imaging performance for detectors that are part of an imaging chain. Preliminary ROD calculations using simulated spheres as the object predicted superior imaging performance by the a-Se detector as compared to existing detectors. New PWMF-G-ROD and NPWMF-G-ROD results still indicate better performance by the a-Se detector in an imaging chain over all sphere sizes for various focal spot sizes and magnifications, although a-Se performance advantages were degraded by focal spot blurring. Nevertheless, the a-Se technology has great potential to provide breakthrough abilities such as visualization of fine details including of neuro-vascular perforator vessels and of small vascular devices.","Comparative metrics, generalized metrics, micro-angiography, DQE, Detector Performance, relative object detectability, Microangiography, CMOS, Flat Panel Detector, amorphous selenium","This paper presents a comparative study of a novel amorphous selenium (a-Se) direct detector with existing high resolution micro-angiographic fluoroscopic (MAF) detectors and a standard flat panel detector (FPD). The study utilizes the Relative Object Detectability (ROD) family of metrics, including the generalized-ROD (G-ROD) metric, to assess the performance of these detectors in imaging small objects.  The results indicate that the a-Se detector exhibits superior imaging performance compared to existing detectors, particularly in terms of resolving fine details.  While focal spot blurring can degrade the performance advantage of the a-Se detector, its potential for breakthrough imaging capabilities in neuro-vascular applications is highlighted."
M. S. Manikandan,Performance Study of Cyclostationary based Digital Modulation Classiﬁcation Schemes,"This paper presents a comparative study of various classifiers in cyclostationary features. The classifiers considered are Neural Network, Naive Bayes, Linear Discriminant Analysis, k-Nearest Neighbor, Support Vector Machine, and Neuro-Fuzzy. The performance of these classifiers is evaluated using confusion matrix and computational complexity.","k-Nearest Neighbor, Classifiers, Naive Bayes, Classiﬁcation, Cyclostationary Features, Cognitive Radio, Neuro-Fuzzy, Digital Modulation, Cyclostationary, Linear Discriminant Analysis, Neural Network, Support Vector Machine","This paper studies the performance of digital modulation classiﬁcation technique based on the cyclostationary features and different classiﬁers such as Neural Network, Support Vector Machine, k-Nearest Neighbor, Naive Bayes, Linear Discriminant Analysis and Neuro-Fuzzy classiﬁer."
M. Sabarimalai Manikandan,ECG Noise Detection and Classification Method,"An assessment of electrocardiogram (ECG) signal quality has become an unavoidable ﬁrst step in most holter and ambulatory ECG signal analysis applications. In this paper, we present a simple method for automatically detection and classiﬁcation of ECG noises.","ECG noise detection, ECG classiﬁcation, signal processing, ECG, noise detection, classification, Wearable ECG monitoring devices, ECG signal quality","The proposed method consists of four major steps: moving average ﬁlter, blocking, feature extraction, and multistage decision-tree algorithm. The dynamic amplitude range and autocorrelation maximum peak features are extracted for each block. The method can achieve an average sensitivity (Se) of 97.88%, positive productivity (+P) of 91.18% and accuracy of 89.06%."
M. Shamim Kaiser,"Toward a Heterogeneous Mist, Fog, and Cloud-Based Framework for the Internet of Healthcare Things","Rapid developments in the fields of information and communication technology and microelectronics allowed seamless interconnection among various devices letting them to communicate with each other. This technological integration opened up new possibilities in many disciplines including healthcare and well-being. With the aim of reducing healthcare costs and providing improved and reliable services, several healthcare frameworks based on Internet of Healthcare Things (IoHT) have been developed. However, due to the critical and heterogeneous nature of healthcare data, maintaining high quality of service (QoS)—in terms of faster responsiveness and data-specific complex analytics—has always been the main challenge in designing such systems. Addressing these issues, this paper proposes a five-layered heterogeneous mist, fog, and cloud-based IoHT framework capable of efficiently handling and routing (near-)real-time as well as offline/batch mode data. Also, by employing software defined networking and link adaptation-based load balancing, the framework ensures optimal resource allocation and efficient resource utilization. The results, obtained by simulating the framework, indicate that the designed network via its various components can achieve high QoS, with reduced end-to-end latency and packet drop rate, which is essential for developing next generation e-healthcare systems.","QoS, healthcare big data, load balancing, healthcare application, healthcare, e-healthcare, IoHT, fog computing, quality of service (QoS), reduced latency, IoT, mist computing, Data fusion, cloud computing, heterogeneous framework, low power consumption, real-time computing, resource allocation","This paper proposes a five-layered heterogeneous mist, fog, and cloud-based Internet of Healthcare Things (IoHT) framework to efficiently handle and route healthcare data. The framework employs software defined networking and link adaptation-based load balancing to ensure optimal resource allocation and efficient resource utilization. The results show that the designed network can achieve high quality of service with reduced latency and packet drop rate, making it essential for developing next generation e-healthcare systems."
M. T. I. S. Al Wadia,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
M. Tahir Ismail,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
M. Tanveer,Deep Sparse Representation Classifier for Facial Recognition  and Detection System ||| Machine learning techniques for the diagnosis of Alzheimer’s disease: A review,"This paper proposes a two-layer Convolutional Neural Network (CNN) to learn the high-level features which utilizes to the face identification via sparse representation. Feature extraction plays a vital role in real-world pattern recognition and classification tasks. The details description of the given input face image, significantly improve the performance of the facial recognition system. Sparse Representation Classifier (SRC) is a popular face classifier that sparsely represents the face image by a subset of training data, which is known as insensitive to the choice of feature space. The proposed method shows the performance improvement of SRC via a precisely selected feature exactor. The experimental results show that the proposed method outperform other methods on given datasets. ||| Alzheimer’s disease is an incurable neurodegenerative disease primarily affecting the elderly population. Efficient automated techniques are needed for early diagnosis of Alzheimers. Many novel approaches are proposed by researchers for classification of Alzheimer’s disease. However, to develop more efficient learning techniques, better understanding of the work done on Alzheimers is needed. Here, we provide a review on 165 papers from 2005-2019 using various feature extraction and machine learning techniques. The machine learning techniques are surveyed under three main categories: support vector machine (SVM), artificial neural network (ANN), and deep learning (DL) and ensemble methods.","Sparse Feature Extraction, Ensemble methods, Support vector machine, Convolutional neural network, Deep learning, Alzheimer’s disease, classification, CNN, Artificial neural network, Sparse representation classifier, Face recognition, Support Vector Machines, Feature extraction, Machine learning","This paper presents a robust face recognition framework based on the combination of sparse feature extraction using Convolutional Neural Networks (CNNs) and Support Vector Machines (SVMs). The proposed framework is evaluated on four widely used face datasets, including Extended YALE B database, AR database, MIT faces database, and ORL faces database. The experimental results show that the proposed framework outperforms the state-of-the-art methods in terms of recognition rate. ||| This paper provides a review of 165 papers on machine learning techniques for the diagnosis of Alzheimer’s disease from 2005-2019. The review covers three main categories: support vector machine (SVM), artificial neural network (ANN), and deep learning (DL) and ensemble methods. The paper discusses the importance of efficient automated techniques for early diagnosis of Alzheimers and the need for better understanding of the work done on Alzheimers to develop more efficient learning techniques."
M.B. Srinivas,Training Data Compression Algorithms and Reliability in Large Wireless Sensor Networks,With the availability of low-cost sensor nodes there have been many standards developed to integrate and network these nodes to form a reliable network allowing many different types of hardware vendors to coexist.,"Probability Model, Sensor Network, Data Compression, Wireless Sensor Networks, Reliability","This paper proposes a data compression algorithm for large wireless sensor networks, which optimizes data redundancy and uses a probability model to efficiently compress data at cluster heads."
M.P.S Bhatia,Classifying the Influential Individuals in Multi-Layer Social Networks ||| Data Mining Techniques for Knowledge Discovery in Environmental Monitoring,"Nowadays, social media is one of the popular modes of interaction and information diffusion. It is commonly found that the main source of information diffusion is done by some entities and such entities are also called as influencers. An influencer is an entity or individual who has the ability to influence others because of his/her relationship or connection with his/her audience. In this article, we propose a methodology to classify influencers from multi-layer social networks. A multi-layer social network is the same as a single layer social network depict that it includes multiple properties of a node and modeled them into multiple layers. The proposed methodology is a fusion of machine learning techniques (SVM, neural networks and so on) with centrality measures. We demonstrate the proposed algorithm on some real-life networks to validate the effectiveness of the approach in multi-layer systems. ||| The area of sensor network has a long history and many kind of sensor devices are used in various real life applications. Here, we introduce Wireless sensor network which when combine with other areas then plays an important role in analyzing the data of forest temperature, bioinformatics, water contamination, traffic control, telecommunication etc. Due to the advancement in the area of wireless sensor network and their ability to generate large amount of spatial/temporal data, always attract researchers for applying data mining techniques and getting interesting results. Wireless sensor networks in monitoring the environmental activities grows and this attract greater interest and challenge for finding out the patterns from large amount of spatial/temporal datasets. These datasets are generated by sensor nodes which are deployed in some tropical regions or from some wearable sensor nodes which are attached with wild animals in wild life centuries. Sensor networks generate continuous stream of data over time. So, Data mining techniques always plays a vital role for extracting the knowledge form large wireless sensor network data. In this paper, we present the detection of sensor data irregularities, Sensor data clustering, Pattern matching and their interesting results and with these results we can analyze the sensor node data in different ways.","Bottleneck Centrality, mining, knowledge discovery, sensor networks, Trend Lines, environmental monitoring, sensor node, Betweenness Centrality, Multiple Layers, Centrality Measures, wireless sensor network, Multi-Layer Networks, clustering, pattern matching, Multiplex Network, Social Network, data mining","This paper proposes a methodology to classify influencers from multi-layer social networks by fusing machine learning techniques with centrality measures. The proposed approach starts by computing the betweenness centrality, closeness centrality, and degree centrality of each node of the multi-layer network. Next, it identifies the communities in the system and uses the influence capabilities of the target user and his/her friends to see how prone the friends are to getting influenced by the target user and user characteristics. ||| This paper presents the detection of sensor data irregularities, Sensor data clustering, Pattern matching and their interesting results. The authors introduce Wireless sensor network which plays an important role in analyzing the data of forest temperature, bioinformatics, water contamination, traffic control, telecommunication etc. They present the implementation strategies of the data mining techniques which they applied to sensor data and show the results."
M.P.S Bhatiaa,Cryptocurrency Price Prediction Approach Using ARIMA ||| Time Series Prediction of Cryptocurrency Prices Using LSTM Networks,"With the increase in popularity of cryptocurrencies, it is becoming extremely crucial to predict what the prices of the currencies are going to be in the future. This paper uses a dataset that consists of over 1500 cryptocurrencies with their prices starting from their initiation till May, 2018. A lot of the effort went into getting the data set ready before predicting the future prices of all the cryptocurrencies, i.e., making sure that the cryptocurrencies were stationary time-series. Beginning with learning about the ARIMA model and the conditions to run the model successfully, first validation of the model is done. An average accuracy of 86.424 is observed for 95% of the currencies are observed. After this validation, forecasting is performed on these cryptocurrencies and the percentage change of the price is calculated. ||| In the modern era, researchers are predicting prices of various kinds of cryptocurrency to understand their trend in the sector of finance. In this paper, we focus on price prediction of cryptocurrencies based on a period, i.e., for the year 2013 t0 2018. From our research, we have identified the highest prices for bitcoin for historical dates and trained Long Short-Term Memory Networks to learn and predict the highest rate for a future period. Thus, trend analysis of cryptocurrency prices has been done, and neural networks have been leveraged to determine from time series data and predict future values.","Price prediction, Cryptocurrency, cryptocurrency prices, Deep learning, LSTM, ARIMA model, ARIMA, stationary time-series, time series prediction, Long Short-Term Memory Networks, Forecasting","This paper focuses on the performance of all the cryptocurrencies using the ARIMA model for forecasting the future prices. The dataset used consists of over 1500 cryptocurrencies with their prices starting from their initiation till May, 2018. The paper discusses the related work in the area of cryptocurrency and ARIMA model, data preprocessing, employing ARIMA to forecast the required values, and validating the applied model. ||| This paper proposes a scalable algorithm to predict the increase and decrease in Bitcoin prices throughout five years using deep machine learning networks. The approach maintains a high accuracy (>90 percent) and low Root Mean Squared Error. The proposed architecture helps to predict the highest price of cryptocurrency based on the previous date, develop LSTM network and make predictions using LSTM that maintain their state over many sequences, and use LSTM to predict prices using regression and window based framing for prediction."
M.P.S. Bhatia,Real Time Smartphone Data for Prediction of Nomophobia Severity using Supervised Machine Learning,"Excessive use of smartphones throughout the day having dependency on them for social interaction, entertainment and information retrieval may lead users to develop nomophobia. This makes them feel anxious during non-availability of smartphones. This study describes the usefulness of real time smartphone usage data for prediction of nomophobia severity using machine learning.","real time data, smartphone addiction, smartphone usage, nomophobia questionnaire, machine learning, nomophobia","The study concludes that real time smartphone usage features extracted from the smartphones of students are effective for prediction of nomophobia among students using machine learning. In future, deep learning models can be implemented for prediction of nomophobia using real time smartphone usage features."
MALA SARASWAT,DRIVER ASSISTANCE SYSTEM,"India is home to one of the most underpaid yet overworking drivers. Transporters expect them to work at least twenty or more hours per day continuously without any consideration to their health. This leads them to have bursts of micro sleep, a temporary episode of sleepiness which may last for a smidgen of a second or up to 30 seconds, where the victim fails to react to some stimulus from the environment and becomes unconscious. As a result of this, road accidents have become a common occurrence in India. One solution to this problem is to enhance the vehicles to an extent, so that it is possible to determine the drowsiness of the driver in real time. In this project, we propose a system to assist a driver through detecting drowsiness, distractions and stop signs. The system is easy to understand and the learning curve is minimal. The system is highly robust and can withstand minimal amount of wear and tear. The products assumes that the driver is not blind or deaf. This assumption does not affect the availability of product to mass customers since there are not many driver with visual impairment or hearing impairment. It also assumes that the driver does not drive with either of their eyes closed since driving is not a fun game, since the lives of other passengers is in the drivers hands.","Eye Aspect Ratio, fatigue detection, yawning detection, Region of Interest, drowsiness detection, Mouth Vertical Distance, driver assistance system","The paper proposes a system to assist a driver through detecting drowsiness, distractions and stop signs. The system is easy to understand and the learning curve is minimal. It is highly robust and can withstand minimal amount of wear and tear. The system assumes that the driver is not blind or deaf and does not drive with either of their eyes closed."
MANORANJAN MOHANTY,Privacy-Preserving Mechanism in Smart Home Using Blockchain,"The IoT, or Internet of Things has been a major talking point amongst technology enthusiasts in recent years. The internet of thing (IoT) has been emerged and evolved rapidly, making the world’s fabric around us smarter and more responsive. The smart home uses one such transformation of IoT, which seems to be the wave of the future. However, with the increasing wide adoption of IoT, data security, and privacy concerns about how our data is collected and shared with others, has also risen. To solve these challenges, an approach to data privacy and security in a smart home using blockchain technology is proposed in this paper. We propose authentication scheme that combines attribute-based access control with smart contracts and edge computing to create a secure framework for IoT devices in smart home systems. The edge server adds scalability to the system by offloading heavy processing activities and using a differential privacy method to aggregate data to the cloud securely and privately. We present several aspects of testing and implementing smart contracts, the differential private stochastic gradient descent algorithm, and system architecture and design. We demonstrate the efficacy of our proposed system by fully examining its security and privacy goals in terms of confidentiality, integrity, and availability. Our framework achieves desired security and privacy goals and is resilient against modification, DoS attacks, data mining and linkage attacks. Finally, we undertake a performance evaluation to demonstrate the proposed scheme’s feasibility and efficiency.","edge computing, cyber threats, smart home, access control, differential privacy, Blockchain, smart contract","This paper proposes a privacy-preserving mechanism in smart homes using blockchain technology. The proposed system combines attribute-based access control with smart contracts and edge computing to create a secure framework for IoT devices in smart home systems. The edge server adds scalability to the system by offloading heavy processing activities and using a differential privacy method to aggregate data to the cloud securely and privately. The proposed system achieves desired security and privacy goals and is resilient against modification, DoS attacks, data mining and linkage attacks."
MECS,A Novel Approach to Predict High Blood Pressure Using ABF Function,"High Blood Pressure (HBP) is a state in the biological system of human beings developed due to physical and psychological changes. Nowadays, it is a most prevalent problem in human beings irrespective of age, place, and profession. The HBP victims are increasing rapidly across the globe. HBP is undiagnosed in the majority of the patients because most of the affected people are not aware of it. To overcome this problem, this paper proposes a new approach that uses ABF (Arterial Blood Flow)-function to predict a person is prone to HBP.","High blood pressure, prediction, ABF function, classifier, age, classification, obesity, cholesterol, data mining","This paper proposes a novel approach that works in two steps. In the first step, for each attribute impact factors are set. The impact factor is a real value which represents the degree of influence of an attribute in elevating blood pressure. Impact factor for each attribute of the selected record is set based on the attribute value and its relationship with class labeled attribute using Pearson correlation coefficient. In the second step, the proposed algorithm calculates the value of class label attribute using impact factor and corresponding attribute value. The class label attribute value is then used to predict whether a person is prone to HBP."
MICHAEL BLUMENSTEIN,Robust Feature-Based Automated Multi-View Human Action Recognition System,"Automated human action recognition has the potential to play an important role in public security, for example, in relation to the multiview surveillance videos taken in public places, such as train stations or airports. This paper compares three practical, reliable, and generic systems for multiview video-based human action recognition, namely, the nearest neighbor classiﬁer, Gaussian mixture model classiﬁer, and the nearest mean classiﬁer. To describe the different actions performed in different views, view-invariant features are proposed to address multiview action recognition. These features are obtained by extracting the holistic features from different temporal scales which are modeled as points of interest which represent the global spatial-temporal distribution. Experiments and cross-data testing are conducted on the KTH, WEIZMANN, and MuHAVi datasets. The system does not need to be retrained when scenarios are changed which means the trained database can be applied in a wide variety of environments, such as view angle or background changes. The experiment results show that the proposed approach outperforms the existing methods on the KTH and WEIZMANN datasets.","feature extraction, points of interest extraction, background subtraction, machine learning, moving object localization, multi-view human action recognition, action recognition, Multi-view video, classiﬁcation","This paper proposes a robust feature-based automated multi-view human action recognition system. The system uses view-invariant features to address multi-view action recognition from a range of perspectives. The proposed approach labels the beginning and end of an action sequence in a video stream automatically and captures sequence motions and occlusions at a low computational cost. The system is evaluated using the KTH, WEIZMAN, and MuHAVi datasets and outperforms existing methods on the KTH and WEIZMANN datasets."
MUKESH PRASAD,IoT-Based Wireless Polysomnography Intelligent System for Sleep Monitoring ||| MSGR: A Mode-Switched Grid-Based Sustainable Routing Protocol for Wireless Sensor Networks ||| Robust Feature-Based Automated Multi-View Human Action Recognition System,"Polysomnography (PSG) is considered the gold standard in the diagnosis of obstructive sleep apnea (OSA). The diagnosis of OSA requires an overnight sleep experiment in a laboratory. However, due to limitations in relation to the number of labs and beds available, patients often need to wait a long time before being diagnosed and eventually treated. In addition, the unfamiliar environment and restricted mobility when a patient is being tested with a polysomnogram may disturb their sleep, resulting in an incomplete or corrupted test. Therefore, it is posed that a PSG conducted in the patient’s home would be more reliable and convenient. The Internet of Things (IoT) plays a vital role in the e-Health system. In this paper, we implement an IoT-based wireless polysomnography system for sleep monitoring, which utilizes a battery-powered, miniature, wireless, portable, and multipurpose recorder. A Java-based PSG recording program in the personal computer is designed to save several bio-signals and transfer them into the European data format. These PSG records can be used to determine a patient’s sleep stages and diagnose OSA. This system is portable, lightweight, and has low power-consumption. To demonstrate the feasibility of the proposed PSG system, a comparison was made between the standard PSG-Alice 5 Diagnostic Sleep System and the proposed system. Several healthy volunteer patients participated in the PSG experiment and were monitored by both the standard PSG-Alice 5 Diagnostic Sleep System and the proposed system simultaneously, under the supervision of specialists at the Sleep Laboratory in Taipei Veteran General Hospital. A comparison of the results of the time-domain waveform and sleep stage of the two systems shows that the proposed system is reliable and can be applied in practice. The proposed system can facilitate the long-term tracing and research of personal sleep monitoring at home. ||| A Wireless Sensor Network (WSN) consists of enormous amount of sensor nodes. These sensor nodes sense the changes in physical parameters from the sensing range and forward the information to the sink nodes or the base station. Since sensor nodes are driven with limited power batteries, prolonging the network lifetime is difficult and very expensive, especially for hostile locations. Therefore, routing protocols for WSN must strategically distribute the dissipation of energy, so as to increase the overall lifetime of the system. ||| Automated human action recognition has the potential to play an important role in public security, for example, in relation to the multiview surveillance videos taken in public places, such as train stations or airports. This paper compares three practical, reliable, and generic systems for multiview video-based human action recognition, namely, the nearest neighbor classiﬁer, Gaussian mixture model classiﬁer, and the nearest mean classiﬁer. To describe the different actions performed in different views, view-invariant features are proposed to address multiview action recognition. These features are obtained by extracting the holistic features from different temporal scales which are modeled as points of interest which represent the global spatial-temporal distribution. Experiments and cross-data testing are conducted on the KTH, WEIZMANN, and MuHAVi datasets. The system does not need to be retrained when scenarios are changed which means the trained database can be applied in a wide variety of environments, such as view angle or background changes. The experiment results show that the proposed approach outperforms the existing methods on the KTH and WEIZMANN datasets.","feature extraction, mobile sink, grid head, wireless PSG, points of interest extraction, background subtraction, wireless, Internet of Things, moving object localization, JAVA, grid-based routing, sleep monitoring, action recognition, Polysomnography (PSG), classiﬁcation, Wireless sensor networks, energy efficiency, machine learning, multi-view human action recognition, scalability, Multi-view video, IoT","This paper proposes an IoT-based wireless polysomnography system for sleep monitoring, which utilizes a battery-powered, miniature, wireless, portable, and multipurpose recorder. The system is designed to save several bio-signals and transfer them into the European data format, allowing for the determination of a patient’s sleep stages and diagnosis of OSA. The proposed system is compared to the standard PSG-Alice 5 Diagnostic Sleep System and shows reliable results, making it a viable option for long-term tracing and research of personal sleep monitoring at home. ||| The paper presents a comprehensive review of grid-based routing protocols for WSNs, highlighting their design principles, advantages, and limitations. It also proposes a new mode-switched grid-based sustainable routing protocol, which adapts to changing network conditions to conserve energy and improve network lifetime. ||| This paper proposes a robust feature-based automated multi-view human action recognition system. The system uses view-invariant features to address multi-view action recognition from a range of perspectives. The proposed approach labels the beginning and end of an action sequence in a video stream automatically and captures sequence motions and occlusions at a low computational cost. The system is evaluated using the KTH, WEIZMAN, and MuHAVi datasets and outperforms existing methods on the KTH and WEIZMANN datasets."
MUSTAFA et al.,Event-Triggered Sliding Mode Control for Trajectory Tracking of Nonlinear Systems,This paper presents a novel approach for designing event-triggered sliding mode control (SMC) for nonlinear input affine systems with external disturbances. The proposed control approach has been designed by modeling the dynamics for a class of nonlinear systems into a general nonlinear control affine system. The control approach can be directly applied to systems that are already in affine form.,"Event-triggered control, Uncertainty, External disturbances, Sliding mode control, Nonlinear systems, Event-triggered sliding mode control, Trajectory tracking","The proposed control approach ensures asymptotic stability of the system in the presence of external disturbances. The event-triggered SMC law is designed to meet two aspects: tracking error should converge to zero, ensuring asymptotic stability of the system, and does not violate the admissibility condition, i.e., non-stacking of actuator actions."
Madhusudhan Rao Kadiri,Applications of machine learning techniques to predict filariasis using socio-economic factors,"Filariasis is one of the major public health concerns in India. Approximately 600 million people spread across 250 districts of India are at risk of filariasis. To predict this disease, a pilot scale study was carried out in 30 villages of Karimnagar district of Telangana from 2004 to 2007 to collect epidemiological and socio-economic data. The collected data are analysed by employing various machine learning techniques such as Naïve Bayes (NB), logistic model tree, probabilistic neural network, J48 (C4.5), classification and regression tree, JRip and gradient boosting machine. The performances of these algorithms are reported using sensitivity, specificity, accuracy and area under ROC curve (AUC). Among all employed classification methods, NB yielded the best AUC of 64% and was equally statistically significant with the rest of the classifiers. Similarly, the J48 algorithm generated 23 decision rules that help in developing an early warning system to implement better prevention and control efforts in the management of filariasis.","Filariasis, mosquito, socio-economic factors, Socio-economic conditions, Machine learning techniques, Predictive classification modelling, Data balancing, Feature subset selection",This study aims to predict filariasis using socio-economic factors and machine learning techniques. A pilot scale study was conducted in 30 villages of Karimnagar district of Telangana from 2004 to 2007 to collect epidemiological and socio-economic data. Various machine learning techniques were employed to analyse the data and predict filariasis. The study found that Naïve Bayes yielded the best AUC of 64% and generated 23 decision rules that help in developing an early warning system to implement better prevention and control efforts in the management of filariasis.
Madichetty Sreedhar,A Novel Approach to Derive the Current Harmonics Present in Circulating Currents and Its Necessary Controller to Suppress the Same in a Five Level MMC,"This paper presents a novel approach to derive the current harmonics present in circulating currents and its necessary controller to suppress the same in a five level modular multilevel converter (MMC). The instantaneous voltage across the capacitors are denoted as Vc1, Vc2, Vc3, Vc4…VcN Also, the voltage distribution across the capacitors is considered as unequal.","experimental approach, modular multilevel converter, MMC, Controller, Current Harmonics, harmonic mitigation, Circulating Currents","This paper presents a new harmonic mitigation scheme for modular multilevel converters, which is an experimental approach. The proposed controller is effective and easy to implement for modular multilevel inverters."
"Mahapatra, K. K.",A New MPPT Design Using Grey Wolf Optimization Technique for Photovoltaic System Under Partial Shading Conditions,"A new maximum power point tracking (MPPT) design using grey wolf optimization (GWO) technique is proposed in this paper. The proposed GWO-based MPPT algorithm is compared with improved particle swarm optimization (IPSO) and perturb and observe (P&O) algorithms. The simulation results show that the proposed GWO-based MPPT outperforms the other two methods in terms of faster convergence to the global peak (GP), tracking speed, reduced steady-state oscillations, and higher tracking efficiency.","Grey wolf optimization, Grey wolf optimization (GWO), Partial shading, MPPT algorithm, maximum power point tracking (MPPT), Maximum power point tracking, GWO-based MPPT, partial shading conditions (PSCs), photovoltaic (PV)","The proposed GWO-based MPPT algorithm is compared with IPSO and P&O algorithms in terms of convergence speed, tracking efficiency, and oscillations. The simulation results show that the proposed GWO-based MPPT outperforms the other two methods."
Makflakes,COVID-19 Metaphors of India,This study examines the metaphors used to describe COVID-19 in Indian tweets and related media. The authors created a list of metaphorical mappings inspired by #ReframeCovid and manual analysis of major Indian newspaper headlines. They used pretrained word2vec embeddings to expand the set of relatable lexical units and identified the top-10 source domains based on their volume in the dataset.,"COVID-19, lexical units, BERT model, India, word2vec, Indian tweets, Twitter, metaphors","The study found that the most often used source domain to describe COVID-19-related events is WAR, followed by MONSTER, CHALLENGE, LESSON, and STORM. The authors also observed that the conceptualization of COVID-19 evolved over time, with the topic of VACCINE initially conceptualized as a WEAPON, later as a PASSPORT/TICKET, and eventually as LUXURY."
Mala Saraswat,Analyzing emotion based movie recommender system using fuzzy emotion features ||| Aspect Term Extraction using Domain Ontology for Sarcasm Detection ||| Enriching Topic Coherence on Reviews for Cross-Domain Recommendation ||| Fake News Detection Through ML and Deep Learning ||| Sentiment Analysis of Drugs related Post Impacting the Society Healthcare ||| Web-Based Movie Recommender System,"User generated contents like reviews and comments contain both the information about a given product and also the opinions asserted by the user. With the surge in internet usage, there is a cascade of user generated data such a reviews and comments. People share their experiences, opinions, sentiments and emotions by writing reviews and comments for products they purchase online or after watching a movie, reading books etc. These user generated data contains emotion lexicons such as happiness, sadness, and surprise. Analysis of such emotion can provide a new aspect for recommending new items based on their emotional preferences. In this work, we extract the emotions from this user generated data using the lexical ontology, WordNet and information from the domain of psychology. These extracted emotions can be used for recommendations. Evaluation on emotion prediction further verifies the effectiveness of the proposed model in comparison to traditional rating based item similarity model. We further compare this with fuzziness in emotion features. ||| Various aspects or characteristic features of an entity come into interplay to create an underlying fabric upon which sentiments blossom. In multi aspect Sentiment Analysis (SA), potentially related aspects of an entity under review are discussed in a single piece of text such as an online review. In this work, we use domain ontologies for enabling multi-aspect Sentiment Analysis. Since, domain ontologies contain the entire domain knowledge, they assist in enhanced aspect identification and detection of the latent or hidden aspects in a review document. We illustrate our approach by developing a system named Ontology driven Multi Aspect Sentiment Analysis (OMASA) system. We provide hotel reviews as input to this system and identify the panorama of explicitly expressed and latent aspects in a review using hotel domain ontology. After detecting the aspects, we link them with the corresponding opinions to gauge the sentiment pertaining to the aspects extracted. OMASA first computes sentiment scores for every aspect of the hotel. It then evaluates the overall sentiment score. On comparing with the baseline, the experimental results of OMASA show a marked improvement in the aspect level evaluation metrics Δaspect2 and ρaspect after detecting the hidden aspects. This shows that OMASA has the potential to identify the latent aspects in text thereby improving the quality of SA. ||| This paper proposes a novel approach for cross-domain recommendation (CDR) that leverages topic coherence between domains to improve recommendation accuracy. The proposed approach, called TC-CDR, consists of nine modules that work together to recommend items from a target domain to a user in a source domain. The approach uses a combination of natural language processing and machine learning techniques to extract semantic features from user reviews and item descriptions, and then uses these features to compute topic coherence between domains. The proposed approach is evaluated on two real-world datasets, Movielens and Bookcrossing, and is shown to outperform state-of-the-art CDR methods in terms of recommendation accuracy. ||| This paper discusses the detection of fake news through machine learning and deep learning algorithms. The authors present a proposed approach for fake news detection using decision tree, XGBoost, and LSTM algorithms. The paper also discusses the preprocessing of data, feature extraction, and the training and testing of the classifiers. The results show that the decision tree algorithm achieves a prediction accuracy of 99.67% for fake news detection. ||| Abstract: People in this digital age spend their important time on social media for diverse application. Generally, social media addiction bound individuals to discuss everything on this platform, because of which their personal and uncultured words used in communication, affect the cultured society. Individuals from different fields discuss about their domain of interest. Sportsperson discuss their sports, doctors discuss medicine, teachers discuss their subject, similarly alcoholic or addicted person discuss on drugs. Drug related tweets are normally visible in social media communication for different discussion. Analyzing these tweets maybe in positive or negative sense will help understand the social impact of these drug related posts in society. Due to the higher drawback of such words, researchers continue finding the spreading of drug related post and their impact on society. Positive sentiment actually means drug advertisement or drug usage encouragement that will actually have NEGATIVE impact on society   Pharmacists also compute the impact of these words for marketing of medicine. In this paper, we compute the negative impact on society through the use of drug associated post using sentiment analysis in different period of time for two prominent cities of India: a) Delhi: capital city creating the honored cultures society b) Bangalore: IT hub city of India.. We find Bangalore has slightly large contribution of 50.90% of positive sentiment drug related tweets compared to Delhi which has 49.10%. Thus Bangalore city tweets have slightly worse impact on society compared to Delhi. ||| All content following this page was uploaded by Mala Saraswat on 24 May 2021.","Sarcasm Detection, Machine Learning, Sentiment Analysis, decision tree, Classification, Content based recommender system, Aspect Term Extraction, Sarcasm, pointwise mutual information, Domain Ontology, Collaborative recommender system, recommender systems, healthcare, explicit semantic analysis, top N recommendation, fake news detection, TripAdvisor, Domain Ontologies, Social Media, WorldNet, topic modeling, topic coherence, LSTM, drug related posts, Social media, News, movie recommendation, Amazon, Hotel Domain, Hontology, XGBoost, Accuracy, emotion based recommendation, deep learning, machine learning, Emotion analysis, Twitter, natural language processing, Detection, Drugs, cross-domain recommendation, Sentiment analysis","This paper proposes a new item based recommender system using both CF and CBF based approaches to recommend items using emotions. Emotions are extracted from user generated data using lexical ontology, WordNet and information from the domain of psychology. The extracted emotions are used for recommendations and evaluated on emotion prediction. The proposed model is compared with traditional rating based item similarity model and fuzziness in emotion features. ||| This paper proposes a novel approach for multi-aspect sentiment analysis using domain ontologies. The proposed system, OMASA, uses domain ontologies to identify and extract latent and hidden aspects in a review document. OMASA computes sentiment scores for every aspect of the hotel and evaluates the overall sentiment score, showing a marked improvement in aspect level evaluation metrics compared to the baseline. ||| The proposed TC-CDR approach uses a combination of natural language processing and machine learning techniques to extract semantic features from user reviews and item descriptions, and then uses these features to compute topic coherence between domains. The approach is evaluated on two real-world datasets, Movielens and Bookcrossing, and is shown to outperform state-of-the-art CDR methods in terms of recommendation accuracy. ||| The detection of fake news is an important challenge to researchers. The detection of misinformation is not an easy task for anyone, but quite is a complex for people. Here, we analyze the different fake news detection approaches followed in current scenario and compute the detection process through machine learning and deep leaning algorithms for better accuracy. ||| This paper presents a sentiment analysis of drug-related posts on social media, specifically Twitter, to understand their impact on society. The authors analyze tweets from two prominent cities in India, Delhi and Bangalore, and find that Bangalore has a slightly higher percentage of positive sentiment drug-related tweets, indicating a worse impact on society compared to Delhi. ||| See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/339920629"
Malabika Basu,Comparative Study of DC and Induction Motors for Electric Vehicle Propulsion ||| Development of a Smart Energy Community by Coupling Neighbouring Community Microgrids for Enhanced Power Sharing Using Customised Droop Control ||| Double Deadbeat Plus Repetitive Control Scheme for Microgrid System,"This paper presents a comparative study of DC and induction motors for electric vehicle propulsion. The characteristics of the traction effort with respect to speed are discussed, and the advantages and disadvantages of each type of motor are highlighted. The paper also discusses the use of vector control and multiphase pole-changing IM drive to improve the performance of induction motors. ||| This paper proposes an enhanced PM-based droop control strategy for power sharing in CMGs. The proposed strategy achieves symmetric and asymmetric power-sharing through a PM-based droop control, enabling efficient coupling of neighboring CMGs. The control strategy also includes an enhanced frequency regulation method without using a secondary controller, maintaining the system frequency within an acceptable range. ||| Parallel connection of converters is a convenient choice when system capacity is to be increased. Parallel-connected voltage source converters, especially neutral point clamped converters, are one of the best choices for its range. However, with the parallel connectivity, the converter possesses a circulating current in its legs, which consequently threatens the safe operation of the system.","Microgrid systems, vector control, droop control, CMGs, Circulating currents, frequency regulation, Parallel-connected inverters, electric vehicle propulsion, repetitive control scheme, power sharing, microgrids, parallel inverter, PM-based droop control, propulsion systems, Repetitive control, parallel converters, electric motors, DC motors, multiphase pole-changing IM drive, Deadbeat control, power management, electric vehicles, Deadbeat control (DB) scheme, energy community, induction motors, interconnected system, community microgrids","The paper discusses the trends in electric motors and their selection for electric vehicle propulsion systems. It reviews the various types of motors that can be used in electric traction, including DC, induction, switched reluctance, permanent magnet brushless AC motors and permanent magnet brushless DC motors. The paper also presents a detailed review of existing motors and the application of power electronic techniques to EVs, and recommendations for some new designs of brushless DC motors. ||| The proposed PM-based droop control strategy is validated through laboratory-scale CMG testing, demonstrating its effectiveness in maintaining system frequency and voltage within acceptable ranges. The control strategy is also shown to be efficient in power sharing, enabling the coupling of neighboring CMGs. The proposed method has the potential to improve the reliability and efficiency of CMG-based power systems. ||| This paper proposes a double deadbeat plus repetitive control scheme to mitigate circulating currents in parallel-connected voltage source converters. The proposed scheme combines the advantages of deadbeat control and repetitive control to achieve high operating bandwidth and stability."
Mamta Dahiya,Optimal Feature Level Fusion Based IRIS and Fingerprint Multimodal Biometric System using Improved Multi Kernel SVM,"The modern society attained secured mechanism to lead their processes in different applications such as airports, hospitals, banks, autonomous and non-autonomous institutions, etc with the improvement of biometric system. Nowadays, biometric technique is employed for human identification process based iris, fingerprint, ear and palm etc. In order to render the effective biometric system we have improved multi-model biometric recognition established on iris and fingerprint. Our work is established on three modules such as recognition module, pre-processing module, and feature extraction module. Then, in the feature extraction module, we processed feature extraction established on changed Local Binary Pattern (MLBP) feature and GLCM features. Fish Swarm optimization algorithm is applied for processing feature level fusion. For recognition, developed Multi Kernel Support vector machine (IMKSVM is inaugurated. In the document, several kernels are integrated to give shape to an innovative hybrid kernel which incredibly improves the classification task of segregating the training data. By way of offering the hybrid kernel, the SVMs gainfully achieve the flexibility to pick the appropriate shape of the threshold, for which it is not essential that it is linear and possesses the identical functional shape for the entire data, in view of its non-parametric function and local operation. We estimated our suggested technique with existing technique therefore; we get better recognition accuracy and successfully implemented our technique in MATLAB platform.","feature extraction, fusion techniques, Fish Swarm Optimization, cancelable score fusion, Reorganization, relevance vector machine, GLCM Feature, bin-based classifier, Preprocessing, multimodal biometric systems, Local Binary Pattern, Biometric System","This paper presents an optimal feature level fusion based IRIS and fingerprint multimodal biometric system using improved multi kernel SVM. The system is established on three modules: recognition module, pre-processing module, and feature extraction module. The feature extraction module uses changed Local Binary Pattern (MLBP) feature and GLCM features. Fish Swarm optimization algorithm is applied for processing feature level fusion. The system is implemented in MATLAB platform and achieves better recognition accuracy compared to existing techniques."
Manan Madan,An Extended Version of WordNet Incorporating Technical Terms and Subject Specific Words/Phrases ||| Evaluating the Learning Perspectives of Students on the Basis of Class Notes,"WordNet is a huge repository being used as a tool in various fields. With an increasing number of applications referring to WordNet as a dictionary, several attempts have been made to update it. The paper proposes to extend the huge repository by adding words and relationships derived from students’ class notes through wikidata. These terms can be phrases, technical terms or any subject specific terminology appearing in students’ notes of a specific subject. Although various WordNet enriching techniques are available, it is for the first time that subject specific terminology is being added. The resulting version of WordNet has some very common phrases and technical terms along with the generic terms. Making subject specific and generic terms available in a hierarchy can improve the accuracy of various applications like text summarization and clustering for text belonging to a specific domain. ||| This paper aims to evaluate the learning perspectives of students on the basis of class notes taken while the teacher is teaching in class. Homogenous and heterogeneous groups are formed on the basis of learning perspectives.","Class Notes, Subject Specific Words/Phrases, English WordNet, Collaborative learning environments, homogeneous grouping, Learning Perspectives, Collaborative Learning, Homogenous Grouping, heterogeneous grouping, WordNet, Hyponym enrichment, Technical Terms, Wikidata","The paper proposes a novel hyponym enrichment in WordNet by enriching the database with subject related technical terms. This is important since the database has not been updated for a long time now. To the best of our knowledge, we are the first to use wikidata for adding subject specific terms and relationships to WordNet. ||| The study evaluates the learning perspectives of students on the basis of class notes taken while the teacher is teaching in class. The study uses a quasi-experimental design and involves 194 undergraduate students from the seventh semester of the computer engineering department. The study finds that homogenous and heterogeneous grouping methods have different effects on student learning outcomes."
Mandelli et al.,Spatial Domain Averaging for Efficient Computation of Camera Fingerprints,"Photo Response Non-Uniformity (PRNU) based camera attribution is an effective method to determine the source camera of visual media (an image or a video). To apply this method, images or videos need to be obtained from a camera to create a “camera fingerprint” which then can be compared against the PRNU of the query media whose origin is under question.","camera fingerprinting, PRNU-based camera attribution, video forensics, PRNU, video stabilization, spatial domain averaging, image forensics, camera fingerprint extraction","This paper proposes a computationally efficient way to compute a camera fingerprint from a large number of media objects, such as individual frames of a video or a large number highly compressed images taken from a social media platform."
Maneesha Sharma,Cloud Computing: Different Approach & Security Challenge,"Cloud computing has generated a lot of interest and competition in the industry and it is recognize as one of the top 10 technologies of 2010. It is an internet based service delivery model which provides internet based services, computing and storage for users in all market including financial, health care & government. In this paper we did systematic review on different types of clouds and the security challenges that should be solved. Cloud security is becoming a key differentiator and competitive edge between cloud providers. This paper discusses the security issues arising in different type of clouds.","Security, Security challenges, Cloud computing, Cloud","This paper discusses the security issues arising in different types of clouds, including personal clouds, general clouds, domain-specific clouds, and hybrid clouds. It highlights the security challenges that need to be solved in each type of cloud, such as compliance and auditing, intrusion detection, access control, and anti-virus/anti-malware protection."
Manju,Energy-Efficient Node Scheduling Mechanism for Target Coverage Problem in Wireless Sensor Networks ||| Improved-Coverage Preserving Clustering Protocol in Wireless Sensor Networks ||| Maximising network lifetime for target coverage problem in wireless sensor networks,"In wireless sensors networks, the sensor nodes are densely deployed. Owing to this excessive deployment of sensor nodes, each target is covered by multiple sensors at a time. To prolong the network lifetime, the authors can schedule the sensor activity in such a way that only a subset of sensor nodes, called cover set, is sufficient enough to cover all the targets. In this study, they propose an energy-efficient scheduling algorithm based on learning automata for target coverage problem. The learning automata-based technique helps a sensor node to select its appropriate state (either active or sleep). To prove the effectiveness of their proposed scheduling method, they conduct a detailed set of simulations and compare the performance of their algorithm with the existing algorithms. ||| Coverage maintenance for longer period is crucial problem in wireless sensor network (WSNs) due to limited inbuilt battery in sensors. Coverage maintenance can be prolonged by using the network energy efficiently, which can be done by keeping sufficient number of sensors in sensor covers. There has been discussed a Coverage-Preserving Clustering Protocol (CPCP) to increase the network lifetime in clustered WSNs. It selects sensors for various roles such as cluster heads and sensor cover members by considering various coverage aware cost metrics. In this paper, we propose a new heuristic called Improved-Coverage-Preserving Clustering Protocol (I-CPCP) to maximize the total network lifetime. In our proposed method, minimal numbers of sensor are selected to construct a sensor covers based on various coverage aware cost metrics. These cost metrics are evaluated by using residual energy of a sensor and their coverage. The simulation results show that our method has longer network lifetime as compared to generic CPCP. ||| Target coverage problem is one of the important problems in wireless sensor network in which each target should be covered by at least one sensor. All the sensors are organised into different groups called sensor cover in such a way that each cover can monitor all the targets for a fixed duration. By keeping one sensor cover active at a time while others in sleep mode, sensors batteries can be utilised in efficient way. This helps in prolonging the network lifetime. In this study, the authors propose a new energy-efficient heuristic to schedule the sensors in different non-disjoint sensor covers which helps to maximise network lifetime.","energy-efficient scheduling, coverage aware cost metrics, sensor networks, clustering protocol, sensor roles, clustering, energy-efficient node scheduling, target coverage problem, learning automata, network lifetime, energy-efficient heuristic, wireless sensor networks, energy-efficiency, coverage","This paper proposes an energy-efficient scheduling algorithm based on learning automata for target coverage problem in wireless sensor networks. The algorithm helps a sensor node to select its appropriate state (either active or sleep) to prolong the network lifetime. The effectiveness of the proposed scheduling method is proven through simulations and comparison with existing algorithms. ||| The paper proposes a Coverage Preserving Clustering Protocol (CPCP) to decide the roles of sensors for various activities in wireless sensor networks. The protocol estimates the total energy available to cover each point in the network area and considers various parameters like residual energy, number of 1-hop neighbouring sensor nodes, number of n-hop neighbouring sensor nodes and distance from the base station. The authors also discuss various coverage aware cost metrics to decide the roles of sensors for various activities. ||| The authors propose a new energy-efficient heuristic to schedule the sensors in different non-disjoint sensor covers which helps to maximise network lifetime. The heuristic identifies all the critical targets (least covered) and the critical sensors (covering critical targets). The critical targets, covered by minimum number of sensors, will be the targets that become uncovered first. Utilising critical sensors efficiently will help to increase the network lifetime."
Manoj Singh,Diurnal Variation of Ozone Levels in Academic Hostel in Delhi,"Urban air pollution has become a serious environmental problem in the last few decades in most of the developing countries including India. Due to widespread industrialization, rapid urbanization and huge growth in the number of motor vehicles have brought about severe deterioration in the urban air quality. Among the various gaseous pollutants, ozone is one of the important pollutants because of its health as well as climatic impacts. This study investigates the levels of ozone concentration at thirteen different hostels in an academic institute, Delhi. The measurements of ozone were carried out in indoor environments by ozone analyzer (Model S-5014 SIR) for 24 hours.","hostels, Delhi, academic hostels, ozone levels, diurnal variation, CPCB, anthropogenic activities, Indoor ozone, VOCs, NOx","The study reveals that the ozone concentration in the entire indoor environment of the JNU campus lies in the range (2.81 to 4.17 ppb for 24 hours) are well below the permissible limits (100 µg/m3 for 8 hours) prescribed by CPCB, India. Also the outdoor ozone concentration is found to lie in the range (13.93 ppb to 78. 15 ppb for 8 hours), which well above the standard (100 µg/m3 for 8 hours) prescribed by CPCB."
Manoranjan Mohanty,Accurate Trafﬁc Flow Prediction in Heterogeneous Vehicular Networks in an Intelligent Transport System Using a Supervised Non-Parametric Classiﬁer ||| Cloud-Based Secured Medical Data Visualization Pipeline ||| Encrypted Domain Camera Attribution ||| Secure Cloud-Based Volume Ray-Casting,"Heterogeneous vehicular networks (HETVNETs) evolve from vehicular ad hoc networks (VANETs), which allow vehicles to always be connected so as to obtain safety services within intelligent transportation systems (ITSs). The services and data provided by HETVNETs should be neither interrupted nor delayed. Therefore, Quality of Service (QoS) improvement of HETVNETs is one of the topics attracting the attention of researchers and the manufacturing community. ||| Outsourcing the tasks of medical data visualization to cloud centers presents new security challenges. In this paper, we propose a framework for cloud-based remote medical data visualization that protects the security of data at the cloud centers. ||| Photo Response Non-Uniformity (PRNU) noise-based source camera attribution is a popular digital forensic method. In this method, a camera fingerprint computed from a set of known images of the camera is matched against the extracted noise of an anonymous questionable image to find out if the camera had taken the anonymous image. ||| Secure Cloud-based Volume Ray-Casting","QoS, utility, 3D Medical Data Visualization, internet of vehicles, cloud-based, SVM, Cloud Computing, data, Secure computation, Vehicular Ad Hoc Network, pipeline, Camera Fingerprinting, secured, Privacy, medical, camera attribution, Prediction Accuracy, RBF, encrypted domain, Support Vector Machines, Ray Casting, PRNU-based camera attribution, visualization, Radial Basis Function, Secret Sharing, HETVNET","This paper proposes a prediction model based on support vector machines (SVMs) to improve Quality of Service (QoS) in Heterogeneous Vehicular Networks (HETVNETs). The model uses a radial basis function (RBF) kernel and outperforms other prediction methods in terms of accuracy and computational complexity. ||| The proposed pipeline protects patient's 3D medical data by distributing shares among n different data centers, allowing clients to reconstruct the secret image from any k shares. ||| The proposed method is based on a secure multi-party computation scheme that enables a third-party entity to perform camera attribution tasks without accessing the sensitive image data. The method uses a combination of homomorphic encryption and secure multi-party computation to ensure both utility and privacy. ||| Secure Cloud-based Volume Ray-Casting is a framework for secure medical data visualization. It addresses security and privacy challenges by using secure pre-classification and post-classification volume ray-casting techniques."
Marc Audebert,Cutting Edge: CD8 T Cell-Mediated Demyelination,"We generated mice (DKI) in which the HA coding sequence was introduced in the ubiquitously active Rosa26 locus but where HA transcription was prevented by an upstream LoxP-flanked Stop cassette. The DKI mice were then crossed with the MOGi-Cre mice, which express Cre specifically in oligodendrocytes. The resulting DKI mice excise the Stop cassette due to MOG-controlled Cre expression, leading to restricted HA expression to oligodendrocytes.  We then decided to test whether effector CD8 T cells can mediate oligodendrocyte cell death and demyelination in vivo. Effector T cells were first generated by in vitro activation of Kd:HA512–520 pentamer-specific CD8 T cells obtained from CL4-TCR mice using HA peptide, IL-2, and IL-12. The resulting Tc1 cells produce large amounts of granzyme B (GrB) and IFN-γ and exhibit potent cytotoxicity to HA-loaded target cells in vivo. Next, we transferred these HA-specific Tc1 cells into DKI and control mice. Following i.v. injection of 3 × 107 HA-specific Tc1 cells, but not naive HA-specific CD8 T cells, ~40% of the DKI mice developed an overt monophasic disease peaking at day 8–10 and waning by 4 wk posttransfer. The clinical manifestations included weight loss and, in the more severe cases, tremors, reduced mobility, and difficulty to right when overturned without overt paralysis. Upon histological analysis, all DKI mice injected with Tc1 cells demonstrated clear CNS pathology from day 5 onwards. Inflammatory lesions were never found in control littermates injected in parallel with HA-specific Tc1 cells.",,"This study investigates the role of CD8 T cells in multiple sclerosis (MS) pathogenesis. Researchers generated a mouse model where a model antigen (influenza hemagglutinin) is expressed specifically in oligodendrocytes, the cells responsible for producing myelin in the central nervous system. Transferring activated CD8 T cells specific for this antigen into these mice resulted in inflammatory lesions in the brain, spinal cord, and optic nerve, resembling active MS lesions. These lesions were characterized by CD8 T cell infiltration, loss of oligodendrocytes, demyelination, and microglia activation. This suggests that CD8 T cells can directly contribute to oligodendrocyte death and demyelination in MS, highlighting their potential as therapeutic targets."
Marcin Dobaczewski,Endogenous IRAK-M Attenuates Postinfarction Remodeling Through Effects on Macrophages and Fibroblasts ||| TSP-1 in Diabetic Cardiomyopathy,"Quantitative polymerase chain reaction analysis demonstrated significant IRAK-M mRNA upregulation in the infarcted myocardium. The time course of IRAK-M induction showed a biphasic response (Figure 1), characterized by marked early upregulation after 6 hours of reperfusion, followed by a second peak after 7 days of reperfusion (Figure 1A). IRAK-M Is Localized in Infarct Macrophages and Myofibroblasts Dual immunofluorescence was used to study IRAK-M localization in the infarcted myocardium. IRAK-M immunoreactivity in the infarcted heart was localized in Mac2+ infarct macrophages and in spindle-shaped, α–smooth muscle actin–positive myofibroblasts (Figure 1B and 1C). Moreover, infarct myofibroblasts and CD11b+ leukocytes isolated from the infarcted heart after 72 hours of reperfusion exhibited IRAK-M expression (Figure 1D–1G). To study cell-type specific changes in the timing of IRAK-M expression, we assessed IRAK-M mRNA levels in cardiac fibroblasts and CD11b+ leukocytes harvested from the infarcted heart. Isolated fibroblasts had a 3-fold increase in IRAK-M mRNA levels after 24 hours to 72 hours of reperfusion in comparison with control cardiac fibroblasts. When compared with control CD11b+ cells harvested from normal hearts, leukocytes isolated after 6 hours of reperfusion showed a trend toward increased IRAK-M mRNA expression (Figure I in the online-only Data Supplement). IRAK-M Loss Is Associated With Enhanced Adverse Remodeling Despite the Absence of Effects on the Size of the Infarct IRAK-M−null and WT animals had comparable mortality after myocardial infarction (P=NS). Triphenyltetrazolium chloride/Evans blue staining demonstrated that IRAK-M loss does not affect the size of the infarct after 1 hour of ischemia and 24 hours of reperfusion (Figure 1H–1J). Two independent techniques, echocardiographic imaging (Figure 2A–2G; Table I in the online-only Data Supplement) and quantitative morphometry (Figure 2H–2L), demonstrated that IRAK-M loss was associated with enhanced adverse remodeling after myocardial infarction. Systolic and diastolic chamber dimensions measured through echocardiography (left ventricular end-diastolic dimension, left ventricular end-systolic dimension, left ventricular end-systolic volume, and left ventricular end-diastolic volume; Figure 2A–2G) and morphometrically-derived left ventricular end-diastolic volume and left ventricular end-diastolic dimension (Figure 2H–2L) were significantly higher in IRAK-M−null mice after 7 and 28 days of reperfusion, indicating increased chamber dilation. Left ventricular mass was also significantly higher in infarcted IRAK-M−null hearts, suggesting accentuated hypertrophic remodeling. Increased adverse remodeling in the absence of IRAK-M was associated with reduced fractional shortening (FS), reflecting worse systolic dysfunction (Figure 2D). Because acute infarct size was comparable between WT and IRAK-M−null mice (Figure 1H–1J), accentuated adverse remodeling in IRAK-M−null hearts was not a result of more extensive cardiomyocyte injury. Moreover, scar size after 7 to 28 days of reperfusion was comparable between IRAK-M−/− and WT animals (Figure 2I). IRAK-M−/− Mice Have Enhanced Postinfarction Inflammation Exhibiting Increased Myocardial Cytokine mRN ||| Diabetes mellitus is associated with cardiac fibrosis. Matricellular proteins are induced in fibrotic conditions and modulate fibrogenic and angiogenic responses by regulating growth factor signaling. Our aim was to test the hypothesis that the prototypical matricellular protein thrombospondin (TSP)-1, a potent angiostatic molecule and crucial activator of transforming growth factor-β, may play a key role in remodeling of the diabetic heart. Obese diabetic db/db mice exhibited marked myocardial TSP-1 upregulation in the interstitial and perivascular space. To study the role of TSP-1 in remodeling of the diabetic heart, we generated and characterized db/db TSP-1–/– (dbTSP) mice. TSP-1 disruption did not significantly affect weight gain and metabolic function in db/db animals. When compared with db/db animals, dbTSP mice had increased left ventricular dilation associated with mild nonprogressive systolic dysfunction. Chamber dilation in dbTSP mice was associated with decreased myocardial collagen content and accentuated matrix metalloproteinase-2 and -9 activity. TSP-1 disruption did not affect inflammatory gene expression and activation of transforming growth factor-β/small mothers against decapendaplegic signaling in the db/db myocardium. In cardiac fibroblasts populating collagen pads, TSP-1 incorporation into the matrix did not activate transforming growth factor-β responses, but inhibited leptin-induced matrix metalloproteinase-2 activation. TSP-1 disruption abrogated age-associated capillary rarefaction in db/db mice, attenuating myocardial upregulation of angiopoietin-2, a mediator that induces vascular regression. In vitro, TSP-1 stimulation increased macrophage, but not endothelial cell, angiopoietin-2 synthesis. Conclusions: TSP-1 upregulation in the diabetic heart prevents chamber dilation by exerting matrix-preserving actions on cardiac fibroblasts and mediates capillary rarefaction through effects that may involve angiopoietin-2 upregulation.","metalloproteinases, cytokines, matrix metalloproteinases, immune system, macrophages, thrombospondins, fibrosis, cardiac remodeling, ventricular remodeling, diabetic cardiomyopathies","This study investigates the role of Interleukin-1 receptor-associated kinase (IRAK)-M in myocardial infarction.  Key findings include: 

* IRAK-M mRNA is significantly upregulated in the infarcted myocardium, with a biphasic response.
* IRAK-M is localized in macrophages and myofibroblasts within the infarcted heart.
* IRAK-M loss is associated with enhanced adverse remodeling after myocardial infarction, characterized by increased chamber dilation and hypertrophy, despite no effect on infarct size.
* IRAK-M−/− mice exhibit increased postinfarction inflammation with elevated myocardial cytokine mRNA levels. ||| This study investigates the role of thrombospondin-1 (TSP-1) in diabetic cardiomyopathy. Researchers found that TSP-1 is upregulated in the hearts of diabetic mice and that its loss attenuates cardiac fibrosis and enhances myocardial protease activity. However, TSP-1 disruption also led to mild left ventricular dilation and modest nonprogressive systolic dysfunction. These findings suggest that TSP-1 plays a complex role in diabetic heart remodeling, with both beneficial and detrimental effects."
Marcin Wo´zniak,Recent Developments in Plant Leaf Disease Identification and Classification,"In the modern era, deep learning techniques have emerged as powerful tools in image recognition. Convolutional Neural Networks, one of the deep learning tools, have attained an impressive outcome in this area. The effectiveness of Convolutional Neural Networks in image recognition motivates the researchers to extend its applications in the field of agriculture for recognition of plant species, yield management, weed detection, soil, and water management, fruit counting, diseases, and pest detection, evaluating the nutrient status of plants, and much more.","leaf, deep learning models, disease, survey, deep learning, machine learning models, plant leaf disease identification, agriculture, convolutional neural networks","This manuscript presents a survey of the existing literature in applying deep Convolutional Neural Networks to predict plant diseases from leaf images. It presents an exemplary comparison of the pre-processing techniques, Convolutional Neural Network models, frameworks, and optimization techniques applied to detect and classify plant diseases using leaf images as a data set."
Marissa Becker,"Seroprevalence of SARS-CoV-2 Antibodies in Uttar Pradesh, India: A Cross-Sectional Study","Population-based serological antibody test for SARS-CoV-2 infection helps in estimating the exposure in the community. We present the findings of the first district representative seroepidemiological survey conducted between 4 and 10 September 2020 among the population aged 5 years and above in the state of Uttar Pradesh, India. Multi-stage cluster sampling was used to select participants from 495 primary sampling units (villages in rural areas and wards in urban areas) across 11 selected districts to provide district-level seroprevalence disaggregated by place of residence (rural/urban), age (5–17 years/aged 18 +) and gender. A venous blood sample was collected to determine seroprevalence. Of 16,012 individuals enrolled in the study, 22.2% [95% CI 21.5–22.9] equating to about 10.4 million population in 11 districts were already exposed to SARS-CoV-2 infection by mid-September 2020. The overall seroprevalence was significantly higher in urban areas (30.6%, 95% CI 29.4–31.7) compared to rural areas (14.7%, 95% CI 13.9–15.6), and among aged 18 + years (23.2%, 95% CI 22.4–24.0) compared to aged 5–17 years (18.4%, 95% CI 17.0–19.9). No differences were observed by gender. Individuals exposed to a COVID confirmed case or residing in a COVID containment zone had higher seroprevalence (34.5% and 26.0%, respectively). There was also a wide variation (10.7–33.0%) in seropositivity across 11 districts indicating that population exposed to COVID was not uniform at the time of the study. Since about 78% of the population (36.5 million) in these districts were still susceptible to infection, public health measures remain essential to reduce further spread.","COVID-19, Seroprevalence, India, SARS-CoV-2, Heterogeneity, Uttar Pradesh","This study presents the first district-level seroprevalence survey of SARS-CoV-2 infection in Uttar Pradesh, India. Conducted in September 2020, the survey found that 22.2% of the population had been exposed to the virus by that time. Seroprevalence was significantly higher in urban areas and among individuals aged 18 and older. The findings highlight the importance of continued public health measures to reduce further spread of the virus."
Mark Hempstead,Design of Next-Generation Low-Power Sensor Network Nodes,This paper presents the design of next-generation low-power sensor network nodes that can scavenge energy from the environment and use this energy to power the sensor network device.,"Ultra Low Power System Architecture, Fine-Grain Power Management, low-power sensor network nodes, hardware acceleration, Sensor Network Applications, event-driven system, Event-Driven Computation, energy scavenging","The paper discusses the design of next-generation low-power sensor network nodes that can scavenge energy from the environment and use this energy to power the sensor network device. The system architecture is designed to be event-driven, with hardware accelerators offloading common tasks to improve performance and power efficiency."
Mark J. Mulligan,First-­in-­Human Study of Bamlanivimab in a Randomized Trial of Hospitalized Patients With COVID-­19,"This first-in-human study in hospitalized patients with COVID-19 was supported by studies assessing in vitro viral neutralization combined with a single-dose non-human primate PK study. The nonclinical safety package to support subsequent studies included tissue cross-reactivity studies on human, rat, and monkey tissues and an in vivo toxicology study.  A complete physical examination was conducted at the screening visit, and one of three bamlanivimab doses or placebo was administered i.v. at the baseline visit (D1) with infusion rates as follows: bamlanivimab 700 mg (50 mL) administered 100 mL/hr for 30 minutes; 2,800 mg (75 mL) administered 100 mL/hr for 45 minutes; and 7,000 mg administered 100 mL/hr for 60 minutes. Placebo infusion was 0.9% normal saline, administered at the same volume and rate as the corresponding bamlanivimab dose cohort. Safety and tolerability were reviewed for sentinel participants up to 24 hours after dosing, at which point the investigators and sponsor team determined whether safety and tolerability were acceptable to continue with dosing subsequent participants. The decision to dose the next cohort was made when all participants from the previous cohort had been dosed and safety data assessed for at least 4 days after the i.v. infusion by the investigators and sponsor team in consultation with an independent safety assessment committee. Blood samples were obtained for assessment of exploratory biomarkers, serology, clinical laboratory assessments, and PD on days 1, 3, 7, 11, 15, 22, and 29, and every 7 days until discharge or day 60, if still an inpatient. Samples for the virology assay were collected using nasopharyngeal (preferred) or mid-turbinate methods. Blood samples obtained for PK analyses were assessed on days 1 (pre-infusion and just before end of infusion), 4, 15, and 29, and follow-up visits up to day 60. Symptom-related physical examinations and assessments of clinical symptoms were performed on days 1, 2, 3, 4, 7, 11, 15, 22, and 29, and the day of discharge from the hospital, with additional follow-up examinations every 7 days thereafter until day 60 if the patient was not discharged from the hospital by day 29. Participants’ clinical status and concurrent procedures of special interest were recorded, including limitation on activities due to COVID-19 and any requirements for the following procedures of special interest, such as ongoing hospital medical care, supplemental oxygen, noninvasive ventilation or a high flow oxygen device, mechanical ventilation, extracorporeal membrane oxygenation, additional organ support, or consciousness status using alert, consciousness, verbal, pain, unresponsive scale. Hospitalization events were recorded, including dates of hospital admission and discharge, admission to the intensive care unit (ICU), discharge from the ICU, and discharge location including to an extended care facility or home. Outcomes The primary objective was to assess safety and tolerability, including adverse events (AEs), serious adverse events (SAEs), and discontinuations due to AEs. Other objectives included PKs (e.g., mean concentration at day 29); PD viral load, area under the response time curve (AUC, from day 1 to day 29), and change from baseline time course; total symptom score; time to symptom resolution; duration of hospitalization; National Institute of Allergy and Infectious Diseases (NIAID), World Health Organization (WHO) scales, and National Early Warning Score (NEWS2); and analysis of viral resistance. Any hypothesis tests were conducted for treatment comparisons without adjustment for multiplicity except for the evaluation of treatment effect on endogenous antibody titers. Success for the trial was claimed using a Bayesian criterion if any of the 3 bamlanivimab doses had at least 60% probability to reduce at least 30% mean AUC (28-day viral load) over placebo.",,"This first-in-human study evaluated the safety, tolerability, pharmacokinetics, clinical course, and viral dynamics of bamlanivimab, a fully human neutralizing monoclonal antibody targeting SARS-CoV-2, in hospitalized patients with moderate to severe COVID-19.  The study found bamlanivimab to be safe and well-tolerated, with no serious adverse events or deaths reported.  Further research is needed to determine the efficacy of bamlanivimab in treating COVID-19."
Martin ˇStˇepniˇcka,On the Suitability of the Bandler–Kohout Subproduct as an Inference Mechanism,"Fuzzy relational inference (FRI) systems form an important part of approximate reasoning schemes using fuzzy sets. The compositional rule of inference (CRI), which was introduced by Zadeh, has attracted the most attention so far. In this paper, we show that the FRI scheme that is based on the Bandler–Kohout (BK) subproduct, along with a suitable realization of the fuzzy rules, possesses all the important properties that are cited in favor of using CRI, viz., equivalent and reasonable conditions for their solvability, their interpolative properties, and the preservation of the indistinguishability that may be inherent in the input fuzzy sets. Moreover, we show that under certain conditions, the equivalence of first-infer-then-aggregate (FITA) and first-aggregate-then-infer (FATI) inference strategies can be shown for the BK subproduct, much like in the case of CRI. Finally, by addressing the computational complexity that may exist in the BK subproduct, we suggest a hierarchical inferencing scheme. Thus, this paper shows that the BK-subproduct-based FRI is as effective and efficient as the CRI itself.","compositional rule of inference (CRI), Fuzzy relational compositions, Inference mechanisms, Bandler–Kohout (BK) subproduct, Bandler–Kohout subproduct, correctness and continuity of inference, Fuzzy rule-based systems, Compositional rule of inference, fuzzy relational inference (FRI) systems, hierarchical CRI, fuzzy relational equations","This paper explores the suitability of the Bandler–Kohout subproduct as an inference mechanism in fuzzy relational inference systems. The authors compare the properties of the Bandler–Kohout subproduct with those of the compositional rule of inference and show that it possesses similar properties, including equivalent and reasonable conditions for solvability, interpolative properties, and preservation of indistinguishability. The authors also suggest a hierarchical inferencing scheme to address computational complexity and demonstrate the equivalence of first-infer-then-aggregate and first-aggregate-then-infer inference strategies under certain conditions."
Matt Mahoney,Hybrid Architecture for Sentiment Classification,"Evolution of plethora of e-commerce sites resulted in fierce competition among their providers. In order to acquire new and retain existing customers, various producers and market managers effectively employ online feedback analytics tools. Most of the online feedback analysis tools are built using sentiment analysis models. Sentiment analysis evolved in the last one and half decades for review mining process. An important sub-task of sentiment analysis called sentiment classification is used mainly to decide whether a written review is expressing either positive or negative sentiment towards a target entity. In order to have better sentiment classification accuracy, we proposed a hybrid deep learning architecture, which is a hybrid of a two layered Restricted Boltzmann Machine and a Probabilistic Neural Network. The proposed approach yielded better accuracy for five different datasets compared to the state-of-the-art.","Restricted Boltzmann Machine, PNN, Dimensionality reduction, Deep learning, sentiment classification, Online learning, RBM, Probabilistic neural network, Sentiment analysis","The proposed architecture is a hybrid of RBM and PNN, which performs dimensionality reduction and sentiment classification in an online learning process. The time complexity of the proposed architecture is O(I*B*n) + O(m), where I is the number of iterations, B is the batch size, and m is the number of samples."
Matthew Mouring,A Novel Algorithm for Bi-Level Image Coding and Lossless Compression based on Virtual Ant Colonies,"This paper presents a novel method for image compression using ant colony optimization. The algorithm works by representing the image as a virtual world where ants move and collect food. The coordinates of the ants and their movements are recorded and used to reconstruct the image. The algorithm consists of eight steps, including converting the image to a food-route representation, determining the coordinates of the image, dropping ants randomly, and recording the movements of the ants. The algorithm uses arithmetic coding to compress the string resulting from the movement of ants.","Ant Colonies, ant colony optimization, Binary Images, Proximity, image compression, Arithmetic Coding, Pheromone",The paper proposes a novel method for image compression using ant colony optimization. The algorithm works by representing the image as a virtual world where ants move and collect food. The algorithm consists of eight steps and uses arithmetic coding to compress the string resulting from the movement of ants.
Maurice Clerc,Spider Monkey Optimization algorithm for numerical optimization,"Swarm intelligence is one of the most promising area for the researchers in the field of numerical optimization. Researchers have developed many algorithms by simulating the swarming behavior of various creatures like ants, honey bees, fish, birds and the findings are very motivating. In this paper, a new approach for numerical optimization is proposed by modeling the foraging behavior of spider monkeys.","Fission–fusion social system, Spider Monkey Optimization algorithm, Optimization, Swarm intelligence based algorithm, foraging behavior, fission-fusion social structure, Spider monkey optimization, stochastic optimization",This paper proposes a new swarm intelligence algorithm based on the foraging behavior of spider monkeys. The foraging behavior of spider monkeys shows that these monkeys fall in the category of fission–fusion social structure (FFSS) based animals. Thus the proposed optimization algorithm which is based on foraging behavior of spider monkeys is explained better in terms of FFSS.
Mayank Sharan Awasthi,Analysing the Performance of Novel Activation Functions on Deep Learning Architectures,"Deep learning is a cutting-edge technology that functions similarly to the human nervous system. Neural networks are at the heart of Deep Learning. Neural networks are made up of numerous layers, in-cluding the input layer, which accepts raw data as input, hidden layers, which process the input data, and a final layer, the output layer, which provides the result. Its workflow pattern is comparable to machine learn-ing [2], [11], allowing us to gain hands-on expertise with this technology, speed up our work, and allow us to make several efforts without hav-ing to develop a basic Machine learning algorithm from scratch. In the case of deep learning, there are several neural networks to choose from. The majority of Deep Learning architectures are built on neural networks such as CNN, RNN, and others. Deep neural network activation function development is often guided by set goals and gradual steps toward tack-ling specific challenges. The primary goal of this study is to examine the performance of innovative activation functions (SBAF parabola [6] [16], AReLU [7], Leaky ReLU, SWISH) on deep learning architectures such as CNN, DENSENET, etc. On deep learning architectures, our study will compare the classification performance of the aforementioned activation functions.","Redundancy, Network reliability, Robotics, Embedded systems","This paper explores the performance of novel activation functions (SBAF parabola, AReLU, Leaky ReLU, SWISH) on deep learning architectures like CNN and DENSENET. The study aims to compare the classification accuracy of these activation functions on various computer vision datasets."
Mayank Swarnkar,Targeted DNS Spoofing Attack,"Domain Name System (DNS) is a central protocol of the internet and provides a way to resolve domain names to their corresponding IP addresses. Due to its working, it is one of the most critical protocols being used in the internet. However, DNS is known to be vulnerable to a popular attack called DNS poisoning. Fortunately, DNS poisoning has become difðcult to launch due to introduction of techniques like source port and query identiðcation value randomization. In this paper, we propose a targeted DNS spooðing attack that exploits a vulnerability present in DHCP server-side IP address conðict detection technique. We show that the proposed attack is easier to launch and requires minimal bandwidth as compared to previously known attacks. We also discuss how proposed attack can target even a single victim client also without affecting other clients. We test the effectiveness of proposed attack in a real network setup and report the results. Further, we discuss how known detection and mitigation techniques are unable to detect the attack.","Vulnerability, targeted attack, DNS Spooðing, DHCP manipulation, DNS, Local Networks, network configuration, DNS spoofing, DHCP",This paper proposes a targeted DNS spooðing attack that exploits a vulnerability in DHCP server-side IP address conðict detection technique. The attack is easier to launch and requires minimal bandwidth compared to previously known attacks. The paper also discusses how the proposed attack can target a single victim client without affecting other clients.
McKeeman,Fifty years of peephole optimization,"Peephole optimization is a technique used in compilers to improve the performance of object programs by replacing sequences of instructions with equivalent single instructions. This article reviews the history and development of peephole optimization, including its application to various programming languages and target machines.","compilers, object programs, peephole optimization, Code generators, instruction sequences, replacement rules","Peephole optimization has been widely used in compilers to improve the performance of object programs. The technique involves replacing sequences of instructions with equivalent single instructions, and has been applied to various programming languages and target machines. The effectiveness of peephole optimization depends on several factors, including the nature of the source language, the parsing and code generation techniques used in the compiler, and the specifications of the target machine."
Md. Asif-Ur-Rahman,"Toward a Heterogeneous Mist, Fog, and Cloud-Based Framework for the Internet of Healthcare Things","Rapid developments in the fields of information and communication technology and microelectronics allowed seamless interconnection among various devices letting them to communicate with each other. This technological integration opened up new possibilities in many disciplines including healthcare and well-being. With the aim of reducing healthcare costs and providing improved and reliable services, several healthcare frameworks based on Internet of Healthcare Things (IoHT) have been developed. However, due to the critical and heterogeneous nature of healthcare data, maintaining high quality of service (QoS)—in terms of faster responsiveness and data-specific complex analytics—has always been the main challenge in designing such systems. Addressing these issues, this paper proposes a five-layered heterogeneous mist, fog, and cloud-based IoHT framework capable of efficiently handling and routing (near-)real-time as well as offline/batch mode data. Also, by employing software defined networking and link adaptation-based load balancing, the framework ensures optimal resource allocation and efficient resource utilization. The results, obtained by simulating the framework, indicate that the designed network via its various components can achieve high QoS, with reduced end-to-end latency and packet drop rate, which is essential for developing next generation e-healthcare systems.","QoS, healthcare big data, load balancing, healthcare application, healthcare, e-healthcare, IoHT, fog computing, quality of service (QoS), reduced latency, IoT, mist computing, Data fusion, cloud computing, heterogeneous framework, low power consumption, real-time computing, resource allocation","This paper proposes a five-layered heterogeneous mist, fog, and cloud-based Internet of Healthcare Things (IoHT) framework to efficiently handle and route healthcare data. The framework employs software defined networking and link adaptation-based load balancing to ensure optimal resource allocation and efficient resource utilization. The results show that the designed network can achieve high quality of service with reduced latency and packet drop rate, making it essential for developing next generation e-healthcare systems."
Meet Ganpatlal Oza,A deep learning model for mass screening of COVID-19,"The objective of this research is to develop a convolutional neural network model ‘COVID-Screen-Net’ for multi-class classification of chest X-ray images into three classes viz. COVID-19, bacterial pneumonia, and normal.","COVID-19, deep learning, X-ray, global pandemic, CNN model, Corona",The authors developed a deep learning model ‘COVID-Screen-Net’ for mass screening of COVID-19 from chest X-ray images. The model achieves an average accuracy of 97.71% and a maximum recall of 100%. It outperforms existing systems for screening of COVID-19 and may prove a useful tool for quick and low-cost mass screening of patients.
Mehul Gulati,Predicting pattern of coronavirus using X-ray and CT scan images,Novel coronavirus is a disease that can propagate easily with very minute carelessness and with very little physical contact between people.,"CT scan, COVID-19, Convolutional Neural Networks, CXR images, Convolutional Neural Network (CNN), Deep learning, X-ray, Coronavirus, Prediction",A lightweight deep learning model is proposed to automate and analyze the diagnostic process by utilizing Convolutional Neural Network (CNN) for predicting the pattern of coronavirus using X-ray and CT scan images.
Meirav Holmdahld,ROS deficiency enhanced mannan-induced PsA,"In and joint inflammation using B10Q.Ncf1m1j/m1j mice that have a mutation in the Ncf1 gene (m1j) (the Ncf1 protein also denoted p47phox), and hence reduced ROS production (oxidative burst) (18). As shown in Fig. 1D, Ncf1 mutated mice developed severe joint inflammation within 2 d after mannan injection, which reached the mean maximal disease severity (30 ± 6 points) within 4 d. The frequency of skin lesions was 100%, with more severe cases in B10Q.Ncf1m1j/m1j mice (Fig. 1E), whereas B10.Q mice had a significantly milder disease course. Multiple Exposures to Mannan Induced a Relapsing Disease. Next, we examined the effect of multiple mannan injections in B10Q and B10Q.Ncf1m1j/m1j mice. We boosted mice twice with mannan on days 7 and 14 after disease initiation. Repetitive injections of mannan reproduced the arthritis phenotype, which reached the maximum severity level on days 9 and 17, similar to the first injection (Fig. 1F). A more severe disease course was observed in B10Q.Ncf1m1j/m1j mice than in B10Q mice (P < 0.05 and P < 0.01, respectively). Interestingly, Ps skin scaling returned only after the second mannan injection (on day 16), but the skin peeled off even more quickly than the first time (Fig. 1G). Moreover, from day 11 onward, B10Q.Ncf1m1j/m1j mice started to develop pruritus on the body, predominantly on the back and above the eye (Fig. S1E). Pruritus was only evident in B10Q.Ncf1m1j/m1j mice, but flaky skin on the tail and alopecia all over the leg was observed in both of the mouse strains. We also observed genetic heterogeneity in disease susceptibility (Fig. Fig. 1. ROS deficiency enhanced mannan-induced PsA. The arthritic joint phenotype and Ps-like skin lesions in the front (A) and hind (B) paws of B10Q.Ncf1m1j/m1j mice are shown. (C) Ps-like skin scaling in diseased B10Q.Ncf1m1j/m1j mouse ear compared with naive mouse ear. Mean arthritis (D) and Ps lesion (E) severity in B10Q (n = 5) and B10Q.Ncf1m1j/m1j (n = 5) mice after a single i.p. mannan injection. Mean arthritis (F) and Ps lesion (G) severity in B10Q (n = 5) and B10Q.Ncf1m1j/m1j (n = 5) mice after repetitive mannan injections (days 7 and 14). (H) Mannan-induced mean maximum arthritis scores ± SEM in different mouse strains: B10Q (n = 8), B10Q.Ncf1m1j/m1j (n = 9), B10RIII (n = 10), B10RIII.Ncf1m1j/m1j (n = 9), B10P (n = 3), B10P.Ncf1m1j/m1j (n = 9), BALB/cByJ/Q (n = 10), BALB/cByJ/Q.Ncf1m1j/m1j (n = 8), BALB/cByJ (n = 5), BALB/cByJ.Ncf1m1j/m1j (n = 7), C57BL/6NJ (n = 8), and C57BL/6NJ.Ncf1m1j/m1j (n = 7). Significance was calculated by comparing the maximal disease severity of B10Q and B10Q.Ncf1m1j/m1j mice with all of the other strains in their respective groups. *P < 0.05; **P < 0.01; ***P < 0.001. E3670 | www.pnas.org/cgi/doi/10.1073/pnas.1405798111 Khmaladze et al. Downloaded from https://www.pnas.org by 122.184.65.228 on February 22, 2023 from IP address 122.184.65.228.","autoimmune disease, Ncf1, animal model","This study identifies a new mechanism for psoriasis (Ps) and psoriasis arthritis (PsA) development in mice. A single injection of mannan, a component of baker's yeast, induced Ps and PsA-like symptoms. This effect was exacerbated in mice lacking reactive oxygen species (ROS), but improved when ROS production was restored in macrophages.  Blocking IL-17A, a cytokine produced by gamma delta T cells, completely prevented disease. The study suggests that mannan activates macrophages, leading to TNF-α secretion and stimulation of IL-17A production by gamma delta T cells. This, in turn, drives neutrophil infiltration and inflammation, mimicking Ps and PsA. This new mouse model could be valuable for testing new therapies for Ps and PsA."
Meng Joo Er,A Review of Clustering Techniques and Developments,"This paper presents a comprehensive study on clustering: exiting methods and developments made at various times. Clustering is defined as an unsupervised learning where the objects are grouped on the basis of some similarity inherent among them. There are different methods for clustering the objects such as hierarchical, partitional, grid, density based and model based. The approaches used in these methods are discussed with their respective states of art and applicability. The measures of similarity as well as the evaluation criteria, which are the central components of clustering are also presented in the paper. The applications of clustering in some fields like image segmentation, object and character recognition and data mining are highlighted.","Data mining, ROCK, Taxonomy, Unsupervised learning, Similarity measures, CURE, Clustering, Hierarchical Clustering, Clustering Approaches, CHAMELEON, Pattern recognition, BIRCH","This paper reviews clustering techniques and developments, discussing methods such as hierarchical, partitional, grid, density-based, and model-based clustering, as well as measures of similarity and evaluation criteria. The applications of clustering in fields like image segmentation, object recognition, and data mining are highlighted."
Michael Dougan,First-­in-­Human Study of Bamlanivimab in a Randomized Trial of Hospitalized Patients With COVID-­19,"This first-in-human study in hospitalized patients with COVID-19 was supported by studies assessing in vitro viral neutralization combined with a single-dose non-human primate PK study. The nonclinical safety package to support subsequent studies included tissue cross-reactivity studies on human, rat, and monkey tissues and an in vivo toxicology study.  A complete physical examination was conducted at the screening visit, and one of three bamlanivimab doses or placebo was administered i.v. at the baseline visit (D1) with infusion rates as follows: bamlanivimab 700 mg (50 mL) administered 100 mL/hr for 30 minutes; 2,800 mg (75 mL) administered 100 mL/hr for 45 minutes; and 7,000 mg administered 100 mL/hr for 60 minutes. Placebo infusion was 0.9% normal saline, administered at the same volume and rate as the corresponding bamlanivimab dose cohort. Safety and tolerability were reviewed for sentinel participants up to 24 hours after dosing, at which point the investigators and sponsor team determined whether safety and tolerability were acceptable to continue with dosing subsequent participants. The decision to dose the next cohort was made when all participants from the previous cohort had been dosed and safety data assessed for at least 4 days after the i.v. infusion by the investigators and sponsor team in consultation with an independent safety assessment committee. Blood samples were obtained for assessment of exploratory biomarkers, serology, clinical laboratory assessments, and PD on days 1, 3, 7, 11, 15, 22, and 29, and every 7 days until discharge or day 60, if still an inpatient. Samples for the virology assay were collected using nasopharyngeal (preferred) or mid-turbinate methods. Blood samples obtained for PK analyses were assessed on days 1 (pre-infusion and just before end of infusion), 4, 15, and 29, and follow-up visits up to day 60. Symptom-related physical examinations and assessments of clinical symptoms were performed on days 1, 2, 3, 4, 7, 11, 15, 22, and 29, and the day of discharge from the hospital, with additional follow-up examinations every 7 days thereafter until day 60 if the patient was not discharged from the hospital by day 29. Participants’ clinical status and concurrent procedures of special interest were recorded, including limitation on activities due to COVID-19 and any requirements for the following procedures of special interest, such as ongoing hospital medical care, supplemental oxygen, noninvasive ventilation or a high flow oxygen device, mechanical ventilation, extracorporeal membrane oxygenation, additional organ support, or consciousness status using alert, consciousness, verbal, pain, unresponsive scale. Hospitalization events were recorded, including dates of hospital admission and discharge, admission to the intensive care unit (ICU), discharge from the ICU, and discharge location including to an extended care facility or home. Outcomes The primary objective was to assess safety and tolerability, including adverse events (AEs), serious adverse events (SAEs), and discontinuations due to AEs. Other objectives included PKs (e.g., mean concentration at day 29); PD viral load, area under the response time curve (AUC, from day 1 to day 29), and change from baseline time course; total symptom score; time to symptom resolution; duration of hospitalization; National Institute of Allergy and Infectious Diseases (NIAID), World Health Organization (WHO) scales, and National Early Warning Score (NEWS2); and analysis of viral resistance. Any hypothesis tests were conducted for treatment comparisons without adjustment for multiplicity except for the evaluation of treatment effect on endogenous antibody titers. Success for the trial was claimed using a Bayesian criterion if any of the 3 bamlanivimab doses had at least 60% probability to reduce at least 30% mean AUC (28-day viral load) over placebo.",,"This first-in-human study evaluated the safety, tolerability, pharmacokinetics, clinical course, and viral dynamics of bamlanivimab, a fully human neutralizing monoclonal antibody targeting SARS-CoV-2, in hospitalized patients with moderate to severe COVID-19.  The study found bamlanivimab to be safe and well-tolerated, with no serious adverse events or deaths reported.  Further research is needed to determine the efficacy of bamlanivimab in treating COVID-19."
Michalak et. al.,Rumour Source Detection Using Game Theory,"Social networks have become a critical part of our lives as they enable us to interact with a lot of people. These networks have become the main sources for creating, sharing and also extracting information regarding various subjects. But all this information may not be true and may contain a lot of unverified rumours that have the potential of spreading incorrect information to the masses, which may even lead to situations of widespread panic. Thus, it is of great importance to identify those nodes and edges that play a crucial role in a network in order to find the most influential sources of rumour spreading. Generally, the basic idea is to classify the nodes and edges in a network with the highest criticality. Most of the existing work regarding the same focuses on using simple centrality measures which focus on the individual contribution of a node in a network. Game-theoretic approaches such as Shapley Value (SV) algorithms suggest that individual marginal contribution should be measured for a given player as the weighted average marginal increase in the yield of any coalition that this player might join. For our experiment, we have played five SV-based games to find the top 10 most influential nodes on three network datasets (Enron, USAir97 and Les Misérables). We have compared our results to the ones obtained by using primitive centrality measures. Our results show that SV-based approach is better at understanding the marginal contribution, and therefore the actual influence, of each node to the entire network.","influential nodes, Jaccard Similarity Coefficient, cooperative game, Rumour Source Detection (RSD), centrality measures, network analysis, Shapley Value (SV), Game-Theory, Network Centrality",This paper aims to identify the most influential nodes in a network that are the primary sources of rumour propagation. The authors propose a game-theoretic approach using the Shapley Value algorithm to find the most influential nodes. They compare their results with primitive centrality measures and show that the SV-based approach is better at understanding the marginal contribution of each node to the entire network.
Michał Baczyński,Yager’s Classes of Fuzzy Implications: Some Properties and Intersections,"Recently, Yager in the article “On some new classes of implication operators and their role in approximate reasoning” [12] has introduced two new classes of fuzzy implications called the f-generated and g-generated implications. Along similar lines, one of us has proposed another class of fuzzy implications called the h-generated implications. In this article we discuss in detail some properties of the above mentioned classes of fuzzy implications and we describe their relationships amongst themselves and with the well established (S, N)-implications and R-implications. In the cases where they intersect the precise sub-families have been determined.","fuzzy implication, S-implication, R-implication, f-generated implication, (S; N)-implication, h-generated implication, g-generated implication","This paper discusses the properties and intersections of Yager’s classes of fuzzy implications, including f-generated, g-generated, and h-generated implications, as well as their relationships with (S, N)-implications and R-implications."
Michele Cavalera,TSP-1 in Diabetic Cardiomyopathy,"Diabetes mellitus is associated with cardiac fibrosis. Matricellular proteins are induced in fibrotic conditions and modulate fibrogenic and angiogenic responses by regulating growth factor signaling. Our aim was to test the hypothesis that the prototypical matricellular protein thrombospondin (TSP)-1, a potent angiostatic molecule and crucial activator of transforming growth factor-β, may play a key role in remodeling of the diabetic heart. Obese diabetic db/db mice exhibited marked myocardial TSP-1 upregulation in the interstitial and perivascular space. To study the role of TSP-1 in remodeling of the diabetic heart, we generated and characterized db/db TSP-1–/– (dbTSP) mice. TSP-1 disruption did not significantly affect weight gain and metabolic function in db/db animals. When compared with db/db animals, dbTSP mice had increased left ventricular dilation associated with mild nonprogressive systolic dysfunction. Chamber dilation in dbTSP mice was associated with decreased myocardial collagen content and accentuated matrix metalloproteinase-2 and -9 activity. TSP-1 disruption did not affect inflammatory gene expression and activation of transforming growth factor-β/small mothers against decapendaplegic signaling in the db/db myocardium. In cardiac fibroblasts populating collagen pads, TSP-1 incorporation into the matrix did not activate transforming growth factor-β responses, but inhibited leptin-induced matrix metalloproteinase-2 activation. TSP-1 disruption abrogated age-associated capillary rarefaction in db/db mice, attenuating myocardial upregulation of angiopoietin-2, a mediator that induces vascular regression. In vitro, TSP-1 stimulation increased macrophage, but not endothelial cell, angiopoietin-2 synthesis. Conclusions: TSP-1 upregulation in the diabetic heart prevents chamber dilation by exerting matrix-preserving actions on cardiac fibroblasts and mediates capillary rarefaction through effects that may involve angiopoietin-2 upregulation.","matrix metalloproteinases, thrombospondins, fibrosis, diabetic cardiomyopathies, ventricular remodeling","This study investigates the role of thrombospondin-1 (TSP-1) in diabetic cardiomyopathy. Researchers found that TSP-1 is upregulated in the hearts of diabetic mice and that its loss attenuates cardiac fibrosis and enhances myocardial protease activity. However, TSP-1 disruption also led to mild left ventricular dilation and modest nonprogressive systolic dysfunction. These findings suggest that TSP-1 plays a complex role in diabetic heart remodeling, with both beneficial and detrimental effects."
Michelle Miller,BELIMUMAB IN PATIENTS OF BLACK AFRICAN ANCESTRY,"Study design. SELENA–SLEDAI = Safety of Estrogens in Lupus Erythematosus National Assessment–Systemic Lupus Erythemato-sus Disease Activity Index; IV = intravenous.

Randomization and treatment. Using an interactive voice/web response system, patients receiving standard therapy were randomized 2:1 to receive either belimumab 10 mg/kg IV or placebo, which was administered on days 0, 14, and 28 and every 28 days thereafter up to week 48, with a final evaluation at week 52. Randomization was stratified by screening SELENA–SLEDAI score (≤9 versus ≥10), region (US/Canada versus rest of world), and complement level (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]). Detailed randomization data are provided in Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Patients who successfully completed the initial 52-week double-blind phase could enter an optional 6-month open-label extension phase, during which they received belimumab 10 mg/kg IV every 28 days plus standard therapy, irrespective of their previous study assignment. The first dose was given at the week 52 (day 364) visit of the double-blind period (day 1 of the open-label extension phase). Patients who completed the 52-week double-blind phase, but did not enter the 6-month open-label extension phase, were required to return for an additional follow-up visit 8 weeks after their last dose. Patients who withdrew early were required to return for an exit visit 4 weeks after their last dose and a follow-up visit 8 weeks after their last dose.

The original protocol plan was to randomize 816 patients, providing ≥90% power to detect ≥12% absolute improvement in the SRI response rate in the belimumab group compared with the placebo group at a 5% significance level. Due to enrollment challenges, a revised sample size was calculated to include 501 patients (≥334 patients in the belimumab group and ≥167 patients in the placebo group). This sample size provided ≥90% power to detect a minimum 15.55% absolute improvement in SRI–SLEDAI-2K response rate in the belimumab group relative to the placebo group at a 5% significance level (based on the pooled data from efficacy studies BEL112341 and BEL113750) (15,21). These calculations assumed a placebo response rate of 43.95% at week 52.

Study end points and assessments. The primary efficacy end point was the SRI–SLEDAI-2K response rate (defined in the Supplementary Material) at week 52 of the double-blind phase. Unlike in the phase II and phase III studies, the SRI–SLEDAI-2K was selected because of the simplification it offers in proteinuria assessment as compared with the SELENA–SLEDAI proteinuria component; both are clinically meaningful (22). The primary efficacy end point for the open-label extension phase was SRI–SLEDAI-2K response rate at open-label extension week 24. If the open-label extension week 24 data were missing, data from the open-label extension week 28/exit visit were used. This time point is referred to as “open-label extension week 24” throughout the text. Data related to the primary efficacy end point, e.g., the response rate over time, percentage of patients with a durable SRI–SLEDAI-2K response from week 44 through week 52, time to first SRI–SLEDAI-2K response that was maintained through week 52, and duration of longest SRI–SLEDAI-2K response among patients with ≥1 SRI–SLEDAI-2K responses were summarized.

The key secondary end points were SRI–SELENA–SLEDAI at week 52 (open-label extension week 24), time to first severe SLE flare (measured by the SELENA–SLEDAI flare index [SFI]), and proportion of patients whose average prednisone dose had been reduced by ≥25% from baseline to ≤7.5 mg/day during week 40 through week 52 (open-label extension week 28/exit visit), in patients receiving >7.5 mg/day at baseline. Key renal end points included time to first renal flare over 52 weeks and over 28 weeks in the open-label extension, SELENA–SLEDAI–SLEDAI-2K renal domain improvement at week 52, SELENA–SLEDAI–SLEDAI-2K renal domain worsening at week 52, percentage reduction in proteinuria by visit and at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours, and proteinuria shift at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours. Renal flare is defined in the Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Biomarkers measured included percentage changes in serum IgG level, anti-dsDNA antibody level (in those who were anti-dsDNA positive [≥30 IU/ml] at baseline), and complement (C3 and C4) levels from baseline. Safety was evaluated by monitoring adverse events (AEs), serious AEs (SAEs), AEs of special interest, vital signs, clinical laboratory test results, and immunogenicity up to 8 weeks posttreatment and throughout the open-label extension phase.

Data analyses. For the double-blind phase, safety analyses were performed on the safety population, defined as all patients who were randomized and treated with at least 1 dose of investigational product. Data on the safety population were summarized according to the treatment the patient was randomized to receive rather than by the treatment that was received, but both were the same for this study. Efficacy analyses were performed on the modified intent-to-treat (ITT) population, defined as the safety population minus those patients who had any assessment at any of 3 study sites that were excluded from the efficacy analyses before the database lock because of potential Good Clinical Practice noncompliance.

For analysis of the primary and 3 key secondary efficacy end points, a step-down sequential testing procedure was used as described in the Supplementary Material. The following subgroup analyses were performed for the primary analysis (SRI–SLEDAI-2K response at week 52): region (US/Canada versus rest of world), baseline SELENA–SLEDAI–SLEDAI-2K score (≤9 versus ≥10), baseline anti-dsDNA antibody level (≥30 IU/ml versus <30 IU/ml), baseline complement levels (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]), and baseline complement and anti-dsDNA antibody levels (≥1 test finding showing low C3/C4 and anti-dsDNA ≥30 IU/ml versus C3/C4 other and anti-dsDNA ≥30 IU/ml). The odds of an SRI–SLEDAI-2K response with belimumab treatment versus placebo were estimated using logistic regression analysis.

For the open-label extension phase, all patients received belimumab, no formal statistical hypothesis t",,"This study investigated the efficacy and safety of belimumab in patients of Black African ancestry with systemic lupus erythematosus (SLE).  Patients were randomized to receive belimumab or placebo for 52 weeks, followed by an optional 6-month open-label extension phase. The primary efficacy endpoint was the SRI–SLEDAI-2K response rate at week 52.  Key secondary endpoints included SRI–SELENA–SLEDAI at week 52, time to first severe SLE flare, and proportion of patients with a reduction in prednisone dose. Renal and biomarker assessments were also conducted.  The study found that belimumab was effective in improving SLE disease activity and reducing renal flares in patients of Black African ancestry."
Milind Ratnaparkhe,A Novel Scalable Apache Spark Based Feature Extraction Approaches for Huge Protein Sequence and their Clustering Performance Analysis,"Genome sequencing projects are rapidly increasing the number of high-dimensional protein sequence datasets. Clustering a high-dimensional protein sequence dataset using traditional machine learning approaches poses many challenges. Many different feature extraction methods exist and are widely used. However, extracting features from millions of protein sequences becomes impractical because they are not scalable with current algorithms. Therefore, there is a need for an efficient feature extraction approach that extracts significant features. We have proposed two scalable feature extraction approaches for extracting features from huge protein sequences using Apache Spark, which are termed 60d-SPF (60-dimensional Scalable Protein Feature) and 6d-SCPSF (6-dimensional Scalable Co-occurrence-based Probability-Speciﬁc Feature). The proposed 60d-SPF and 6d-SCPSF approaches capture the statistical properties of amino acids to create a fixed-length numeric feature vector that represents each protein sequence in terms of 60-dimensional and 6-dimensional features, respectively.","Big Data, protein sequences, Fuzzy Clustering, Scalable Algorithms, Apache Spark Cluster, Feature Extraction, Apache Spark, Huge Protein Sequences","This paper proposes two scalable feature extraction approaches for huge protein sequences using Apache Spark, which are termed 60d-SPF and 6d-SCPSF. The proposed approaches capture the statistical properties of amino acids to create a fixed-length numeric feature vector that represents each protein sequence in terms of 60-dimensional and 6-dimensional features, respectively. The paper also discusses the clustering of huge protein sequences using SRSIO-FCM and SLFCM algorithms."
"Mimi Y. Kim, ScD",Cardiac Neonatal Lupus: Maternal and Fetal Risk Factors for Mortality,"Background: Cardiac neonatal lupus (CNL) is a serious complication of maternal anti-Ro/SSA and anti-La/SSB antibodies.  We sought to identify maternal and fetal risk factors for mortality in infants with CNL.

Methods and Results: We retrospectively analyzed data from 325 infants with CNL born to 297 mothers. Overall, 57 deaths (17.5%) occurred. Hydrops, carditis, and EFE were associated with increased mortality in both in utero and postnatal deaths. Maternal diagnosis of SLE and/or SS was associated with increased mortality in the overall analysis and in utero deaths.  Whites were less likely to die than minorities.

Conclusions: Hydrops, carditis, EFE, and maternal SLE and/or SS are significant risk factors for mortality in infants with CNL.","mortality, morbidity, cardiomyopathy, antibodies, heart block","This study investigates maternal and fetal risk factors for mortality in infants with cardiac neonatal lupus (CNL).  Key findings include the significant association of hydrops, carditis, EFE, and maternal SLE and/or SS with increased mortality. Additionally, white infants were found to have a lower mortality rate compared to minorities."
Ming Zhang,Encrypted Domain Camera Attribution,"Photo Response Non-Uniformity (PRNU) noise-based source camera attribution is a popular digital forensic method. In this method, a camera fingerprint computed from a set of known images of the camera is matched against the extracted noise of an anonymous questionable image to find out if the camera had taken the anonymous image.","PRNU-based camera attribution, Camera Fingerprinting, utility, Privacy, camera attribution, Secure computation, encrypted domain",The proposed method is based on a secure multi-party computation scheme that enables a third-party entity to perform camera attribution tasks without accessing the sensitive image data. The method uses a combination of homomorphic encryption and secure multi-party computation to ensure both utility and privacy.
Mingsong Cheng,Convergence Analysis of Online Gradient Methods for Feedforward Neural Networks,"This paper considers a class of online gradient learning methods for backpropagation (BP) neural networks with a single hidden layer. We assume that in each training cycle, each sample in the training set is supplied in a stochastic order to the network exactly once. It is interesting that these stochastic learning methods can be shown to be deterministically convergent. This paper presents some weak and strong convergence results for the learning methods, indicating that the gradient of the error function goes to zero and the weight sequence goes to a fixed point, respectively. The conditions on the activation function and the learning rate to guarantee the convergence are relaxed compared with the existing results. Our convergence results are valid for not only S–S type neural networks (both the output and hidden neurons are Sigmoid functions), but also for P–P, P–S and S–P type neural networks, where S and P represent Sigmoid and polynomial functions, respectively.","Backpropagation learning, Strong convergence, feedforward neural networks, Online gradient method, convergence analysis, OGM-SS, Weak convergence, online gradient methods, Neural networks, OGM-F","This paper presents a comprehensive study on the weak and strong convergence for OGM-F and OGM-SS, indicating that the gradient of the error function goes to zero and the weight sequence goes to a fixed point, respectively. The conditions on the activation function and the learning rate to guarantee the convergence are much relaxed compared with the existing results."
Minni Jain,"An Emotion-Based Multi-Task Approach to Fake News Detection ||| Early Detection of Alzheimer’s Disease using Deep Learning Models and Word Embeddings ||| L,M&A: An Algorithm for Music Lyrics Mining and Sentiment Analysis ||| Semi Supervised Graph Based Keyword Extraction Using Lexical Chains and Centrality Measures","Social media, blogs, and online articles are instant sources of news for internet users globally. But due to their unmoderated nature, a significant percentage of these texts are fake news or rumors. Their deceptive nature and ability to propagate instantly can have an adverse effect on society. In this work, we hypothesize that legitimacy of news has a correlation with its emotion, and propose a multi-task framework predicting both the emotion and legitimacy of news. Experimental results verify that our multi-task models outperform their single-task counterparts in terms of accuracy. ||| Alzheimer’s Disease (AD) is an irrecoverable, progressive neurodegenerative disorder that deteriorates the cognitive and linguistic abilities of a person over time. Ample research has been done on the early detection of AD; it remains a challenging task. Doctors use the patient’s history, laboratory tests, and change in behaviour to diagnose the disease. Natural Language Processing(NLP) techniques can help automate the detection of AD, as Language impairments accompany this disease. This work aims to analyze the effect of different Embedding models on the DementiaBank dataset in order to detect the disease. ||| Here we propose an open source algorithm, L,M&A(Lyrics, Mine and Analyse) to create a dataset of lyrics of the works of various artists. The aim of this approach is to facilitate the generation of a large data set that can be used for improving accuracy of song recommendation algorithms. ||| This paper proposes a semi-supervised graph-based keyword extraction algorithm using lexical chains and centrality measures. The algorithm first extracts nouns from each paragraph and creates lexical chains based on the similarity between words. The chains are then scored using two different methods, and the best chains are selected based on their scores. The selected chains are used to create a graph, and centrality measures are applied to identify the most central words as the extracted keywords.","Semi-supervised learning, musicology, Sentiment Analysis, musixmatch, early detection, Word sense disambiguation, Cookie theft Description task, legitimacy of news, Alzheimer’s Disease, rumors, Deep Learning, fake news detection, Genius, Lyrics Database, lexical chains, WordNet, keyword extraction, Word Embeddings, Natural Language Processing, algorithm, Data Mining, Graph centrality, emotion-based multi-task approach, Centrality measures, genius API, Music Recommendation, social media, small world approach, Graph-based keyword extraction, music lyrics mining, Rstudio, semantic similarity","This paper proposes an emotion-based multi-task approach to fake news detection, which predicts both the emotion and legitimacy of news. The approach uses a multi-task framework and outperforms single-task models in terms of accuracy. The results show that there is a correlation between the legitimacy of news and its emotion, and that the proposed approach can effectively detect fake news and rumors. ||| This paper explores the effect of different embedding algorithms and neural architectures on early detection of Alzheimer’s Disease using the DementiaBank dataset. The study uses both generic and domain-specific Word Embeddings on three deep learning models - CNN, Bidirectional LSTM(BLSTM), and CNN+BLSTM. Results indicate that domain-specific Word Embeddings tend to work better for a specific picture description task like cookie theft description. The study also discusses how results are affected by the use of different Embedding models (Fasttext, Word2Vec, GloVe). ||| This paper proposes an algorithm to mine lyric data for various artists which can be further utilized to generate a sentiment for individual artists. The employed model is an independent function that requires an artist’s name as primary input and through open-source APIs gathers the required data regarding that artist’s work and then employs our algorithm, L,M&A(Lyrics, Mine and Analyse) to generate a sentiment (based on the different categories of sentiment present in the lexicons used) for that particular artist and is also able to quantitate that sentiment. ||| The proposed algorithm uses a combination of lexical chains and centrality measures to extract keywords from a document. It first extracts nouns from each paragraph and creates lexical chains based on the similarity between words. The chains are then scored using two different methods, and the best chains are selected based on their scores. The selected chains are used to create a graph, and centrality measures are applied to identify the most central words as the extracted keywords."
Mirsad Hadzikadic,A Novel Algorithm for Bi-Level Image Coding and Lossless Compression based on Virtual Ant Colonies,"This paper presents a novel method for image compression using ant colony optimization. The algorithm works by representing the image as a virtual world where ants move and collect food. The coordinates of the ants and their movements are recorded and used to reconstruct the image. The algorithm consists of eight steps, including converting the image to a food-route representation, determining the coordinates of the image, dropping ants randomly, and recording the movements of the ants. The algorithm uses arithmetic coding to compress the string resulting from the movement of ants.","Ant Colonies, ant colony optimization, Binary Images, Proximity, image compression, Arithmetic Coding, Pheromone",The paper proposes a novel method for image compression using ant colony optimization. The algorithm works by representing the image as a virtual world where ants move and collect food. The algorithm consists of eight steps and uses arithmetic coding to compress the string resulting from the movement of ants.
Mittermayer Barreto Santiago,BELIMUMAB IN PATIENTS OF BLACK AFRICAN ANCESTRY,"Study design. SELENA–SLEDAI = Safety of Estrogens in Lupus Erythematosus National Assessment–Systemic Lupus Erythemato-sus Disease Activity Index; IV = intravenous.

Randomization and treatment. Using an interactive voice/web response system, patients receiving standard therapy were randomized 2:1 to receive either belimumab 10 mg/kg IV or placebo, which was administered on days 0, 14, and 28 and every 28 days thereafter up to week 48, with a final evaluation at week 52. Randomization was stratified by screening SELENA–SLEDAI score (≤9 versus ≥10), region (US/Canada versus rest of world), and complement level (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]). Detailed randomization data are provided in Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Patients who successfully completed the initial 52-week double-blind phase could enter an optional 6-month open-label extension phase, during which they received belimumab 10 mg/kg IV every 28 days plus standard therapy, irrespective of their previous study assignment. The first dose was given at the week 52 (day 364) visit of the double-blind period (day 1 of the open-label extension phase). Patients who completed the 52-week double-blind phase, but did not enter the 6-month open-label extension phase, were required to return for an additional follow-up visit 8 weeks after their last dose. Patients who withdrew early were required to return for an exit visit 4 weeks after their last dose and a follow-up visit 8 weeks after their last dose.

The original protocol plan was to randomize 816 patients, providing ≥90% power to detect ≥12% absolute improvement in the SRI response rate in the belimumab group compared with the placebo group at a 5% significance level. Due to enrollment challenges, a revised sample size was calculated to include 501 patients (≥334 patients in the belimumab group and ≥167 patients in the placebo group). This sample size provided ≥90% power to detect a minimum 15.55% absolute improvement in SRI–SLEDAI-2K response rate in the belimumab group relative to the placebo group at a 5% significance level (based on the pooled data from efficacy studies BEL112341 and BEL113750) (15,21). These calculations assumed a placebo response rate of 43.95% at week 52.

Study end points and assessments. The primary efficacy end point was the SRI–SLEDAI-2K response rate (defined in the Supplementary Material) at week 52 of the double-blind phase. Unlike in the phase II and phase III studies, the SRI–SLEDAI-2K was selected because of the simplification it offers in proteinuria assessment as compared with the SELENA–SLEDAI proteinuria component; both are clinically meaningful (22). The primary efficacy end point for the open-label extension phase was SRI–SLEDAI-2K response rate at open-label extension week 24. If the open-label extension week 24 data were missing, data from the open-label extension week 28/exit visit were used. This time point is referred to as “open-label extension week 24” throughout the text. Data related to the primary efficacy end point, e.g., the response rate over time, percentage of patients with a durable SRI–SLEDAI-2K response from week 44 through week 52, time to first SRI–SLEDAI-2K response that was maintained through week 52, and duration of longest SRI–SLEDAI-2K response among patients with ≥1 SRI–SLEDAI-2K responses were summarized.

The key secondary end points were SRI–SELENA–SLEDAI at week 52 (open-label extension week 24), time to first severe SLE flare (measured by the SELENA–SLEDAI flare index [SFI]), and proportion of patients whose average prednisone dose had been reduced by ≥25% from baseline to ≤7.5 mg/day during week 40 through week 52 (open-label extension week 28/exit visit), in patients receiving >7.5 mg/day at baseline. Key renal end points included time to first renal flare over 52 weeks and over 28 weeks in the open-label extension, SELENA–SLEDAI–SLEDAI-2K renal domain improvement at week 52, SELENA–SLEDAI–SLEDAI-2K renal domain worsening at week 52, percentage reduction in proteinuria by visit and at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours, and proteinuria shift at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours. Renal flare is defined in the Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Biomarkers measured included percentage changes in serum IgG level, anti-dsDNA antibody level (in those who were anti-dsDNA positive [≥30 IU/ml] at baseline), and complement (C3 and C4) levels from baseline. Safety was evaluated by monitoring adverse events (AEs), serious AEs (SAEs), AEs of special interest, vital signs, clinical laboratory test results, and immunogenicity up to 8 weeks posttreatment and throughout the open-label extension phase.

Data analyses. For the double-blind phase, safety analyses were performed on the safety population, defined as all patients who were randomized and treated with at least 1 dose of investigational product. Data on the safety population were summarized according to the treatment the patient was randomized to receive rather than by the treatment that was received, but both were the same for this study. Efficacy analyses were performed on the modified intent-to-treat (ITT) population, defined as the safety population minus those patients who had any assessment at any of 3 study sites that were excluded from the efficacy analyses before the database lock because of potential Good Clinical Practice noncompliance.

For analysis of the primary and 3 key secondary efficacy end points, a step-down sequential testing procedure was used as described in the Supplementary Material. The following subgroup analyses were performed for the primary analysis (SRI–SLEDAI-2K response at week 52): region (US/Canada versus rest of world), baseline SELENA–SLEDAI–SLEDAI-2K score (≤9 versus ≥10), baseline anti-dsDNA antibody level (≥30 IU/ml versus <30 IU/ml), baseline complement levels (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]), and baseline complement and anti-dsDNA antibody levels (≥1 test finding showing low C3/C4 and anti-dsDNA ≥30 IU/ml versus C3/C4 other and anti-dsDNA ≥30 IU/ml). The odds of an SRI–SLEDAI-2K response with belimumab treatment versus placebo were estimated using logistic regression analysis.

For the open-label extension phase, all patients received belimumab, no formal statistical hypothesis t",,"This study investigated the efficacy and safety of belimumab in patients of Black African ancestry with systemic lupus erythematosus (SLE).  Patients were randomized to receive belimumab or placebo for 52 weeks, followed by an optional 6-month open-label extension phase. The primary efficacy endpoint was the SRI–SLEDAI-2K response rate at week 52.  Key secondary endpoints included SRI–SELENA–SLEDAI at week 52, time to first severe SLE flare, and proportion of patients with a reduction in prednisone dose. Renal and biomarker assessments were also conducted.  The study found that belimumab was effective in improving SLE disease activity and reducing renal flares in patients of Black African ancestry."
Mohammad Al Shinwan,Hybrid Harmony Search Algorithm to Solve the Feature Selection for Data Mining Applications,"The increasing size of all sorts text and data information on websites makes the method of text clustering (TC) a lot more complicated. The TC technique is employed to cluster an enormous variety of documents into a set of intelligible and connected clusters. Usually, TC is employed in several domains like text mining, data processing, pattern recognition, image clustering.","Hybrid Harmony Search Algorithm, Vector Space Model, Feature Selection, Text Clustering, Data Mining, Data Mining Applications","This paper proposes a hybrid harmony search algorithm to solve the feature selection problem for data mining applications. The algorithm uses the harmony search rule to select and obtain a new set of informative knowledge features, reducing the runtime of the system and decreasing the uninformative knowledge feature. The results show that the proposed modification of the harmony search rule enriched the performance value of the feature choice method in regard to the correct set, owing to its fine features."
Mohammad Shehab,Hybrid Harmony Search Algorithm to Solve the Feature Selection for Data Mining Applications,"The increasing size of all sorts text and data information on websites makes the method of text clustering (TC) a lot more complicated. The TC technique is employed to cluster an enormous variety of documents into a set of intelligible and connected clusters. Usually, TC is employed in several domains like text mining, data processing, pattern recognition, image clustering.","Hybrid Harmony Search Algorithm, Vector Space Model, Feature Selection, Text Clustering, Data Mining, Data Mining Applications","This paper proposes a hybrid harmony search algorithm to solve the feature selection problem for data mining applications. The algorithm uses the harmony search rule to select and obtain a new set of informative knowledge features, reducing the runtime of the system and decreasing the uninformative knowledge feature. The results show that the proposed modification of the harmony search rule enriched the performance value of the feature choice method in regard to the correct set, owing to its fine features."
Mohammed Ali Hussain,The Role of Commercial Websites in the Improvements of E-Business,"Electronic Business (e-Business) is revolutionizing the way of communication between internal and external stakeholders in an organization. E-business can lead to competitive advantage and at the same time, increase profitability. There are several factors resulting on the success of e-business. One of the most important factors is trust. Acquiring customers’ trust depends on many things that an e-business controls. Some relating factors for gaining customers’ trust are: appeal of the website, product/service offering, branding, quality of service, and trusted seals. The paper seeks to address industry uncertainties and consumer concerns about commercial Internet sites by developing a framework identifying factors and facilities for business-to consumer web sites.","quality of service, security, e-Business, web site evaluation, trust, website",This paper aims to address industry uncertainties and consumer concerns about commercial Internet sites by developing a framework identifying factors and facilities for business-to consumer web sites. The framework is based on a broad literature review ranging from consumer adoption of technology-based innovations to evaluations of web sites as well as a review of internationally recognized leading examples of Business to Consumer web sites.
Mohammed Brahimi,Automatic and Intelligent Data Collector and Classiﬁer for Plant Disease Detection,"This paper proposes the Automatic and Intelligent Data Collector and Classiﬁer (AIDCC) for the collection of data, detection, and classiﬁcation of rust, and blast diseases in pearl millet. The framework is an integration of three components, including a digital drone, camera, global positioning system (GPS), and sensors.","AIDCC, plant disease detection, DL, deep transfer learning, IoT","The proposed framework, AIDCC, integrates IoT and deep transfer learning to automate the collection of imagery and parametric data, storage of collected dataset, plant disease detection, generating alerts, and classiﬁcation of detected diseases."
Mohammed Rayid Ali Masood,Leveraging Network Similarity Measures for Recommendation Systems,"With the growth of e-commerce websites, efficient recommendation systems are desired to reduce the turnaround time for servicing a customer. This study focuses on understanding the various techniques and algorithms that are used to model real-life recommendation systems. We present a recommendation engine for Amazon products that uses collaborative filtering (CF). Given a list of users and their reviews of Amazon products, our CF-based recommendation engine generates a ranked list of the top k products for individual users. The generated recommendations are based on the preferences of similar users and past purchases.","bipartite graph, Amazon electronics reviews, recommendation systems, memory-based CF, model-based CF, collaborative filtering, recommendation system, matrix factorization, singular value decomposition, similarity metrics",This paper presents a recommendation engine for Amazon products that uses collaborative filtering (CF). The engine generates a ranked list of the top k products for individual users based on the preferences of similar users and past purchases. The authors also propose a graph-based recommendation technique that generates a list of the most similar products using network-based local similarity metrics.
"Mohanty, P.",A New MPPT Design Using Grey Wolf Optimization Technique for Photovoltaic System Under Partial Shading Conditions,"A new maximum power point tracking (MPPT) design using grey wolf optimization (GWO) technique is proposed in this paper. The proposed GWO-based MPPT algorithm is compared with improved particle swarm optimization (IPSO) and perturb and observe (P&O) algorithms. The simulation results show that the proposed GWO-based MPPT outperforms the other two methods in terms of faster convergence to the global peak (GP), tracking speed, reduced steady-state oscillations, and higher tracking efficiency.","Grey wolf optimization, Grey wolf optimization (GWO), Partial shading, MPPT algorithm, maximum power point tracking (MPPT), Maximum power point tracking, GWO-based MPPT, partial shading conditions (PSCs), photovoltaic (PV)","The proposed GWO-based MPPT algorithm is compared with IPSO and P&O algorithms in terms of convergence speed, tracking efficiency, and oscillations. The simulation results show that the proposed GWO-based MPPT outperforms the other two methods."
Mohit Agarwal,Ensuring Data Security in Databases Using Format Preserving Encryption,"In the current scenario data security has become an important issue with the growth of digital media. Many users and the applications are accessing the data both from inside and outside the database. Hence, the database as well as data within these databases has become the key target for most of the attackers. Many cryptographic schemes have been designed to solve this problem. Encryption plays an important role in providing the data confidentiality to data stored within the databases. But, the problem in adopting the standard encryption methods is that they may cause a damage to the existing schema as well as to the underlying applications or database as the output length is different from the input length and it also changes the format of data. This paper proposes a Format Preserving Encryption method by accumulating with Advance encryption standard(AES), eXclusive OR operation and a translation method for 16 digit numeric data. Format preserving encryption technique is used to minimizes the databases changes by preserving the format as well as the length of the input data.","numeric data, Database, Data Length, Data security, Advanced encryption standard(AES), Format preserving encryption, AES","This paper proposes a Format Preserving Encryption method to ensure data security in databases. The proposed method accumulates Advance encryption standard(AES), eXclusive OR operation, and a translation method for 16-digit numeric data. The technique minimizes database changes by preserving the format and length of the input data."
Mohit Bansal,"MOTIVATING CHILD DEVELOPMENT AND ERADICATION OF CHILD LABOR BY PROMPT EFFORTS BY US, SOCIETY AND GOVERNMENT","One of the menacing curses that our nation is facing today is child labor. Lack of economy and basic education has been monitored as a cause for majority of child labor activities. It is being generally realized that, child labor especially in hazardous occupation is one of the worst social evil and has to be eliminated at the earliest. Government has been taking various pro-active measures to tackle this problem. However, considering the magnitude and extent of the problem and that it is essentially a socio-economic problem inextricably linked to poverty and illiteracy, it requires concerted efforts from all sections of the society to make a dent in the problem.","government schemes, government, illiteracy, child labor, education, menacing, eradication, awareness","The paper discusses the menace of child labor in India and proposes a plan to eradicate it through education, financial support, and awareness. The plan involves collecting donations, providing financial assistance to underprivileged families, and setting up schools for primary education. The authors aim to make children skillful by imparting professional education and provide alternative employment opportunities."
Mohuya B. Kar,Interval-Valued Intuitionistic Fuzzy Soft Sets and Matrices,"A noticeable progress has been found in decision making problems since the introduction of soft set theory by Molodtsov in 1999. It is found that classical soft sets are not suitable to deal with imprecise parameters whereas fuzzy soft sets (FSS) are proved to be useful. Use of intuitionistic fuzzy soft sets (IFSS) is more effective in environment where arguments are presented using membership and non-membership values. In this paper we propose an algorithmic approach for multiple attribute group decision making problems using interval-valued intuitionistic fuzzy soft matrix (IVIFSM). IVIFSM is the matrix representation of interval-valued intuitionistic fuzzy soft set (IVIFSS), where IVIFSS is a natural combination of interval-valued intuitionistic fuzzy set and soft set theory. Firstly, we propose the concept of IVIFSM. Then an algorithm is developed to find out the desired alternative(s) based on product interval-valued intuitionistic fuzzy soft matrix, combined choice matrix, and score values of the set of alternatives. Finally, a practical example has been demonstrated to show the effectiveness of the proposed algorithm.","interval-valued intuitionistic fuzzy soft set, Multiple attribute group decision making, interval-valued intuitionistic fuzzy soft matrix, Fuzzy Soft Sets, Interval-Valued Intuitionistic Fuzzy Soft Matrices, choice matrix, Fuzzy Soft Matrices, Interval-Valued Intuitionistic Fuzzy Soft Sets",This paper proposes an algorithmic approach for multiple attribute group decision making problems using interval-valued intuitionistic fuzzy soft matrix (IVIFSM). The proposed approach uses combined choice matrix for individual decision maker by incorporating the choice parameters of the set of experts. The score and accuracy values are calculated to yield the desired alternative(s).
Mokhtar M. Hasan,Gesture Recognition,"Hand Gesture detection is now getting a lot of attention because it has a lot of uses and the specialty to connect with machines around efficiently by human interaction to computers. In this we are trying to make a knowhow of hand gesture detection system. The problems of hand gesture detection system are also discussed in this. Conclusion of results, methods, data and difference between different phases are also mentioned. Pros and cons are also discussed. In this project we are trying to understand how the image processing works and how can we use it to make a hand gesture detection system so that we can operate the computer without any physical contact with the machine itself. There are many researches that are done before and are still undergoing. Many big companies are currently working on this technology so that they can make their products even more useful that they are now because this technology has very high scope in the upcoming future. The people that are not mentally stable or weak from mind can also benefit by technology and can operate the computer. We can use this technology to make the computer even more accessible for humans.","Feature Extract, Tools for classification, Neural Networks, Posture of Hand, Gesture, Interaction of human with computer (HCI), Phases of recognition, brightness factor matching, fuzzy c-means clustering algorithm, gesture recognition",The main motive to build a hand gesture detection system is to make an interaction between human and computer that can be done by recognizing gestures for controlling robots or a simple computer. How do we make this system is understood and interpreted by the computer. The interaction of humans with computer is also called as man-machine interaction (MMI). Since A computer is insignificant if it not being utilized by human. There are some features that should be looked before we design this system. The function of the system and the use of the system. Function means the things that the system gives to its user and use means the scope of the system that it can be used efficiently. The system which has these both properties is known as powerful system.
Monali Mavani,IPv6 Address Spoofing in 6LoWPANs,"An attacker can disrupt the network operations in the 6LoWPANs by spoofing the IPv6 address while evading the detection. Despite many existing spoofing prevention techniques, spoofing threat still persists. Thus, it becomes necessary to devise a method which can offer resilience against spoofing by reducing the attack disruption time. This study aims at reducing IPv6 spoofing attack disruption time in 6LoWPANs. Hence, it provides the resiliency against IPv6 spoofing threat. The time complexity analysis of the attack tree for the spoofing attack is performed to analyze the attack disruption time. The analytical results show that attack disruption window is directly proportional to the lifetime of the node addresses. The lower lifetime of node addresses ensure the reduction of the attack disruption window. Thus, the use of temporary node addresses can be a solution for reducing the spoofing attack disruption window. Node’s IPv6 address can be changed periodically to dissociate a node from its permanent identity. Hence, an attacker has to re-perform the attack to gain significant benefits. Corrupted routing table as a result of spoofing attack and its countermeasure is simulated in Cooja running Contiki operating system. The length of the attack window depends upon the periodicity of the address change. The higher frequency of address change decreases the attack disruption time with an increase in the communication cost. Simulations have been performed to compare the optimum value of address change periodicity concerning the communication cost for two private addressing schemes proposed in the literature.","spoofing attack, IPv6 spoofing, IPv6 address spoofing, Privacy addressing, RPL, Attack disruption window, Time-To-Live, temporal analysis, 6LoWPAN-ND, 6LoWPANs, TTL parameter, 6LoWPAN",This study aims to reduce the attack disruption time due to spoofing in 6LoWPAN networks by periodically changing the node’s addresses. The attack disruption time can be reduced by incorporating parameters like Attack Disruption Window (ADW) and Time-To-Live (TTL) to the attack tree. The use of temporary node addresses can be a solution for reducing the spoofing attack disruption window. Simulations have been performed to compare the optimum value of address change periodicity concerning the communication cost for two private addressing schemes proposed in the literature.
Monika Agarwal,Range Limited Double Threshold Weighted Histogram Equalization with Dynamic Range Stretching (RLDTWHE-DRS),"In the recent era, a boom was observed in the field of information retrieval from images. Digital images with high contrast are sources of abundant information. The gathered information is useful in the precise detection of an object, event, or anomaly captured in an image scene. Existing systems do uniform distribution of intensities and apply intensity histogram equalization. These improve the characteristics of an image in terms of visual appearance. The problem of over enhancement and the increase in noise level produces undesirable visual artefacts. The use of Otsu’s single threshold method in existing systems is inefficient for segmenting an image with multiple objects and complex background. Additionally, these are incapable to improve the yield of the maximum entropy and brightness preservation. The aforementioned limitations motivate us to propose an efficient statistical pipelined approach, the Range Limited Double Threshold Weighted Histogram Equalization (RLDTWHE). This approach is an integration of Otsu’s double threshold, dynamic range stretching, weighted distribution, adaptive gamma correction, and homomorphic filtering. It provides optimum contrast enhancement by selecting the best appropriate threshold value for image segmentation. The proposed approach is efficient in the enhancement of low contrast medical MRI images and digital natural scene images. It effectively preserves all essential information recorded in an image. Experimental results prove its efficacy in terms of maximum entropy preservation, brightness preservation, contrast enhancement, and retaining the natural appearance of an image.","Histogram Weighting, Homomorphic Filtering, Adaptive Gamma Correction, Automatic Threshold Selection, contrast enhancement, weighted distribution, Optimum Contrast Enhancement, dynamic range stretching, Range Stretching, histogram equalization","This paper proposes a new approach for digital image contrast enhancement, called Range Limited Double Threshold Weighted Histogram Equalization (RLDTWHE). The approach integrates several techniques, including Otsu’s double threshold, dynamic range stretching, weighted distribution, adaptive gamma correction, and homomorphic filtering. The proposed approach is efficient in enhancing low contrast medical MRI images and digital natural scene images, and effectively preserves all essential information recorded in an image."
Mourad Debbabi,A Simple Dynamic Decision Making System for Filtering Out DoS Attacks in SDN,The Software Deﬁned Networking (SDN) paradigm is expected to heavily integrate into future networks. Enterprises have already started migrating their networks to SDNs. Billions of smart devices constituting the Internet of Things will be connected to these high speed networks and will be communicating over these networks. The ubiquity of these networks along with the user devices connected to them becomes of paramount importance for the end users. This work presents a SDN switch based module to detect a Denial Of Service attack on the network and its connected components.,"Trafﬁc Filtering, Denial of Service Attacks, SDN, Internet of Things, DoS attacks, packet filtering, Software Deﬁned Networks, decision making system","This paper discusses the different Denial of Service attacks that are possible on Software Deﬁned Networks, along with various methods to identify and detect such attacks, and finally the methods to mitigate these attacks."
Moﬂeh Al-diabat,Hybrid Harmony Search Algorithm to Solve the Feature Selection for Data Mining Applications,"The increasing size of all sorts text and data information on websites makes the method of text clustering (TC) a lot more complicated. The TC technique is employed to cluster an enormous variety of documents into a set of intelligible and connected clusters. Usually, TC is employed in several domains like text mining, data processing, pattern recognition, image clustering.","Hybrid Harmony Search Algorithm, Vector Space Model, Feature Selection, Text Clustering, Data Mining, Data Mining Applications","This paper proposes a hybrid harmony search algorithm to solve the feature selection problem for data mining applications. The algorithm uses the harmony search rule to select and obtain a new set of informative knowledge features, reducing the runtime of the system and decreasing the uninformative knowledge feature. The results show that the proposed modification of the harmony search rule enriched the performance value of the feature choice method in regard to the correct set, owing to its fine features."
Mudit Bhargava,Stylometric Analysis for Authorship Attribution on Twitter,"Authorship Attribution (AA), the science of inferring an author for a given piece of text based on its characteristics is a problem with a long history. In this paper, we study the problem of authorship attribution for forensic purposes and present machine learning techniques and stylometric features of the authors that enable authorship to be determined at rates significantly better than chance for texts of 140 characters or less.","Online Social Media, stylometric analysis, Twitter streaming API, Stylometry Analysis, Authorship Attribution, Twitter client application, author-classiﬁed tweets, Twitter, Machine Learning Classiﬁer",This paper focuses on the problem of identification of the original author for a given tweet from a list of suspected authors for it using stylometric information. Various stylometric features have been taken into consideration for the training and later testing purposes of the machine learning algorithms such as Support Vector Machine (SVM) classiﬁer.
Mufti Mahmud,"Toward a Heterogeneous Mist, Fog, and Cloud-Based Framework for the Internet of Healthcare Things","Rapid developments in the fields of information and communication technology and microelectronics allowed seamless interconnection among various devices letting them to communicate with each other. This technological integration opened up new possibilities in many disciplines including healthcare and well-being. With the aim of reducing healthcare costs and providing improved and reliable services, several healthcare frameworks based on Internet of Healthcare Things (IoHT) have been developed. However, due to the critical and heterogeneous nature of healthcare data, maintaining high quality of service (QoS)—in terms of faster responsiveness and data-specific complex analytics—has always been the main challenge in designing such systems. Addressing these issues, this paper proposes a five-layered heterogeneous mist, fog, and cloud-based IoHT framework capable of efficiently handling and routing (near-)real-time as well as offline/batch mode data. Also, by employing software defined networking and link adaptation-based load balancing, the framework ensures optimal resource allocation and efficient resource utilization. The results, obtained by simulating the framework, indicate that the designed network via its various components can achieve high QoS, with reduced end-to-end latency and packet drop rate, which is essential for developing next generation e-healthcare systems.","QoS, healthcare big data, load balancing, healthcare application, healthcare, e-healthcare, IoHT, fog computing, quality of service (QoS), reduced latency, IoT, mist computing, Data fusion, cloud computing, heterogeneous framework, low power consumption, real-time computing, resource allocation","This paper proposes a five-layered heterogeneous mist, fog, and cloud-based Internet of Healthcare Things (IoHT) framework to efficiently handle and route healthcare data. The framework employs software defined networking and link adaptation-based load balancing to ensure optimal resource allocation and efficient resource utilization. The results show that the designed network can achieve high quality of service with reduced latency and packet drop rate, making it essential for developing next generation e-healthcare systems."
Muhammad Attique khan et al.,Deep Learning Techniques for Disease Detection in Fruits and Vegetables,"Plant Diseases are one of the leading reasons of economic shortfalls in agricultural and farming sectors worldwide. It is the most essential element since it reduces crop quantity and quality significantly. Fruits are one of the largest essential nutritional resources from plants. Unfortunately, a variety of conditions might impair both the content and outcome of fruits. As a result, an autonomous Computer Vision (CV) -based approach for reliable Fruit Disease Detection (FDD) is necessary.","Attention mechanisms, Transfer learning, Convolutional neural networks, Computer Vision, Machine Learning, Disease detection, Deep Learning, Fruits and vegetables, Fruit Disease Detection","This paper presents a detailed review of different ML and DL algorithms developed to predict and classify FDs from different fruit images. First, different FDD and classification systems designed by many researchers based on ML and DL algorithms are studied in brief. Then, a detailed analysis is carried out in order to identify the shortcomings of existing algorithms and to provide a novel strategy for properly classifying fruit pathogens."
Muhammad Fazal Ijaz,Recent Developments in Plant Leaf Disease Identification and Classification,"In the modern era, deep learning techniques have emerged as powerful tools in image recognition. Convolutional Neural Networks, one of the deep learning tools, have attained an impressive outcome in this area. The effectiveness of Convolutional Neural Networks in image recognition motivates the researchers to extend its applications in the field of agriculture for recognition of plant species, yield management, weed detection, soil, and water management, fruit counting, diseases, and pest detection, evaluating the nutrient status of plants, and much more.","leaf, deep learning models, disease, survey, deep learning, machine learning models, plant leaf disease identification, agriculture, convolutional neural networks","This manuscript presents a survey of the existing literature in applying deep Convolutional Neural Networks to predict plant diseases from leaf images. It presents an exemplary comparison of the pre-processing techniques, Convolutional Neural Network models, frameworks, and optimization techniques applied to detect and classify plant diseases using leaf images as a data set."
Muhammad R. Ahmed,"Toward a Heterogeneous Mist, Fog, and Cloud-Based Framework for the Internet of Healthcare Things","Rapid developments in the fields of information and communication technology and microelectronics allowed seamless interconnection among various devices letting them to communicate with each other. This technological integration opened up new possibilities in many disciplines including healthcare and well-being. With the aim of reducing healthcare costs and providing improved and reliable services, several healthcare frameworks based on Internet of Healthcare Things (IoHT) have been developed. However, due to the critical and heterogeneous nature of healthcare data, maintaining high quality of service (QoS)—in terms of faster responsiveness and data-specific complex analytics—has always been the main challenge in designing such systems. Addressing these issues, this paper proposes a five-layered heterogeneous mist, fog, and cloud-based IoHT framework capable of efficiently handling and routing (near-)real-time as well as offline/batch mode data. Also, by employing software defined networking and link adaptation-based load balancing, the framework ensures optimal resource allocation and efficient resource utilization. The results, obtained by simulating the framework, indicate that the designed network via its various components can achieve high QoS, with reduced end-to-end latency and packet drop rate, which is essential for developing next generation e-healthcare systems.","QoS, healthcare big data, load balancing, healthcare application, healthcare, e-healthcare, IoHT, fog computing, quality of service (QoS), reduced latency, IoT, mist computing, Data fusion, cloud computing, heterogeneous framework, low power consumption, real-time computing, resource allocation","This paper proposes a five-layered heterogeneous mist, fog, and cloud-based Internet of Healthcare Things (IoHT) framework to efficiently handle and route healthcare data. The framework employs software defined networking and link adaptation-based load balancing to ensure optimal resource allocation and efficient resource utilization. The results show that the designed network can achieve high quality of service with reduced latency and packet drop rate, making it essential for developing next generation e-healthcare systems."
Muhammad Rizwan Asghar,Encrypted Domain Camera Attribution,"Photo Response Non-Uniformity (PRNU) noise-based source camera attribution is a popular digital forensic method. In this method, a camera fingerprint computed from a set of known images of the camera is matched against the extracted noise of an anonymous questionable image to find out if the camera had taken the anonymous image.","PRNU-based camera attribution, Camera Fingerprinting, utility, Privacy, camera attribution, Secure computation, encrypted domain",The proposed method is based on a secure multi-party computation scheme that enables a third-party entity to perform camera attribution tasks without accessing the sensitive image data. The method uses a combination of homomorphic encryption and secure multi-party computation to ensure both utility and privacy.
Mukesh Prasad,Accurate Trafﬁc Flow Prediction in Heterogeneous Vehicular Networks in an Intelligent Transport System Using a Supervised Non-Parametric Classiﬁer ||| A Layered-Coevolution-Based Attribute-Boosted Reduction Using Adaptive Quantum Behavior PSO and Its Consistent Segmentation for Neonates Brain Tissue ||| A Review of Clustering Techniques and Developments ||| Deep Sparse Representation Classifier for Facial Recognition  and Detection System ||| Towards Precision Agriculture: IoT-Enabled Intelligent Irrigation Systems Using Deep Learning Neural Network ||| Virtualization in Wireless Sensor Networks: Fault Tolerant Embedding for Internet of Things,"Heterogeneous vehicular networks (HETVNETs) evolve from vehicular ad hoc networks (VANETs), which allow vehicles to always be connected so as to obtain safety services within intelligent transportation systems (ITSs). The services and data provided by HETVNETs should be neither interrupted nor delayed. Therefore, Quality of Service (QoS) improvement of HETVNETs is one of the topics attracting the attention of researchers and the manufacturing community. ||| The main challenge of attribute reduction in large data applications is to develop a new algorithm to deal with large, noisy, and uncertain large data linking multiple relevant data sources, structured or unstructured. This paper proposes a new and efficient layered-coevolution-based attribute-boosted reduction algorithm (LCQ-ABR*) using adaptive quantum behavior particle swarm optimization (PSO). ||| This paper presents a comprehensive study on clustering: exiting methods and developments made at various times. Clustering is defined as an unsupervised learning where the objects are grouped on the basis of some similarity inherent among them. There are different methods for clustering the objects such as hierarchical, partitional, grid, density based and model based. The approaches used in these methods are discussed with their respective states of art and applicability. The measures of similarity as well as the evaluation criteria, which are the central components of clustering are also presented in the paper. The applications of clustering in some fields like image segmentation, object and character recognition and data mining are highlighted. ||| This paper proposes a two-layer Convolutional Neural Network (CNN) to learn the high-level features which utilizes to the face identification via sparse representation. Feature extraction plays a vital role in real-world pattern recognition and classification tasks. The details description of the given input face image, significantly improve the performance of the facial recognition system. Sparse Representation Classifier (SRC) is a popular face classifier that sparsely represents the face image by a subset of training data, which is known as insensitive to the choice of feature space. The proposed method shows the performance improvement of SRC via a precisely selected feature exactor. The experimental results show that the proposed method outperform other methods on given datasets. ||| This paper presents a deep learning NN-based IoT-enabled intelligent irrigation system for precision agriculture (DLiSA). An LSTM RNN model is employed to predict volumetric soil moisture content of the next day based on the historical temporal dynamics of climate and soil. The proposed model uses a closed-loop approach, which takes feedback from soil sensors and climate sensors that keeps its functionality higher in the unpredicted climate of any region. ||| Recently, virtualization in wireless sensor networks (WSNs) has witnessed significant attention due to the growing service domain for IoT. Related literature on virtualization in WSNs explored resource optimization without considering communication failure in WSNs environments. The failure of a communication link in WSNs impacts many virtual networks running IoT services. In this context, this paper proposes a framework for optimizing fault tolerance in virtualization in WSNs, focusing on heterogeneous networks for service-oriented IoT applications.","QoS, Sparse Feature Extraction, Unsupervised learning, Convolutional neural network, Deep Learning Neural Network, Deep learning, IoT, Clustering, Sensor, sulci and gyrus estimate, internet of vehicles, Face recognition, Data mining, SVM, Fault Tolerant Embedding, Deep Learning, Internet of Things, Neonatal Brain Tissue 3D-MRI, Hierarchical Clustering, Precision Agriculture, Self-Adaptive Memeplexes, layered-coevolution with multi-agent interaction, Vehicular Ad Hoc Network, ROCK, Quantum-Behavior PSO, Similarity measures, Prediction Accuracy, Clustering Approaches, RBF, CNN, consistent segmentation for neonates brain tissue, Sparse representation classifier, Support Vector Machines, Pattern recognition, Long Short Term Memory, BIRCH, IoT-enabled Intelligent Irrigation Systems, LSTM RNN model, Wireless sensor networks, Layered Co-Evolutionary Model, Volumetric Soil Moisture Content, Taxonomy, Radial Basis Function, Attribute-boosted reduction, adaptive quantum behavior PSO, CURE, Multi-Agent Interaction, Virtualization, CHAMELEON, Feature extraction, HETVNET","This paper proposes a prediction model based on support vector machines (SVMs) to improve Quality of Service (QoS) in Heterogeneous Vehicular Networks (HETVNETs). The model uses a radial basis function (RBF) kernel and outperforms other prediction methods in terms of accuracy and computational complexity. ||| This paper proposes a new attribute reduction algorithm using quantum behavior PSO, which aims to choose attribute subsets for large-scale, noisy, and uncertain datasets. The algorithm is evaluated on several benchmark datasets and compared with other representative algorithms. The results show that the proposed algorithm has better feasibility and effectiveness than the compared algorithms. ||| This paper reviews clustering techniques and developments, discussing methods such as hierarchical, partitional, grid, density-based, and model-based clustering, as well as measures of similarity and evaluation criteria. The applications of clustering in fields like image segmentation, object recognition, and data mining are highlighted. ||| This paper presents a robust face recognition framework based on the combination of sparse feature extraction using Convolutional Neural Networks (CNNs) and Support Vector Machines (SVMs). The proposed framework is evaluated on four widely used face datasets, including Extended YALE B database, AR database, MIT faces database, and ORL faces database. The experimental results show that the proposed framework outperforms the state-of-the-art methods in terms of recognition rate. ||| The proposed DLiSA system consists of a smart irrigation model and associated sensing IoT network model deployed on farmland. The system uses a closed-loop approach to predict volumetric soil moisture content of the next day based on historical temporal dynamics of climate and soil. The performance of DLiSA is compared with state-of-the-art algorithms subject to the prediction of soil moisture content, soil water deficit, and water volume irrigated over a month. ||| The paper discusses the importance of virtualization in WSNs for IoT applications, focusing on fault-tolerant embedding. It reviews existing proposals on virtualization in WSNs, highlighting their limitations and proposing a new approach to enhance fault tolerance."
Mukesh Saraswat,A New Fuzzy Cluster Validity Index for Hyperellipsoid or Hyperspherical Shape Close Clusters With Distant Centroids ||| Chaotic Kbest gravitational search algorithm (CKGSA) ||| Classiﬁcation of Histopathological Images Through Bag-of-Visual-Words,"Determining the correct number of clusters is essential for efficient clustering and cluster validity indices are widely used for the same. Generally, the effectiveness of a cluster validity index relies on two factors: (i) separation, defined by the distance between a pair of cluster centroids or a pair of data points belonging to different clusters and (ii) compactness which is determined in terms of the distance between a data point and a centroid or between a pair of data points belonging to the same cluster. ||| Gravitational search algorithm is a popular adaptive search algorithm among nature-inspired algorithms and has been successfully used for optimizing many real-world problems. Gravitational search algorithm uses the law of Newton gravity for finding the optimal solution. The performance of gravitational search algorithm is controlled by exploration and exploitation capabilities and Kbest is one of its parameters that controls this trade-off. In this paper, a novel chaotic Kbest gravitational search algorithm has been proposed that uses the chaotic model in Kbest to balance the exploration and exploitation non-linearly. The proposed algorithm shows better convergence rate at later iterations with high precision and does not trap into local optima. ||| The automated quantiﬁcation of different cell structures available in histopathological images is a challenging task due to the presence of complex back-ground structures. Moreover, the tissues of different categories, namely epithelium tissue, connective tissue, muscular tissue, and nervous tissue have heterogeneous structure which limits the applicability of an algorithm to only a single class of tissue for the quantiﬁcation analysis of histopathological images.","Chaotic, Kbest, Cluster validity index, Chaotic Kbest Gravitational Search Algorithm, SIFT, SVM, Gravitational search algorithm, histopathological images, optimization algorithm, Bag-of-visual-words, fuzzy c-means, global optimization, Adaptive search algorithm, SIFT method, hyper-ellipsoid or hyper-spherical clusters, centroid-based clustering, Histopathological image classiﬁcation","This paper proposes a new fuzzy cluster validity index for hyper-ellipsoid or hyper-spherical shape close clusters with distant centroids, generated by fuzzy c-means. The proposed index computes compactness in terms of the distance between data points and corresponding centroids, while the distance between data points of disjoint clusters defines separation. ||| This paper proposes a novel chaotic Kbest gravitational search algorithm (CKGSA) that uses the chaotic model in Kbest to balance exploration and exploitation non-linearly. The proposed algorithm shows better convergence rate at later iterations with high precision and does not trap into local optima. ||| This paper introduces a novel method for categorization of histopathological images into the respective tissue category before quantiﬁcation analysis. The proposed method uses SIFT method for feature extraction which are further processed by gravitational search algorithm to obtain optimal bag-of-visual-words."
Mukkamalla Mounika,A Novel Scalable Apache Spark Based Feature Extraction Approaches for Huge Protein Sequence and their Clustering Performance Analysis,"Genome sequencing projects are rapidly increasing the number of high-dimensional protein sequence datasets. Clustering a high-dimensional protein sequence dataset using traditional machine learning approaches poses many challenges. Many different feature extraction methods exist and are widely used. However, extracting features from millions of protein sequences becomes impractical because they are not scalable with current algorithms. Therefore, there is a need for an efficient feature extraction approach that extracts significant features. We have proposed two scalable feature extraction approaches for extracting features from huge protein sequences using Apache Spark, which are termed 60d-SPF (60-dimensional Scalable Protein Feature) and 6d-SCPSF (6-dimensional Scalable Co-occurrence-based Probability-Speciﬁc Feature). The proposed 60d-SPF and 6d-SCPSF approaches capture the statistical properties of amino acids to create a fixed-length numeric feature vector that represents each protein sequence in terms of 60-dimensional and 6-dimensional features, respectively.","Big Data, protein sequences, Fuzzy Clustering, Scalable Algorithms, Apache Spark Cluster, Feature Extraction, Apache Spark, Huge Protein Sequences","This paper proposes two scalable feature extraction approaches for huge protein sequences using Apache Spark, which are termed 60d-SPF and 6d-SCPSF. The proposed approaches capture the statistical properties of amino acids to create a fixed-length numeric feature vector that represents each protein sequence in terms of 60-dimensional and 6-dimensional features, respectively. The paper also discusses the clustering of huge protein sequences using SRSIO-FCM and SLFCM algorithms."
Munjal et. al.,Rumour Source Detection Using Game Theory,"Social networks have become a critical part of our lives as they enable us to interact with a lot of people. These networks have become the main sources for creating, sharing and also extracting information regarding various subjects. But all this information may not be true and may contain a lot of unverified rumours that have the potential of spreading incorrect information to the masses, which may even lead to situations of widespread panic. Thus, it is of great importance to identify those nodes and edges that play a crucial role in a network in order to find the most influential sources of rumour spreading. Generally, the basic idea is to classify the nodes and edges in a network with the highest criticality. Most of the existing work regarding the same focuses on using simple centrality measures which focus on the individual contribution of a node in a network. Game-theoretic approaches such as Shapley Value (SV) algorithms suggest that individual marginal contribution should be measured for a given player as the weighted average marginal increase in the yield of any coalition that this player might join. For our experiment, we have played five SV-based games to find the top 10 most influential nodes on three network datasets (Enron, USAir97 and Les Misérables). We have compared our results to the ones obtained by using primitive centrality measures. Our results show that SV-based approach is better at understanding the marginal contribution, and therefore the actual influence, of each node to the entire network.","influential nodes, Jaccard Similarity Coefficient, cooperative game, Rumour Source Detection (RSD), centrality measures, network analysis, Shapley Value (SV), Game-Theory, Network Centrality",This paper aims to identify the most influential nodes in a network that are the primary sources of rumour propagation. The authors propose a game-theoretic approach using the Shapley Value algorithm to find the most influential nodes. They compare their results with primitive centrality measures and show that the SV-based approach is better at understanding the marginal contribution of each node to the entire network.
N. Bharill,A Generalized Enhanced Quantum Fuzzy Approach for Efficient Data Clustering ||| Generalized Enhanced Quantum Fuzzy Approach for Efficient Data Clustering,"Data clustering is a challenging task to gain insights into data in various fields. In this paper, an Enhanced Quantum-Inspired Evolutionary Fuzzy C-Means (EQIE-FCM) algorithm is proposed for data clustering. In the EQIE-FCM, quantum computing concept is utilized in combination with the FCM algorithm to improve the clustering process by evolving the clustering parameters. The improvement in the clustering process leads to improvement in the quality of clustering results. To validate the quality of clustering results achieved by the proposed EQIE-FCM approach, its performance is compared with the other quantum-based fuzzy clustering approaches and also with other evolutionary clustering approaches.","Fuzzy C-Means, evolutionary algorithm, Clustering, fuzzy set theory, Data Clustering, bioinformatics, quantum computing, Data clustering",The proposed EQIE-FCM algorithm uses the quantum computing concept to evolve the optimal value of the fuzziﬁer parameter m and the number of clusters C along with the best location of initial cluster centers from subspaces in several generations. The algorithm is designed with the novel quantum bit representation of the fuzziﬁer parameter m and set of cluster centers VC. The quantum rotational gate is used in this algorithm for updating the qubits of m and VC. ||| This paper proposes an Enhanced Quantum-Inspired Evolutionary Fuzzy C-Means (EQIE-FCM) algorithm for data clustering. The EQIE-FCM algorithm utilizes quantum computing concept in combination with the FCM algorithm to improve the clustering process by evolving the clustering parameters. The performance of the proposed EQIE-FCM approach is compared with other quantum-based fuzzy clustering approaches and other evolutionary clustering approaches.
N. Malpica,A Peer-Assessment Based Approach for Teaching Microprogramming,"The course on microprocessors introduces undergraduate computer science students to hardware-level programming. The course was taught by the authors to 130 students in context of the 8085 and 8086 microprocessors in the Spring semester of 2019. The students executed their programs on hardware kits, and participated in a double-blind peer-assessment exercise in which they assessed and rated programs written by their peers and also advised them on improving the efficiency and readability of their programs.","Computer science education, microprocessor, undergraduate students, computer science, microprocessors, microprogramming, peer-assessment, performance","This paper presents a study on the utility of peer-assessment in teaching microprogramming to undergraduate computer science students attending a course on microprocessors. The study found that the peer-assessment exercise helped the students to perform better in examination, with a 6.97% increase in marks in the post-intervention test compared to the pre-intervention test."
N. R. Vundekode,A Study on Vision Based Method for Damage Detection in Structures,"To ensure the safety and the usefulness of civil structures, it is fundamental to visually inspect and survey its physical and functional condition. Current techniques in condition and safety assessment of large concrete structures are performed physically promoting to subjective and unreliable outcomes, costly and time-consuming data collection, and safety issues. This paper presents a study on less time consuming and less expensive alternative to the present methods of preliminary assessment for the detection of damages in structures. Henceforth, the focus is set on various vision-based methods for different parameters like cracks, corrosion and spalling which cause damage and deterioration of structures. Thus, a study is made on the current achievements and drawbacks of existing methods as well as open research difficulties are outlined to help both the structural engineers and the computer science researchers in setting a motivation for future research.","Convolutional Neural Networks, Vision based methods, Damage detection, Structural health assessment, Computer based techniques","This paper presents a study on vision-based methods for damage detection in structures. The focus is on various parameters like cracks, corrosion, and spalling that cause damage and deterioration of structures. The paper outlines the current achievements and drawbacks of existing methods and identifies open research difficulties to motivate future research."
N.K. Verma,Impact of Eurasian Snow Cover on Indian Summer Monsoon Rainfall over the Northwestern Himalayas,"The entire Indo-Himalayan region from northwest (Kashmir) to northeast (Assam) is facing prevalence of floods and landslides in recent years causing massive loss of property, human and animal lives, infrastructure, and eventually threatening tourist activities substantially. Extremely intense rainfall event of A.D. 2013 (between 15 and 17 June) kicked off mammoth flash floods in the Kedarnath area of Uttarakhand state, resulting in huge socioeconomic losses to the state and country.","Eurasian snow cover, extreme rainfall events, flash floods, gridded data sets, Himalayas, Arctic Oscillation, northwestern Himalayas, Indian summer monsoon rainfall","The study investigates ~100-year-long monthly rainfall and air temperature time series data for a selected grid covering most parts of Uttarakhand state. The results indicate that under warming scenario, JJ rainfall (over AS) may further increase with occasional extreme rainfall spells when AO index (March) is negative."
NABIN SHARMA,Robust Feature-Based Automated Multi-View Human Action Recognition System,"Automated human action recognition has the potential to play an important role in public security, for example, in relation to the multiview surveillance videos taken in public places, such as train stations or airports. This paper compares three practical, reliable, and generic systems for multiview video-based human action recognition, namely, the nearest neighbor classiﬁer, Gaussian mixture model classiﬁer, and the nearest mean classiﬁer. To describe the different actions performed in different views, view-invariant features are proposed to address multiview action recognition. These features are obtained by extracting the holistic features from different temporal scales which are modeled as points of interest which represent the global spatial-temporal distribution. Experiments and cross-data testing are conducted on the KTH, WEIZMANN, and MuHAVi datasets. The system does not need to be retrained when scenarios are changed which means the trained database can be applied in a wide variety of environments, such as view angle or background changes. The experiment results show that the proposed approach outperforms the existing methods on the KTH and WEIZMANN datasets.","feature extraction, points of interest extraction, background subtraction, machine learning, moving object localization, multi-view human action recognition, action recognition, Multi-view video, classiﬁcation","This paper proposes a robust feature-based automated multi-view human action recognition system. The system uses view-invariant features to address multi-view action recognition from a range of perspectives. The proposed approach labels the beginning and end of an action sequence in a video stream automatically and captures sequence motions and occlusions at a low computational cost. The system is evaluated using the KTH, WEIZMAN, and MuHAVi datasets and outperforms existing methods on the KTH and WEIZMANN datasets."
NATIONAL INSTITUTE OF TECHNOLOGY SURATHKAL,Health Monitoring for Rotating Machine Using SVM Based Methods,Fault diagnosis in reciprocating air compressors is essential for continuous monitoring of their performance and thereby ensuring quality output. Support Vector Machines (SVMs) are machine learning tools based on structural risk minimization principle and have the advantageous characteristic of good generalization.,"fuzzy decision function, Compressor Dataset, fault diagnosis, reciprocating air compressor, Health Monitoring, SVM Based Methods, support vector machine, Rotating Machine",This paper proposes an optimized SVM based method for classification based fault diagnosis in reciprocating air compressors. The results obtained through implementation of all five techniques are compared as per their accuracy rate in percentages.
Na Li,Endogenous IRAK-M Attenuates Postinfarction Remodeling Through Effects on Macrophages and Fibroblasts,"Quantitative polymerase chain reaction analysis demonstrated significant IRAK-M mRNA upregulation in the infarcted myocardium. The time course of IRAK-M induction showed a biphasic response (Figure 1), characterized by marked early upregulation after 6 hours of reperfusion, followed by a second peak after 7 days of reperfusion (Figure 1A). IRAK-M Is Localized in Infarct Macrophages and Myofibroblasts Dual immunofluorescence was used to study IRAK-M localization in the infarcted myocardium. IRAK-M immunoreactivity in the infarcted heart was localized in Mac2+ infarct macrophages and in spindle-shaped, α–smooth muscle actin–positive myofibroblasts (Figure 1B and 1C). Moreover, infarct myofibroblasts and CD11b+ leukocytes isolated from the infarcted heart after 72 hours of reperfusion exhibited IRAK-M expression (Figure 1D–1G). To study cell-type specific changes in the timing of IRAK-M expression, we assessed IRAK-M mRNA levels in cardiac fibroblasts and CD11b+ leukocytes harvested from the infarcted heart. Isolated fibroblasts had a 3-fold increase in IRAK-M mRNA levels after 24 hours to 72 hours of reperfusion in comparison with control cardiac fibroblasts. When compared with control CD11b+ cells harvested from normal hearts, leukocytes isolated after 6 hours of reperfusion showed a trend toward increased IRAK-M mRNA expression (Figure I in the online-only Data Supplement). IRAK-M Loss Is Associated With Enhanced Adverse Remodeling Despite the Absence of Effects on the Size of the Infarct IRAK-M−null and WT animals had comparable mortality after myocardial infarction (P=NS). Triphenyltetrazolium chloride/Evans blue staining demonstrated that IRAK-M loss does not affect the size of the infarct after 1 hour of ischemia and 24 hours of reperfusion (Figure 1H–1J). Two independent techniques, echocardiographic imaging (Figure 2A–2G; Table I in the online-only Data Supplement) and quantitative morphometry (Figure 2H–2L), demonstrated that IRAK-M loss was associated with enhanced adverse remodeling after myocardial infarction. Systolic and diastolic chamber dimensions measured through echocardiography (left ventricular end-diastolic dimension, left ventricular end-systolic dimension, left ventricular end-systolic volume, and left ventricular end-diastolic volume; Figure 2A–2G) and morphometrically-derived left ventricular end-diastolic volume and left ventricular end-diastolic dimension (Figure 2H–2L) were significantly higher in IRAK-M−null mice after 7 and 28 days of reperfusion, indicating increased chamber dilation. Left ventricular mass was also significantly higher in infarcted IRAK-M−null hearts, suggesting accentuated hypertrophic remodeling. Increased adverse remodeling in the absence of IRAK-M was associated with reduced fractional shortening (FS), reflecting worse systolic dysfunction (Figure 2D). Because acute infarct size was comparable between WT and IRAK-M−null mice (Figure 1H–1J), accentuated adverse remodeling in IRAK-M−null hearts was not a result of more extensive cardiomyocyte injury. Moreover, scar size after 7 to 28 days of reperfusion was comparable between IRAK-M−/− and WT animals (Figure 2I). IRAK-M−/− Mice Have Enhanced Postinfarction Inflammation Exhibiting Increased Myocardial Cytokine mRN","metalloproteinases, cytokines, immune system, macrophages, cardiac remodeling","This study investigates the role of Interleukin-1 receptor-associated kinase (IRAK)-M in myocardial infarction.  Key findings include: 

* IRAK-M mRNA is significantly upregulated in the infarcted myocardium, with a biphasic response.
* IRAK-M is localized in macrophages and myofibroblasts within the infarcted heart.
* IRAK-M loss is associated with enhanced adverse remodeling after myocardial infarction, characterized by increased chamber dilation and hypertrophy, despite no effect on infarct size.
* IRAK-M−/− mice exhibit increased postinfarction inflammation with elevated myocardial cytokine mRNA levels."
Nadine Rouphael,First-­in-­Human Study of Bamlanivimab in a Randomized Trial of Hospitalized Patients With COVID-­19,"This first-in-human study in hospitalized patients with COVID-19 was supported by studies assessing in vitro viral neutralization combined with a single-dose non-human primate PK study. The nonclinical safety package to support subsequent studies included tissue cross-reactivity studies on human, rat, and monkey tissues and an in vivo toxicology study.  A complete physical examination was conducted at the screening visit, and one of three bamlanivimab doses or placebo was administered i.v. at the baseline visit (D1) with infusion rates as follows: bamlanivimab 700 mg (50 mL) administered 100 mL/hr for 30 minutes; 2,800 mg (75 mL) administered 100 mL/hr for 45 minutes; and 7,000 mg administered 100 mL/hr for 60 minutes. Placebo infusion was 0.9% normal saline, administered at the same volume and rate as the corresponding bamlanivimab dose cohort. Safety and tolerability were reviewed for sentinel participants up to 24 hours after dosing, at which point the investigators and sponsor team determined whether safety and tolerability were acceptable to continue with dosing subsequent participants. The decision to dose the next cohort was made when all participants from the previous cohort had been dosed and safety data assessed for at least 4 days after the i.v. infusion by the investigators and sponsor team in consultation with an independent safety assessment committee. Blood samples were obtained for assessment of exploratory biomarkers, serology, clinical laboratory assessments, and PD on days 1, 3, 7, 11, 15, 22, and 29, and every 7 days until discharge or day 60, if still an inpatient. Samples for the virology assay were collected using nasopharyngeal (preferred) or mid-turbinate methods. Blood samples obtained for PK analyses were assessed on days 1 (pre-infusion and just before end of infusion), 4, 15, and 29, and follow-up visits up to day 60. Symptom-related physical examinations and assessments of clinical symptoms were performed on days 1, 2, 3, 4, 7, 11, 15, 22, and 29, and the day of discharge from the hospital, with additional follow-up examinations every 7 days thereafter until day 60 if the patient was not discharged from the hospital by day 29. Participants’ clinical status and concurrent procedures of special interest were recorded, including limitation on activities due to COVID-19 and any requirements for the following procedures of special interest, such as ongoing hospital medical care, supplemental oxygen, noninvasive ventilation or a high flow oxygen device, mechanical ventilation, extracorporeal membrane oxygenation, additional organ support, or consciousness status using alert, consciousness, verbal, pain, unresponsive scale. Hospitalization events were recorded, including dates of hospital admission and discharge, admission to the intensive care unit (ICU), discharge from the ICU, and discharge location including to an extended care facility or home. Outcomes The primary objective was to assess safety and tolerability, including adverse events (AEs), serious adverse events (SAEs), and discontinuations due to AEs. Other objectives included PKs (e.g., mean concentration at day 29); PD viral load, area under the response time curve (AUC, from day 1 to day 29), and change from baseline time course; total symptom score; time to symptom resolution; duration of hospitalization; National Institute of Allergy and Infectious Diseases (NIAID), World Health Organization (WHO) scales, and National Early Warning Score (NEWS2); and analysis of viral resistance. Any hypothesis tests were conducted for treatment comparisons without adjustment for multiplicity except for the evaluation of treatment effect on endogenous antibody titers. Success for the trial was claimed using a Bayesian criterion if any of the 3 bamlanivimab doses had at least 60% probability to reduce at least 30% mean AUC (28-day viral load) over placebo.",,"This first-in-human study evaluated the safety, tolerability, pharmacokinetics, clinical course, and viral dynamics of bamlanivimab, a fully human neutralizing monoclonal antibody targeting SARS-CoV-2, in hospitalized patients with moderate to severe COVID-19.  The study found bamlanivimab to be safe and well-tolerated, with no serious adverse events or deaths reported.  Further research is needed to determine the efficacy of bamlanivimab in treating COVID-19."
Nag et al.,Multi-Objective Genetic Algorithm for Optimization of Catalytic Reaction,"This paper discusses the use of a multi-objective genetic algorithm (MOGA) for the optimization of a catalytic reaction. The MOGA is used to find a set of solutions that are close to the Pareto front, well spread, and cover the whole spectrum of the Pareto front. The algorithm is applied to a competitive enzyme inhibition reaction scheme and the results are discussed.","Genetic Algorithm, Cellular Automata, Optimization, Enzyme kinetics, Pareto Front, Multi-Objective Optimization, Multi-Objective Genetic Algorithm, Catalytic Reaction","The paper presents a multi-objective genetic algorithm for the optimization of a catalytic reaction. The algorithm is used to find a set of solutions that are close to the Pareto front, well spread, and cover the whole spectrum of the Pareto front. The results of the algorithm are discussed and compared with other optimization methods."
"Nair, P. B.",Local Surrogate Modeling for Parallel Evolutionary Optimization of Computationally Expensive Problems,This paper presents a local surrogate modeling algorithm for parallel evolutionary optimization of computationally expensive problems. The algorithm uses radial basis function networks to construct local surrogate models in the spirit of transductive inference. The proposed algorithm can be efficiently parallelized on grid computing architectures and does not compromise on the intrinsic parallelism offered by evolutionary algorithms.,"Radial basis function networks, evolutionary optimization, Transductive inference, Local surrogate modeling, surrogate modeling, Parallel evolutionary optimization, computationally expensive problems",The paper presents a parallel evolutionary optimization algorithm that uses surrogate models to solve computationally expensive design problems with general constraints on a limited computational budget. The algorithm combines an evolutionary algorithm with a feasible sequential quadratic programming solver and uses a trust-region approach to leverage exact and surrogate models during local search.
Nalin Nanda,MUTUAL LEARNING IN TREE PARITY MACHINES USING CUCKOO SEARCH ALGORITHM FOR SECURE PUBLIC KEY EXCHANGE,"In Neural Cryptography, Artificial Neural Networks are used for the process of key generation and encryption. Tree Parity Machine (TPM) is a single layer neural network that approaches symmetric key exchange using the process of mutual learning. This method is exploited to design a secure key exchange protocol, where the sender and the receiver TPMs are synchronized to obtain an identically tuned weight vectors in both the networks.","Mutual Learning, Neural Synchronisation, Neural Networks, Secure Public Key Exchange, Tree Parity Machine, Cuckoo Search Algorithm, Security, Key Exchange","This paper proposes a novel approach for the process of synchronisation in Tree Parity Machines using Cuckoo Search Algorithm for secure public key exchange. The results show that using CS algorithm for weight vector initialisation decreases the number of iterations significantly, resulting in ~30% decrease on an average. The effect of CS algorithm was observed by changing the weight range from 4 to 7 with N = 3, K = 100, and the results show that using CS, the synchronisation steps are decreased tremendously i.e. >50% decrease is observed."
Naman Chhikara,MUTUAL LEARNING IN TREE PARITY MACHINES USING CUCKOO SEARCH ALGORITHM FOR SECURE PUBLIC KEY EXCHANGE,"In Neural Cryptography, Artificial Neural Networks are used for the process of key generation and encryption. Tree Parity Machine (TPM) is a single layer neural network that approaches symmetric key exchange using the process of mutual learning. This method is exploited to design a secure key exchange protocol, where the sender and the receiver TPMs are synchronized to obtain an identically tuned weight vectors in both the networks.","Mutual Learning, Neural Synchronisation, Neural Networks, Secure Public Key Exchange, Tree Parity Machine, Cuckoo Search Algorithm, Security, Key Exchange","This paper proposes a novel approach for the process of synchronisation in Tree Parity Machines using Cuckoo Search Algorithm for secure public key exchange. The results show that using CS algorithm for weight vector initialisation decreases the number of iterations significantly, resulting in ~30% decrease on an average. The effect of CS algorithm was observed by changing the weight range from 4 to 7 with N = 3, K = 100, and the results show that using CS, the synchronisation steps are decreased tremendously i.e. >50% decrease is observed."
Namita Sharma,Power Optimization Strategy for Android Applications,"Energy efficiency is a critical factor in mobile systems, and a significant body of recent research efforts has focused on reducing the energy dissipation in mobile hardware and applications. The Android OS Power Manager provides programming interface routines called wakelocks for controlling the activation state of devices on a mobile system.","Data Flow Analysis, Android, Wakelock Placement, Power Optimization, Mobile Systems, Energy Optimization",This paper proposes a data flow analysis based strategy for determining the placement of wakelock statements corresponding to the uses of devices in an application. The proposed optimization strategy shows significant (up to 32%) energy savings with experimental evaluation on a set of Android applications.
Nandi,Agriculture Extension System in India: A Meta-analysis,"Agriculture extension system bridges the gap between research labs to a farmer’s field. Agricultural research, education and extension are said to be the most critical for promoting farm productivity and enhancing farmer’s income. The public sector is major extension service provider and the reach of the public extension is limited in India and in addition it is burdened with non-extension responsibilities such as the distribution of subsidies and inputs, with little time left to attend to core extension activities.","Investment, Extension approaches, Farmers Producers' Organizations, India, Agriculture extension, Meta analysis, ICT, Manpower","The article reviews the agricultural extension system in India to suggest pathways for better extension system in India. The public extension services are highly skewed towards crop husbandry ignoring allied sectors in India. The growth in the High-Value Agriculture sector has been twice or sometimes even thrice that of the crop production. However, Agriculture extension services for such sectors almost nil or unorganized."
Narendra Kohli,Multiclass SVM Methods for Classification,"This paper presents support vector machine based methods for arrhythmia classification in ECG datasets with selected features. Among various existing SVM methods, four well-known and widely used algorithms One Against One (OAO), One Against All (OAA), Fuzzy Decision Function (FDF) and Decision Directed Acyclic Graph (DDAG) are used here to distinguish between the presence and absence of cardiac arrhythmia and classifying them into one of the arrhythmia groups.","Principal Component Analysis, Feature Selection, Classification, Multiclass SVM, Arrhythmia, Support Vector Machine, Electrocardiogram","The paper presents a comprehensive review of multiclass SVM methods, including their strengths and weaknesses. It also discusses the importance of feature selection in improving classification accuracy and proposes the use of Principal Component Analysis for this purpose."
Nareshkumar Reddy Beechu,Automatic disease diagnosis using optimised weightless neural networks for low-power wearable devices,"Low-power wearable devices for disease diagnosis are used at anytime and anywhere. These are non-invasive and pain-free for the better quality of life. However, these devices are resource constrained in terms of memory and processing capability. Memory constraint allows these devices to store a limited number of patterns and processing constraint provides delayed response. It is a challenging task to design a robust classiﬁcation system under above constraints with high accuracy. In this Letter, to resolve this problem, a novel architecture for weightless neural networks (WNNs) has been proposed. It uses variable sized random access memories to optimise the memory usage and a modiﬁed binary TRIE data structure for reducing the test time. In addition, a bio-inspired-based genetic algorithm has been employed to improve the accuracy. The proposed architecture is experimented on various disease datasets using its software and hardware realisations. The experimental results prove that the proposed architecture achieves better performance in terms of accuracy, memory saving and test time as compared to standard WNNs. It also outperforms in terms of accuracy as compared to conventional neural network-based classiﬁers.","low-power wearable devices, binary TRIE data structure, TRIE data structure, genetic algorithm, neuron memory search, weightless neural networks, VG-RAM, VVG-RAM, disease diagnosis, modified TRIE data structure","A novel architecture for weightless neural networks (WNNs) is proposed to improve the classiﬁcation accuracy, reduce the memory usage, and decrease the test time for low-power wearable devices. The proposed architecture uses variable sized random access memories and a modiﬁed binary TRIE data structure. A bio-inspired-based genetic algorithm is employed to improve the accuracy. The experimental results show that the proposed architecture outperforms the standard WNNs and conventional neural network-based classiﬁers in terms of accuracy, memory saving, and test time."
Nauman Aslam,A Cost-Efficient Communication Framework For Battery Switch Based Electric Vehicle Charging ||| Towards Video Streaming in IoT Environments: Vehicular Communication Perspective,"This paper proposes a battery switch service for electric vehicles (EVs) using a publish/subscribe (P/S) communication paradigm. The system consists of road side units (RSUs), electric vehicles (EVs), and charging stations (CSs). RSUs act as brokers to bridge the information flow from CSs to EVs, while EVs and CSs interact through RSUs. The system enables efficient radio resource utilization and alleviates interference to EVs. ||| Multimedia oriented Internet of Things (IoT) enables pervasive and real-time communication of video, audio and image data among devices in immediate surroundings. Today’s vehicles have the capability of supporting real time multimedia acquisition. Vehicles with high illuminating infrared cameras and customized sensors can communicate with other on-road devices using dedicated short-range communication (DSRC) and 5G enabled communication technologies. Real time incidence of both urban and highway vehicular traffic environment can be captured and transmitted using vehicle-to-vehicle and vehicle-to-infrastructure communication modes. Video streaming in vehicular IoT (VSV-IoT) environments is in growing stage with several challenges that need to be addressed ranging from limited resources in IoT devices, intermittent connection in vehicular networks, heterogeneous devices, dynamism and scalability in video encoding, bandwidth underutilization in video delivery, and attaining application-precise quality of service in video streaming. In this context, this paper presents a comprehensive review on video streaming in IoT environments focusing on vehicular communication perspective. Specifically, the significance of video streaming in vehicular IoT environments is highlighted focusing on the integration of vehicular communication with 5G enabled IoT technologies, and smart city oriented application areas for VSV-IoT. A taxonomy is presented for the classification of related literature on video streaming in vehicular network environments. Following the taxonomy, critical review of literature is performed focusing on major functional model, strengths and weaknesses. Metrics for video streaming in vehicular IoT environments are derived and comparatively analyzed in terms of their usage and evaluation capabilities. Open research challenges in VSV-IoT are identified as future directions of research in the area. The survey would benefit both IoT and vehicle industry practitioners and researchers, in terms of augmenting understanding of vehicular video streaming and its IoT related trends and issues.","Electric Vehicles, publish/subscribe, road side units, Internet of vehicles, Video streaming, traffic safety, vehicular ad-hoc networks, Smart Cities, Vehicular Communication, Communication Framework, Intelligent transportation system, Charging Management, Battery Switch, Internet of things, IoT, charging stations","This article presents a cost-efﬁcient communication framework for battery switch based electric vehicle charging. The framework is provisioned to support the EV charging service and considers urban travel uncertainties, e.g., trafﬁc congestions and drivers’ preferences. Results demonstrate a guidance for the provisioning of P/S communication framework to improve EV drivers’ experience, e.g., charging waiting time and total trip duration. ||| The paper discusses the significance of video streaming in vehicular IoT environments, presents a taxonomy for the classification of literature on video streaming over vehicular ad-hoc networks, derives performance metrics for video streaming in vehicular IoT environments, and identifies open research issues and challenges in vehicular video streaming under IoT environments."
Navaneeth Gatttagoni,Quantifying Influential Communities in Information Diffusion Dynamics,This paper studies the information diffusion process in networks and quantifies influential communities. The authors propose a method to study the intertwining of community structure and core-periphery structure.,"community structure, core-periphery structure, k-shell decomposition, networks, information diffusion, coreness, entropy",The paper investigates the information diffusion process in networks and proposes a method to quantify influential communities. The authors show that core nodes are densely packed in the same community and that the core-periphery structure and community structure are intertwined.
Naveed Ahmad,A Novel EV Charging Management Scheme Considering Mobility Uncertainty,"This paper proposes a novel EV charging management scheme that considers mobility uncertainty due to traffic jams in a city. The scheme uses a centralized aggregator to manage charging plans for all EVs in the network, and each EV reports its charging reservation to the aggregator, including its expected arrival time and charging time. The aggregator then makes CS-selection decisions based on the reported information and updates the reservations periodically to adjust for mobility uncertainty.","Charging System, Mobility Uncertainty, CS-Selection Decision Making, Traffic Jams, Centralized Aggregator, CS-Selection, Electric Vehicle, Driver's Trip Duration, Electric Vehicle Charging","This paper proposes an EV charging management system that considers drivers' trip duration and mobility uncertainty. The system selects charging stations based on reported EVs' reservation information and parking duration, minimizing trip duration for on-the-move EVs."
Navneet Kumar Verma,Analgesic activity of synthesized compounds ||| Isoprenaline Induced Model for Myocardial Necrosis ||| Study the modern biochemical analysis techniques of proteins and alkaline phasphtase enzyme system from biological sample chicken liver,"In an approach to synthesize some potent benzoxazole derivatives, some compounds were synthesized. The details of these compounds are given below- The structures were confirmed using IR and NMR spectroscopy. The potency of synthesized compounds were established using following pharmacological screening- Analgesic activity  Paw edema- Male or female Wistar rats with a body weight between 100 and 150 g are used. The animals are starved overnight. To insure uniform hydration, the rats receive 5 ml of water by stomach tube (controls) or the test drug dissolved or suspended in the same volume. Thirty minutes later, the rats are challenged by a subcutaneous injection of 0.05 ml of 1% solution of carrageenan into the plantar side of the left hind paw. The paw is marked with ink at the level of the lateral malleolus and immersed in mercury up to this mark. The paw volume is measured plethysmographically immediately after injection, again 3 and 6 h, and eventually 24 h after challenge. [3] Analgesic activity Writhing tests- Mice of either sex with a weight between 20 and 25 g are used. Acetic acid in a concentration of 1% (1ml/kg) is used to produce writhing. An aliquot of 0.025 ml of this suspension is injected intraperitoneally. Groups of 6 animals are used for controls and treated mice. Preferably, two groups of 6 mice are used as controls. Test animals are administered the drug or the standard at various pretreatment times prior to Acetic acid administration. The mice are placed individually into glass beakers and five min are allowed to elapse. The mice are then observed for a period of ten min and the number of writhes is recorded for each animal. For scoring purposes, a writhe is indicated by stretching of the abdomen with simultaneous stretching of at least one hind limb. The formula for computing percent inhibition is: average writhes in the control group minus writhes in the drug group divided by writhes in the control group times 100%. The time period with the greatest percent of inhibition is considered the peak time. A dose range is reserved for interesting compounds or those which inhibit writhing more than 70%. Compounds with less than 70% inhibition are considered to have minimal activity. [4] Microbiological screening For both antibacterial and assay compounds were dissolved in absolute ethanol (0.8 mg/ml). Further dilutions of the compounds and standard drugs in the test medium have concentrations of 400, 200, 100, 50, 25, 12.5, 6.25, 3.12, 1.56, 0.78 mg/ml. The minimum inhibitory concentrations (MIC) were determined using the method of two-fold serial dilution. In order to ensure that the solvent ‘per se’ had no effect on bacterial growth, a control test was also performed containing inoculated broth supplemented with only ethanol at the same dilutions used in our experiments and found inactive in culture medium. Antibacterial assay- The cultures were obtained in Nutrient agar broth (Difco) for all the bacteria after 24 h of incubation at 37+1°C. Testing was carried out in Nutrient agar broth at pH 7.4 and the two-fold serial dilution technique was applied. The final inoculums size was 105 CFU/ml. A set of tubes containing only inoculated broth was kept as controls. Ciprofoxacine was taken as standard. After incubation for 24 h at 37+1°C, the last tube with no growth of microorganism was recorded to represent MIC expressed in g/ml. [5] ||| The study used isoprenaline-induced myocardial necrosis as an experimental model to evaluate the cardioprotective effects of various herbal drugs. The pathophysiological changes following ISO administration in rats are comparable to those taking place during MI in humans. ||| The objective of the study was the biochemical analysis of proteins and Alkaline Phosphatase enzyme system from biological sample Chicken Liver using modern biochemical analysis techniques, including protein extraction, fractionation and electrophoresis separation technique and enzyme analysis.","Benzoxazole, benzoxazole derivatives, Biochemical analysis, antibacterial assay, acid phosphatase, alkaline phosphatase, Isoprenaline, Microbiological screening, Amino acids, Isoproterenol, Proteins, pharmacological screening, myocardial necrosis, proteases, Anti-inflammatory activity, Nelumbo nucifera, Enzymes, Cardioprotective Effects, peroxidases, cardioprotective effect, Herbal Drugs, Protein chains, Analgesic activity","The study aimed to synthesize potent benzoxazole derivatives and evaluate their analgesic activity using pharmacological screening. The compounds were synthesized and their structures confirmed using IR and NMR spectroscopy. The potency of the synthesized compounds was established using analgesic activity tests, including paw edema and writhing tests. The results showed that some of the compounds exhibited significant analgesic activity, with one compound showing 63.33% inhibition at a dose of 30 mg/kg. The study also evaluated the antibacterial activity of the compounds using the two-fold serial dilution technique and found that some of the compounds exhibited significant antibacterial activity. The study concluded that the synthesized compounds have potential as analgesic and antibacterial agents. ||| The study aimed to develop a pharmacologic technique for producing myocardial necrosis of standard severity in animals using isoprenaline-induced myocardial necrosis as an experimental model. ||| The paper discusses the biochemical analysis of proteins and alkaline phosphatase enzyme system from chicken liver using modern biochemical analysis techniques. It covers topics such as protein synthesis, structure, and purification, and highlights the importance of proteins in living organisms."
Navneet Munoth,The Idealized Heritage Village: Surveying the Public Perception for a Sustainable Development,"A comprehensive site survey was conducted for the area under study forming the historic core, combined with a detailed photo survey of the relevant components in the rural environment. The well documented photo survey of the elevations and places of interest facilitated a better understanding of the identified patterns and their locations.","Heritage Village, Community Participation, Rural Heritage, Public Perception, Settlement pattern, Sustainable Development, Human Perception, Vernacular architecture","The study aimed to investigate the planning tools that can be used to guide new developments, while respecting rural cultural heritage, distinctive characteristics of the traditional buildings, and understanding priorities and needs of villagers related to make alterations and extensions."
Navneet Pratap Singh,Cube Sampled K-Prototype Algorithm for Clustering ||| EXPERIMENTAL STUDY OF REGENERATIVE BRAKING SYSTEM (RBS) ||| Preconditioned Iterative Solves in Model Reduction ||| Reusing Preconditioners in Projection Based Model Order Reduction Algorithms,"This paper proposes a novel algorithm called Cube Sampled K-Prototype for clustering mixed data types. The algorithm integrates the K-Means and K-Modes algorithms and uses cube sampling to reduce the computational complexity. The proposed algorithm is compared with other clustering algorithms and shows better performance in terms of clustering accuracy. ||| In this era, the automobile sector is facing a major challenge to reduce consumption of fuel and greenhouse gases emission, this is often because limited fuel reserves and continuous degrade in air quality. An experimental setup is made for the current study to reduce the loss of energy by reusing it. In this present study, an alternator is connected to the driver shaft through chain and sprocket. When brakes are applied to slow the vehicle down or make it come to a halt, the alternator is activated with an electromagnetic clutch, and the energy lost during braking is utilized to generate electrical energy. ||| This paper proposes the use of preconditioned iterative methods for solving linear systems in model reduction. The authors discuss the importance of preconditioning in improving the performance of iterative methods and present a new preconditioner, the Sparse Approximate Inverse (SPAI) preconditioner. They also discuss the use of SPAI preconditioner in the Adaptive Iterative Rational Global Arnoldi Algorithm (AIRGA) and present results showing the effectiveness of the proposed method. ||| Dynamical systems are pervasive in almost all engineering and scientific applications. Simulating such systems is computationally very intensive. Hence, Model Order Reduction (MOR) is used to reduce them to a lower dimension. Most of the MOR algorithms require solving large sparse sequences of linear systems. Since using direct methods for solving such systems does not scale well in time with respect to the increase in the input dimension, efficient preconditioned iterative methods are commonly used. In one of our previous works, we have shown substantial improvements by reusing preconditioners for the parametric MOR (Singh et al. 2019). Here, we had proposed techniques for both, the non-parametric and the parametric cases, but had applied them only to the latter. We have three main contributions here. First, we demonstrate that preconditioners can be reused more effectively in the non-parametric case as compared to the parametric one. Second, we show that reusing preconditioners is an art via detailed algorithmic implementations in multiple MOR algorithms. Third and final, we demonstrate that reusing preconditioners for reducing a real-life industrial problem (of size 1.2 million), leads to relative savings of up to 64% in the total computation time (in absolute terms a saving of 5 days).","Mixed Data Types, Sparse Approximate Inverse (SPAI) preconditioner, Regenerative braking, Sampling, Clustering, reusing preconditioners, Adaptive Iterative Rational Global Arnoldi Algorithm (AIRGA), Cube Sampling, Global Arnoldi Algorithm, Automobile, Model reduction, preconditioners, K-Prototype, K-Prototype Clustering, Model order reduction, moment matching, iterative methods, Iterative Methods, Electromagnetic clutch, Energy recovery system, Principal Component Analysis, Model Order Reduction, Clustering Accuracy, Generator, Preconditioned iterative methods, Preconditioner and Stability Analysis, Moment Matching, Linear systems","This paper proposes a probabilistic sampling technique called cube sampling along with K-Prototype clustering. Cube sampling is used because of its accurate sample selection. The novelty of this work is in obtaining the crucial inclusion probabilities for cube sampling using Principal Component Analysis (PCA). ||| This paper presents an experimental study of regenerative braking system (RBS) to reduce energy loss during braking. An experimental setup is designed to reuse the energy lost during braking by activating an alternator with an electromagnetic clutch. The study shows that 16.32% of brake energy was recovered, and the current from the alternator increases with engine speed. ||| This paper focuses on efficiently solving linear systems arising in the model reduction process using iterative methods and preconditioners. The authors propose the use of relevant iterative algorithms and the Sparse Approximate Inverse (SPAI) preconditioner, and provide a technique to cheaply update the SPAI preconditioner in each iteration step. ||| This paper demonstrates the reuse of preconditioners in projection-based model order reduction algorithms for non-parametric dynamical systems. The authors have three main contributions: (i) they demonstrate that preconditioners can be reused more effectively in the non-parametric case, (ii) they show that reusing preconditioners is an art via detailed algorithmic implementations in multiple MOR algorithms, and (iii) they demonstrate that reusing preconditioners leads to relative savings of up to 64% in the total computation time for a real-life industrial problem."
Navneet Singh,"Estimate of variability, heritability and genetic advance with respect to yield and yield contributing characters in field pea (Pisum sativum L.) ||| Genetic variability and associations studies for yield and its component traits in potato (Solanum tuberosum L.) ||| Identification of Efficient Wireless Sensor Network Using Fuzzy Logic Method","The present investigation entitled “Estimate of variability, heritability and genetic advance with respect to yield and yield contributing characters in field pea (Pisum sativum L.)” for 10 characters. The experiment comprising of 23 genotypes of pea were grown in a Randomized Block Design (RBD), with three replications at Research Farm, Department of Genetics & Plant Breeding, Post Graduate College, Ghazipur, during rabi season of 2017-2018, plant to plant and row to row distance was kept 10 cm and 45 cm, respectively. ||| The present investigation was conducted during growing season of 2017-18. Data collected on tuber yield and its components were subjected for analysis of variability parameters, correlation coefficient and genetic advance. The estimates of analysis of variance were significant for the all parameters. The analysis of genetic variance revealed that the sufficient variability was present in experimental material. The Phenotypic coefficient of variation (PCV) was slightly higher in magnitude than genotypic coefficient of variation (GCV) for all the parameters. The high heritability estimates in broad sense was recorded in weight of ‘C’ grade tubers per hill, number of stems per hill, yield of tubers per hill (kg plant-1), number of leaves per plant, weight of ‘A’ grade tubers per hill, weight of ‘B’ grade tubers per hill, number of ‘C’ grade tubers per hill, weight of ‘D’ grade tubers per hill. The high heritability estimates coupled with high genetic advance was recorded for the parameters number of ‘D’ grade tubers per hill, weight of ‘D’ grade tubers per hill, weight of ‘C’ grade tubers per hill, number of ‘B’ grade tubers per hill, weight of ‘B’ grade tubers per hill and yield of tubers per hill (kg plot-1). ||| A wireless sensor network (WSN) consists of sensor nodes and base stations which are connected via wireless medium. A key functionality of WSNs consists in collecting information from sensor nodes & transporting the information of interest to the base stations required by the applications. Wireless connectivity, size and low cost of sensors in WSNs are its advantages which enable it to be deployed in hostile or inaccessible environments at a very low cost. However, WSNs suffer from high data loss due to error prone wireless transmission medium, transmission problems in hostile environments and node failures due to limited energy of sensor nodes. Hence reliable data transportation i.e. ensuring data delivery with minimum loss becomes the key issue in WSNs.","potato, Pisum sativum L., heritability, Genetic variability, yield contributing characters, Correlation coefficient, energy efficiency, genetic advance, Wireless Sensor Network, Solanum tuberosum L., Fuzzy Logic, Genetic advance, correlation, congestion, field pea, communication protocol","The estimates of genotypic coefficient of variation (GCV) and phenotypic coefficient of variation (PCV) and environmental coefficient of variation (ECV) showed a wide range. The high estimates of genotypic coefficient of variation (GCV) were observed for plant height, biological yield per plant, number of pods per plant, seed yield per plant, number, 100 seed weight. The high estimates of phenotypic coefficient of variation (PCV) were observed for seed yield per pod, number of pods per plant, biological yield per plant, harvest index, plant height. ||| The study aimed to investigate the genetic variability and associations studies for yield and its component traits in potato (Solanum tuberosum L.). The results showed significant differences among genotypes for all the characters studied, with sufficient variability present in genotypes. The high heritability estimates and genetic advance were recorded for several parameters, indicating the potential for selection and breeding of high-yielding cultivars. ||| The paper proposes a fuzzy logic based system for identifying efficient wireless sensor networks. The system uses three fuzzy inputs and a rule base to determine the energy efficiency of the system. The results show that the system can prioritize energy efficient systems based on the protocol of communication and mitigation of congestion with respect to the size of the wireless sensor network."
Navneet Verma,Wound Healing Potential of Raloxifene Nanoemulsion Gel for the Management of Postmenopausal Cutaneous Wounds,"Background: Depletion in estrogen level(s) especially in postmenopausal women is reported to have delayed wound healing effects; hence we have evaluated the wound healing potential of raloxifene in rat model. Objectives: Investigating the wound healing effects of raloxifene nanoemulsion for the management of postmenopausal cutaneous wounds. Materials and Methods: The optimized nanoemulsion gel contains 0.072% raloxifene hydrochloride. Female Wistar rats were used to investigate its wound healing effects. After three months of ovariectomy, wound healing effect was observed in terms of breaking strength, tensile strength, area of wound contraction, wound closure time, hydroxyproline content and histopathological changes. Results: The nanoemulsion gel exhibited better retention (34.31%) than its nanoemulsion. The raloxifene nanoemulsion gel has no erythema and no eschar formation recorded, and it is safe for topical use. In the incision wound model in ovariectomized rats, breaking (898±25g) and tensile strengths (4.47±0.12 g/mm2) in raloxifene treated groups were found to be higher than the untreated control group. Additionally, in ovariectomized rats, wound contraction was found to be 100% in the treated group s following 20 days of post-wounding, where as in control group only 88% was contraction was observed. Also, more hydroxyproline content in raloxifene treated ovariectomized rat was observed that recommend more collagen content than the untreated ovariectomized rat but approximately similar effects to untreated non-ovariectomized rats. Histopathological studies confirmed that the raloxifene treated groups had more re-epithelialization, neo-vascularization, fibroblast proliferation, and collagen deposition than the control group. Conclusion: These results confirms that the raloxifene nanoemulsion gel has significant wound healing potential, as observed in ovariectomized rats, which will be helpful in postmenopausal cutaneous wound healing.","Raloxifene, Histopathology, Ovariectomized, Hydroxyproline, Wound contraction, Postmenopausal Cutaneous Wounds, Postmenopausal, Breaking strength, Nanoemulsion gel, Wound Healing","This study investigates the wound healing potential of raloxifene nanoemulsion gel in postmenopausal cutaneous wounds. The results show that the nanoemulsion gel has significant wound healing potential, as observed in ovariectomized rats, and is safe for topical use. The study suggests that raloxifene nanoemulsion gel can be a good alternative for wound healing in postmenopausal women."
Nedumaran,Agriculture Extension System in India: A Meta-analysis,"Agriculture extension system bridges the gap between research labs to a farmer’s field. Agricultural research, education and extension are said to be the most critical for promoting farm productivity and enhancing farmer’s income. The public sector is major extension service provider and the reach of the public extension is limited in India and in addition it is burdened with non-extension responsibilities such as the distribution of subsidies and inputs, with little time left to attend to core extension activities.","Investment, Extension approaches, Farmers Producers' Organizations, India, Agriculture extension, Meta analysis, ICT, Manpower","The article reviews the agricultural extension system in India to suggest pathways for better extension system in India. The public extension services are highly skewed towards crop husbandry ignoring allied sectors in India. The growth in the High-Value Agriculture sector has been twice or sometimes even thrice that of the crop production. However, Agriculture extension services for such sectors almost nil or unorganized."
Neelu Joshi,"Antioxidant Activity, Phenol and Flavonoid Content of Helicteres isora (L.)","Helicteres isora L., commonly known as Indian Screw Tree is a highly valued medicinal plant in South-East Asia. The various phytochemicals like phenols, flavonoids and other antioxidants that impart the medicinal properties in this plant, vary in their composition and concentration in different plant parts. In the present research, the total phenolic content, total flavonoids content and free radical scavenging activity (FRAP and DPPH assay) in fresh and dry sample extracts of leaf, bark, fruit and root of H. isora L., prepared in four different solvents (distilled water, ethanol, methanol and acetone) were studied, and their results compared using Pearson’s Correlation. The plant extracts were also subjected to RP-HPLC for detection and quantitation of naturally occurring phenolic compounds using six phenolic standards (Gallic acid, Vanillin, Catechol, Ferrulic acid, p-coumaric acid and Caffeic acid). The highest total phenolic content (7.22 mg/g GAE) and FRAP value (64.98 mg/g TE) were observed in aqueous dry root extract. The acetone extract of fresh leaf (57.08 mg/g of RE) was found richest in total flavonoids, while the methanolic extract of fresh fruit uniquely exhibited strong free radical scavenging activity as evidenced by the low IC50 value (34.37 mg/ml) in DPPH assay. The RP-HPLC analysis revealed that Catechol and Gallic acid were most abundantly found phenolic compounds in extracts of H. isora L. The total phenolic content showed strong positive correlation with free radical scavenging activity (FRAP and DPPH assays) in both fresh and dry plant parts, suggesting that phenols are the main compounds responsible for the antioxidant activity. The root of H. isora L. was found rich in phenolics and antioxidant capacity indicating its strong potential for medicinal use, followed by fruit, leaf and bark.","Flavonoids, FRAP, DPPH, Phenols, Helicteres isora L., RP-HPLC","The qualitative tests for various phytochemicals revealed presence of saponins, alkaloids, steroids, terpenoids, glycosides, cardiac glycosides, phenols and flavonoids. The glycosides, phenols and flavonoids were present in all of the 32 extracts tested. Steroids and terpenoids were mainly found in dry plant part extracts whereas only few extracts of fresh plant parts, showed their presence. Tannins were uniquely present in only aqueous extract of dry leaf. Steroids were present in all extracts of dry leaf while present only in aqueous extracts of dry fruit, root, and bark. Out of the four plant parts, dry leaf extracts in four solvents, aqueous, ethanol, methanol and acetone, showed presence of all phytochemicals (Table 2). The fresh plant extracts were found to be low in steroids, terpenoids, and tannins while moderate in saponins and alkaloids. The dry plant extracts were found richer in phytochemicals as compared to fresh ones."
Neetin S. Desai,Evaluation of Total Phenolic and Flavonoid Content and Antioxidant Activity of *Hibiscus isora* (L.),"Plant extracts rich in polyphenols are important for preparation of medicines as polyphenols are easily obtained from natural sources. Though medicinal plants of India constitute about 20% of total plant species 19, but the medicinal properties of most of them are not completely explored.  There are very few studies available where commercially viable formulations are being prepared, therefore, it is imperative to promote their studies for their application in curing diseases. The present investigation evaluates the phenolic and flavonoid content as well as antioxidant activity of one such scantily explored but potentially useful plant species *H. isora* (L.) Solvent extraction is most frequently used technique for isolation of plant antioxidant compounds with varied characteristics and polarities that may or may not be soluble in a particular solvent. Polar solvents are frequently employed for the recovery of polyphenols from a plant matrix 13. The selection of an appropriate solvent is one of the most relevant previous steps in estimating phytochemical activities. The yield of antioxidant compounds from plant parts is influenced mainly by the conditions under which the process of liquid-solid extraction is achieved, the type of solvent used to separate the soluble fraction from the permeable solid, the degree of polymerization of phenolics and their interaction with the other components20.  In present investigation, four types of extracts with water, ethanol, methanol, and acetone were prepared from different plant parts and used to check TPC, TFC and their antioxidant potential.","RP- HPLC, Phenolic content, Helicteres isora, Antioxidant activity, Flavonoid content","This study investigated the antioxidant potential of different parts of the Indian screw tree (Helicteres isora) using various solvents. Dried plant parts showed higher antioxidant activity compared to fresh ones, with leaves exhibiting the highest phenolic and flavonoid content and DPPH˙ radical scavenging activity.  The study suggests that dried leaves, roots, and fruits of H. isora, particularly when prepared in distilled water or methanol, hold potential for developing herbal formulations with antioxidant properties."
"Negi, S.",A Multi-Task Approach to Open Domain Suggestion Mining,"Consumer reviews online may contain suggestions useful for improving the target products and services. Mining suggestions is challenging because the field lacks large labelled and balanced datasets. Furthermore, most prior studies have only focused on mining suggestions in a single domain. In this work, we introduce a novel up-sampling technique to address the problem of class imbalance, and propose a multi-task deep learning approach for mining suggestions from multiple domains.","Deep Learning, Suggestion Mining, Artificial Intelligence, Class Imbalance, Multi-Task Learning","This paper presents a multi-task approach to open domain suggestion mining, addressing the class imbalance problem using a novel up-sampling technique and a multi-task deep learning framework. Experimental results show that the proposed approach outperforms state-of-the-art models in terms of F-1 measure and AUC."
Neha Bharill,A Novel Scalable Apache Spark Based Feature Extraction Approaches for Huge Protein Sequence and their Clustering Performance Analysis ||| A Review of Clustering Techniques and Developments,"Genome sequencing projects are rapidly increasing the number of high-dimensional protein sequence datasets. Clustering a high-dimensional protein sequence dataset using traditional machine learning approaches poses many challenges. Many different feature extraction methods exist and are widely used. However, extracting features from millions of protein sequences becomes impractical because they are not scalable with current algorithms. Therefore, there is a need for an efficient feature extraction approach that extracts significant features. We have proposed two scalable feature extraction approaches for extracting features from huge protein sequences using Apache Spark, which are termed 60d-SPF (60-dimensional Scalable Protein Feature) and 6d-SCPSF (6-dimensional Scalable Co-occurrence-based Probability-Speciﬁc Feature). The proposed 60d-SPF and 6d-SCPSF approaches capture the statistical properties of amino acids to create a fixed-length numeric feature vector that represents each protein sequence in terms of 60-dimensional and 6-dimensional features, respectively. ||| This paper presents a comprehensive study on clustering: exiting methods and developments made at various times. Clustering is defined as an unsupervised learning where the objects are grouped on the basis of some similarity inherent among them. There are different methods for clustering the objects such as hierarchical, partitional, grid, density based and model based. The approaches used in these methods are discussed with their respective states of art and applicability. The measures of similarity as well as the evaluation criteria, which are the central components of clustering are also presented in the paper. The applications of clustering in some fields like image segmentation, object and character recognition and data mining are highlighted.","Unsupervised learning, Apache Spark Cluster, Clustering, Data mining, protein sequences, Feature Extraction, Hierarchical Clustering, Big Data, ROCK, Fuzzy Clustering, Scalable Algorithms, Similarity measures, Clustering Approaches, Pattern recognition, BIRCH, Taxonomy, CURE, CHAMELEON, Apache Spark, Huge Protein Sequences","This paper proposes two scalable feature extraction approaches for huge protein sequences using Apache Spark, which are termed 60d-SPF and 6d-SCPSF. The proposed approaches capture the statistical properties of amino acids to create a fixed-length numeric feature vector that represents each protein sequence in terms of 60-dimensional and 6-dimensional features, respectively. The paper also discusses the clustering of huge protein sequences using SRSIO-FCM and SLFCM algorithms. ||| This paper reviews clustering techniques and developments, discussing methods such as hierarchical, partitional, grid, density-based, and model-based clustering, as well as measures of similarity and evaluation criteria. The applications of clustering in fields like image segmentation, object recognition, and data mining are highlighted."
Neha Nagendra,A Novel Scalable Apache Spark Based Feature Extraction Approaches for Huge Protein Sequence and their Clustering Performance Analysis,"Genome sequencing projects are rapidly increasing the number of high-dimensional protein sequence datasets. Clustering a high-dimensional protein sequence dataset using traditional machine learning approaches poses many challenges. Many different feature extraction methods exist and are widely used. However, extracting features from millions of protein sequences becomes impractical because they are not scalable with current algorithms. Therefore, there is a need for an efficient feature extraction approach that extracts significant features. We have proposed two scalable feature extraction approaches for extracting features from huge protein sequences using Apache Spark, which are termed 60d-SPF (60-dimensional Scalable Protein Feature) and 6d-SCPSF (6-dimensional Scalable Co-occurrence-based Probability-Speciﬁc Feature). The proposed 60d-SPF and 6d-SCPSF approaches capture the statistical properties of amino acids to create a fixed-length numeric feature vector that represents each protein sequence in terms of 60-dimensional and 6-dimensional features, respectively.","Big Data, protein sequences, Fuzzy Clustering, Scalable Algorithms, Apache Spark Cluster, Feature Extraction, Apache Spark, Huge Protein Sequences","This paper proposes two scalable feature extraction approaches for huge protein sequences using Apache Spark, which are termed 60d-SPF and 6d-SCPSF. The proposed approaches capture the statistical properties of amino acids to create a fixed-length numeric feature vector that represents each protein sequence in terms of 60-dimensional and 6-dimensional features, respectively. The paper also discusses the clustering of huge protein sequences using SRSIO-FCM and SLFCM algorithms."
Neha S. Joshi,Edge Detection Using Fuzzy Logic,"Image processing supports applications in different fields such as medicine, astronomy, product quality, industrial applications. Edge detection plays important role in segmentation and object identification process. This paper is a review of the various approaches adopted by several authors for edge detection in image processing.","Image processing, Genetic algorithm, Edge detection, Neural network, Fuzzy logic","The paper presents a comprehensive review of edge detection methods using fuzzy logic, including the use of fuzzy sets, fuzzy inference systems, and fuzzy operators. The authors discuss the advantages and limitations of traditional edge detection methods and propose the use of soft computing approaches for improved performance."
Neminath Hubballi,Application Layer Denial-of-Service (DoS) Attacks and Defense Mechanisms: A Survey ||| Targeted DNS Spoofing Attack,"Application layer Denial of Service (DoS) attacks are generated by exploiting vulnerabilities of the protocol implementation or its design. Unlike volumetric DoS attacks, these are stealthy in nature and target a specific application running on the victim. There are several attacks discovered against popular application layer protocols in recent years. In this paper, we provide a structured and comprehensive survey of the existing application layer DoS attacks and defense mechanisms. We classify existing attacks and defense mechanisms into different categories, describe their working, and compare them based on relevant parameters. We conclude this paper with directions for future research. ||| Domain Name System (DNS) is a central protocol of the internet and provides a way to resolve domain names to their corresponding IP addresses. Due to its working, it is one of the most critical protocols being used in the internet. However, DNS is known to be vulnerable to a popular attack called DNS poisoning. Fortunately, DNS poisoning has become difðcult to launch due to introduction of techniques like source port and query identiðcation value randomization. In this paper, we propose a targeted DNS spooðing attack that exploits a vulnerability present in DHCP server-side IP address conðict detection technique. We show that the proposed attack is easier to launch and requires minimal bandwidth as compared to previously known attacks. We also discuss how proposed attack can target even a single victim client also without affecting other clients. We test the effectiveness of proposed attack in a real network setup and report the results. Further, we discuss how known detection and mitigation techniques are unable to detect the attack.","distributed application layer DoS attacks, Vulnerability, targeted attack, DNS Spooðing, Protocol-specific and generic application layer DoS attacks, Survey, DNS, DHCP manipulation, defense mechanisms, DNS spoofing, Local Networks, network configuration, Application Layer Denial-of-Service (DoS) Attacks, DHCP","This paper provides a survey of existing application layer DoS attacks and defense mechanisms. It classifies existing attacks and defense mechanisms into different categories, describes their working, and compares them based on relevant parameters. The paper concludes with directions for future research. ||| This paper proposes a targeted DNS spooðing attack that exploits a vulnerability in DHCP server-side IP address conðict detection technique. The attack is easier to launch and requires minimal bandwidth compared to previously known attacks. The paper also discusses how the proposed attack can target a single victim client without affecting other clients."
Neri et al.,Memetic search in artiﬁcial bee colony algorithm,"Artiﬁcial bee colony (ABC) optimization algorithm is relatively a simple and recent population based probabilistic approach for global optimization. ABC has been outperformed over some Nature Inspired Algorithms (NIAs) when tested over benchmark as well as real world optimization problems. The solution search equation of ABC is signiﬁcantly inﬂuenced by a random quantity which helps in exploration at the cost of exploitation of the search space. In the solution search equation of ABC, there is a enough chance to skip the true solution due to large step size. In order to balance between diversity and con-vergence capability of the ABC, a new local search phase is integrated with the basic ABC to exploit the search space identiﬁed by the best individual in the swarm. In the proposed phase, ABC works as a local search algorithm in which, the step size that is required to update the best solution, is controlled by Golden Section Search approach. The proposed strategy is named as Memetic ABC (MeABC). In MeABC, new solutions are generated around the best solution and it helps to enhance the exploitation capability of ABC. MeABC is established as a modiﬁed ABC algorithm through experiments over 20 test problems of different complexities and 4 well known engineering optimization problems.","Exploration-exploitation, Swarm intelligence, Memetic algorithm, Memetic Search, Honey Bees, Artiﬁcial bee colony","This paper proposes a new local search strategy, Memetic ABC (MeABC), which integrates a Golden Section Search approach with the basic Artificial Bee Colony (ABC) algorithm to balance exploration and exploitation behavior. MeABC is established as a modified ABC algorithm through experiments over 20 test problems and 4 engineering optimization problems."
"Neumann, M.",A Multi-Task Approach to Open Domain Suggestion Mining,"Consumer reviews online may contain suggestions useful for improving the target products and services. Mining suggestions is challenging because the field lacks large labelled and balanced datasets. Furthermore, most prior studies have only focused on mining suggestions in a single domain. In this work, we introduce a novel up-sampling technique to address the problem of class imbalance, and propose a multi-task deep learning approach for mining suggestions from multiple domains.","Deep Learning, Suggestion Mining, Artificial Intelligence, Class Imbalance, Multi-Task Learning","This paper presents a multi-task approach to open domain suggestion mining, addressing the class imbalance problem using a novel up-sampling technique and a multi-task deep learning framework. Experimental results show that the proposed approach outperforms state-of-the-art models in terms of F-1 measure and AUC."
Newmark-Hall,3D FE MODELLING OF BURIED CONTINUOUS PIPELINE EXPOSED TO FAULT MOTION WITH MATERIAL NONLINEARITY AND LARGE DEFORMATION,"Pipeline generally extends over long distances traversing through wide variety of different soils, geological conditions and regions with different seismicity. Majority of the past works in the area of pipeline subjected to fault motion is restricted in several ways. There were many analytical models developed in the past for pipeline fault crossing, however, they are of limited usage, for example analytical model developed for pipeline fault crossing can be useful for strike slip fault crossing only. Likewise incorporating the large geometric changes in analytical study is a tricky task; however pipeline subjected to the fault motion itself is a phenomenon of large geometric changes. Especially when pipeline subjected to compression, where in addition to material deformation it also undergoes general as well as local buckling with bending, contradictorily past work mostly assumed that pipeline is under tension. With day by day increasing capacity of computation and advancement in numerical modeling, one can find more facts for pipeline subjected fault motions including cases of pipe under compression as well. In this paper, past work is reviewed for pipeline subjected to large fault motion. A three dimensional FE based numerical model is suggested to carry out pipeline performance of buried pipeline subjected to fault motion. A proposed model includes material nonlinearity, as well as effect of the large geometric changes. For this purpose, three dimensional FE program is developed in MATLAB. Displacement controlled Arc-length technique is implemented to solve the nonlinear behavior. To reduce the computation time of analysis here parallelization tool kit of MATLAB is utilized.","pipeline performance, Displacement controlled Arc-length technique, material nonlinearity, finite element method, Fault motion, Buried continuous pipeline, Nonlinear-large deformation FEM, large deformation","This paper presents a three-dimensional finite element model for buried continuous pipelines exposed to fault motion with material nonlinearity and large deformation. The model is developed using isoparametric brick elements and is validated by comparing the load-deflection curve with the results obtained from the commercially available finite element package ANSYS-12. The performance of the pipeline is evaluated for various fault offset, pipeline-fault crossing angle, wall thickness to diameter ratio, and depth of the buried pipeline."
Nidhi Sridhar,Shifting Behaviour of Users: Towards Understanding the Fundamental Law of Social Networks,"Social Networking Sites (SNSs) are powerful marketing and communication tools. There are hundreds of SNSs that have entered and exited the market over time. The coexistence of multiple SNSs is a rarely observed phenomenon. Most coexisting SNSs either serve different purposes for its users or have cultural differences among them. The introduction of a new SNS with a better set of features can lead to the demise of an existing SNS, as observed in the transition from Orkut to Facebook. The paper proposes a model for analyzing the transition of users from one SNS to another, when a new SNS is introduced in the system. The game theoretic model proposed considers two major factors in determining the success of a new SNS. The first being time that an old SNS gets to stabilise. We study whether the time that a SNS like Facebook received to monopolize its reach had a distinguishable effect. The second factor is the set of features showcased by the new SNS. The results of the model are also experimentally verified with data collected by means of a survey.","game theory, Game Theoretic Model, Diffusive Shift, Social Networking Sites, modeling, social networking, Cascading Pattern",This paper proposes a model for analyzing the transition of users from one Social Networking Site (SNS) to another when a new SNS is introduced in the system. The model considers two major factors in determining the success of a new SNS: the time an old SNS gets to stabilize and the set of features showcased by the new SNS. The results of the model are experimentally verified with data collected by means of a survey.
Niharika Pandey,Diurnal Variation of Ozone Levels in Academic Hostel in Delhi,"Urban air pollution has become a serious environmental problem in the last few decades in most of the developing countries including India. Due to widespread industrialization, rapid urbanization and huge growth in the number of motor vehicles have brought about severe deterioration in the urban air quality. Among the various gaseous pollutants, ozone is one of the important pollutants because of its health as well as climatic impacts. This study investigates the levels of ozone concentration at thirteen different hostels in an academic institute, Delhi. The measurements of ozone were carried out in indoor environments by ozone analyzer (Model S-5014 SIR) for 24 hours.","hostels, Delhi, academic hostels, ozone levels, diurnal variation, CPCB, anthropogenic activities, Indoor ozone, VOCs, NOx","The study reveals that the ozone concentration in the entire indoor environment of the JNU campus lies in the range (2.81 to 4.17 ppb for 24 hours) are well below the permissible limits (100 µg/m3 for 8 hours) prescribed by CPCB, India. Also the outdoor ozone concentration is found to lie in the range (13.93 ppb to 78. 15 ppb for 8 hours), which well above the standard (100 µg/m3 for 8 hours) prescribed by CPCB."
Nikhil R. Pal,PAL AND PAL: SOGARG: A SELF-ORGANIZED GENETIC ALGORITHM-BASED RULE GENERATION SCHEME FOR FUZZY CONTROLLERS ||| Robust Consensus: A New Measure for Multicriteria Robust Group Decision Making Problems Using Evolutionary Approach,"The paper discusses various methods for generating fuzzy controllers using genetic algorithms. It presents different approaches to designing fuzzy controllers, including the use of genetic algorithms to determine membership functions and rule sets. ||| In fuzzy group decision making problems, we often use multi-objective evolutionary optimization. The optimizers search through the whole search space and provide a set of nondominated solutions. But, sometimes the decision makers express their prior preferences using fuzzy numbers. In this case, the optimizers search in the preferred soft region and provide solutions with higher consensus. If perturbation in the decision variable space is unavoidable, we also need to search for robust solutions. Again, this perturbation aﬀects the degree of consensus of the solutions. This leads to search for solutions those are robust to their degree of consensus. In this work, we address these issues by redeﬁning consensus and proposing a new measure called robust consensus. We also provide a reformulation mechanism for multiobjective optimization problems. Our experimental results show that the proposed method is capable of ﬁnding robust solutions having robust consensus in the speciﬁed soft region.","genetic algorithm (GA), membership functions, Consensus, robustness, self-organizing, evolutionary algorithms, fuzzy group decision making, genetic algorithms, fuzzy controllers, multiobjective optimization, rule sets, Controllability","The paper reviews various methods for generating fuzzy controllers using genetic algorithms. It discusses the use of genetic algorithms to determine membership functions and rule sets, and presents different approaches to designing fuzzy controllers. ||| This paper proposes a new measure called robust consensus for multicriteria robust group decision making problems using evolutionary approach. The proposed method addresses the issues of prior preferences using fuzzy numbers and perturbation in the decision variable space. Experimental results show that the proposed method is capable of finding robust solutions having robust consensus in the specified soft region."
Nikhil Tripathi,"Application Layer Denial-of-Service (DoS) Attacks and Defense Mechanisms: A Survey ||| Design of Next-Generation Low-Power Sensor Network Nodes ||| Design Space Exploration Using the AccelFPGA Compiler ||| Detection and Prevention of ARP Poisoning ||| MOTIVATING CHILD DEVELOPMENT AND ERADICATION OF CHILD LABOR BY PROMPT EFFORTS BY US, SOCIETY AND GOVERNMENT ||| Observability-based Sequential Analysis for Redundant Reset Identification ||| Power Optimization Strategy for Android Applications ||| Slow Rate Denial of Service Attacks Against HTTP/2 and Detection ||| Targeted DNS Spoofing Attack ||| Upgradation Of Biogas Using Combined Method Of Alkaline Water Scrubbing And Adsoption Through Carbon Molecular Sieve","Application layer Denial of Service (DoS) attacks are generated by exploiting vulnerabilities of the protocol implementation or its design. Unlike volumetric DoS attacks, these are stealthy in nature and target a specific application running on the victim. There are several attacks discovered against popular application layer protocols in recent years. In this paper, we provide a structured and comprehensive survey of the existing application layer DoS attacks and defense mechanisms. We classify existing attacks and defense mechanisms into different categories, describe their working, and compare them based on relevant parameters. We conclude this paper with directions for future research. ||| This paper presents the design of next-generation low-power sensor network nodes that can scavenge energy from the environment and use this energy to power the sensor network device. ||| This paper discusses the use of the AccelFPGA compiler to perform design space exploration of various area-performance tradeoffs. The compiler allows the user to use compiler directives to demarcate parts of the input source that are targeted for hardware synthesis and parts that are not. The paper presents a case study of a 16 tap FIR filter implemented using the AccelFPGA compiler and discusses the performance and area tradeoffs of the design. ||| This paper presents a feasible technique to detect and prevent the ARP poisoning by removing the multiple entries for the same MAC address or IP address from the ARP table using a secondary cache. ||| One of the menacing curses that our nation is facing today is child labor. Lack of economy and basic education has been monitored as a cause for majority of child labor activities. It is being generally realized that, child labor especially in hazardous occupation is one of the worst social evil and has to be eliminated at the earliest. Government has been taking various pro-active measures to tackle this problem. However, considering the magnitude and extent of the problem and that it is essentially a socio-economic problem inextricably linked to poverty and illiteracy, it requires concerted efforts from all sections of the society to make a dent in the problem. ||| Resets are required in the design to initialize the hardware for system operation and to force it into a known state for simulation or to recover from an error. ||| Energy efficiency is a critical factor in mobile systems, and a significant body of recent research efforts has focused on reducing the energy dissipation in mobile hardware and applications. The Android OS Power Manager provides programming interface routines called wakelocks for controlling the activation state of devices on a mobile system. ||| HTTP/2 is a newly standardized protocol designed to efficiently utilize the TCP’s transmission rate and has other advantages compared to HTTP/1.1. However its threat vectors are not completely understood yet. Our contribution in this paper is threefold. First we describe few new threat vectors of HTTP/2 which are Slow Rate DoS attacks and can be launched by injecting specially crafted HTTP requests. We perform an empirical evaluation of these attacks against popular web servers and report that majority of web servers are vulnerable to these attacks. We also test the effectiveness of proposed attacks using both clear text and encrypted HTTP/2 requests and find that the attack is effective independent of the request type. Second we compare structurally similar attacks with HTTP/1.1 and report that HTTP/2 has more threat vectors compared to its predecessor. Third we propose an anomaly detection scheme which uses chi-square (χ2) test between traffic profiles generated in normal and attack scenarios to detect these attacks. ||| Domain Name System (DNS) is a central protocol of the internet and provides a way to resolve domain names to their corresponding IP addresses. Due to its working, it is one of the most critical protocols being used in the internet. However, DNS is known to be vulnerable to a popular attack called DNS poisoning. Fortunately, DNS poisoning has become difðcult to launch due to introduction of techniques like source port and query identiðcation value randomization. In this paper, we propose a targeted DNS spooðing attack that exploits a vulnerability present in DHCP server-side IP address conðict detection technique. We show that the proposed attack is easier to launch and requires minimal bandwidth as compared to previously known attacks. We also discuss how proposed attack can target even a single victim client also without affecting other clients. We test the effectiveness of proposed attack in a real network setup and report the results. Further, we discuss how known detection and mitigation techniques are unable to detect the attack. ||| Over the past decade there is increasing demand of energy in rural, urban areas of India. This has led to the depletion of natural resources like coal, wood and kerosene. These sources are inefficient and harmful to the environment. Thus there is an imminent need to replace them with clean, eco-friendly and efficient source of energy.","Vulnerability Assessment, RTL, IP-MAC bindings, awareness, Vulnerability, Ultra Low Power System Architecture, Chi-square Test, menacing, Alkaline Water Scrubbing, network configuration, Anomaly Detection, Combined Method, Routability, Event-Driven Computation, low-power sensor network nodes, MATLAB, education, AccelFPGA, ICMP protocol, Data Flow Analysis, ASIC, eradication, Wakelock Placement, secondary ARP cache, DHCP manipulation, FPGAs, Application Layer Denial-of-Service (DoS) Attacks, government, Fine-Grain Power Management, biomethane, Observability, Cyber Defense, HTTP/1.1, energy scavenging, High level synthesis, pressure swing adsorption, VHDL, DoS Attacks, FIR filter, Network Security, water scrubbing, Android, HTTP/2, Survey, compiler, Local Networks, Resets, government schemes, Sequential Analysis, Slow Rate DoS attacks, DHCP, design space exploration, Redundant Reset Identification, Optimization, DNS, Biogas, Mobile Systems, DNS Spooðing, Sensor Network Applications, event-driven system, Adsoption Through Carbon Molecular Sieve, DNS spoofing, Verilog, Power, Man-in-the-Middle, RTL Power Analysis, child labor, illiteracy, hardware acceleration, Observability-based Sequential Analysis, defense mechanisms, Energy Optimization, distributed application layer DoS attacks, area-performance tradeoffs, DOS scenario, Protocol-specific and generic application layer DoS attacks, ICMP, targeted attack, IP Exhaustion, Power Optimization, ARP Poisoning, Address Resolution Protocol","This paper provides a survey of existing application layer DoS attacks and defense mechanisms. It classifies existing attacks and defense mechanisms into different categories, describes their working, and compares them based on relevant parameters. The paper concludes with directions for future research. ||| The paper discusses the design of next-generation low-power sensor network nodes that can scavenge energy from the environment and use this energy to power the sensor network device. The system architecture is designed to be event-driven, with hardware accelerators offloading common tasks to improve performance and power efficiency. ||| The paper presents a case study of a 16 tap FIR filter implemented using the AccelFPGA compiler and discusses the performance and area tradeoffs of the design. The compiler allows the user to use compiler directives to demarcate parts of the input source that are targeted for hardware synthesis and parts that are not. The paper also discusses the use of the compiler to perform high-level estimates of area and performance. ||| The paper proposes a technique to detect and prevent ARP poisoning by using a secondary cache that contains entries according to ICMP responses. This approach prevents multiple entries for the same IP address or MAC address, mitigates IP exhaustion, and is distributed in nature, preventing single point failure. ||| The paper discusses the menace of child labor in India and proposes a plan to eradicate it through education, financial support, and awareness. The plan involves collecting donations, providing financial assistance to underprivileged families, and setting up schools for primary education. The authors aim to make children skillful by imparting professional education and provide alternative employment opportunities. ||| The proposed algorithm was applied on six industrial designs from variety of applications: multi-media, video processing, storage devices and smart-phone. The results show a maximum of 70% reduction in load of reset network, 22% sequential power saving and 2% design area reduction. ||| This paper proposes a data flow analysis based strategy for determining the placement of wakelock statements corresponding to the uses of devices in an application. The proposed optimization strategy shows significant (up to 32%) energy savings with experimental evaluation on a set of Android applications. ||| This paper presents few new threat vectors of HTTP/2 which are Slow Rate DoS attacks. The authors propose a statistical abnormality measurement technique that uses chi-square statistic test to detect any deviation in the HTTP/2 traffic profile created with normal HTTP/2 traffic. The method can identify deviations in network traffic patterns due to presence of anomalous connections originating from these Slow Rate attacks. ||| This paper proposes a targeted DNS spooðing attack that exploits a vulnerability in DHCP server-side IP address conðict detection technique. The attack is easier to launch and requires minimal bandwidth compared to previously known attacks. The paper also discusses how the proposed attack can target a single victim client without affecting other clients. ||| The paper discusses the upgradation of biogas using a combined method of alkaline water scrubbing and adsorption through carbon molecular sieve. The method involves the passage of compressed biogas through a cylindrical pipe packed with carbon molecular sieves, which enriches the methane content to 88% or more. The paper also discusses the environmental advantages of biogas, including its renewable nature, ability to reduce greenhouse gas emissions, and potential to replace fossil fuels."
Nikolaos G. Frangogiannis,Endogenous IRAK-M Attenuates Postinfarction Remodeling Through Effects on Macrophages and Fibroblasts ||| Opposing Actions of Fibroblast and Cardiomyocyte Smad3 Signaling in the Infarcted Myocardium ||| TSP-1 in Diabetic Cardiomyopathy,"Quantitative polymerase chain reaction analysis demonstrated significant IRAK-M mRNA upregulation in the infarcted myocardium. The time course of IRAK-M induction showed a biphasic response (Figure 1), characterized by marked early upregulation after 6 hours of reperfusion, followed by a second peak after 7 days of reperfusion (Figure 1A). IRAK-M Is Localized in Infarct Macrophages and Myofibroblasts Dual immunofluorescence was used to study IRAK-M localization in the infarcted myocardium. IRAK-M immunoreactivity in the infarcted heart was localized in Mac2+ infarct macrophages and in spindle-shaped, α–smooth muscle actin–positive myofibroblasts (Figure 1B and 1C). Moreover, infarct myofibroblasts and CD11b+ leukocytes isolated from the infarcted heart after 72 hours of reperfusion exhibited IRAK-M expression (Figure 1D–1G). To study cell-type specific changes in the timing of IRAK-M expression, we assessed IRAK-M mRNA levels in cardiac fibroblasts and CD11b+ leukocytes harvested from the infarcted heart. Isolated fibroblasts had a 3-fold increase in IRAK-M mRNA levels after 24 hours to 72 hours of reperfusion in comparison with control cardiac fibroblasts. When compared with control CD11b+ cells harvested from normal hearts, leukocytes isolated after 6 hours of reperfusion showed a trend toward increased IRAK-M mRNA expression (Figure I in the online-only Data Supplement). IRAK-M Loss Is Associated With Enhanced Adverse Remodeling Despite the Absence of Effects on the Size of the Infarct IRAK-M−null and WT animals had comparable mortality after myocardial infarction (P=NS). Triphenyltetrazolium chloride/Evans blue staining demonstrated that IRAK-M loss does not affect the size of the infarct after 1 hour of ischemia and 24 hours of reperfusion (Figure 1H–1J). Two independent techniques, echocardiographic imaging (Figure 2A–2G; Table I in the online-only Data Supplement) and quantitative morphometry (Figure 2H–2L), demonstrated that IRAK-M loss was associated with enhanced adverse remodeling after myocardial infarction. Systolic and diastolic chamber dimensions measured through echocardiography (left ventricular end-diastolic dimension, left ventricular end-systolic dimension, left ventricular end-systolic volume, and left ventricular end-diastolic volume; Figure 2A–2G) and morphometrically-derived left ventricular end-diastolic volume and left ventricular end-diastolic dimension (Figure 2H–2L) were significantly higher in IRAK-M−null mice after 7 and 28 days of reperfusion, indicating increased chamber dilation. Left ventricular mass was also significantly higher in infarcted IRAK-M−null hearts, suggesting accentuated hypertrophic remodeling. Increased adverse remodeling in the absence of IRAK-M was associated with reduced fractional shortening (FS), reflecting worse systolic dysfunction (Figure 2D). Because acute infarct size was comparable between WT and IRAK-M−null mice (Figure 1H–1J), accentuated adverse remodeling in IRAK-M−null hearts was not a result of more extensive cardiomyocyte injury. Moreover, scar size after 7 to 28 days of reperfusion was comparable between IRAK-M−/− and WT animals (Figure 2I). IRAK-M−/− Mice Have Enhanced Postinfarction Inflammation Exhibiting Increased Myocardial Cytokine mRN ||| Transforming growth factor (TGF)–βs are highly pleiotropic mediators with critical roles in regulating cellular phenotype and function in embryonic development, tissue homeostasis, and disease. Normal tissues contain stores of latent TGF-β bound to the extracellular matrix through its association with a large binding protein, the latent TGF-β binding protein. Tissue injury is associated with marked induction of TGF-β isoforms and activation of TGF-β signaling cascades. Parenchymal cells, extravasated leukocytes, and platelets synthesize and release large amounts of TGF-β in the injury site. Reactive oxygen species, proteases, matricellular proteins, and integrins cooperate to trigger the release of bioactive TGF-β from the latent stores. Subsequent binding of the active TGF-β dimer to the type II TGF-β receptor, followed by transphosphorylation of the type I receptor, triggers the TGF-β signaling response. The cellular effects of TGF-β are mediated through a canonical pathway involving a series of intracellular effectors, the Smads, or through activation of noncanonical signaling cascades. Activation of TGF-β signaling induces phosphorylation of the receptor-activated Smads, Smad2 and Smad3, which can form heteromeric complexes with the common Smad, Smad4. These complexes are transported to the nucleus, where they regulate gene transcription. TGF–β receptors and Smads are ubiquitously expressed by all cell types. Thus, all cells are responsive to the actions of TGF-β. Cardiac injury is associated with the marked induction of TGF-β and activation of TGF-β cascades. Our laboratory and other investigators have documented activation of Smad2 and Smad3 signaling in the infarcted myocardium, localized in both cardiomyocytes and interstitial cells. In isolated cardiac fibroblasts, Smad3 signaling accentuates myofibroblast transdifferentiation and stimulates a matrix-preserving program. In a model of reperfused infarction, global loss of Smad3 attenuated remodeling after infarction. However, considering the ubiquitous expression of Smad3 in all cell types, the cell biological basis for the actions of Smad3 in the infarcted heart remains unknown. Our study dissects the cell-specific actions of Smad3 signaling in the infarcted myocardium by developing and studying mice with cell-specific loss of Smad3 in activated fibroblasts and cardiomyocytes. It is surprising that fibroblast-specific loss of Smad3 worsened remodeling after infarction, resulting in accentuated chamber dilation. The deleterious consequences of fibroblast-specific Smad3 loss reflected unrestrained fibroblast proliferation, defective scar remodeling, and perturbed organization of myofibroblast arrays in the border zone. Smad3 signaling regulated fibroblast function, activating integrin-mediated nicotinamide adenine dinucleotide phosphate (NADPH) oxidase (NOX)–2 expression. In contrast, cardiomyocyte-specific loss of Smad3 protected the infarcted heart from dysfunction after infarction. The protective effects of cardiomyocyte-specific Smad3 loss were associated with attenuated cardiomyocyte apoptosis in remodeling myocardium and accompanied by decreased NOX2 levels, reduced nitrosative stress, and decreased matrix metalloproteinase (MMP)–2 expression. ||| Diabetes mellitus is associated with cardiac fibrosis. Matricellular proteins are induced in fibrotic conditions and modulate fibrogenic and angiogenic responses by regulating growth factor signaling. Our aim was to test the hypothesis that the prototypical matricellular protein thrombospondin (TSP)-1, a potent angiostatic molecule and crucial activator of transforming growth factor-β, may play a key role in remodeling of the diabetic heart. Obese diabetic db/db mice exhibited marked myocardial TSP-1 upregulation in the interstitial and perivascular space. To study the role of TSP-1 in remodeling of the diabetic heart, we generated and characterized db/db TSP-1–/– (dbTSP) mice. TSP-1 disruption did not significantly affect weight gain and metabolic function in db/db animals. When compared with db/db animals, dbTSP mice had increased left ventricular dilation associated with mild nonprogressive systolic dysfunction. Chamber dilation in dbTSP mice was associated with decreased myocardial collagen content and accentuated matrix metalloproteinase-2 and -9 activity. TSP-1 disruption did not affect inflammatory gene expression and activation of transforming growth factor-β/small mothers against decapendaplegic signaling in the db/db myocardium. In cardiac fibroblasts populating collagen pads, TSP-1 incorporation into the matrix did not activate transforming growth factor-β responses, but inhibited leptin-induced matrix metalloproteinase-2 activation. TSP-1 disruption abrogated age-associated capillary rarefaction in db/db mice, attenuating myocardial upregulation of angiopoietin-2, a mediator that induces vascular regression. In vitro, TSP-1 stimulation increased macrophage, but not endothelial cell, angiopoietin-2 synthesis. Conclusions: TSP-1 upregulation in the diabetic heart prevents chamber dilation by exerting matrix-preserving actions on cardiac fibroblasts and mediates capillary rarefaction through effects that may involve angiopoietin-2 upregulation.","SMAD, metalloproteinases, fibroblast, cytokines, matrix metalloproteinases, immune system, heart failure, macrophages, cardiomyocyte, thrombospondins, fibrosis, cardiac remodeling, ventricular remodeling, remodeling, diabetic cardiomyopathies","This study investigates the role of Interleukin-1 receptor-associated kinase (IRAK)-M in myocardial infarction.  Key findings include: 

* IRAK-M mRNA is significantly upregulated in the infarcted myocardium, with a biphasic response.
* IRAK-M is localized in macrophages and myofibroblasts within the infarcted heart.
* IRAK-M loss is associated with enhanced adverse remodeling after myocardial infarction, characterized by increased chamber dilation and hypertrophy, despite no effect on infarct size.
* IRAK-M−/− mice exhibit increased postinfarction inflammation with elevated myocardial cytokine mRNA levels. ||| This study investigates the role of Smad3 in cardiac fibroblasts following myocardial infarction. Using a mouse model with fibroblast-specific Smad3 deletion (FS3KO), the researchers found that loss of Smad3 in fibroblasts exacerbated dilative remodeling and worsened systolic dysfunction after both reperfused and nonreperfused infarction.  While acute infarct size was not affected, FS3KO mice exhibited larger scars, increased myofibroblast density, and enhanced myofibroblast proliferation. These findings suggest that Smad3 plays a protective role in cardiac fibroblasts and its loss contributes to adverse cardiac remodeling after infarction. ||| This study investigates the role of thrombospondin-1 (TSP-1) in diabetic cardiomyopathy. Researchers found that TSP-1 is upregulated in the hearts of diabetic mice and that its loss attenuates cardiac fibrosis and enhances myocardial protease activity. However, TSP-1 disruption also led to mild left ventricular dilation and modest nonprogressive systolic dysfunction. These findings suggest that TSP-1 plays a complex role in diabetic heart remodeling, with both beneficial and detrimental effects."
Nikula et al.,Characterizing relatedness of web and requirements engineering,"Web and Requirements Engineering have been well-recognized as two individual active areas of research in the past. Convergence between these two notable areas has been a point-of-discussion in recent years and offers new avenues of research. This paper explores this alliance from two perspectives; firstly, where Requirement Engineering can be viewed as a process for Web application development as it primarily concerns with adapting the Requirement Engineering process to the Web applications which are special in characteristics as compared to traditional software applications and secondly, where Web can be viewed as a supporting technology for improving the requirements engineering process and enabling new capabilities.","Web Applications, Web 3.0, Web 2.0, SWOT Analysis, Web application, Requirements engineering","The paper explores the relationship between Web and Requirements Engineering from two perspectives, highlighting the need for a more extensive and efficient Requirements Engineering process for Web applications, and the potential of Web technologies to support and improve the requirements engineering process."
Nilagiri Harshith,A Novel Scalable Apache Spark Based Feature Extraction Approaches for Huge Protein Sequence and their Clustering Performance Analysis,"Genome sequencing projects are rapidly increasing the number of high-dimensional protein sequence datasets. Clustering a high-dimensional protein sequence dataset using traditional machine learning approaches poses many challenges. Many different feature extraction methods exist and are widely used. However, extracting features from millions of protein sequences becomes impractical because they are not scalable with current algorithms. Therefore, there is a need for an efficient feature extraction approach that extracts significant features. We have proposed two scalable feature extraction approaches for extracting features from huge protein sequences using Apache Spark, which are termed 60d-SPF (60-dimensional Scalable Protein Feature) and 6d-SCPSF (6-dimensional Scalable Co-occurrence-based Probability-Speciﬁc Feature). The proposed 60d-SPF and 6d-SCPSF approaches capture the statistical properties of amino acids to create a fixed-length numeric feature vector that represents each protein sequence in terms of 60-dimensional and 6-dimensional features, respectively.","Big Data, protein sequences, Fuzzy Clustering, Scalable Algorithms, Apache Spark Cluster, Feature Extraction, Apache Spark, Huge Protein Sequences","This paper proposes two scalable feature extraction approaches for huge protein sequences using Apache Spark, which are termed 60d-SPF and 6d-SCPSF. The proposed approaches capture the statistical properties of amino acids to create a fixed-length numeric feature vector that represents each protein sequence in terms of 60-dimensional and 6-dimensional features, respectively. The paper also discusses the clustering of huge protein sequences using SRSIO-FCM and SLFCM algorithms."
Nirmal Kumar Gupta,Automated Cryptanalysis of Substitution Ciphers using Swarm Intelligence Techniques,"This paper presents a comparative analysis of various swarm intelligence techniques for automated cryptanalysis of substitution ciphers. The techniques used include particle swarm optimization (PSO), bees algorithm, ant colony optimization, firefly algorithm, and cuckoo search. The results show that the cuckoo search technique is the most effective, with an average number of key elements correctly recovered of 26.17 out of 27, and a mean performance time of 0.137 seconds.","Bees Algorithm, Automated Cryptanalysis, Firefly Algorithm, Substitution Ciphers, Particle Swarm Optimization, Swarm Intelligence, Ant Colony Optimization, Classical Substitution Cipher, Cuckoo Search","This paper presents a comparative analysis of various swarm intelligence techniques for automated cryptanalysis of substitution ciphers. The results show that the cuckoo search technique is the most effective, with an average number of key elements correctly recovered of 26.17 out of 27, and a mean performance time of 0.137 seconds."
Nishchal K Verma,Support Vector Machines for Pattern Recognition,We propose a novel approach for content based color image classification using Support Vector Machine (SVM). Traditional classification approaches deal poorly on content based image classification tasks being one of the reasons of high dimensionality of the feature space.,"Pattern Recognition, image classification, color image histogram, Knowledge Discovery, Data Mining, Support Vector Machines, Support Vector Machine",The paper proposes a novel approach for content based color image classification using Support Vector Machine (SVM). The approach uses color image histograms as features and is found to be efficient and insensitive to small changes in camera viewpoint.
Nishchal K. Verma,Adaptive Type-2 Fuzzy Approach for Filtering Salt and Pepper Noise in Grayscale Images ||| A Correlation Model for Sensor Networks ||| Event-Triggered Sliding Mode Control for Trajectory Tracking of Nonlinear Systems ||| Generic correlation model for wireless sensor network applications ||| Health Monitoring for Rotating Machine Using SVM Based Methods ||| Multiclass SVM Methods for Classification ||| SVM based Methods for Arrhythmia Classification in ECG,"This paper presents a novel approach for removing salt and pepper noise from images using Type-2 fuzzy filter. The proposed approach uses two different methods for designing the upper and lower membership functions of the Type-2 fuzzy set. The first method uses distinct means and same variance, while the second method uses distinct means and variances. The proposed approach is compared with the existing methods using various images and the results show that it outperforms the existing methods in terms of noise removal and image quality. ||| Wireless sensor networks (WSN) are densely deployed to promise the fine-grain monitoring in various applications. For example, it may be as high as 20 nodes/m3 or more [1]. Due to high density of sensor nodes, spatially correlated information is observed and transmitted by surrounding sensor nodes once an interest of event detected. Thus, there exists spatial correlation among the sensor observations. The spatial correlation brings significant potential advantages along with collaborative nature of the WSN in energy-efficient design of communication protocols. This paper presents a novel spatial correlation model for wireless sensor networks. Based on sensor coverage model and location of sensor nodes, a spatial correlation function is derived to describe the correlation characteristics of measurements observed by sensor nodes. The case studies using correlation function are performed to study the correlation relationship between sensor nodes. Finally, based on case studies, their results, and discussions, a correlated cell construction algorithm is proposed and possible approaches are explored to exploit spatial correlation for efficient medium access and clustering protocols for WSN. ||| This paper presents a novel approach for designing event-triggered sliding mode control (SMC) for nonlinear input affine systems with external disturbances. The proposed control approach has been designed by modeling the dynamics for a class of nonlinear systems into a general nonlinear control affine system. The control approach can be directly applied to systems that are already in affine form. ||| A generic spatial correlation model for wireless sensor networks is proposed. The model is based on the assumption that the received sensory data from reporting nodes is jointly Gaussian. The covariance between the two measured values from nodes ni and nj at location si and sj, respectively, can be expressed by Cov si, sj = s2 SKq ∥si −sj∥. The correlation function Kϑ(.) is used to model the correlation between sensor nodes. The control parameter ϑ is used to control the degree of correlation between nodes. The proposed model is a generic correlation model that can be applied to all sensor network applications. ||| Fault diagnosis in reciprocating air compressors is essential for continuous monitoring of their performance and thereby ensuring quality output. Support Vector Machines (SVMs) are machine learning tools based on structural risk minimization principle and have the advantageous characteristic of good generalization. ||| This paper presents support vector machine based methods for arrhythmia classification in ECG datasets with selected features. Among various existing SVM methods, four well-known and widely used algorithms One Against One (OAO), One Against All (OAA), Fuzzy Decision Function (FDF) and Decision Directed Acyclic Graph (DDAG) are used here to distinguish between the presence and absence of cardiac arrhythmia and classifying them into one of the arrhythmia groups. ||| This paper presents a multiclass classification algorithm using support vector machines (SVMs). The algorithm is applied to the standard multivariate ECG dataset taken from the University of California at Irvine (UCI) Cardiac Arrhythmias database. The results show that the one-against-all algorithm shows the highest percentage of accuracy rate.","peak signal-noise-ratio (PSNR), Type-2 fuzzy filter, fuzzy decision function, spatial correlation, External disturbances, fault diagnosis, Support vector machine, correlation function, Classification, Multiclass Classification, SVM Based Methods, Nonlinear systems, Event-triggered sliding mode control, Trajectory tracking, wireless sensor networks, Rotating Machine, Clustering protocol, Event-triggered control, Type-1 fuzzy set, data aggregation, reciprocating air compressor, distributed source coding, salt and pepper noise, Mean of k-middle, ECG Database, control parameter, sensor networks, Compressor Dataset, Sliding mode control, image denoising, spatial correlation model, Arrhythmias, correlation model, MAC protocol, energy-efﬁcient methodologies, Support Vector Machines, Support Vector Machine, support vector machine, Electrocardiogram, membership functions, Principal Component Analysis, Uncertainty, Feature Selection, Wireless Sensor Networks, Type-2 fuzzy set, Health Monitoring, Multiclass SVM, Arrhythmia","The proposed approach uses a Type-2 fuzzy filter to remove salt and pepper noise from images. The filter uses two different methods for designing the upper and lower membership functions of the Type-2 fuzzy set. The first method uses distinct means and same variance, while the second method uses distinct means and variances. The proposed approach is compared with the existing methods using various images and the results show that it outperforms the existing methods in terms of noise removal and image quality. ||| This paper presents a novel spatial correlation model for wireless sensor networks. The model derives a spatial correlation function to describe the correlation characteristics of measurements observed by sensor nodes. The case studies using correlation function are performed to study the correlation relationship between sensor nodes. A correlated cell construction algorithm is proposed and possible approaches are explored to exploit spatial correlation for efficient medium access and clustering protocols for WSN. ||| The proposed control approach ensures asymptotic stability of the system in the presence of external disturbances. The event-triggered SMC law is designed to meet two aspects: tracking error should converge to zero, ensuring asymptotic stability of the system, and does not violate the admissibility condition, i.e., non-stacking of actuator actions. ||| The proposed spatial correlation model is a generic model that can be applied to all sensor network applications. It is based on the assumption that the received sensory data from reporting nodes is jointly Gaussian. The model uses the correlation function Kϑ(.) to model the correlation between sensor nodes. The control parameter ϑ is used to control the degree of correlation between nodes. The proposed model can provide guidelines for designing energy-efﬁcient communication protocols for most of the WSNs. ||| This paper proposes an optimized SVM based method for classification based fault diagnosis in reciprocating air compressors. The results obtained through implementation of all five techniques are compared as per their accuracy rate in percentages. ||| The paper presents a comprehensive review of multiclass SVM methods, including their strengths and weaknesses. It also discusses the importance of feature selection in improving classification accuracy and proposes the use of Principal Component Analysis for this purpose. ||| The paper presents a study on the use of Support Vector Machine (SVM) based methods for classifying electrocardiogram (ECG) arrhythmias. The authors used three well-known SVM methods, one-against-one, one-against-all, and fuzzy decision function, to distinguish between the presence and absence of cardiac arrhythmia and classify them into one of the arrhythmia groups."
Nishi Gupta,MUTUAL LEARNING IN TREE PARITY MACHINES USING CUCKOO SEARCH ALGORITHM FOR SECURE PUBLIC KEY EXCHANGE,"In Neural Cryptography, Artificial Neural Networks are used for the process of key generation and encryption. Tree Parity Machine (TPM) is a single layer neural network that approaches symmetric key exchange using the process of mutual learning. This method is exploited to design a secure key exchange protocol, where the sender and the receiver TPMs are synchronized to obtain an identically tuned weight vectors in both the networks.","Mutual Learning, Neural Synchronisation, Neural Networks, Secure Public Key Exchange, Tree Parity Machine, Cuckoo Search Algorithm, Security, Key Exchange","This paper proposes a novel approach for the process of synchronisation in Tree Parity Machines using Cuckoo Search Algorithm for secure public key exchange. The results show that using CS algorithm for weight vector initialisation decreases the number of iterations significantly, resulting in ~30% decrease on an average. The effect of CS algorithm was observed by changing the weight range from 4 to 7 with N = 3, K = 100, and the results show that using CS, the synchronisation steps are decreased tremendously i.e. >50% decrease is observed."
Nitesh Pradhan,Transforming view of medical images using deep learning,"Since the last decade, there is a significant change in the procedure of medical diagnosis and treatment. Specifically, when internal tissues, organs such as heart, lungs, brain, kidneys and bones are the target regions, a doctor recommends ‘computerized tomography’ scan and/or magnetic resonance imaging to get a clear picture of the damaged portion of an organ or a bone. This is important for correct examination of the medical deformities such as bone fracture, arthritis, and brain tumor. It ensures prescription of the best possible treatment. But ‘computerized tomography’ scan exposes a patient to high ionizing radiation. These rays make a person more prone to cancer. Magnetic resonance imaging requires a strong magnetic field. Thus, it becomes impractical for patients with implants in their body. Moreover, the high cost makes the above-stated techniques unaffordable for low economy class of society. The above-mentioned challenges of ‘computerized tomography’ scan and magnetic resonance imaging motivate researchers to focus on developing a technique for conversion of 2-dimensional view of medical images into their corresponding multiple views. In this manuscript, the authors design and develop a deep learning model that makes an effective use of conditional generative adversarial network, an extension of generative adversarial network for the transformation of 2-dimensional views of human bone into the corresponding multiple views at different angles. The model will prove useful for both doctors and patients.","CT scan, 2-Dimensional, DCGAN, ACGAN, Deep learning, MRI, Conditional generative adversarial network, InfoGAN, CCAN, SGAN, SRGAN, Generative Adversarial Networks, 3-Dimensional, Image-to-Image Translation","The paper discusses the application of GANs in image-to-image translation and presents various techniques such as InfoGAN, SGAN, SRGAN, CCAN, DCGAN, and ACGAN. The paper highlights the advantages and disadvantages of each technique and provides a clear idea about the extension of the application area of the existing work."
Nitin Gupta,Mining Quantitative Association Rules in Protein Sequences,"Lot of research has gone into understanding the composition and nature of proteins, still many things remain to be understood satisfactorily. It is now generally believed that amino acid sequences of proteins are not random, and thus the patterns of amino acids that we observe in the protein sequences are also non-random.","Data mining, protein sequences, amino acids, protein composition, quantitative association rule mining",This study attempts to decipher the nature of associations between different amino acids that are present in a protein. The authors have attempted to find out rules that can tell that occurrence of one amino-acid is more likely when another amino-acid is present or absent.
Nitin Mangal,Mining Quantitative Association Rules in Protein Sequences,"Lot of research has gone into understanding the composition and nature of proteins, still many things remain to be understood satisfactorily. It is now generally believed that amino acid sequences of proteins are not random, and thus the patterns of amino acids that we observe in the protein sequences are also non-random.","Data mining, protein sequences, amino acids, protein composition, quantitative association rule mining",This study attempts to decipher the nature of associations between different amino acids that are present in a protein. The authors have attempted to find out rules that can tell that occurrence of one amino-acid is more likely when another amino-acid is present or absent.
Nitin S. Choubey,Edge Detection Using Fuzzy Logic,"Image processing supports applications in different fields such as medicine, astronomy, product quality, industrial applications. Edge detection plays important role in segmentation and object identification process. This paper is a review of the various approaches adopted by several authors for edge detection in image processing.","Image processing, Genetic algorithm, Edge detection, Neural network, Fuzzy logic","The paper presents a comprehensive review of edge detection methods using fuzzy logic, including the use of fuzzy sets, fuzzy inference systems, and fuzzy operators. The authors discuss the advantages and limitations of traditional edge detection methods and propose the use of soft computing approaches for improved performance."
Nooshin Anari,A comparative study of testing semantic web services,"Web Services provide efficient reusability mechanism, thereby reducing the development time and cost. Mostly the source code of web services is unavailable to other developers who use these services. The manual effort spent by them in testing these web services is very large in order to increase the interoperability. Thus, automated testing needs to be developed for testing these Web services. This paper reviews test cases for Web Services using reduction techniques Pair-Wise Testing (PWT) and Orthogonal Array Testing (OAT) and compares the two techniques with general method. The structure of Web Services is specified using UML diagrams. The pre and post conditions for the service rule are specified using Object Constraint Language (OCL). The framework transforms into WSDL-S specifications. These specifications are parsed and transformed into structured DOM tree. Test data set generated by this framework would satisfy the constraints of the WSDL. The test cases are then developed based on the data generated, documented in XML based test files. The number of test cases required by general testing, PWT, OAT are compared and the better testing technique for testing Web Services is determined.","Semantics, Reduction Techniques, Reduction, Test case, Web Services, Pair wise, Orthogonal Array Testing, web service, Test Cases, Pair-Wise Testing, Orthogonal Array","This paper compares Pair-Wise Testing (PWT) and Orthogonal Array Testing (OAT) for reducing the number of test cases needed for Web Services. It finds that OAT is more efficient when dealing with a large number of parameters, while PWT is suitable for smaller sets of parameters. Both techniques significantly reduce the testing effort compared to a general approach."
Nuseibeh & Easterbrook,Characterizing relatedness of web and requirements engineering,"Web and Requirements Engineering have been well-recognized as two individual active areas of research in the past. Convergence between these two notable areas has been a point-of-discussion in recent years and offers new avenues of research. This paper explores this alliance from two perspectives; firstly, where Requirement Engineering can be viewed as a process for Web application development as it primarily concerns with adapting the Requirement Engineering process to the Web applications which are special in characteristics as compared to traditional software applications and secondly, where Web can be viewed as a supporting technology for improving the requirements engineering process and enabling new capabilities.","Web Applications, Web 3.0, Web 2.0, SWOT Analysis, Web application, Requirements engineering","The paper explores the relationship between Web and Requirements Engineering from two perspectives, highlighting the need for a more extensive and efficient Requirements Engineering process for Web applications, and the potential of Web technologies to support and improve the requirements engineering process."
O. P. Patel,Advanced Quantum Based Neural Network Classifier and Its Application for Objectionable Web Content Filtering,"In this paper, an Advanced Quantum-based Neural Network Classiﬁer (AQNN) is proposed. The proposed AQNN is used to form an objectionable Web content ﬁltering system (OWF). The aim is to design a neural network with a few numbers of hidden layer neurons with the optimal connection weights and the threshold of neurons. The proposed algorithm uses the concept of quantum computing and genetic concept to evolve connection weights and the threshold of neurons.","OWF, Web crawler, AQNN, neural network classiﬁer, Neural Network, Objectionable Web Content Filtering, objectionable Web content, Quantum computing","The proposed AQNN is used to form an objectionable Web content ﬁltering system (OWF) which detects objectionable Web request by the user. The results of AQNN are compared with QNN-F and well-known classiﬁers as backpropagation, support vector machine (SVM), multilayer perceptron, decision tree algorithm, and artiﬁcial neural network. The results show that the AQNN as classiﬁer performs better than existing classiﬁers."
O. Soliman,Diabetes Classiﬁcation using Radial Basis Function Network by Combining Cluster Validity Index and BAT Optimization with Novel Fitness Function,This paper discusses the use of cluster validity indices for diabetes diagnosis. The authors present a literature survey related to the problem and propose a methodology for identifying the optimal number of clusters. The experimental outcomes confirm the performance of the proposed methodology. The paper also reviews the performance of various neural network-based classifiers on the Pima Indians data set.,"diabetes diagnosis, Optimal number of clusters, Medical Diagnosis, Classiﬁcation, methodology, Diabetes, literature survey, Bat Algorithm, Radial Basis Function Networks, cluster validity indices, neural network-based classifiers","This paper presents a new model based on cluster validity index with radial basis neural network for classiﬁcation of diabetic patients data. The proposed model is tested on Pima Indians Diabetes data set and synthetic data sets, and experimental results proved that our approach performs better in terms of accuracy, sensitivity, speciﬁcity, classiﬁcation time, training time, network complexity and computational time compared to conventional radial basis function neural network."
O.P. Verma,"Ownership and Tamper Detection of Relational Data: Framework, Techniques and Security Analysis","Databases play a pivotal role in all domains of technology, encompassing data mining, medical records, stock market data, e-commerce etc. With this elevated need for databases and their wide distribution in the web sphere, their security has become a major concern today. It is in this context that watermarked protection of databases has started receiving increasing attention from researchers.","ownership, ownership proof, piracy detection, watermarking, databases, tamper detection, relational database, watermarked protection, security, relational databases","The paper proposes a robust watermarking model for relational databases to detect piracy and ownership. The model consists of a watermark preparator, a watermark embedder, and a watermark extractor. The watermark preparator selects and secures the watermark with a secret key, while the watermark embedder embeds the watermark into the database. The model also discusses the importance of usability constraints and the selection of candidate attributes and bit positions for embedding the watermark."
OM PRAKASH PATEL,Novel quantum inspired binary neural network algorithm,"In this paper, a quantum based binary neural network algorithm is proposed, named as novel quantum binary neural network algorithm (NQ-BNN). It forms a neural network structure by deciding weights and separability parameter in quantum based manner. Quantum computing concept represents solution probabilistically and gives large search space to find optimal value of required parameters using Gaussian random number generator. The neural network structure forms constructively having three number of layers input layer: hidden layer and output layer. A constructive way of deciding the network eliminates the unnecessary training of neural network. A new parameter that is a quantum separability parameter (QSP) is introduced here, which finds an optimal separability plane to classify input samples. During learning, it searches for an optimal separability plane. This parameter is taken as the threshold of neuron for learning of neural network. This algorithm is tested with three benchmark datasets and produces improved results than existing quantum inspired and other classification approaches.","Binary Neural Network, quantum gates, separability plane, neural network, classification, Novel Algorithm, Quantum computing","A novel quantum inspired binary neural network algorithm is proposed, which uses quantum computing concept to decide the parameters like weights of neural networks and quantum separability parameter (QSP) or threshold. The algorithm forms a neural network structure with three layers, input layer, hidden layer and output layer, and uses a constructive way of deciding the network to eliminate unnecessary training. The algorithm is tested on three benchmark datasets and produces improved results than existing quantum inspired and other classification approaches."
Okawa,Deformation Adjustment with Single Real Signature Image for Biometric Verification Using CNN,"Signature verification is the widely used biometric verification method for maintaining individual privacy. It is generally used in legal documents and in financial transactions. A vast range of research has been done so far to tackle different system issues, but there are various hot issues that remain unaddressed. The scale and orientation of the signatures are some issues to address, and the deformation of the signature within the genuine examples is the most critical for the verification system.","biometric authentication, Single real signature image, soft biometrics, deep learning, hard biometrics, CNN, Signature verification, Deformation adjustment, Biometric verification, writer-independent","This work proposes a two-phase system requiring only one target signature image to verify a query signature image. It takes care of the target signature's scaling, orientation, and spatial translation in the first phase. The second phase uses this transformed sample image and verifies the given sample as the target signature with the help of another deep neural network."
Olga Frunza,TSP-1 in Diabetic Cardiomyopathy,"Diabetes mellitus is associated with cardiac fibrosis. Matricellular proteins are induced in fibrotic conditions and modulate fibrogenic and angiogenic responses by regulating growth factor signaling. Our aim was to test the hypothesis that the prototypical matricellular protein thrombospondin (TSP)-1, a potent angiostatic molecule and crucial activator of transforming growth factor-β, may play a key role in remodeling of the diabetic heart. Obese diabetic db/db mice exhibited marked myocardial TSP-1 upregulation in the interstitial and perivascular space. To study the role of TSP-1 in remodeling of the diabetic heart, we generated and characterized db/db TSP-1–/– (dbTSP) mice. TSP-1 disruption did not significantly affect weight gain and metabolic function in db/db animals. When compared with db/db animals, dbTSP mice had increased left ventricular dilation associated with mild nonprogressive systolic dysfunction. Chamber dilation in dbTSP mice was associated with decreased myocardial collagen content and accentuated matrix metalloproteinase-2 and -9 activity. TSP-1 disruption did not affect inflammatory gene expression and activation of transforming growth factor-β/small mothers against decapendaplegic signaling in the db/db myocardium. In cardiac fibroblasts populating collagen pads, TSP-1 incorporation into the matrix did not activate transforming growth factor-β responses, but inhibited leptin-induced matrix metalloproteinase-2 activation. TSP-1 disruption abrogated age-associated capillary rarefaction in db/db mice, attenuating myocardial upregulation of angiopoietin-2, a mediator that induces vascular regression. In vitro, TSP-1 stimulation increased macrophage, but not endothelial cell, angiopoietin-2 synthesis. Conclusions: TSP-1 upregulation in the diabetic heart prevents chamber dilation by exerting matrix-preserving actions on cardiac fibroblasts and mediates capillary rarefaction through effects that may involve angiopoietin-2 upregulation.","matrix metalloproteinases, thrombospondins, fibrosis, diabetic cardiomyopathies, ventricular remodeling","This study investigates the role of thrombospondin-1 (TSP-1) in diabetic cardiomyopathy. Researchers found that TSP-1 is upregulated in the hearts of diabetic mice and that its loss attenuates cardiac fibrosis and enhances myocardial protease activity. However, TSP-1 disruption also led to mild left ventricular dilation and modest nonprogressive systolic dysfunction. These findings suggest that TSP-1 plays a complex role in diabetic heart remodeling, with both beneficial and detrimental effects."
Om Prakash Patel,A Novel Scalable Apache Spark Based Feature Extraction Approaches for Huge Protein Sequence and their Clustering Performance Analysis ||| A Review of Clustering Techniques and Developments ||| Generalized Enhanced Quantum Fuzzy Approach for Efficient Data Clustering ||| Quantum-inspired evolutionary approach for selection of optimal parameters of fuzzy clustering,"Genome sequencing projects are rapidly increasing the number of high-dimensional protein sequence datasets. Clustering a high-dimensional protein sequence dataset using traditional machine learning approaches poses many challenges. Many different feature extraction methods exist and are widely used. However, extracting features from millions of protein sequences becomes impractical because they are not scalable with current algorithms. Therefore, there is a need for an efficient feature extraction approach that extracts significant features. We have proposed two scalable feature extraction approaches for extracting features from huge protein sequences using Apache Spark, which are termed 60d-SPF (60-dimensional Scalable Protein Feature) and 6d-SCPSF (6-dimensional Scalable Co-occurrence-based Probability-Speciﬁc Feature). The proposed 60d-SPF and 6d-SCPSF approaches capture the statistical properties of amino acids to create a fixed-length numeric feature vector that represents each protein sequence in terms of 60-dimensional and 6-dimensional features, respectively. ||| This paper presents a comprehensive study on clustering: exiting methods and developments made at various times. Clustering is defined as an unsupervised learning where the objects are grouped on the basis of some similarity inherent among them. There are different methods for clustering the objects such as hierarchical, partitional, grid, density based and model based. The approaches used in these methods are discussed with their respective states of art and applicability. The measures of similarity as well as the evaluation criteria, which are the central components of clustering are also presented in the paper. The applications of clustering in some fields like image segmentation, object and character recognition and data mining are highlighted. ||| Data clustering is a challenging task to gain insights into data in various fields. In this paper, an Enhanced Quantum-Inspired Evolutionary Fuzzy C-Means (EQIE-FCM) algorithm is proposed for data clustering. In the EQIE-FCM, quantum computing concept is utilized in combination with the FCM algorithm to improve the clustering process by evolving the clustering parameters. The improvement in the clustering process leads to improvement in the quality of clustering results. To validate the quality of clustering results achieved by the proposed EQIE-FCM approach, its performance is compared with the other quantum-based fuzzy clustering approaches and also with other evolutionary clustering approaches. ||| Recently, Fuzzy c-Means (FCM) algorithm is most widely used because of its efficiency and simplicity. However, FCM is sensitive to the initialization of fuzziness factor (m) and the number of clusters (c) due to which it easily trapped in local optima. A selection of these parameters is a critical issue because an adverse selection can blur the clusters in the data.","Cluster validity index, Unsupervised learning, Apache Spark Cluster, fuzzy set theory, Clustering, Quantum computing, Fuzzy clustering, Data mining, protein sequences, Feature Extraction, evolutionary algorithm, Hierarchical Clustering, Data Clustering, Big Data, ROCK, Fuzzy Clustering, Scalable Algorithms, Fuzzy C-Means, Similarity measures, Clustering Approaches, quantum computing, bioinformatics, Pattern recognition, BIRCH, Taxonomy, Quantum-Inspired Evolutionary Fuzzy c-Means, CURE, Fuzzy c-Means algorithm, CHAMELEON, Apache Spark, Huge Protein Sequences, Fuzzy c-Means","This paper proposes two scalable feature extraction approaches for huge protein sequences using Apache Spark, which are termed 60d-SPF and 6d-SCPSF. The proposed approaches capture the statistical properties of amino acids to create a fixed-length numeric feature vector that represents each protein sequence in terms of 60-dimensional and 6-dimensional features, respectively. The paper also discusses the clustering of huge protein sequences using SRSIO-FCM and SLFCM algorithms. ||| This paper reviews clustering techniques and developments, discussing methods such as hierarchical, partitional, grid, density-based, and model-based clustering, as well as measures of similarity and evaluation criteria. The applications of clustering in fields like image segmentation, object recognition, and data mining are highlighted. ||| This paper proposes an Enhanced Quantum-Inspired Evolutionary Fuzzy C-Means (EQIE-FCM) algorithm for data clustering. The EQIE-FCM algorithm utilizes quantum computing concept in combination with the FCM algorithm to improve the clustering process by evolving the clustering parameters. The performance of the proposed EQIE-FCM approach is compared with other quantum-based fuzzy clustering approaches and other evolutionary clustering approaches. ||| This paper proposes a hybrid fuzzy clustering algorithm, Quantum-Inspired Evolutionary Fuzzy c-Means (QIE–FCM), which uses the merits of quantum computing for finding the global optimal value of m and its corresponding value of c in the FCM. The proposed approach improves the way of initialization of the fuzziness factor (m) in the FCM and provides the diversity in selecting the optimal value of m and c from a large quantum search space."
Om Prakash Verma,Watermarking Categorical Data: Algorithm and Robustness Analysis,"The importance of watermarking digital databases has increased by leaps and bounds due to the high vulnerability of digital assets to piracy attempts when they traverse through the internet. To deter piracy, we propose a robust watermarking scheme for relational databases containing categorical data that resolves ownership issues.","categorical data, algorithm, Information security, watermarking, database protection, digital watermarking, robustness analysis, copyright issues","The paper proposes a technique for watermarking categorical data, which involves embedding a watermark in the database by re-arranging the tuples partition-wise. The technique is entirely distortion free and provides a high level of security against attacks."
OmPrakash Kaiwartya,A Reliable Energy-Efficient Pressure-Based Routing Protocol for Underwater Wireless Sensor Network ||| IoT Challenges and Opportunities,"Underwater wireless sensor networks (UWSNs) are similar to the terrestrial sensor networks. Nevertheless, there are different characteristics among them such as low battery power, limited bandwidth and high variable propagation delay. One of the common major problems in UWSNs is determining an efficient and reliable routing between the source node and the destination node. Therefore, researchers tend to design efficient protocols with consideration of the different characteristics of underwater communication. Furthermore, many routing protocols have been proposed and these protocols may be classified as location-based and location-free routing protocols. Pressure-based routing protocols are a subcategory of the location-free routing protocols. This paper focuses on reviewing the pressure-based routing protocols that may further be classified into non-void avoidance protocols and void avoidance protocols. Moreover, non-void avoidance protocols have been classified into single factor based and multi factor based routing protocols. Finally, this paper provides a comparison between these protocols based on their features, performance and simulation parameters and the paper concludes with some future works on which further study can be conducted. ||| This paper discusses the challenges and opportunities in the Internet of Things (IoT) era. It highlights the need for a unified addressing scheme, energy-efficient network architecture, and intelligent routing mechanism. The paper also explores the challenges of big data management, energy consumption, devices/links heterogeneity, and transmission media in IoT applications.","Multi Factor Based Routing Protocols, UWSNs, Non-Avoidance Routing Protocols, Energy Consumption, Single Factor Based Routing Protocols, Routing Protocols, Transmission Media, Communication Void, challenges and opportunities, Addressing Scheme, Big Data, Energy Efficiency, Void Avoidance Routing Protocols, Internet of things (IoT), Pressure Based Routing Protocols, Pressure Sensors, Devices/Links Heterogeneity, Underwater Wireless Sensor Network, wireless sensor networks (WSNs), Reliability, IoT","This paper reviews the pressure-based routing protocols for underwater wireless sensor networks, which are a subcategory of location-free routing protocols. The paper provides a comparison between these protocols based on their features, performance, and simulation parameters, and concludes with some future works on which further study can be conducted. ||| The paper presents a comprehensive overview of the challenges and opportunities in IoT applications. It highlights the need for a unified addressing scheme, energy-efficient network architecture, and intelligent routing mechanism. The paper also explores the challenges of big data management, energy consumption, devices/links heterogeneity, and transmission media in IoT applications."
Omer Rana,"Explainable AI (XAI): Core Ideas, Techniques and Solutions","As our dependence on intelligent machines continues to grow, so does the demand for more transparent and interpretable models. In addition, the ability to explain the model generally is now the gold standard for building trust and deployment of Artificial Intelligence (AI) systems in critical domains. Explainable Artificial Intelligence (XAI) aims to provide a suite of machine learning (ML) techniques that enable human users to understand, appropriately trust, and produce more explainable models.","Explainable AI, Stakeholders, Machine Learning, Software toolkits, Programming framework, Bias, Robustness, Interpretable AI, Explainable Artiﬁcial Intelligence, XAI, Decision Making","The paper presents the core ideas, techniques, and solutions of XAI, emphasizing its importance in various phases of the machine learning process. It discusses the stakeholders involved in these phases, including developers, theorists, data scientists, users, consumers, businesses, regulators, and scientists, and highlights the use cases of XAI in detecting bias, scientific understanding, building robust models, and better decision making."
Omkarprakash Kaiwartya,Adaptive Energy-Aware Algorithms for Minimizing Energy Consumption and SLA Violation in Cloud Computing,"In cloud computing, high energy consumption and service-level agreements (SLAs) violation are the challenging issues considering that the demand for computational power is growing rapidly, thereby requiring large-scale cloud data centers. This paper proposes three adaptive models, namely, gradient descent-based regression (Gdr), maximize correlation percentage (MCP), and bandwidth-aware selection policy (Bw), that can significantly minimize energy consumption and SLA violation.","regression method, energy-efﬁciency, service level agreements, SLA violation, host overloaded detection, energy efficiency, cloud data center, VM consolidation, Cloud computing, meta-heuristic approach, green computing","This paper proposes three adaptive models to minimize energy consumption and SLA violation in cloud computing. The models are based on gradient descent-based regression, maximize correlation percentage, and bandwidth-aware selection policy. The proposed algorithms reduce energy consumption while maintaining the required performance levels in a cloud data center."
Omprakash Kaiwartya,"A Cost-Efficient Communication Framework For Battery Switch Based Electric Vehicle Charging ||| A Dynamic Congestion Control Scheme for safety applications in vehicular ad hoc networks ||| A Novel EV Charging Management Scheme Considering Mobility Uncertainty ||| Mobile Edge Computing for Big Data-Enabled Electric Vehicle Charging ||| Towards Video Streaming in IoT Environments: Vehicular Communication Perspective ||| Toward a Heterogeneous Mist, Fog, and Cloud-Based Framework for the Internet of Healthcare Things ||| Virtualization in Wireless Sensor Networks: Fault Tolerant Embedding for Internet of Things","This paper proposes a battery switch service for electric vehicles (EVs) using a publish/subscribe (P/S) communication paradigm. The system consists of road side units (RSUs), electric vehicles (EVs), and charging stations (CSs). RSUs act as brokers to bridge the information flow from CSs to EVs, while EVs and CSs interact through RSUs. The system enables efficient radio resource utilization and alleviates interference to EVs. ||| In recent years, various types of applications have emerged from Vehicular Ad hoc Networks (VANETs) for safety, infotainment, rescue and security purposes. Safety applications have their own strict communication requirements, and they require reliable and timely data communication within networks. Due to a variety of network applications, safety applications have been negatively impacted by communication channel congestion issues. Channel congestion leads to packet loss, delay and unreliability issues, and has a serious impact on vehicular traffic, including road accidents, road jams, and wrong traffic decisions. In addressing these issues, this paper's authors have proposed a Dynamic Congestion Control Scheme (DCCS) as a means of reliable and timely data delivery, in safety applications. The proposed scheme is designed for communication channels, as a means of broadcasting safety messages, and to ensure the reliable and timely delivery of messages to all neighbours in a network. The DCCS scheme is designed for inter-vehicle communication, without fixed infrastructure. Comprehensive simulation is conducted, in order to evaluate the performance of a proposed scheme, and to compare it with other state of the art schemes. ||| This paper proposes a novel EV charging management scheme that considers mobility uncertainty due to traffic jams in a city. The scheme uses a centralized aggregator to manage charging plans for all EVs in the network, and each EV reports its charging reservation to the aggregator, including its expected arrival time and charging time. The aggregator then makes CS-selection decisions based on the reported information and updates the reservations periodically to adjust for mobility uncertainty. ||| As one of the key drivers of smart grid, Electric Vehicles (EVs) are environment-friendly to alleviate CO2 pollution. Big data analytics could enable the move from Internet of EVs, to optimized EV charging in smart transportation. In this paper, we propose a Mobile Edge Computing (MEC) based system, in line with a big data-driven planning strategy on which Charging Station (CS) to charge. ||| Multimedia oriented Internet of Things (IoT) enables pervasive and real-time communication of video, audio and image data among devices in immediate surroundings. Today’s vehicles have the capability of supporting real time multimedia acquisition. Vehicles with high illuminating infrared cameras and customized sensors can communicate with other on-road devices using dedicated short-range communication (DSRC) and 5G enabled communication technologies. Real time incidence of both urban and highway vehicular traffic environment can be captured and transmitted using vehicle-to-vehicle and vehicle-to-infrastructure communication modes. Video streaming in vehicular IoT (VSV-IoT) environments is in growing stage with several challenges that need to be addressed ranging from limited resources in IoT devices, intermittent connection in vehicular networks, heterogeneous devices, dynamism and scalability in video encoding, bandwidth underutilization in video delivery, and attaining application-precise quality of service in video streaming. In this context, this paper presents a comprehensive review on video streaming in IoT environments focusing on vehicular communication perspective. Specifically, the significance of video streaming in vehicular IoT environments is highlighted focusing on the integration of vehicular communication with 5G enabled IoT technologies, and smart city oriented application areas for VSV-IoT. A taxonomy is presented for the classification of related literature on video streaming in vehicular network environments. Following the taxonomy, critical review of literature is performed focusing on major functional model, strengths and weaknesses. Metrics for video streaming in vehicular IoT environments are derived and comparatively analyzed in terms of their usage and evaluation capabilities. Open research challenges in VSV-IoT are identified as future directions of research in the area. The survey would benefit both IoT and vehicle industry practitioners and researchers, in terms of augmenting understanding of vehicular video streaming and its IoT related trends and issues. ||| Rapid developments in the fields of information and communication technology and microelectronics allowed seamless interconnection among various devices letting them to communicate with each other. This technological integration opened up new possibilities in many disciplines including healthcare and well-being. With the aim of reducing healthcare costs and providing improved and reliable services, several healthcare frameworks based on Internet of Healthcare Things (IoHT) have been developed. However, due to the critical and heterogeneous nature of healthcare data, maintaining high quality of service (QoS)—in terms of faster responsiveness and data-specific complex analytics—has always been the main challenge in designing such systems. Addressing these issues, this paper proposes a five-layered heterogeneous mist, fog, and cloud-based IoHT framework capable of efficiently handling and routing (near-)real-time as well as offline/batch mode data. Also, by employing software defined networking and link adaptation-based load balancing, the framework ensures optimal resource allocation and efficient resource utilization. The results, obtained by simulating the framework, indicate that the designed network via its various components can achieve high QoS, with reduced end-to-end latency and packet drop rate, which is essential for developing next generation e-healthcare systems. ||| Recently, virtualization in wireless sensor networks (WSNs) has witnessed significant attention due to the growing service domain for IoT. Related literature on virtualization in WSNs explored resource optimization without considering communication failure in WSNs environments. The failure of a communication link in WSNs impacts many virtual networks running IoT services. In this context, this paper proposes a framework for optimizing fault tolerance in virtualization in WSNs, focusing on heterogeneous networks for service-oriented IoT applications.","QoS, Charging System, healthcare application, Communication Technologies, Internet of vehicles, Transmit Power Control, MAC Blocking, Safety, Vehicular Communication, fog computing, reduced latency, Congestion, CS-Selection Decision Making, CS-Selection, cloud computing, Broadcasting, resource allocation, Electric Vehicle, Driver's Trip Duration, Mobile Edge Computing, Congestion Control, load balancing, healthcare, traffic safety, Network Entities, Fault Tolerant Embedding, Smart Transportation, Measurement-Based Detection, Urban, Charging Planning, Internet of Things, Traffic Jams, Smart Grid, Battery Switch, low power consumption, Electric Vehicles, Big Data, healthcare big data, Mobility, Mobility Uncertainty, e-healthcare, IoHT, Decentralized Charging Management, mist computing, Communication, publish/subscribe, Big Data-Enabled Electric Vehicle Charging, real-time computing, charging stations, Electric Vehicle Charging, road side units, MEC Based System, EV Charging, Wireless sensor networks, Video streaming, vehicular ad-hoc networks, Charging Management, Smart Cities, Communication Framework, Centralized Charging Management, Intelligent transportation system, quality of service (QoS), Virtualization, Data fusion, Vehicular, Control, heterogeneous framework, VANETs, Centralized Aggregator, Internet of things, IoT, Queue Freezing","This article presents a cost-efﬁcient communication framework for battery switch based electric vehicle charging. The framework is provisioned to support the EV charging service and considers urban travel uncertainties, e.g., trafﬁc congestions and drivers’ preferences. Results demonstrate a guidance for the provisioning of P/S communication framework to improve EV drivers’ experience, e.g., charging waiting time and total trip duration. ||| This paper proposes a Dynamic Congestion Control Scheme (DCCS) for safety applications in Vehicular Ad hoc Networks (VANETs). The scheme detects congestion and controls it by exploiting existing network resources for road traffic safety and cum security. The main objectives of this research are to determine whether a congestion detection scheme will reduce congestion by using realistic weighting factors and whether a congestion control scheme can control congestion through message originated-based queue freezing. ||| This paper proposes an EV charging management system that considers drivers' trip duration and mobility uncertainty. The system selects charging stations based on reported EVs' reservation information and parking duration, minimizing trip duration for on-the-move EVs. ||| This paper proposes a Mobile Edge Computing (MEC) based system for big data-enabled electric vehicle charging. The system integrates big data analytics to opportunistically disseminate the outcome from a Global Controller and collect driving big data from mobile clients. The MEC servers implement big data mining and aggregation in a decentralized way, alleviating the size of data to be processed by the Global Controller. ||| The paper discusses the significance of video streaming in vehicular IoT environments, presents a taxonomy for the classification of literature on video streaming over vehicular ad-hoc networks, derives performance metrics for video streaming in vehicular IoT environments, and identifies open research issues and challenges in vehicular video streaming under IoT environments. ||| This paper proposes a five-layered heterogeneous mist, fog, and cloud-based Internet of Healthcare Things (IoHT) framework to efficiently handle and route healthcare data. The framework employs software defined networking and link adaptation-based load balancing to ensure optimal resource allocation and efficient resource utilization. The results show that the designed network can achieve high quality of service with reduced latency and packet drop rate, making it essential for developing next generation e-healthcare systems. ||| The paper discusses the importance of virtualization in WSNs for IoT applications, focusing on fault-tolerant embedding. It reviews existing proposals on virtualization in WSNs, highlighting their limitations and proposing a new approach to enhance fault tolerance."
"Ong, Y. S.",Local Surrogate Modeling for Parallel Evolutionary Optimization of Computationally Expensive Problems,This paper presents a local surrogate modeling algorithm for parallel evolutionary optimization of computationally expensive problems. The algorithm uses radial basis function networks to construct local surrogate models in the spirit of transductive inference. The proposed algorithm can be efficiently parallelized on grid computing architectures and does not compromise on the intrinsic parallelism offered by evolutionary algorithms.,"Radial basis function networks, evolutionary optimization, Transductive inference, Local surrogate modeling, surrogate modeling, Parallel evolutionary optimization, computationally expensive problems",The paper presents a parallel evolutionary optimization algorithm that uses surrogate models to solve computationally expensive design problems with general constraints on a limited computational budget. The algorithm combines an evolutionary algorithm with a feasible sequential quadratic programming solver and uses a trust-region approach to leverage exact and surrogate models during local search.
P. C. Saxena,Missing,"This thesis presents an experimental study on operating systems. It develops a design of a new operating system, called JNUOS, and provides a commentary on its implementation. The operating system has been developed following a few well established paradigms and models of CS. It has been designed to have a microkernel based architecture and has a modular and stratified design with five distinct layers.","Missing, pedagogical, operating system, microkernel, object oriented","The thesis introduces the concept of verbose mode of operation of an operating system and the reincarnation server to enhance the robustness of operating systems. It also discusses the implementation of the operating system in C++ programming language and its features such as inheritance, delegation, function overloading, and runtime function dispatch."
P. CHANDANA,Real-Time Monitoring System for Aquaculture,The idea behind building up the real-time monitoring system is to lessen the manual fish farming which uses more work powers. There are sensors which measure water parameters and control those to keep aquarium clean and fishes healthy. Farmers are given alert messages if the water parameters exceed and also remedial actions are performed before he reached to the Aquarium. This device is useful for fishes as well as other Aqua life also. By using this we can save the aqua life.,"Fish Farming, IOT, Sensors, Sensor Networks, Arduino, Water Parameters, Real-Time Monitoring, GSM, Aquaculture",The proposed method aims at continuously monitoring the harmful gases and relative humidity in a cost effective way by polling sensor at fixed interval of time. Arduino processes data and will be updated continuously on the system.
P. Chakraborty,Augmented Reality Wordbook App for Kindergarteners (ARWAK) ||| A Peer-Assessment Based Approach for Teaching Microprogramming ||| Missing,"In the last two decades, augmented reality educational software tools have been used to teach various subjects to schoolchildren around the world. We developed a wordbook smartphone app and used it to teach new words to children in kindergartens in New Delhi between January and April of 2018. The app uses marker-based augmented reality technology and displays three dimensional pictures of objects whose names the children are learning blended in their immediate surrounding. The app was designed to make the learning process more interactive and intuitive. We found that children can learn slightly more number of words from the app than from a printed wordbook. However, the main benefit of the app was that it was able to increase participation by the children and keep them engaged. The teachers who used the app to teach felt that it was easy to integrate the app in the kindergarten environment and it presented information in a way suitable for young children. We recommend the use of augmented reality smartphone apps to teach children various concepts in kindergartens and schools. ||| The course on microprocessors introduces undergraduate computer science students to hardware-level programming. The course was taught by the authors to 130 students in context of the 8085 and 8086 microprocessors in the Spring semester of 2019. The students executed their programs on hardware kits, and participated in a double-blind peer-assessment exercise in which they assessed and rated programs written by their peers and also advised them on improving the efficiency and readability of their programs. ||| This thesis presents an experimental study on operating systems. It develops a design of a new operating system, called JNUOS, and provides a commentary on its implementation. The operating system has been developed following a few well established paradigms and models of CS. It has been designed to have a microkernel based architecture and has a modular and stratified design with five distinct layers.","Computer science education, Missing, undergraduate students, Kindergarteners, pedagogical, computer science, microkernel, smartphone app, microprogramming, peer-assessment, performance, wordbook, microprocessors, Learning, augmented reality, vocabulary, Education, microprocessor, operating system, object oriented, Kindergarten","This paper presents the development and evaluation of an augmented reality wordbook smartphone app for kindergarteners. The app uses marker-based augmented reality technology to display three dimensional pictures of objects whose names the children are learning. The app was found to increase participation and engagement of children, and was easy to integrate into the kindergarten environment. The authors recommend the use of augmented reality smartphone apps to teach children various concepts in kindergartens and schools. ||| This paper presents a study on the utility of peer-assessment in teaching microprogramming to undergraduate computer science students attending a course on microprocessors. The study found that the peer-assessment exercise helped the students to perform better in examination, with a 6.97% increase in marks in the post-intervention test compared to the pre-intervention test. ||| The thesis introduces the concept of verbose mode of operation of an operating system and the reincarnation server to enhance the robustness of operating systems. It also discusses the implementation of the operating system in C++ programming language and its features such as inheritance, delegation, function overloading, and runtime function dispatch."
P. Chaovalit,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
P. Dou,Cost Eﬀective Inﬂuence Maximisation,"In the context of virality prediction, many researchers have leveraged the existence of a core-periphery structure in a network to identify the super-spreaders of information. Topologically, the nodes in the core of a network are the most eﬃcient spreaders. However, these nodes are less susceptible, i.e., unlikely to be inﬂuenced by the periphery nodes. Consequently, large payoﬀs are required to market information (ideas, products, memes, etc.) via them. In this paper, we show the presence of several non-core nodes whose spreading power is close to that of the core nodes.","Virality, Inﬂuence maximisation, Information diﬀusion, cost-effective, Core-periphery structure, information diffusion, social networks, influence maximisation","This paper proposes a cost-eﬀective strategy to make a meme reach the super-spreaders without the need for global information. The proposed hill-climbing based strategy can be eﬀectively used with both, global as well as local characteristics of the nodes in a network. In terms of the cost metric, it outperforms the conventional independent cascade model by more than 5 times for the core and 2 times for the non-core super-spreaders."
P. J. Fleming,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
P. Jeatrakul,Diabetes Classiﬁcation using Radial Basis Function Network by Combining Cluster Validity Index and BAT Optimization with Novel Fitness Function,This paper discusses the use of cluster validity indices for diabetes diagnosis. The authors present a literature survey related to the problem and propose a methodology for identifying the optimal number of clusters. The experimental outcomes confirm the performance of the proposed methodology. The paper also reviews the performance of various neural network-based classifiers on the Pima Indians data set.,"diabetes diagnosis, Optimal number of clusters, Medical Diagnosis, Classiﬁcation, methodology, Diabetes, literature survey, Bat Algorithm, Radial Basis Function Networks, cluster validity indices, neural network-based classifiers","This paper presents a new model based on cluster validity index with radial basis neural network for classiﬁcation of diabetic patients data. The proposed model is tested on Pima Indians Diabetes data set and synthetic data sets, and experimental results proved that our approach performs better in terms of accuracy, sensitivity, speciﬁcity, classiﬁcation time, training time, network complexity and computational time compared to conventional radial basis function neural network."
P. Khanna,Machine learning techniques for the diagnosis of Alzheimer’s disease: A review,"Alzheimer’s disease is an incurable neurodegenerative disease primarily affecting the elderly population. Efficient automated techniques are needed for early diagnosis of Alzheimers. Many novel approaches are proposed by researchers for classification of Alzheimer’s disease. However, to develop more efficient learning techniques, better understanding of the work done on Alzheimers is needed. Here, we provide a review on 165 papers from 2005-2019 using various feature extraction and machine learning techniques. The machine learning techniques are surveyed under three main categories: support vector machine (SVM), artificial neural network (ANN), and deep learning (DL) and ensemble methods.","Ensemble methods, Support vector machine, Deep learning, Alzheimer’s disease, classification, Artificial neural network, Machine learning","This paper provides a review of 165 papers on machine learning techniques for the diagnosis of Alzheimer’s disease from 2005-2019. The review covers three main categories: support vector machine (SVM), artificial neural network (ANN), and deep learning (DL) and ensemble methods. The paper discusses the importance of efficient automated techniques for early diagnosis of Alzheimers and the need for better understanding of the work done on Alzheimers to develop more efficient learning techniques."
P. Khobragade,Micro-Computed tomography (CT) based assessment of dental regenerative therapy in the canine mandible model,"High-resolution 3D bone-tissue structure measurements may provide information critical to the understanding of the bone regeneration processes and to the bone strength assessment. Tissue engineering studies rely on such nondestructive measurements to monitor bone graft regeneration area. In this study, we measured bone yield, fractal dimension and trabecular thickness through micro-CT slices for different grafts and controls. Eight canines underwent surgery to remove a bone volume (defect) in the canine’s jaw at a total of 44 different locations. We kept 11 defects empty for control and filled the remaining ones with three regenerative materials; NanoGen (NG), a FDA-approved material (n=11), a novel NanoCalcium Sulfate (NCS) material (n=11) and NCS alginate (NCS+alg) material (n=11). After a minimum of four and eight weeks, the canines were sacrificed and the jaw samples were extracted. We used a custom-built micro-CT system to acquire the data volume and developed software to measure the bone yield, fractal dimension and trabecular thickness. The software used a segmentation algorithm based on histograms derived from volumes of interest indicated by the operator. Using bone yield and fractal dimension as indices we are able to differentiate between the control and regenerative material (p<0.005). Regenerative material NCS showed an average 63.15% bone yield improvement over the control sample, NCS+alg showed 55.55% and NanoGen showed 37.5%. The bone regeneration process and quality of bone were dependent upon the position of defect and time period of healing. This study presents one of the first quantitative comparisons using non-destructive Micro-CT analysis for bone regenerative material in a large animal with a critical defect model. Our results indicate that Micro-CT measurement could be used to monitor in-vivo bone regeneration studies for greater regenerative process understanding.","Regenerative Materials, Quantitative Analysis, Bone Regeneration, Micro-CT, LabVIEW","This study investigates the effectiveness of three different bone regenerative materials (NanoGen, NanoCalcium Sulfate, and NanoCalcium Sulfate alginate) in a canine mandible model using micro-computed tomography (micro-CT). The study found that all three materials significantly improved bone regeneration compared to the control group. NanoCalcium Sulfate showed the most significant improvement, followed by NanoCalcium Sulfate alginate and NanoGen. The position of the defect and the healing time period were also found to influence the regeneration process."
P. Kundu,A solid transportation model with product blending and parameters as rough variables,"In this paper, we formulate a practical solid transportation problem with product blending which is a common issue in many operational and planning models in the chemical, petroleum, gasoline and process industries.","trust theory, Chance-constrained programming, solid transportation model, Blending, Rough variable, Solid transportation problem, Trust measure",The paper formulates a solid transportation model with product blending and rough parameters based on trust measure. The model is transformed into a deterministic form to solve the problem. A numeric example is presented to illustrate the problem model and solution strategy.
P. Majumder,YASS: Yet Another Suﬃx Stripper,"This paper presents a set of string distance measures for clustering the lexicon. The main intuition behind defining these distances was to reward long matching prefixes, and to penalize an early mismatch.","string distance measures, morphological variants, information retrieval, resource-poor languages, clustering, lexicon clustering, Bengali language, equivalence classes, stemming","The paper proposes a set of string distance measures for clustering words into homogeneous groups, with the goal of representing an equivalence class consisting of morphological variants of a single root word."
"P. Melville, R.J. Mooney, R. Nagarajan",Feature Weighting in Content Based Recommendation System Using Social Network Analysis,A hybridization of content based and collaborative filtering based recommendation is proposed. The weights of different attributes of an item are computed from the collaborative social network using regression analysis.,"Feature Similarity, hybrid recommender systems, Recommender System, content-based filtering, collaborative filtering, Social Network, regression analysis",This paper proposes a hybridization of collaborative filtering and content based recommendation system. The authors assign weights to attributes used for content based recommendations based on their importance to users. The weights are estimated from a social network graph which captures human judgment about similarity of items.
P. Mitra,YASS: Yet Another Suﬃx Stripper,"This paper presents a set of string distance measures for clustering the lexicon. The main intuition behind defining these distances was to reward long matching prefixes, and to penalize an early mismatch.","string distance measures, morphological variants, information retrieval, resource-poor languages, clustering, lexicon clustering, Bengali language, equivalence classes, stemming","The paper proposes a set of string distance measures for clustering words into homogeneous groups, with the goal of representing an equivalence class consisting of morphological variants of a single root word."
P. Ravisankar,Detection of Financial Statement Fraud Using Data Mining Techniques,"Recently, high profile cases of financial statement fraud have been dominating the news. This paper uses data mining techniques such as Multilayer Feed Forward Neural Network (MLFF), Support Vector Machines (SVM), Genetic Programming (GP), Group Method of Data Handling (GMDH), Logistic Regression (LR), and Probabilistic Neural Network (PNN) to identify companies that resort to financial statement fraud. Each of these techniques is tested on a dataset involving 202 Chinese companies and compared with and without feature selection. PNN outperformed all the techniques without feature selection, and GP and PNN outperformed others with feature selection and with marginally equal accuracies.","Data mining, artificial intelligence, SVM, Feature selection, GP, financial statement fraud, fraud detection, Financial fraud detection, Neural networks, t-statistic","This paper uses data mining techniques to identify companies that resort to financial statement fraud. The techniques used include Multilayer Feed Forward Neural Network (MLFF), Support Vector Machines (SVM), Genetic Programming (GP), Group Method of Data Handling (GMDH), Logistic Regression (LR), and Probabilistic Neural Network (PNN). The results show that PNN outperformed all the techniques without feature selection, and GP and PNN outperformed others with feature selection and with marginally equal accuracies."
P. V. Madhu,Parameter Extraction of Photovoltaic Module Using BFO Algorithm,"This paper presents a new parameter extraction method for photovoltaic modules exploiting Bacterial Foraging Optimization (BFO) technique. In a PV system, validation of the model of a PV module with correctly chosen parameters is essential. An efficient parameter extraction method is required to estimate the parameters of PV module.","evolutionary techniques, BFO, PV module parameters, photovoltaic module, Newton-Raphson method, parameter extraction, PSO, BFO algorithm","The proposed BFO based parameter extraction method has been tested for different types of PV modules at different test conditions. Analyzing both the simulation and experimental results obtained using BFO; it is found that the module parameters are more accurate compared to that of Newton-Raphson, Particle Swarm Optimization and Enhanced Simulated Annealing methods."
P. Venkatesan,Diabetes Classiﬁcation using Radial Basis Function Network by Combining Cluster Validity Index and BAT Optimization with Novel Fitness Function,This paper discusses the use of cluster validity indices for diabetes diagnosis. The authors present a literature survey related to the problem and propose a methodology for identifying the optimal number of clusters. The experimental outcomes confirm the performance of the proposed methodology. The paper also reviews the performance of various neural network-based classifiers on the Pima Indians data set.,"diabetes diagnosis, Optimal number of clusters, Medical Diagnosis, Classiﬁcation, methodology, Diabetes, literature survey, Bat Algorithm, Radial Basis Function Networks, cluster validity indices, neural network-based classifiers","This paper presents a new model based on cluster validity index with radial basis neural network for classiﬁcation of diabetic patients data. The proposed model is tested on Pima Indians Diabetes data set and synthetic data sets, and experimental results proved that our approach performs better in terms of accuracy, sensitivity, speciﬁcity, classiﬁcation time, training time, network complexity and computational time compared to conventional radial basis function neural network."
P.C. Saxena,Fifty Years of Automata Simulation: A Review,"This paper reviews the development of automata simulators over the past fifty years. It discusses various approaches to modeling automata, including notational, assembly-like, procedural, and descriptive languages. The paper also presents several examples of automata simulators, including a Pushdown Automata Simulator, a Turing Machine Simulator, and a Finite Automaton Description Language.","automata theory, automata simulation, procedural languages, simulation, notational languages, assembly-like languages, descriptive languages, computer science education",The article reviews the major initiatives in the field of simulation of automata in the last five decades with emphasis on those automata simulators actually used at universities for teaching. It also identifies some salient trends in the research on simulation of automata and concludes with an advocacy for continuing research on simulation of automata and integration of automata simulators in teaching.
P.Krishna Reddy,Understanding Helicoverpa armigera Pest Population Dynamics related to Chickpea Crop Using Neural Networks,Insect pests are a major cause of crop loss globally. Pest management will be effective and efficient if we can predict the occurrence of peak activities of a given pest. Research efforts are going on to understand the pest dynamics by applying analytical and other techniques on pest surveillance data sets. In this study we make an effort to understand pest population dynamics using Neural Networks by analyzing  pest surveillance data set of Helicoverpa armigera or Pod borer on chickpea (Cicer arietinum L.)  crop. The results show that neural network method successfully predicts the pest attack incidences for one week in advance.,"Climatic Data, Pest Population Dynamics, Neural Networks, Pest Surveillance Databases, Chickpea Crop, Helicoverpa armigera, Neural Network, Pest Attack Prediction","The experimental results show that it is possible to predict the pest attack with high probability for one week in advance. These predictions would help the farmers in pest management programs by avoiding the crop losses with improved environment quality, as it can avoid unnecessary sprays of chemical pesticides."
P.T.V. Bhuvaneswari et.al,Energy-Efficient Routing Algorithm for Wireless Sensor Networks,"Wireless Sensor Network (WSN) is a collection of sensor nodes. A sensor node covers all information which is present in its sensing range. To access the information present in some other sensor range, the networks use a process called Routing. Routing problem in wireless sensor network (WSN) concerned with maximizing the sensor network lifetime while continuously routing the collected data (information) to the base station (central server).","Network Lifetime, Energy –Efficiency, Energy-Efficient Routing, Sensor Networks, Routes, Wireless Sensor Networks, Wireless Sensor Networks (WSN), Energy Consumption, Routing problem, Routing Algorithm",The paper presents a new energy-efficient routing algorithm for wireless sensor networks. The algorithm prioritizes sensors according to their remaining battery life and selects the shortest path to maximize the total network lifetime.
P.V.N HARINI,Real-Time Monitoring System for Aquaculture,The idea behind building up the real-time monitoring system is to lessen the manual fish farming which uses more work powers. There are sensors which measure water parameters and control those to keep aquarium clean and fishes healthy. Farmers are given alert messages if the water parameters exceed and also remedial actions are performed before he reached to the Aquarium. This device is useful for fishes as well as other Aqua life also. By using this we can save the aqua life.,"Fish Farming, IOT, Sensors, Sensor Networks, Arduino, Water Parameters, Real-Time Monitoring, GSM, Aquaculture",The proposed method aims at continuously monitoring the harmful gases and relative humidity in a cost effective way by polling sensor at fixed interval of time. Arduino processes data and will be updated continuously on the system.
PAL,"Web Mining in Soft Computing Framework: Relevance, State of the Art and Future Directions","This paper summarizes the different characteristics of web data, the basic components of web mining and its different types, and their current states of the art. The reason for considering web mining, a separate field from data mining, is explained. The limitations of some of the existing web mining methods and tools are enunciated, and the significance of soft computing (comprising fuzzy logic (FL), artificial neural networks (ANNs), genetic algorithms (GAs), and rough sets (RSs) highlighted. A survey of the existing literature on “soft web mining” is provided along with the commercially available systems. The prospective areas of web mining where the application of soft computing needs immediate attention are outlined with justification. Scope for future research in developing “soft web mining” systems is explained. An extensive bibliography is also provided.","knowledge discovery, genetic algorithms (GAs), generalization, information extraction, information retrieval, search engines, fuzzy logic (FL), information retrieval (IR), web mining, rough sets (RSs), Artificial neural networks (ANNs), pattern recognition, data mining","The paper discusses the relevance of soft computing in web mining, its current state of the art, and future directions. It highlights the limitations of existing web mining methods and tools, and the significance of soft computing in handling real-life ambiguous situations. The paper provides a survey of existing literature on soft web mining, and outlines prospective areas where soft computing needs immediate attention. It also explains the scope for future research in developing soft web mining systems."
PANKAJ KUMAR SA,NPReId Framework for Video Surveillance,"This paper presents a neuromorphic person re-identiﬁcation (NPReId) framework to establish the correspondence among individuals observed across two disjoint camera views. The proposed framework comprises three modules (observation, cognition, and contemplation), inspired by the form-and-color-and-depth (FACADE) theory model of object recognition system.","person re-identification, recognition, FACADE theory, Surveillance, video surveillance, consensus clustering, person re-identiﬁcation, NPReId","The proposed NPReId framework comprises three interactive modules – observation, cognition, and contemplation. The observation module suppresses the background and extracts the chromatic and texture details from the segmented pedestrian. The cognition module projects the psychological result of observation to learn the underlying pedestrian signature. The results of observation and cognition modules are forwarded to the contemplation module that recognizes the correct match for any individual."
PRADHAN et al.,Position Control of a Flexible Manipulator Using a New Nonlinear Self-Tuning PID Controller,This paper presents a new nonlinear self-tuning PID controller for position control of a flexible manipulator (FLM). The FLM dynamics are described in a nonlinear form and a new nonlinear self-tuning PID controller is designed to track a reference joint trajectory and simultaneously suppress the link deflection when it is subjected to carry different payloads (parametric uncertainty). The control law proposed in this paper can achieve the above objective in finite time.,"position control, NARMAX, Flexible-link manipulator, Parametric Uncertainty, self-tuning control, Nonlinear Self-Tuning PID Controller, Flexible Manipulator, trajectory tracking","The proposed NSPID controller has been implemented in real-time on an experimental set-up. The joint tracking and link deflection performances of the proposed adaptive controller are compared with that of a popular direct adaptive controller (DAC). From the obtained results, it is confirmed that the proposed controller exhibits improved performance over the DAC both in terms of accurate position tracking and quick damping of link deflections when subjected to variable payloads."
PRIYADARSI NANDA,Privacy-Preserving Mechanism in Smart Home Using Blockchain,"The IoT, or Internet of Things has been a major talking point amongst technology enthusiasts in recent years. The internet of thing (IoT) has been emerged and evolved rapidly, making the world’s fabric around us smarter and more responsive. The smart home uses one such transformation of IoT, which seems to be the wave of the future. However, with the increasing wide adoption of IoT, data security, and privacy concerns about how our data is collected and shared with others, has also risen. To solve these challenges, an approach to data privacy and security in a smart home using blockchain technology is proposed in this paper. We propose authentication scheme that combines attribute-based access control with smart contracts and edge computing to create a secure framework for IoT devices in smart home systems. The edge server adds scalability to the system by offloading heavy processing activities and using a differential privacy method to aggregate data to the cloud securely and privately. We present several aspects of testing and implementing smart contracts, the differential private stochastic gradient descent algorithm, and system architecture and design. We demonstrate the efficacy of our proposed system by fully examining its security and privacy goals in terms of confidentiality, integrity, and availability. Our framework achieves desired security and privacy goals and is resilient against modification, DoS attacks, data mining and linkage attacks. Finally, we undertake a performance evaluation to demonstrate the proposed scheme’s feasibility and efficiency.","edge computing, cyber threats, smart home, access control, differential privacy, Blockchain, smart contract","This paper proposes a privacy-preserving mechanism in smart homes using blockchain technology. The proposed system combines attribute-based access control with smart contracts and edge computing to create a secure framework for IoT devices in smart home systems. The edge server adds scalability to the system by offloading heavy processing activities and using a differential privacy method to aggregate data to the cloud securely and privately. The proposed system achieves desired security and privacy goals and is resilient against modification, DoS attacks, data mining and linkage attacks."
Pabitra Mitra,"Active Support Vector Learning for Pixel Classification ||| Data Mining in Soft Computing Framework ||| Deep learning in multi-object detection and tracking: state of the art ||| Feature Weighting in Content Based Recommendation System Using Social Network Analysis ||| Mining Quantitative Association Rules in Protein Sequences ||| Multispectral Image Segmentation Using the Rough-Set-Initialized EM Algorithm ||| Object Extraction Based on Rough Entropy ||| Pattern Recognition Algorithms for Data Mining: Scalability, Knowledge Discovery, and Soft Granular Computing ||| Web Mining in Soft Computing Framework: Relevance, State of the Art and Future Directions","This paper presents an active support vector learning algorithm for pixel classification in remote sensing images. The algorithm is based on the principle of breaking down the large quadratic programming problem into a series of smaller problems, and identifying the support vectors while discarding the non-support vectors. ||| The present article provides a survey of the available literature on data mining using soft computing. A categorization has been provided based on the different soft computing tools and their hybridizations used, the data mining function implemented, and the preference criterion selected by the model. ||| Object detection and tracking is one of the most important and challenging branches in computer vision, and have been widely applied in various fields, such as health-care monitoring, autonomous driving, anomaly detection, and so on. With the rapid development of deep learning (DL) networks and GPU’s computing power, the performance of object detectors and trackers has been greatly improved. To understand the main development status of object detection and tracking pipeline thoroughly, in this survey, we have critically analyzed the existing DL network-based methods of object detection and tracking and described various benchmark datasets. This includes the recent development in granulated DL models. Primarily, we have provided a comprehensive overview of a variety of both generic object detection and specific object detection models. We have enlisted various comparative results for obtaining the best detector, tracker, and their combination. Moreover, we have listed the traditional and new applications of object detection and tracking showing its developmental trends. Finally, challenging issues, including the relevance of granular computing, in the said domain are elaborated as a future scope of research, together with some concerns. An extensive bibliography is also provided. ||| A hybridization of content based and collaborative filtering based recommendation is proposed. The weights of different attributes of an item are computed from the collaborative social network using regression analysis. ||| Lot of research has gone into understanding the composition and nature of proteins, still many things remain to be understood satisfactorily. It is now generally believed that amino acid sequences of proteins are not random, and thus the patterns of amino acids that we observe in the protein sequences are also non-random. ||| The problem of segmentation of multispectral satellite images is addressed. An integration of rough-set-theoretic knowledge extraction, the Expectation Maximization (EM) algorithm, and minimal spanning tree (MST) clustering is described. ||| This paper presents a method of object enhancement/extraction based on the principle of minimizing the roughness of both object and background regions, i.e., maximizing RET. The determination of T* by maximization of rough entropy or minimization of roughness depends on the granule size. ||| This book contains information obtained from authentic and highly regarded sources. Reprinted material is quoted with permission, and sources are indicated. A wide variety of references are listed. Reasonable efforts have been made to publish reliable data and information, but the author and the publisher cannot assume responsibility for the validity of all materials or for the consequences of their use. ||| This paper summarizes the different characteristics of web data, the basic components of web mining and its different types, and their current states of the art. The reason for considering web mining, a separate field from data mining, is explained. The limitations of some of the existing web mining methods and tools are enunciated, and the significance of soft computing (comprising fuzzy logic (FL), artificial neural networks (ANNs), genetic algorithms (GAs), and rough sets (RSs) highlighted. A survey of the existing literature on “soft web mining” is provided along with the commercially available systems. The prospective areas of web mining where the application of soft computing needs immediate attention are outlined with justification. Scope for future research in developing “soft web mining” systems is explained. An extensive bibliography is also provided.","rough knowledge encoding, Semi-supervised learning, knowledge discovery, granule size, Soft granular computing, Multi-object tracking, granular computing, Deep learning, genetic algorithms, collaborative filtering, Clustering, Rough Sets, Image segmentation, Artificial neural networks (ANNs), Machine learning, Social Network, regression analysis, Data mining, protein sequences, Hybrid Approach, Rough Set Theory, neural networks, pattern recognition, Image Segmentation, information extraction, Active Learning, Recommender System, content-based filtering, protein composition, web mining, Knowledge discovery, Object tracking, information retrieval, Deep learning (DL), Granular computing, Rough sets, Entropy, rough entropy, minimal spanning tree, object extraction, rough sets (RSs), Set approximation, Scalability, Feature Similarity, Video analysis, Data Mining, Multi-object detection, amino acids, mixture modeling, search engines, Pattern recognition, Support Vector Machine, rule extraction, quantitative association rule mining, Fuzzy logic, Remote Sensing, Fuzzy Logic, Pixel Classification, genetic algorithms (GAs), generalization, hybrid recommender systems, Query support vector machine, Soft Computing, Knowledge Discovery in Databases, fuzzy logic (FL), information retrieval (IR), neuro-fuzzy computing, rough sets, Mixture Models, Transductive learning, Object detection, Granules, data mining","The paper proposes an active support vector learning algorithm for pixel classification in remote sensing images, which uses a smaller number of labeled samples and has a substantial improvement in performance compared to the conventional support vector machine. ||| Data mining is a form of knowledge discovery essential for solving problems in a specific domain. Individual data sets may be gathered and studied collectively for purposes other than those for which they were originally created. ||| This paper provides a comprehensive overview of the current state of object detection and tracking using deep learning (DL) networks. It discusses the rapid development of DL networks and GPU’s computing power, which has greatly improved the performance of object detectors and trackers. The paper also provides a critical analysis of existing DL network-based methods of object detection and tracking, and describes various benchmark datasets. It highlights the recent development in granulated DL models and provides a comprehensive overview of generic and specific object detection models. The paper also discusses the traditional and new applications of object detection and tracking, and elaborates on the challenging issues in the domain, including the relevance of granular computing. ||| This paper proposes a hybridization of collaborative filtering and content based recommendation system. The authors assign weights to attributes used for content based recommendations based on their importance to users. The weights are estimated from a social network graph which captures human judgment about similarity of items. ||| This study attempts to decipher the nature of associations between different amino acids that are present in a protein. The authors have attempted to find out rules that can tell that occurrence of one amino-acid is more likely when another amino-acid is present or absent. ||| The paper presents a method for multispectral image segmentation using the rough-set-initialized EM algorithm. The method integrates rough-set-theoretic knowledge extraction, the EM algorithm, and MST clustering to address the problem of segmentation of multispectral satellite images. ||| This paper addresses the problem of image object extraction in the framework of rough sets and granular computing. A measure called 'rough entropy of image' is defined based on the concept of image granules. Its maximization results in minimization of roughness in both object and background regions; thereby determining the threshold of partitioning. ||| The book covers various aspects of pattern recognition algorithms for data mining, including scalability, knowledge discovery, and soft granular computing. It discusses different perspectives of data mining, scaling pattern recognition algorithms to large data sets, and the significance of soft computing in KDD. ||| The paper discusses the relevance of soft computing in web mining, its current state of the art, and future directions. It highlights the limitations of existing web mining methods and tools, and the significance of soft computing in handling real-life ambiguous situations. The paper provides a survey of existing literature on soft web mining, and outlines prospective areas where soft computing needs immediate attention. It also explains the scope for future research in developing soft web mining systems."
Pankaj Bansal,"Cardioprotection from ischemia and reperfusion injury by Withania somnifera: A hemodynamic, biochemical and histopathological assessment","The efficacy of Withania somnifera (Ws) to limit myocardial injury after ischemia and reperfusion was explored and compared to that of Vit E, a reference standard known to reduce mortality and infarct size due to myocardial infarction. Wistar rats (150–200 g) were divided into six groups and received orally saline (sham, control group), Ws-50/kg (Ws control and treated group) and Vit E-100 mg/kg (Vit E control and treated group) respectively for 1 month. On the 31st day, rats of the control, Vit E and Ws treated groups were anesthetized and subjected to 45 min occlusion of the LAD coronary artery followed by 60 min reperfusion. Hemodynamic parameters: systolic, diastolic and mean arterial pressure (SAP, DAP, MAP), heart rate (HR), left ventricular end diastolic pressure (LVEDP), left ventricular peak (+)LVdP/dt and (–)LVdP/dt were monitored. Hearts were removed and processed for histopathological and biochemical studies: Myocardial enzyme viz, creatin phosphokinase (CPK), and antioxidant parameters: malondialdehyde (MDA), glutathione (GSH), superoxide dismutase (SOD), catalase (CAT), glu-tathione peroxidase (GSHPx) were estimated. Postischemic reperfusion produced significant cardiac necrosis, depression of left ventricular functions (MAP, LVEDP, (+) and (–)LVdP/dt) and a significant fall in GSH (p < 0.01), SOD, CAT (p < 0.05), LDH and CPK (p < 0.01) as well as an increase in MDA level (p < 0.05) in the control group rats as compared to sham group. The changes in levels of protein and GPx was however, not significant. Ws and Vit E favorably modulated most of the hemo-dynamic, biochemical and histopathological parameters though no significant restoration in GSH, MAP (with Vit E) were ob-served. Ws on chronic administration markedly augmented antioxidants (GSH, GSHPx, SOD, CAT) while Vit E did not stimulate the synthesis of endogenous antioxidants compared to sham. Results indicate that Ws significantly reduced myocardial injury and emphasize the beneficial action of Ws as a cardioprotective agent.","Withania somnifera, adaptogens, Adaptogenic, myocardial infarction, Ischemia-reperfusion injury, Myocardial damage, ischemia, Vitamin E, antioxidants, reperfusion","This study investigated the cardioprotective effects of Withania somnifera (Ws) compared to Vitamin E in a rat model of ischemia and reperfusion induced myocardial injury. Ws significantly reduced myocardial injury, improved hemodynamic parameters, and enhanced antioxidant defense mechanisms. These findings suggest that Ws has potential as a cardioprotective agent."
Pankaj K Sa,Image Sonification: A Review of Techniques and Applications,"With the advent of image and video representation of visual scenes in digital computer, subsequent necessity of vision-substitution representation of a given image is felt. The medium for non-visual representation of an image is chosen to be sound due to well developed auditory sensing ability of human beings and wide availability of cheap audio hardware. Visionary information of an image can be conveyed to blind and partially sighted persons through auditory representation of the image within some of the known limitations of human hearing system.","sound visualization, Non-visual image representation, Auditory image, Sonification, image sonification, Image representation, Stereo vision, auditory data, color information","Image sonification is a process that converts visual data into sound, allowing people to perceive and understand visual information through sound. The paper reviews the different techniques and applications of image sonification, including the use of color information and the applications in various fields."
Pankaj Kumar Kashyap,Towards Precision Agriculture: IoT-Enabled Intelligent Irrigation Systems Using Deep Learning Neural Network,"This paper presents a deep learning NN-based IoT-enabled intelligent irrigation system for precision agriculture (DLiSA). An LSTM RNN model is employed to predict volumetric soil moisture content of the next day based on the historical temporal dynamics of climate and soil. The proposed model uses a closed-loop approach, which takes feedback from soil sensors and climate sensors that keeps its functionality higher in the unpredicted climate of any region.","Volumetric Soil Moisture Content, Deep Learning Neural Network, Deep Learning, Internet of Things, Precision Agriculture, Sensor, Long Short Term Memory, IoT-enabled Intelligent Irrigation Systems, LSTM RNN model","The proposed DLiSA system consists of a smart irrigation model and associated sensing IoT network model deployed on farmland. The system uses a closed-loop approach to predict volumetric soil moisture content of the next day based on historical temporal dynamics of climate and soil. The performance of DLiSA is compared with state-of-the-art algorithms subject to the prediction of soil moisture content, soil water deficit, and water volume irrigated over a month."
Pankaj Kumar SA,Direction Estimation for Pedestrian Monitoring System in Smart Cities: An HMM Based Approach,"The paper proposes a novel approach for direction estimation of a moving pedestrian as perceived in a 2-D coordinate of field camera. The proposed direction estimation method is intended for pedestrian monitoring in traffic control systems. Apart from traffic control, direction of motion estimation is also very important in accident avoidance system for smart cars, assisted living systems, in occlusion prediction for seamless tracking in visual surveillance, and so on.","perspective distortion, hidden Markov model, direction estimation, HMM, pedestrian monitoring, Visual surveillance, pedestrian direction estimation, surveillance video, occlusion handling","The proposed method is robust to various issues like illumination changes, environmental factors, partial occlusion, and low resolution of surveillance videos. It can be used alone or with existing methods of orientation estimation over consecutive frames to enhance the direction estimation results."
Pankaj Kumar Sa,Evaluation of Background Subtraction for Object Detection Vis-a-Vis Mitigating Challenging Scenarios,"Background subtraction is a popular technique for detecting objects moving across a fixed camera view. The performance of this paradigm is influenced by various challenges, such as object relocation, illumination change, cast shadows, waving background, camera shake, bootstrapping, camouflage, and so on. In this paper, we present a synopsis on the evolution of the background subtraction techniques over the last two decades. The different ways of mathematical modeling are taken into consideration to categorize the methods. We also evaluate the performance of some of the state-of-the-art techniques vis-a-vis the challenges associated. Eleven different algorithms of background subtraction have been simulated on thirty-four image sequences collected from five benchmark datasets. For each image sequence, seven performance metrics are evaluated and an exhaustive comparative analysis has been made to derive inferences. The potential findings in the result analysis are presented for future exploration. The obtained image and video results are uploaded at https://sites.google.com/site/soaBSevaluation.","background modeling, object detection, low-rank sparse decomposition, background subtraction, challenging scenarios, learning model, non-parametric model, shadow removal, non-recursive buffer-based subtraction, fuzzy model, shadow removal model, foreground extraction, background maintenance, Video surveillance",This paper evaluates the performance of background subtraction techniques for object detection in challenging scenarios. The authors present a synopsis of the evolution of background subtraction techniques over the last two decades and evaluate the performance of eleven state-of-the-art algorithms on thirty-four image sequences collected from five benchmark datasets. The results reveal some key findings in background subtraction methodologies and are available at https://sites.google.com/site/soaBSevaluation.
Pankesh Patel,"Explainable AI (XAI): Core Ideas, Techniques and Solutions ||| Title Suppressed Due to Excessive Length","As our dependence on intelligent machines continues to grow, so does the demand for more transparent and interpretable models. In addition, the ability to explain the model generally is now the gold standard for building trust and deployment of Artificial Intelligence (AI) systems in critical domains. Explainable Artificial Intelligence (XAI) aims to provide a suite of machine learning (ML) techniques that enable human users to understand, appropriately trust, and produce more explainable models. ||| The objective of an online Mart is to match buyers and sellers, to weigh animals and to oversee their sale. A reliable pricing method can be developed by ML models that can read through historical sales data. However, when AI models suggest or recommend a price, that in itself does not reveal too much (i.e., it acts like a black box) about the qualities and the abilities of an animal. An interested buyer would like to know more about the salient features of an animal before making the right choice based on his requirements. A model capable of explaining the different factors that impact the price point is essential for the needs of the market. It can also inspire confidence in buyers and sellers about the price point offered.","Machine Learning, Software toolkits, Video Analytics, Decision Making, vision based feature extraction, Internet of Things, Bias, Interpretable AI, XAI, Explainable AI, cow, Robustness, computer vision, ML based price prediction, weight estimation, Stakeholders, machine learning, Programming framework, Explainable Artiﬁcial Intelligence","The paper presents the core ideas, techniques, and solutions of XAI, emphasizing its importance in various phases of the machine learning process. It discusses the stakeholders involved in these phases, including developers, theorists, data scientists, users, consumers, businesses, regulators, and scientists, and highlights the use cases of XAI in detecting bias, scientific understanding, building robust models, and better decision making. ||| The paper discusses a method for estimating the weight of cows using a machine learning approach. The method involves training a model to predict the weight of cows based on images of their faces. However, the paper notes that the face of a cow is not sufficient for weight estimation and that the model can get biased according to color. The paper also discusses the limitations of the approach and suggests future directions for research."
Paras Aggarwal,Predicting pattern of coronavirus using X-ray and CT scan images,Novel coronavirus is a disease that can propagate easily with very minute carelessness and with very little physical contact between people.,"CT scan, COVID-19, Convolutional Neural Networks, CXR images, Convolutional Neural Network (CNN), Deep learning, X-ray, Coronavirus, Prediction",A lightweight deep learning model is proposed to automate and analyze the diagnostic process by utilizing Convolutional Neural Network (CNN) for predicting the pattern of coronavirus using X-ray and CT scan images.
Parth,"Estimate of variability, heritability and genetic advance with respect to yield and yield contributing characters in field pea (Pisum sativum L.)","The present investigation entitled “Estimate of variability, heritability and genetic advance with respect to yield and yield contributing characters in field pea (Pisum sativum L.)” for 10 characters. The experiment comprising of 23 genotypes of pea were grown in a Randomized Block Design (RBD), with three replications at Research Farm, Department of Genetics & Plant Breeding, Post Graduate College, Ghazipur, during rabi season of 2017-2018, plant to plant and row to row distance was kept 10 cm and 45 cm, respectively.","Pisum sativum L., heritability, Genetic variability, yield contributing characters, genetic advance, field pea","The estimates of genotypic coefficient of variation (GCV) and phenotypic coefficient of variation (PCV) and environmental coefficient of variation (ECV) showed a wide range. The high estimates of genotypic coefficient of variation (GCV) were observed for plant height, biological yield per plant, number of pods per plant, seed yield per plant, number, 100 seed weight. The high estimates of phenotypic coefficient of variation (PCV) were observed for seed yield per pod, number of pods per plant, biological yield per plant, harvest index, plant height."
Parthapratim De,Blind Spectrum Sensing Using Compressed Sensing and Multi-Antennas,"Cognitive Radios exploit the unutilized spectrum by transmitting opportunistically without disturbing the primary user (PU) or licensed user. So, the sensing should be fast enough that the secondary user (SU) can vacate the spectrum when the PU becomes active.","Compressed Sensing, Multi-Antennas, Blind Spectrum Sensing, Cognitive Radio","This paper proposes a novel blind spectrum sensing method using compressed sensing, which reduces the number of measurements required for spectrum sensing. The proposed method employs multiple receive antennas and uses compressed sensing at the receiver front end to reduce the complexity of the A/D converter. Simulation results show that the proposed method achieves a good probability of detection in very low SNR even at 50% measurements."
Parziale et al.,Deformation Adjustment with Single Real Signature Image for Biometric Verification Using CNN,"Signature verification is the widely used biometric verification method for maintaining individual privacy. It is generally used in legal documents and in financial transactions. A vast range of research has been done so far to tackle different system issues, but there are various hot issues that remain unaddressed. The scale and orientation of the signatures are some issues to address, and the deformation of the signature within the genuine examples is the most critical for the verification system.","biometric authentication, Single real signature image, soft biometrics, deep learning, hard biometrics, CNN, Signature verification, Deformation adjustment, Biometric verification, writer-independent","This work proposes a two-phase system requiring only one target signature image to verify a query signature image. It takes care of the target signature's scaling, orientation, and spatial translation in the first phase. The second phase uses this transformed sample image and verifies the given sample as the target signature with the help of another deep neural network."
Patricia Brown-­Augsburger,First-­in-­Human Study of Bamlanivimab in a Randomized Trial of Hospitalized Patients With COVID-­19,"This first-in-human study in hospitalized patients with COVID-19 was supported by studies assessing in vitro viral neutralization combined with a single-dose non-human primate PK study. The nonclinical safety package to support subsequent studies included tissue cross-reactivity studies on human, rat, and monkey tissues and an in vivo toxicology study.  A complete physical examination was conducted at the screening visit, and one of three bamlanivimab doses or placebo was administered i.v. at the baseline visit (D1) with infusion rates as follows: bamlanivimab 700 mg (50 mL) administered 100 mL/hr for 30 minutes; 2,800 mg (75 mL) administered 100 mL/hr for 45 minutes; and 7,000 mg administered 100 mL/hr for 60 minutes. Placebo infusion was 0.9% normal saline, administered at the same volume and rate as the corresponding bamlanivimab dose cohort. Safety and tolerability were reviewed for sentinel participants up to 24 hours after dosing, at which point the investigators and sponsor team determined whether safety and tolerability were acceptable to continue with dosing subsequent participants. The decision to dose the next cohort was made when all participants from the previous cohort had been dosed and safety data assessed for at least 4 days after the i.v. infusion by the investigators and sponsor team in consultation with an independent safety assessment committee. Blood samples were obtained for assessment of exploratory biomarkers, serology, clinical laboratory assessments, and PD on days 1, 3, 7, 11, 15, 22, and 29, and every 7 days until discharge or day 60, if still an inpatient. Samples for the virology assay were collected using nasopharyngeal (preferred) or mid-turbinate methods. Blood samples obtained for PK analyses were assessed on days 1 (pre-infusion and just before end of infusion), 4, 15, and 29, and follow-up visits up to day 60. Symptom-related physical examinations and assessments of clinical symptoms were performed on days 1, 2, 3, 4, 7, 11, 15, 22, and 29, and the day of discharge from the hospital, with additional follow-up examinations every 7 days thereafter until day 60 if the patient was not discharged from the hospital by day 29. Participants’ clinical status and concurrent procedures of special interest were recorded, including limitation on activities due to COVID-19 and any requirements for the following procedures of special interest, such as ongoing hospital medical care, supplemental oxygen, noninvasive ventilation or a high flow oxygen device, mechanical ventilation, extracorporeal membrane oxygenation, additional organ support, or consciousness status using alert, consciousness, verbal, pain, unresponsive scale. Hospitalization events were recorded, including dates of hospital admission and discharge, admission to the intensive care unit (ICU), discharge from the ICU, and discharge location including to an extended care facility or home. Outcomes The primary objective was to assess safety and tolerability, including adverse events (AEs), serious adverse events (SAEs), and discontinuations due to AEs. Other objectives included PKs (e.g., mean concentration at day 29); PD viral load, area under the response time curve (AUC, from day 1 to day 29), and change from baseline time course; total symptom score; time to symptom resolution; duration of hospitalization; National Institute of Allergy and Infectious Diseases (NIAID), World Health Organization (WHO) scales, and National Early Warning Score (NEWS2); and analysis of viral resistance. Any hypothesis tests were conducted for treatment comparisons without adjustment for multiplicity except for the evaluation of treatment effect on endogenous antibody titers. Success for the trial was claimed using a Bayesian criterion if any of the 3 bamlanivimab doses had at least 60% probability to reduce at least 30% mean AUC (28-day viral load) over placebo.",,"This first-in-human study evaluated the safety, tolerability, pharmacokinetics, clinical course, and viral dynamics of bamlanivimab, a fully human neutralizing monoclonal antibody targeting SARS-CoV-2, in hospitalized patients with moderate to severe COVID-19.  The study found bamlanivimab to be safe and well-tolerated, with no serious adverse events or deaths reported.  Further research is needed to determine the efficacy of bamlanivimab in treating COVID-19."
Patrick Mauro,Design of Next-Generation Low-Power Sensor Network Nodes,This paper presents the design of next-generation low-power sensor network nodes that can scavenge energy from the environment and use this energy to power the sensor network device.,"Ultra Low Power System Architecture, Fine-Grain Power Management, low-power sensor network nodes, hardware acceleration, Sensor Network Applications, event-driven system, Event-Driven Computation, energy scavenging","The paper discusses the design of next-generation low-power sensor network nodes that can scavenge energy from the environment and use this energy to power the sensor network device. The system architecture is designed to be event-driven, with hardware accelerators offloading common tasks to improve performance and power efficiency."
Patrick Wspanialy et al.,Deep Learning Techniques for Disease Detection in Fruits and Vegetables,"Plant Diseases are one of the leading reasons of economic shortfalls in agricultural and farming sectors worldwide. It is the most essential element since it reduces crop quantity and quality significantly. Fruits are one of the largest essential nutritional resources from plants. Unfortunately, a variety of conditions might impair both the content and outcome of fruits. As a result, an autonomous Computer Vision (CV) -based approach for reliable Fruit Disease Detection (FDD) is necessary.","Attention mechanisms, Transfer learning, Convolutional neural networks, Computer Vision, Machine Learning, Disease detection, Deep Learning, Fruits and vegetables, Fruit Disease Detection","This paper presents a detailed review of different ML and DL algorithms developed to predict and classify FDs from different fruit images. First, different FDD and classification systems designed by many researchers based on ML and DL algorithms are studied in brief. Then, a detailed analysis is carried out in order to identify the shortcomings of existing algorithms and to provide a novel strategy for properly classifying fruit pathogens."
Paul Klekotka,First-­in-­Human Study of Bamlanivimab in a Randomized Trial of Hospitalized Patients With COVID-­19,"This first-in-human study in hospitalized patients with COVID-19 was supported by studies assessing in vitro viral neutralization combined with a single-dose non-human primate PK study. The nonclinical safety package to support subsequent studies included tissue cross-reactivity studies on human, rat, and monkey tissues and an in vivo toxicology study.  A complete physical examination was conducted at the screening visit, and one of three bamlanivimab doses or placebo was administered i.v. at the baseline visit (D1) with infusion rates as follows: bamlanivimab 700 mg (50 mL) administered 100 mL/hr for 30 minutes; 2,800 mg (75 mL) administered 100 mL/hr for 45 minutes; and 7,000 mg administered 100 mL/hr for 60 minutes. Placebo infusion was 0.9% normal saline, administered at the same volume and rate as the corresponding bamlanivimab dose cohort. Safety and tolerability were reviewed for sentinel participants up to 24 hours after dosing, at which point the investigators and sponsor team determined whether safety and tolerability were acceptable to continue with dosing subsequent participants. The decision to dose the next cohort was made when all participants from the previous cohort had been dosed and safety data assessed for at least 4 days after the i.v. infusion by the investigators and sponsor team in consultation with an independent safety assessment committee. Blood samples were obtained for assessment of exploratory biomarkers, serology, clinical laboratory assessments, and PD on days 1, 3, 7, 11, 15, 22, and 29, and every 7 days until discharge or day 60, if still an inpatient. Samples for the virology assay were collected using nasopharyngeal (preferred) or mid-turbinate methods. Blood samples obtained for PK analyses were assessed on days 1 (pre-infusion and just before end of infusion), 4, 15, and 29, and follow-up visits up to day 60. Symptom-related physical examinations and assessments of clinical symptoms were performed on days 1, 2, 3, 4, 7, 11, 15, 22, and 29, and the day of discharge from the hospital, with additional follow-up examinations every 7 days thereafter until day 60 if the patient was not discharged from the hospital by day 29. Participants’ clinical status and concurrent procedures of special interest were recorded, including limitation on activities due to COVID-19 and any requirements for the following procedures of special interest, such as ongoing hospital medical care, supplemental oxygen, noninvasive ventilation or a high flow oxygen device, mechanical ventilation, extracorporeal membrane oxygenation, additional organ support, or consciousness status using alert, consciousness, verbal, pain, unresponsive scale. Hospitalization events were recorded, including dates of hospital admission and discharge, admission to the intensive care unit (ICU), discharge from the ICU, and discharge location including to an extended care facility or home. Outcomes The primary objective was to assess safety and tolerability, including adverse events (AEs), serious adverse events (SAEs), and discontinuations due to AEs. Other objectives included PKs (e.g., mean concentration at day 29); PD viral load, area under the response time curve (AUC, from day 1 to day 29), and change from baseline time course; total symptom score; time to symptom resolution; duration of hospitalization; National Institute of Allergy and Infectious Diseases (NIAID), World Health Organization (WHO) scales, and National Early Warning Score (NEWS2); and analysis of viral resistance. Any hypothesis tests were conducted for treatment comparisons without adjustment for multiplicity except for the evaluation of treatment effect on endogenous antibody titers. Success for the trial was claimed using a Bayesian criterion if any of the 3 bamlanivimab doses had at least 60% probability to reduce at least 30% mean AUC (28-day viral load) over placebo.",,"This first-in-human study evaluated the safety, tolerability, pharmacokinetics, clinical course, and viral dynamics of bamlanivimab, a fully human neutralizing monoclonal antibody targeting SARS-CoV-2, in hospitalized patients with moderate to severe COVID-19.  The study found bamlanivimab to be safe and well-tolerated, with no serious adverse events or deaths reported.  Further research is needed to determine the efficacy of bamlanivimab in treating COVID-19."
Pawan Lingras,Advances in Machine Learning and Data Science—Recent Achievements and Research Directives,ooperation to publish the proceedings as a volume of “Advances in Machine Learning and Data Science—Recent Achievements and Research Directives.” We wish to extend our gratitude to all the keynote speakers and participants who enabled the success of this year’s edition of LAMDA.,"Data Science, Research Directives, Recent Achievements, Machine Learning","The proceedings of LAMDA 2017, a conference on machine learning and data science, are published as a volume of Advances in Machine Learning and Data Science—Recent Achievements and Research Directives. The editors extend their gratitude to the keynote speakers and participants who made the conference a success."
Payal Khurana Batra,Predicting pattern of coronavirus using X-ray and CT scan images ||| Trusted Secure Geographic Routing Protocol for Detecting Insider Attacks in MANET,"Novel coronavirus is a disease that can propagate easily with very minute carelessness and with very little physical contact between people. ||| In Mobile Ad hoc Network (MANET), the nodes are linked to one another wirelessly and are self sustaining. The member nodes of MANET are very robust and minute. The deployment and maintenance of this network is less expensive and comparatively easy when compared with the conventional networks. However, MANET is highly susceptible to attacks due to its infrastructureless topology. The possible attacks vary over a wide range and affect the network in different levels. To overcome these attacks and safeguard the network performance, in this paper we propose to develop a trusted secure geographical routing protocol for detecting insider attacks.","CT scan, COVID-19, Convolutional Neural Networks, CXR images, Convolutional Neural Network (CNN), trust value estimation, Deep learning, X-ray, Mobile Ad hoc Network, Coronavirus, Insider Attacks, Trusted Secure Geographic Routing Protocol, MANET, Prediction","A lightweight deep learning model is proposed to automate and analyze the diagnostic process by utilizing Convolutional Neural Network (CNN) for predicting the pattern of coronavirus using X-ray and CT scan images. ||| The protocol estimates the overall trust value of neighboring nodes in two steps: initially, the agent in each node computes the trust value based on two desired functionalities at every Trust Update Interval (TUI); then, after packets are transmitted to the next hop node, the transmitting node overhears the channel to determine the number of packets forwarded and dropped by the next hop node, and computes the trust value of the next hop node based on the overheard information."
Peter Chen,First-­in-­Human Study of Bamlanivimab in a Randomized Trial of Hospitalized Patients With COVID-­19,"This first-in-human study in hospitalized patients with COVID-19 was supported by studies assessing in vitro viral neutralization combined with a single-dose non-human primate PK study. The nonclinical safety package to support subsequent studies included tissue cross-reactivity studies on human, rat, and monkey tissues and an in vivo toxicology study.  A complete physical examination was conducted at the screening visit, and one of three bamlanivimab doses or placebo was administered i.v. at the baseline visit (D1) with infusion rates as follows: bamlanivimab 700 mg (50 mL) administered 100 mL/hr for 30 minutes; 2,800 mg (75 mL) administered 100 mL/hr for 45 minutes; and 7,000 mg administered 100 mL/hr for 60 minutes. Placebo infusion was 0.9% normal saline, administered at the same volume and rate as the corresponding bamlanivimab dose cohort. Safety and tolerability were reviewed for sentinel participants up to 24 hours after dosing, at which point the investigators and sponsor team determined whether safety and tolerability were acceptable to continue with dosing subsequent participants. The decision to dose the next cohort was made when all participants from the previous cohort had been dosed and safety data assessed for at least 4 days after the i.v. infusion by the investigators and sponsor team in consultation with an independent safety assessment committee. Blood samples were obtained for assessment of exploratory biomarkers, serology, clinical laboratory assessments, and PD on days 1, 3, 7, 11, 15, 22, and 29, and every 7 days until discharge or day 60, if still an inpatient. Samples for the virology assay were collected using nasopharyngeal (preferred) or mid-turbinate methods. Blood samples obtained for PK analyses were assessed on days 1 (pre-infusion and just before end of infusion), 4, 15, and 29, and follow-up visits up to day 60. Symptom-related physical examinations and assessments of clinical symptoms were performed on days 1, 2, 3, 4, 7, 11, 15, 22, and 29, and the day of discharge from the hospital, with additional follow-up examinations every 7 days thereafter until day 60 if the patient was not discharged from the hospital by day 29. Participants’ clinical status and concurrent procedures of special interest were recorded, including limitation on activities due to COVID-19 and any requirements for the following procedures of special interest, such as ongoing hospital medical care, supplemental oxygen, noninvasive ventilation or a high flow oxygen device, mechanical ventilation, extracorporeal membrane oxygenation, additional organ support, or consciousness status using alert, consciousness, verbal, pain, unresponsive scale. Hospitalization events were recorded, including dates of hospital admission and discharge, admission to the intensive care unit (ICU), discharge from the ICU, and discharge location including to an extended care facility or home. Outcomes The primary objective was to assess safety and tolerability, including adverse events (AEs), serious adverse events (SAEs), and discontinuations due to AEs. Other objectives included PKs (e.g., mean concentration at day 29); PD viral load, area under the response time curve (AUC, from day 1 to day 29), and change from baseline time course; total symptom score; time to symptom resolution; duration of hospitalization; National Institute of Allergy and Infectious Diseases (NIAID), World Health Organization (WHO) scales, and National Early Warning Score (NEWS2); and analysis of viral resistance. Any hypothesis tests were conducted for treatment comparisons without adjustment for multiplicity except for the evaluation of treatment effect on endogenous antibody titers. Success for the trial was claimed using a Bayesian criterion if any of the 3 bamlanivimab doses had at least 60% probability to reduce at least 30% mean AUC (28-day viral load) over placebo.",,"This first-in-human study evaluated the safety, tolerability, pharmacokinetics, clinical course, and viral dynamics of bamlanivimab, a fully human neutralizing monoclonal antibody targeting SARS-CoV-2, in hospitalized patients with moderate to severe COVID-19.  The study found bamlanivimab to be safe and well-tolerated, with no serious adverse events or deaths reported.  Further research is needed to determine the efficacy of bamlanivimab in treating COVID-19."
Peter J. Haas,Secure Robust and Imperceptible Algorithm for Watermarking Relational Databases,"This paper proposes a secure robust and imperceptible algorithm for watermarking relational databases. The algorithm divides the embedding algorithm into three phases: Watermark preparator, watermark position detector, and watermark embedder. The ownership identification issue is resolved by embedding owner's identity as watermark in Preparator phase.","imperceptible algorithm, Ownership identification, robust algorithm, Relational Database, watermarking, Watermark, Copyright protection, Proof of ownership, relational databases","The paper proposes a new robust secure and imperceptible embedding mechanism to resolve the two important concerns namely; owner identification and proof of ownership. The proposed mechanism involves encoding and decoding on numerical attribute of relational database in three phases; 1)Watermark preparator, 2)Watermark position detector and 3) Watermark Embedder or Detector."
"Peter M. Izmirly, MD",Cardiac Neonatal Lupus: Maternal and Fetal Risk Factors for Mortality,"Background: Cardiac neonatal lupus (CNL) is a serious complication of maternal anti-Ro/SSA and anti-La/SSB antibodies.  We sought to identify maternal and fetal risk factors for mortality in infants with CNL.

Methods and Results: We retrospectively analyzed data from 325 infants with CNL born to 297 mothers. Overall, 57 deaths (17.5%) occurred. Hydrops, carditis, and EFE were associated with increased mortality in both in utero and postnatal deaths. Maternal diagnosis of SLE and/or SS was associated with increased mortality in the overall analysis and in utero deaths.  Whites were less likely to die than minorities.

Conclusions: Hydrops, carditis, EFE, and maternal SLE and/or SS are significant risk factors for mortality in infants with CNL.","mortality, morbidity, cardiomyopathy, antibodies, heart block","This study investigates maternal and fetal risk factors for mortality in infants with cardiac neonatal lupus (CNL).  Key findings include the significant association of hydrops, carditis, EFE, and maternal SLE and/or SS with increased mortality. Additionally, white infants were found to have a lower mortality rate compared to minorities."
"Peters, M. E.",A Multi-Task Approach to Open Domain Suggestion Mining,"Consumer reviews online may contain suggestions useful for improving the target products and services. Mining suggestions is challenging because the field lacks large labelled and balanced datasets. Furthermore, most prior studies have only focused on mining suggestions in a single domain. In this work, we introduce a novel up-sampling technique to address the problem of class imbalance, and propose a multi-task deep learning approach for mining suggestions from multiple domains.","Deep Learning, Suggestion Mining, Artificial Intelligence, Class Imbalance, Multi-Task Learning","This paper presents a multi-task approach to open domain suggestion mining, addressing the class imbalance problem using a novel up-sampling technique and a multi-task deep learning framework. Experimental results show that the proposed approach outperforms state-of-the-art models in terms of F-1 measure and AUC."
Phani Krishna Kondeti,Applications of machine learning techniques to predict filariasis using socio-economic factors,"Filariasis is one of the major public health concerns in India. Approximately 600 million people spread across 250 districts of India are at risk of filariasis. To predict this disease, a pilot scale study was carried out in 30 villages of Karimnagar district of Telangana from 2004 to 2007 to collect epidemiological and socio-economic data. The collected data are analysed by employing various machine learning techniques such as Naïve Bayes (NB), logistic model tree, probabilistic neural network, J48 (C4.5), classification and regression tree, JRip and gradient boosting machine. The performances of these algorithms are reported using sensitivity, specificity, accuracy and area under ROC curve (AUC). Among all employed classification methods, NB yielded the best AUC of 64% and was equally statistically significant with the rest of the classifiers. Similarly, the J48 algorithm generated 23 decision rules that help in developing an early warning system to implement better prevention and control efforts in the management of filariasis.","Filariasis, mosquito, socio-economic factors, Socio-economic conditions, Machine learning techniques, Predictive classification modelling, Data balancing, Feature subset selection",This study aims to predict filariasis using socio-economic factors and machine learning techniques. A pilot scale study was conducted in 30 villages of Karimnagar district of Telangana from 2004 to 2007 to collect epidemiological and socio-economic data. Various machine learning techniques were employed to analyse the data and predict filariasis. The study found that Naïve Bayes yielded the best AUC of 64% and generated 23 decision rules that help in developing an early warning system to implement better prevention and control efforts in the management of filariasis.
Phool Chandra,Wound Healing Potential of Raloxifene Nanoemulsion Gel for the Management of Postmenopausal Cutaneous Wounds,"Background: Depletion in estrogen level(s) especially in postmenopausal women is reported to have delayed wound healing effects; hence we have evaluated the wound healing potential of raloxifene in rat model. Objectives: Investigating the wound healing effects of raloxifene nanoemulsion for the management of postmenopausal cutaneous wounds. Materials and Methods: The optimized nanoemulsion gel contains 0.072% raloxifene hydrochloride. Female Wistar rats were used to investigate its wound healing effects. After three months of ovariectomy, wound healing effect was observed in terms of breaking strength, tensile strength, area of wound contraction, wound closure time, hydroxyproline content and histopathological changes. Results: The nanoemulsion gel exhibited better retention (34.31%) than its nanoemulsion. The raloxifene nanoemulsion gel has no erythema and no eschar formation recorded, and it is safe for topical use. In the incision wound model in ovariectomized rats, breaking (898±25g) and tensile strengths (4.47±0.12 g/mm2) in raloxifene treated groups were found to be higher than the untreated control group. Additionally, in ovariectomized rats, wound contraction was found to be 100% in the treated group s following 20 days of post-wounding, where as in control group only 88% was contraction was observed. Also, more hydroxyproline content in raloxifene treated ovariectomized rat was observed that recommend more collagen content than the untreated ovariectomized rat but approximately similar effects to untreated non-ovariectomized rats. Histopathological studies confirmed that the raloxifene treated groups had more re-epithelialization, neo-vascularization, fibroblast proliferation, and collagen deposition than the control group. Conclusion: These results confirms that the raloxifene nanoemulsion gel has significant wound healing potential, as observed in ovariectomized rats, which will be helpful in postmenopausal cutaneous wound healing.","Raloxifene, Histopathology, Ovariectomized, Hydroxyproline, Wound contraction, Postmenopausal Cutaneous Wounds, Postmenopausal, Breaking strength, Nanoemulsion gel, Wound Healing","This study investigates the wound healing potential of raloxifene nanoemulsion gel in postmenopausal cutaneous wounds. The results show that the nanoemulsion gel has significant wound healing potential, as observed in ovariectomized rats, and is safe for topical use. The study suggests that raloxifene nanoemulsion gel can be a good alternative for wound healing in postmenopausal women."
Pinaki Chakraborty,"An Analysis of ICT Tools in Medical Education During the COVID-19 Pandemic ||| An Extended Version of WordNet Incorporating Technical Terms and Subject Specific Words/Phrases ||| A brief survey of computerized expert systems for crop protection being used in India ||| A Compiler Technology Based Approach to Simulation of Basic Forms of Automata ||| A Line Drawing Language (LDDL) and its Compiler ||| Children's interaction with touchscreen devices: Performance and validity of Fitts' law ||| Earthquake Precursory Research at MPGO, Ghuttu ||| Emotion Analysis of Frequent Twitter Users During Lockdown ||| Evaluating the Learning Perspectives of Students on the Basis of Class Notes ||| Fifty Years of Automata Simulation: A Review ||| Fifty years of peephole optimization ||| Genetic Algorithm-Based Approach for Teaching Programming ||| Grid Computing: A New Avenue for System Software ||| Human Behavior and Emerging Technologies ||| Improving Compiler Construction Education in India ||| Intelligent Model for Smartphone Addiction Assessment in University Students using Android Application and Smartphone Addiction Scale ||| Intelligent System for Classroom Studies and Dynamic Environment ||| KELDEC: A System for Mining Knowledge Sources from Images ||| Opinion of Engineering Students on the Use of Live Online Lectures after the Pandemic ||| OSAVA_An Android App for Teaching a Course on Operating Systems ||| Real Time Smartphone Data for Prediction of Nomophobia Severity using Supervised Machine Learning ||| The Design of a Pedagogical Operating System ||| Use of Software to Enhance Classroom Teaching ||| Video-chatting with young children ||| VISTA: A teaching aid to enhance contextual teaching ||| Visual Tools for Teaching Programming","The COVID-19 pandemic has disrupted life and all forms of education. However, the impact on medical education is unique since the need for continuity of training medical students is urgent and traditionally calls for hands-on training and a physical presence. ||| WordNet is a huge repository being used as a tool in various fields. With an increasing number of applications referring to WordNet as a dictionary, several attempts have been made to update it. The paper proposes to extend the huge repository by adding words and relationships derived from students’ class notes through wikidata. These terms can be phrases, technical terms or any subject specific terminology appearing in students’ notes of a specific subject. Although various WordNet enriching techniques are available, it is for the first time that subject specific terminology is being added. The resulting version of WordNet has some very common phrases and technical terms along with the generic terms. Making subject specific and generic terms available in a hierarchy can improve the accuracy of various applications like text summarization and clustering for text belonging to a specific domain. ||| In the recent years, a plethora of computerized expert systems has been developed for various sectors of agriculture in India. The availability of low-cost computers, agricultural knowledge and information technology professionals are the principal reasons for the development of so many agricultural expert systems. Among all agricultural expert systems, the expert systems for crop protection need special mention. These expert systems are meant to be used by farmers and other persons without much experience of using computers. Hence, special care must be taken while developing them. The current paper develops a taxonomy for the expert systems for crop protection and brieﬂy discusses four such expert systems for crop protection being used in India. ||| This dissertation formalizes a comprehensive approach based on compiler technology to simulate some basic forms of automata viz., finite accepters, finite transducers, pushdown accepters and Turing machines. ||| A domain-specific language to draw line drawings is introduced in this paper. The compiler converts the specification of a line drawing written in this language into an image file. The language is suitable for drawing line drawings used in scientific literature. ||| This study investigates whether the interaction between children and a touchscreen obeys Fitts' law, which describes the relationship between the index of difficulty and movement time. The study involved 30 children aged 4-10 years who performed a touchscreen task using a smartphone app. The results show that the ability of children to acquire onscreen targets improves with age and depends on the touchscreen gesture used. ||| The paper discusses earthquake precursory research at MPGO, Ghuttu, focusing on radon emanation variation as a parameter. ||| This study analyzed the emotions of frequent Twitter users during the COVID-19 lockdown in India. The authors collected 7688 emotion-based tweets and 1690 situation-based tweets, and identified 222 frequent users who posted a total of 45,710 tweets during the lockdown period. The k-means clustering algorithm grouped the users into four clusters based on their daily usage pattern, and the authors found that the overall emotion of users varied significantly across the clusters. ||| This paper aims to evaluate the learning perspectives of students on the basis of class notes taken while the teacher is teaching in class. Homogenous and heterogeneous groups are formed on the basis of learning perspectives. ||| This paper reviews the development of automata simulators over the past fifty years. It discusses various approaches to modeling automata, including notational, assembly-like, procedural, and descriptive languages. The paper also presents several examples of automata simulators, including a Pushdown Automata Simulator, a Turing Machine Simulator, and a Finite Automaton Description Language. ||| Peephole optimization is a technique used in compilers to improve the performance of object programs by replacing sequences of instructions with equivalent single instructions. This article reviews the history and development of peephole optimization, including its application to various programming languages and target machines. ||| Pair programming is an approach where two programmers work to solve one programming problem sitting shoulder to shoulder on a computer. Several studies indicating numerous benefits of using pair programming as a teaching strategy exist. However, only a few of them take into consideration the mechanism followed for pair formation. With an aim to study the impact of pair programming on undergraduate students, we try to make the pairs compatible with a genetic algorithm‐based approach. Using a genetic algorithm, the system ensures that every pair in the class gets a particular combination of skills and personality traits. We also developed a desktop application to assign programming exercises to students dynamically. To assess the efficacy of pair programming in introductory programming course, a formal pair programming experiment was run at Netaji Subhas University of Technology. The pair programming experiment involved a total 171 undergraduate students from a computer engineering course. At the end of the program, we assessed the programming abilities of every student. We also analyzed the impact of a genetic algorithm‐based pairing mechanism. On the basis of assessments, it is observed that pair programming is a successful pedagogical tool for facilitating active learning of introductory programming courses. Responses to survey garnered from undergraduate students hint that the genetic algorithm approach leads to compatible pairs. ||| Grid computing creates the illusion of an enormously powerful computer system using a diverse assortment of simple computers. Grid computing provides many benefits that are inconceivable in simple computers and conventional distributed systems. The objective of current article is to theoretically identify the most important of these benefits. ||| Children now get access to smartphones at an early age and gradually acquire skills to use different types of smartphone apps. We developed a mathematical model for the ability and interest of children to use smartphone apps. The model can be used to determine the level of difficulty of apps and identify niche app, i.e. apps that are designed specifically to be used by a narrow age range of children. ||| The author discusses the relevance of compiler construction in the current era of computer science, highlighting its importance in software development and research. ||| Smartphones have been owned and used ubiquitously in all facets of society utilized for a wide number of tasks such as calling and messaging, social media, surfing as well as for entertainment. Spending a large amount of time on smartphone might lead to a dependence on it for a variety of purposes. This study uses objective measures of real time smartphone usage features to assess smartphone addiction. A purpose built android application to collect real time smartphone usage has been developed and linear classification models namely Support Vector Machine and Logistic Regression are used to predict smartphone addiction among university students. ||| The paper discusses an intelligent system that links classroom studies to a dynamic environment. The system extracts relevant information from handwritten notes and images, and uses a Mutual Influence Factor (MIF) to filter search results. The system was tested with notes and images of students studying operating systems and high performance computing, and the results showed that the system was able to provide relevant information to the students. ||| KELDEC is a system that mines knowledge sources from images by extracting technical phrases and using them to scout for relevant websites. The system uses a combination of natural language processing and machine learning techniques to identify relevant websites and rank them based on their semantic similarity to the image and the class notes. ||| The first outbreak of COVID-19 was reported in December 2019 and the disease took the shape of a pandemic in the next few months. Universities around the world imported lessons to their student mostly in online mode in 2020 and 2021. Thirty-five undergraduate computer science students were interviewed about their experience of attending online lectures during the COVID-19 pandemic. A quantitative analysis of their responses revealed that 43% of them felt that they can learn equally well from online and offline lectures, 49% felt that online lectures provide them flexibility which in turn helps them to perform better in academics and 54% felt that professors have improved their online teaching skills since the beginning of the pandemic. Further, a qualitative analysis revealed that students appreciate online lectures for allowing them to access ebooks and digital resources while attending lectures, and making it easier to study topics that require a lot of visualization and ask queries to professors. Consequently, 77% students said that a combination of online and offline lectures may be used in the future with students being allowed to choose how they learn. Alternatively, only online lectures may be scheduled on some days of the week so that students need not travel to the campus on those days. ||| Excessive use of smartphones throughout the day having dependency on them for social interaction, entertainment and information retrieval may lead users to develop nomophobia. This makes them feel anxious during non-availability of smartphones. This study describes the usefulness of real time smartphone usage data for prediction of nomophobia severity using machine learning. ||| Operating systems are indispensable part of all computer systems used today. The concepts and principles used to design and implement operating systems have been evolving over the decades. However, the researchers are still busy in improving the operating systems and imparting new properties in them. One such desired property is that of being pedagogical in nature. In the current paper, the primal design of a pedagogical operating system is being developed. To attain respectable modularity and flexibility, the multiple server microkernel based architecture has been used. Additionally, object oriented methodologies and software engineering principles has been employed to obtain a well designed and well documented operating system. The pedagogical operating system whose design is being developed in this paper is expected to be helpful in teaching and learning courses on operating systems in various universities and other educational organizations on its completion. Furthermore, the proficient design of the operating system, obtained by employing various august paradigms and introducing new features, aims at enlivening academic atmosphere and promoting scientific innovation. ||| This paper discusses the use of educational software in an Indian university. We discuss the use of software tools to teach five courses of different types. We have used software tools to teach courses on theory of automata, computer programming, operating systems, compiler construction and English pronunciation. Undergraduate and graduate computer science students attended these courses. ||| We conducted a study in New Delhi in February 2017 to check the interest and ability of children younger than 2 years with regard to video-chatting. ||| In this study, an innovative tool for enabling contextual teaching based on visual inputs, named Visual Stimuli-based Teaching Aid (VISTA), was developed. This system establishes the meaning and significance of concepts that are taught in the classroom within different environmental contexts. ||| Courses on computer programming are included in the curricula of almost all engineering disciplines. We surveyed the research literature and identified the techniques that are commonly used by instructors for teaching these courses. We observed that visual programming and game-based learning can enhance computational thinking and problem-solving skills in students and may be used to introduce them to programming. Robot programming may be used to attract students to programming, but the success of this technique is subjected to the availability of robots. Pair and collaborative programming allows students to learn from one another and write efficient programs. Assessment systems help instructors in evaluating programs written by students and provide them with timely feedback. Furthermore, an analysis of citations showed that Scratch is the most researched tool for teaching programming.","movement time, pedagogical, interest, smartphone addiction, genetic algorithm, Compiler Technology, object oriented operating system, computer science, young children, Agricultural expert system, software development, Operating system, cross-compilation, Subject Specific Words/Phrases, research, pair programming, content delivery, game-based learning, touchscreen, online lecture, domain-specific language, Basic Forms of Automata, computer science education, instruction sequences, replacement rules, grid-aware application, screen-based devices, professor-student interaction, MPGO, robot programming, COVID-19 pandemic, visual programming, mobile phone camera, device driver, notational languages, Image analysis, grid device driver, descriptive languages, earthquake precursory research, Smartphone addiction, COVID-19 lockdown, applicability, Collaborative learning environments, education, machine learning, Collaborative Learning, heterogeneous grouping, medical education, message passing, procedural languages, Programming Exercises, technical phrases, crop specificity, suitability, Search results, Ghuttu, real time data, Twitter users, e-learning, Learning Perspectives, Web content mining, microkernel, programming, compiler construction, Dynamic Environment, autonomic computing, classroom teaching, compilers, automata simulators, object programs, English WordNet, peephole optimization, Lockdown, Hyponym enrichment, Technical Terms, ICT tools, educational software, teaching, system software, radon emanation, introductory programming, Classroom studies, psychomotor abilities, Line drawing, Wikidata, Homogenous Grouping, video-chatting, pandemic, contextual teaching, COVID-19, automata theory, Social media addiction, Emotion analysis, mobile learning, image mining, nomophobia, reincarnation server, Intelligent system, verbose server, Computerized expert system, smartphone usage, information and communication technology, pair and collaborative programming, graphic language, index of difficulty, Code generators, compiler, knowledge source, Agriculture, movement task, WordNet, collaborative learning, Mutual Influence Factor, children, taxonomy, assembly-like languages, live streamed lecture, Grid computing, disease specificity, Image Based Search, Class Notes, Fitts' law, software tools, mathematical model, ability, KELDEC, Twitter, simulation, Automata Simulation, bootstrapping, nomophobia questionnaire, linear classification, pedagogical operating system, visual tools, LDDL, expert systems, line drawing language, smartphone apps, contextual teaching and learning, automata simulation, online lectures, Personalized mobile learning, Educational recommender system, smartphone, flexible learning, assessment system, E-learning, android application, operating system, k-means clustering, Crop protection, massive parallel processing, Pair Formation, pedagogical tool, Classroom learning points, touchscreen interaction, homogeneous grouping, semantic similarity","The COVID-19 pandemic has accelerated the adoption of ICT tools in medical education, enabling real-time collaboration, virtual classroom lectures, and online conferences. Various tools such as videoconferencing, teleconferencing, prerecorded videos, social media, live streaming applications, and web-based learning tools are being used to ensure educational continuity. ||| The paper proposes a novel hyponym enrichment in WordNet by enriching the database with subject related technical terms. This is important since the database has not been updated for a long time now. To the best of our knowledge, we are the first to use wikidata for adding subject specific terms and relationships to WordNet. ||| The paper discusses the development of expert systems for crop protection in India, the design and implementation issues, and the current trend of agricultural expert systems in India. It also provides a brief survey of four expert systems for crop protection being used in India. ||| The dissertation presents a comprehensive approach based on compiler technology to simulate basic forms of automata, including finite accepters, finite transducers, pushdown accepters, and Turing machines. ||| This paper introduces a domain-specific language, named Line Drawing Description Language (LDDL), in which the specification of a line drawing can be written. The language is suitable for drawing line drawings used in scientific literature. ||| This study aimed to assess the ability of children to acquire onscreen targets while using smartphones and determine if their interaction with smartphones follows Fitts' law. The study found that the interaction of children with smartphones does not obey Fitts' law, and recommends that smartphone apps for children be developed taking into consideration their ability to acquire onscreen targets. ||| The authors discuss the merits and demerits of bootstrapping and cross-compilation approaches in compiler construction, highlighting their suitability for different computer architectures and programming languages. ||| This study analyzed the social media usage pattern of people during the COVID-19 imposed lockdown in India and the effects of emotion on the same. The study found that 13.5% of users were found to be addicted to Twitter and posted 13.67 tweets daily on an average, while 3.2% were found to be highly addicted and posted 40.71 tweets daily on an average. The overall emotion of 40.1% of the users was happiness throughout the study period. However, it was also observed that users who tweeted more frequently were typically angry, disgusted, or sad about the prevailing situation. ||| The study evaluates the learning perspectives of students on the basis of class notes taken while the teacher is teaching in class. The study uses a quasi-experimental design and involves 194 undergraduate students from the seventh semester of the computer engineering department. The study finds that homogenous and heterogeneous grouping methods have different effects on student learning outcomes. ||| The article reviews the major initiatives in the field of simulation of automata in the last five decades with emphasis on those automata simulators actually used at universities for teaching. It also identifies some salient trends in the research on simulation of automata and concludes with an advocacy for continuing research on simulation of automata and integration of automata simulators in teaching. ||| Peephole optimization has been widely used in compilers to improve the performance of object programs. The technique involves replacing sequences of instructions with equivalent single instructions, and has been applied to various programming languages and target machines. The effectiveness of peephole optimization depends on several factors, including the nature of the source language, the parsing and code generation techniques used in the compiler, and the specifications of the target machine. ||| This paper studies the usefulness of pair programming as a method to teach an introductory programming course. The contributions of the study are the following: Keeping in mind the role of personality traits in determining the success of pair programming, we use a blend of skills and personality‐based pairing mechanism. A five‐factor model comprising of skill levels of students, personality type, and attitude toward programming is considered for pairing students. To minimize conflicts and automate the pair formation, we propose a novel genetic algorithm‐based approach. The experiment was conducted for one semester covering the entire course syllabus to analyze the effects of pair programming better. ||| Grid computing has numerous benefits, including load balancing, reliability, and the possibility of sharing resources. However, the success of grid computing lies in several factors, including the organizational structure, the application domain, and the available resources. ||| The model uses a Gaussian function to represent the interest of children in an app and a parabola to represent the most important skill required to use the app. The parameters c and A are used to determine the applicability and suitability of an app, respectively. The study analyzed several smartphone apps and found that most of them do not take into account the psychomotor abilities of children, leading to a mismatch between the skills required to use the app and the skills possessed by children. The study suggests that developers should identify the target age group and ensure that using the app requires only the skills that children of that age group possess. ||| The author argues that compiler construction is not a dead subject, citing its continued relevance in software development and research, and highlighting the importance of understanding compilers in developing new programming languages and computer hardware. ||| This study aims to use real time smartphone usage data to predict smartphone addiction using supervised machine learning. A purpose built android application has been developed to track real time smartphone usage patterns among multiple attributes such as duration of smartphone use and internet data used over the past 30 days. The applications installed in the smartphone are categorized into nine types namely Social Media, Communication, Entertainment, Productivity, News & Surfing, Gaming, Work, Photos & Camera, and Others. ||| The system uses a combination of natural language processing and computer vision to extract relevant information from handwritten notes and images. The MIF is used to filter search results and provide relevant information to the students. The system was tested with notes and images of students studying operating systems and high performance computing, and the results showed that the system was able to provide relevant information to the students. ||| The KELDEC system is designed to extract technical phrases from images and use them to recommend relevant websites to users. The system uses a combination of natural language processing and machine learning techniques to identify relevant websites and rank them based on their semantic similarity to the image and the class notes. ||| This study investigated the opinion of undergraduate computer science students in an Indian university on different aspects of online lectures. The students were interviewed and asked, inter alia, whether they would like online lectures to be used even after the pandemic is over. ||| The study concludes that real time smartphone usage features extracted from the smartphones of students are effective for prediction of nomophobia among students using machine learning. In future, deep learning models can be implemented for prediction of nomophobia using real time smartphone usage features. ||| The paper introduces a novel operating system design with a focus on pedagogy. The system consists of five layers and uses a message passing mechanism for communication. Two novel features, the reincarnation server and the verbose server, are also introduced. ||| This paper discusses the use of educational software in teaching computer science courses. It highlights the use of automata simulators, visual programming tools, game-based approach, and assessment systems in teaching programming and algorithmic concepts. ||| The study found that only a small proportion of parents feel the need for, and engage in, video-chatting with their children. The behaviour of a child towards video-chatting varies with time and context, but there are some salient trends in their behaviour. ||| VISTA is a system that uses a mobile phone camera to gather information from the environment and provide personalized knowledge awareness maps to assist in learning. It captures images of the teacher's notes and the physical environment, and uses optical character recognition (OCR) to convert the notes into a textual format. The system then extracts the fundamental concepts embedded within the notes by selecting informative words and searching the entries in the index of an e-book. ||| The paper reviews the use of visual tools for teaching programming, including the development of various visual tools and their widespread use in teaching programming courses. It also discusses the use of game-based approaches and pair and collaborative programming for teaching programming."
Ping Kong,Opposing Actions of Fibroblast and Cardiomyocyte Smad3 Signaling in the Infarcted Myocardium ||| TSP-1 in Diabetic Cardiomyopathy,"Transforming growth factor (TGF)–βs are highly pleiotropic mediators with critical roles in regulating cellular phenotype and function in embryonic development, tissue homeostasis, and disease. Normal tissues contain stores of latent TGF-β bound to the extracellular matrix through its association with a large binding protein, the latent TGF-β binding protein. Tissue injury is associated with marked induction of TGF-β isoforms and activation of TGF-β signaling cascades. Parenchymal cells, extravasated leukocytes, and platelets synthesize and release large amounts of TGF-β in the injury site. Reactive oxygen species, proteases, matricellular proteins, and integrins cooperate to trigger the release of bioactive TGF-β from the latent stores. Subsequent binding of the active TGF-β dimer to the type II TGF-β receptor, followed by transphosphorylation of the type I receptor, triggers the TGF-β signaling response. The cellular effects of TGF-β are mediated through a canonical pathway involving a series of intracellular effectors, the Smads, or through activation of noncanonical signaling cascades. Activation of TGF-β signaling induces phosphorylation of the receptor-activated Smads, Smad2 and Smad3, which can form heteromeric complexes with the common Smad, Smad4. These complexes are transported to the nucleus, where they regulate gene transcription. TGF–β receptors and Smads are ubiquitously expressed by all cell types. Thus, all cells are responsive to the actions of TGF-β. Cardiac injury is associated with the marked induction of TGF-β and activation of TGF-β cascades. Our laboratory and other investigators have documented activation of Smad2 and Smad3 signaling in the infarcted myocardium, localized in both cardiomyocytes and interstitial cells. In isolated cardiac fibroblasts, Smad3 signaling accentuates myofibroblast transdifferentiation and stimulates a matrix-preserving program. In a model of reperfused infarction, global loss of Smad3 attenuated remodeling after infarction. However, considering the ubiquitous expression of Smad3 in all cell types, the cell biological basis for the actions of Smad3 in the infarcted heart remains unknown. Our study dissects the cell-specific actions of Smad3 signaling in the infarcted myocardium by developing and studying mice with cell-specific loss of Smad3 in activated fibroblasts and cardiomyocytes. It is surprising that fibroblast-specific loss of Smad3 worsened remodeling after infarction, resulting in accentuated chamber dilation. The deleterious consequences of fibroblast-specific Smad3 loss reflected unrestrained fibroblast proliferation, defective scar remodeling, and perturbed organization of myofibroblast arrays in the border zone. Smad3 signaling regulated fibroblast function, activating integrin-mediated nicotinamide adenine dinucleotide phosphate (NADPH) oxidase (NOX)–2 expression. In contrast, cardiomyocyte-specific loss of Smad3 protected the infarcted heart from dysfunction after infarction. The protective effects of cardiomyocyte-specific Smad3 loss were associated with attenuated cardiomyocyte apoptosis in remodeling myocardium and accompanied by decreased NOX2 levels, reduced nitrosative stress, and decreased matrix metalloproteinase (MMP)–2 expression. ||| Diabetes mellitus is associated with cardiac fibrosis. Matricellular proteins are induced in fibrotic conditions and modulate fibrogenic and angiogenic responses by regulating growth factor signaling. Our aim was to test the hypothesis that the prototypical matricellular protein thrombospondin (TSP)-1, a potent angiostatic molecule and crucial activator of transforming growth factor-β, may play a key role in remodeling of the diabetic heart. Obese diabetic db/db mice exhibited marked myocardial TSP-1 upregulation in the interstitial and perivascular space. To study the role of TSP-1 in remodeling of the diabetic heart, we generated and characterized db/db TSP-1–/– (dbTSP) mice. TSP-1 disruption did not significantly affect weight gain and metabolic function in db/db animals. When compared with db/db animals, dbTSP mice had increased left ventricular dilation associated with mild nonprogressive systolic dysfunction. Chamber dilation in dbTSP mice was associated with decreased myocardial collagen content and accentuated matrix metalloproteinase-2 and -9 activity. TSP-1 disruption did not affect inflammatory gene expression and activation of transforming growth factor-β/small mothers against decapendaplegic signaling in the db/db myocardium. In cardiac fibroblasts populating collagen pads, TSP-1 incorporation into the matrix did not activate transforming growth factor-β responses, but inhibited leptin-induced matrix metalloproteinase-2 activation. TSP-1 disruption abrogated age-associated capillary rarefaction in db/db mice, attenuating myocardial upregulation of angiopoietin-2, a mediator that induces vascular regression. In vitro, TSP-1 stimulation increased macrophage, but not endothelial cell, angiopoietin-2 synthesis. Conclusions: TSP-1 upregulation in the diabetic heart prevents chamber dilation by exerting matrix-preserving actions on cardiac fibroblasts and mediates capillary rarefaction through effects that may involve angiopoietin-2 upregulation.","SMAD, fibroblast, matrix metalloproteinases, heart failure, cardiomyocyte, thrombospondins, fibrosis, diabetic cardiomyopathies, ventricular remodeling, remodeling","This study investigates the role of Smad3 in cardiac fibroblasts following myocardial infarction. Using a mouse model with fibroblast-specific Smad3 deletion (FS3KO), the researchers found that loss of Smad3 in fibroblasts exacerbated dilative remodeling and worsened systolic dysfunction after both reperfused and nonreperfused infarction.  While acute infarct size was not affected, FS3KO mice exhibited larger scars, increased myofibroblast density, and enhanced myofibroblast proliferation. These findings suggest that Smad3 plays a protective role in cardiac fibroblasts and its loss contributes to adverse cardiac remodeling after infarction. ||| This study investigates the role of thrombospondin-1 (TSP-1) in diabetic cardiomyopathy. Researchers found that TSP-1 is upregulated in the hearts of diabetic mice and that its loss attenuates cardiac fibrosis and enhances myocardial protease activity. However, TSP-1 disruption also led to mild left ventricular dilation and modest nonprogressive systolic dysfunction. These findings suggest that TSP-1 plays a complex role in diabetic heart remodeling, with both beneficial and detrimental effects."
Pooshpendra Singh Dixit,"Estimate of variability, heritability and genetic advance with respect to yield and yield contributing characters in field pea (Pisum sativum L.)","The present investigation entitled “Estimate of variability, heritability and genetic advance with respect to yield and yield contributing characters in field pea (Pisum sativum L.)” for 10 characters. The experiment comprising of 23 genotypes of pea were grown in a Randomized Block Design (RBD), with three replications at Research Farm, Department of Genetics & Plant Breeding, Post Graduate College, Ghazipur, during rabi season of 2017-2018, plant to plant and row to row distance was kept 10 cm and 45 cm, respectively.","Pisum sativum L., heritability, Genetic variability, yield contributing characters, genetic advance, field pea","The estimates of genotypic coefficient of variation (GCV) and phenotypic coefficient of variation (PCV) and environmental coefficient of variation (ECV) showed a wide range. The high estimates of genotypic coefficient of variation (GCV) were observed for plant height, biological yield per plant, number of pods per plant, seed yield per plant, number, 100 seed weight. The high estimates of phenotypic coefficient of variation (PCV) were observed for seed yield per pod, number of pods per plant, biological yield per plant, harvest index, plant height."
Porwik et al.,Deformation Adjustment with Single Real Signature Image for Biometric Verification Using CNN,"Signature verification is the widely used biometric verification method for maintaining individual privacy. It is generally used in legal documents and in financial transactions. A vast range of research has been done so far to tackle different system issues, but there are various hot issues that remain unaddressed. The scale and orientation of the signatures are some issues to address, and the deformation of the signature within the genuine examples is the most critical for the verification system.","biometric authentication, Single real signature image, soft biometrics, deep learning, hard biometrics, CNN, Signature verification, Deformation adjustment, Biometric verification, writer-independent","This work proposes a two-phase system requiring only one target signature image to verify a query signature image. It takes care of the target signature's scaling, orientation, and spatial translation in the first phase. The second phase uses this transformed sample image and verifies the given sample as the target signature with the help of another deep neural network."
Prabhat Mittal,Human Behavior and Emerging Technologies,"Children now get access to smartphones at an early age and gradually acquire skills to use different types of smartphone apps. We developed a mathematical model for the ability and interest of children to use smartphone apps. The model can be used to determine the level of difficulty of apps and identify niche app, i.e. apps that are designed specifically to be used by a narrow age range of children.","suitability, children, mathematical model, psychomotor abilities, interest, applicability, ability, smartphone apps","The model uses a Gaussian function to represent the interest of children in an app and a parabola to represent the most important skill required to use the app. The parameters c and A are used to determine the applicability and suitability of an app, respectively. The study analyzed several smartphone apps and found that most of them do not take into account the psychomotor abilities of children, leading to a mismatch between the skills required to use the app and the skills possessed by children. The study suggests that developers should identify the target age group and ensure that using the app requires only the skills that children of that age group possess."
Prabhat Ranjan Singh,Adaptive Energy-Aware Algorithms for Minimizing Energy Consumption and SLA Violation in Cloud Computing,"In cloud computing, high energy consumption and service-level agreements (SLAs) violation are the challenging issues considering that the demand for computational power is growing rapidly, thereby requiring large-scale cloud data centers. This paper proposes three adaptive models, namely, gradient descent-based regression (Gdr), maximize correlation percentage (MCP), and bandwidth-aware selection policy (Bw), that can significantly minimize energy consumption and SLA violation.","regression method, energy-efﬁciency, service level agreements, SLA violation, host overloaded detection, energy efficiency, cloud data center, VM consolidation, Cloud computing, meta-heuristic approach, green computing","This paper proposes three adaptive models to minimize energy consumption and SLA violation in cloud computing. The models are based on gradient descent-based regression, maximize correlation percentage, and bandwidth-aware selection policy. The proposed algorithms reduce energy consumption while maintaining the required performance levels in a cloud data center."
Pradeep Atrey,Cloud-Based Secured Medical Data Visualization Pipeline,"Outsourcing the tasks of medical data visualization to cloud centers presents new security challenges. In this paper, we propose a framework for cloud-based remote medical data visualization that protects the security of data at the cloud centers.","cloud-based, visualization, pipeline, 3D Medical Data Visualization, secured, Secret Sharing, Cloud Computing, medical, data, Ray Casting","The proposed pipeline protects patient's 3D medical data by distributing shares among n different data centers, allowing clients to reconstruct the secret image from any k shares."
Pradeep K. Atrey,Secure Cloud-Based Volume Ray-Casting,Secure Cloud-based Volume Ray-Casting,,Secure Cloud-based Volume Ray-Casting is a framework for secure medical data visualization. It addresses security and privacy challenges by using secure pre-classification and post-classification volume ray-casting techniques.
Pradeep Kumar Ramancharla,Structural Dynamics Virtual Laboratory: A Learning Tool Kit for Young Engineers and Practicing Professionals,"India has been facing earthquake problems from many centuries which need no introduction. From recent earthquakes, it is very well understood that lack of awareness is one of the major factor for huge casualty losses. While still having the probability of occurrences of earthquakes in India, it becomes very important and need to increase the awareness about the effects of earthquakes among growing  professionals involved in construction by making them understanding the concepts of Structural Dynamics and Earthquake Engineering.","Structural Dynamics, User Interface, Interactive, Virtual Lab, Virtual Laboratory",This paper will detail the use of virtual laboratory in real time environment of structural dynamics. Virtual Laboratory provides a new methodology to convey and learn concepts using the power of visualization of ideas and computations. Virtual labs rely on an active engagement of the learner in the knowledge acquisition process.
Pradhan and Subudhi,Real-Time Adaptive Control of a Flexible Manipulator Using Reinforcement Learning,This paper presents a real-time adaptive control of a flexible manipulator using reinforcement learning. The proposed method utilizes an actor-critic block and a PD control loop to adapt the actor and critic weights in order to compensate for the joint torque input under payload uncertainties.,"Reinforcement learning, Flexible-link manipulator, Tip trajectory tracking, PD Control Loop, Actor-Critic Block, Adaptive control, Real-Time Adaptive Control, Flexible Manipulator",The paper proposes a real-time adaptive control for a two-link flexible manipulator using actor-critic-based reinforcement learning. The proposed algorithm uses recursive least square (RLS)-based temporal difference (TD) learning with eligibility trace and adaptive memory to estimate the critic weights and actor weights. The results show that the proposed RL-based adaptive controller outperforms both the nonlinear regression-based direct adaptive controller and the fuzzy learning-based adaptive controller.
Pradip Sircar,Support Vector Machines for Pattern Recognition,We propose a novel approach for content based color image classification using Support Vector Machine (SVM). Traditional classification approaches deal poorly on content based image classification tasks being one of the reasons of high dimensionality of the feature space.,"Pattern Recognition, image classification, color image histogram, Knowledge Discovery, Data Mining, Support Vector Machines, Support Vector Machine",The paper proposes a novel approach for content based color image classification using Support Vector Machine (SVM). The approach uses color image histograms as features and is found to be efficient and insensitive to small changes in camera viewpoint.
Prakarsh Yadav,"L,M&A: An Algorithm for Music Lyrics Mining and Sentiment Analysis","Here we propose an open source algorithm, L,M&A(Lyrics, Mine and Analyse) to create a dataset of lyrics of the works of various artists. The aim of this approach is to facilitate the generation of a large data set that can be used for improving accuracy of song recommendation algorithms.","Music Recommendation, Natural Language Processing, algorithm, musicology, Sentiment Analysis, musixmatch, Data Mining, Genius, Lyrics Database, music lyrics mining, Rstudio, genius API","This paper proposes an algorithm to mine lyric data for various artists which can be further utilized to generate a sentiment for individual artists. The employed model is an independent function that requires an artist’s name as primary input and through open-source APIs gathers the required data regarding that artist’s work and then employs our algorithm, L,M&A(Lyrics, Mine and Analyse) to generate a sentiment (based on the different categories of sentiment present in the lexicons used) for that particular artist and is also able to quantitate that sentiment."
Prakash Chandra Sharma,Automated Cryptanalysis of Substitution Ciphers using Swarm Intelligence Techniques ||| Design and Performance Analysis of MIMO Patch Antenna Using CST Microwave Studio,"This paper presents a comparative analysis of various swarm intelligence techniques for automated cryptanalysis of substitution ciphers. The techniques used include particle swarm optimization (PSO), bees algorithm, ant colony optimization, firefly algorithm, and cuckoo search. The results show that the cuckoo search technique is the most effective, with an average number of key elements correctly recovered of 26.17 out of 27, and a mean performance time of 0.137 seconds. ||| This paper presents the design and performance analysis of MIMO antenna system using Computer Simulation Technology (CST) Microwave Studio software. Several design techniques are discussed in detail with examples, and the fundamental properties of different antenna types are analyzed.","CST Microwave Studio software, Bees Algorithm, MIMO, Automated Cryptanalysis, microstrip patch antenna, MIMO antenna system, Patch Antenna, Firefly Algorithm, Wireless Communication, Substitution Ciphers, Particle Swarm Optimization, CST Microwave Studio, Swarm Intelligence, Ant Colony Optimization, Classical Substitution Cipher, Cuckoo Search","This paper presents a comparative analysis of various swarm intelligence techniques for automated cryptanalysis of substitution ciphers. The results show that the cuckoo search technique is the most effective, with an average number of key elements correctly recovered of 26.17 out of 27, and a mean performance time of 0.137 seconds. ||| This paper presents the design and performance analysis of MIMO patch antennas using CST Microwave Studio. The antennas are designed to operate at a resonant frequency of 2.45 GHz and are suitable for applications such as industrial, scientific, and medical (ISM) band. The main objective of this paper is to implement a 2 × 2 multiple-input multiple-output (MIMO) system and design four mutually orthogonal MIMO patch antennas with a single substrate, which are fed by four microstrip lines using the same resonant frequency of 2.45 GHz."
Prakhar Sonkar,EXPERIMENTAL STUDY OF REGENERATIVE BRAKING SYSTEM (RBS),"In this era, the automobile sector is facing a major challenge to reduce consumption of fuel and greenhouse gases emission, this is often because limited fuel reserves and continuous degrade in air quality. An experimental setup is made for the current study to reduce the loss of energy by reusing it. In this present study, an alternator is connected to the driver shaft through chain and sprocket. When brakes are applied to slow the vehicle down or make it come to a halt, the alternator is activated with an electromagnetic clutch, and the energy lost during braking is utilized to generate electrical energy.","Generator, Automobile, Regenerative braking, Electromagnetic clutch, Energy recovery system","This paper presents an experimental study of regenerative braking system (RBS) to reduce energy loss during braking. An experimental setup is designed to reuse the energy lost during braking by activating an alternator with an electromagnetic clutch. The study shows that 16.32% of brake energy was recovered, and the current from the alternator increases with engine speed."
Prakriti Bansal,KELDEC: A System for Mining Knowledge Sources from Images,KELDEC is a system that mines knowledge sources from images by extracting technical phrases and using them to scout for relevant websites. The system uses a combination of natural language processing and machine learning techniques to identify relevant websites and rank them based on their semantic similarity to the image and the class notes.,"knowledge source, Educational recommender system, Personalized mobile learning, Web content mining, KELDEC, Classroom learning points, Image analysis, image mining, semantic similarity, technical phrases",The KELDEC system is designed to extract technical phrases from images and use them to recommend relevant websites to users. The system uses a combination of natural language processing and machine learning techniques to identify relevant websites and rank them based on their semantic similarity to the image and the class notes.
Prakriti Sinha,Evaluation of Total Phenolic and Flavonoid Content and Antioxidant Activity of *Hibiscus isora* (L.),"Plant extracts rich in polyphenols are important for preparation of medicines as polyphenols are easily obtained from natural sources. Though medicinal plants of India constitute about 20% of total plant species 19, but the medicinal properties of most of them are not completely explored.  There are very few studies available where commercially viable formulations are being prepared, therefore, it is imperative to promote their studies for their application in curing diseases. The present investigation evaluates the phenolic and flavonoid content as well as antioxidant activity of one such scantily explored but potentially useful plant species *H. isora* (L.) Solvent extraction is most frequently used technique for isolation of plant antioxidant compounds with varied characteristics and polarities that may or may not be soluble in a particular solvent. Polar solvents are frequently employed for the recovery of polyphenols from a plant matrix 13. The selection of an appropriate solvent is one of the most relevant previous steps in estimating phytochemical activities. The yield of antioxidant compounds from plant parts is influenced mainly by the conditions under which the process of liquid-solid extraction is achieved, the type of solvent used to separate the soluble fraction from the permeable solid, the degree of polymerization of phenolics and their interaction with the other components20.  In present investigation, four types of extracts with water, ethanol, methanol, and acetone were prepared from different plant parts and used to check TPC, TFC and their antioxidant potential.","RP- HPLC, Phenolic content, Helicteres isora, Antioxidant activity, Flavonoid content","This study investigated the antioxidant potential of different parts of the Indian screw tree (Helicteres isora) using various solvents. Dried plant parts showed higher antioxidant activity compared to fresh ones, with leaves exhibiting the highest phenolic and flavonoid content and DPPH˙ radical scavenging activity.  The study suggests that dried leaves, roots, and fruits of H. isora, particularly when prepared in distilled water or methanol, hold potential for developing herbal formulations with antioxidant properties."
Pramod Kumar Rai,Adsorption and Photodegradation of Dyes Using Graphene Composites: A Review,"Water contamination has reached an alarming state due to industrialization and urbanization and has become a worldwide issue. Dyes contaminate water and are addressed extensively by researchers. Various technologies and materials have been developed for the treatment of contaminated water. Among them, adsorption has attracted great attention due to its ease and cost-effective nature. In recent years, graphene-based composites have shown great potential for the removal of contaminants from water. The literature reveals the usefulness of composites of graphene with metal oxides, carbon derivatives, metal hybrids and polymers for the removal of organic dyes from contaminated water. In this review, efforts have been made to compile the studies on the removal of cationic and anionic dyes from water using graphene-based composites.","Graphene, Dye removal, Photodegradation, Graphene composites, Degradation, Water treatment, Composites, Contaminated water, Adsorption, Dyes","Graphene composites are emerging as promising materials for the removal of dyes from wastewater due to their high surface area, excellent electrical conductivity, and tunable properties. This review summarizes the recent progress in using graphene composites for both adsorption and photodegradation of dyes. It discusses the mechanisms involved, key factors affecting dye removal efficiency, and the advantages of graphene-based materials over conventional methods. The review also highlights the potential of graphene composites for sustainable and efficient dye remediation in the future."
Pramoud K. Misra,Gesture Recognition,"Hand Gesture detection is now getting a lot of attention because it has a lot of uses and the specialty to connect with machines around efficiently by human interaction to computers. In this we are trying to make a knowhow of hand gesture detection system. The problems of hand gesture detection system are also discussed in this. Conclusion of results, methods, data and difference between different phases are also mentioned. Pros and cons are also discussed. In this project we are trying to understand how the image processing works and how can we use it to make a hand gesture detection system so that we can operate the computer without any physical contact with the machine itself. There are many researches that are done before and are still undergoing. Many big companies are currently working on this technology so that they can make their products even more useful that they are now because this technology has very high scope in the upcoming future. The people that are not mentally stable or weak from mind can also benefit by technology and can operate the computer. We can use this technology to make the computer even more accessible for humans.","Feature Extract, Tools for classification, Neural Networks, Posture of Hand, Gesture, Interaction of human with computer (HCI), Phases of recognition, brightness factor matching, fuzzy c-means clustering algorithm, gesture recognition",The main motive to build a hand gesture detection system is to make an interaction between human and computer that can be done by recognizing gestures for controlling robots or a simple computer. How do we make this system is understood and interpreted by the computer. The interaction of humans with computer is also called as man-machine interaction (MMI). Since A computer is insignificant if it not being utilized by human. There are some features that should be looked before we design this system. The function of the system and the use of the system. Function means the things that the system gives to its user and use means the scope of the system that it can be used efficiently. The system which has these both properties is known as powerful system.
Pranav Saxena,Map-reduce-based tournament empowered whale optimization algorithm for recommendation,"In the era of Web 2.0, the data are growing immensely and is assisting E-commerce websites for better decision-making. Collaborative filtering, one of the prominent recommendation approaches, performs recommendation by finding similarity. However, this approach fails in managing large-scale datasets. To mitigate the same, an efficient map-reduce-based clustering recommendation system is presented. The proposed method uses a novel variant of the whale optimization algorithm, tournament selection empowered whale optimization algorithm, to attain the optimal clusters.","tournament empowered WOA, Map-reduce, Recommendation system, Clustering, Whale optimization algorithm, Big data, map-reduce architecture","This paper presents a novel meta-heuristic-based recommendation system for the big data environment. The proposed method uses a novel variant of the whale optimization algorithm, tournament selection empowered whale optimization algorithm, to attain the optimal clusters. The clustering efficiency of the proposed method is measured on four large-scale datasets in terms of F-measure and computation time."
Prashant Yadav,"MOTIVATING CHILD DEVELOPMENT AND ERADICATION OF CHILD LABOR BY PROMPT EFFORTS BY US, SOCIETY AND GOVERNMENT","One of the menacing curses that our nation is facing today is child labor. Lack of economy and basic education has been monitored as a cause for majority of child labor activities. It is being generally realized that, child labor especially in hazardous occupation is one of the worst social evil and has to be eliminated at the earliest. Government has been taking various pro-active measures to tackle this problem. However, considering the magnitude and extent of the problem and that it is essentially a socio-economic problem inextricably linked to poverty and illiteracy, it requires concerted efforts from all sections of the society to make a dent in the problem.","government schemes, government, illiteracy, child labor, education, menacing, eradication, awareness","The paper discusses the menace of child labor in India and proposes a plan to eradicate it through education, financial support, and awareness. The plan involves collecting donations, providing financial assistance to underprivileged families, and setting up schools for primary education. The authors aim to make children skillful by imparting professional education and provide alternative employment opportunities."
Prateek Tamrakar,Support Vector Machines for Pattern Recognition,We propose a novel approach for content based color image classification using Support Vector Machine (SVM). Traditional classification approaches deal poorly on content based image classification tasks being one of the reasons of high dimensionality of the feature space.,"Pattern Recognition, image classification, color image histogram, Knowledge Discovery, Data Mining, Support Vector Machines, Support Vector Machine",The paper proposes a novel approach for content based color image classification using Support Vector Machine (SVM). The approach uses color image histograms as features and is found to be efficient and insensitive to small changes in camera viewpoint.
Pravat Kumar Ray,An Adaptive Sliding Mode Control Scheme for Grid Integration of a PV System ||| A Combined Reinforcement Learning and Sliding Mode Control Scheme for Grid Integration of a PV System ||| Ensemble-Kalman-Filter-Based Power System Harmonic Estimation,"This paper presents an adaptive sliding mode control scheme for grid integration of a PV system. The proposed scheme is compared with the SMC-IC-IPT scheme and the results show that the ASMC-IC-IPT scheme reduces the grid current THD from 29.35% to 2.80%. ||| The paper presents development of a reinforcement learning (RL) and sliding mode control (SMC) algorithm for a 3-phase PV system integrated to a grid. The PV system is integrated to grid through a voltage source inverter (VSI), in which PV-VSI combination supplies active power and compensates reactive power of the local non-linear load connected to the point of common coupling (PCC). For extraction of maximum power from the PV panel, we develop a RL based maximum power point tracking (MPPT) algorithm. The instantaneous power theory (IPT) is adopted for generation reference inverter current (RIC). An SMC algorithm has been developed for injecting current to the local non-linear load at a reference value. The RL-SMC scheme is implemented in both simulation using MATLAB/SIMULINK software and on a prototype PV experimental. The performance of the proposed RL-SMC scheme is compared with that of fuzzy logic-sliding mode control (FL-SMC) and incremental conductance-sliding mode control (IC-SMC) algorithms. From the obtained results, it is observed that the proposed RL-SMC scheme provides better maximum power extraction and active power control than the FL-SMC and IC-SMC schemes. ||| This paper presents an ensemble Kalman filter (EnKF)-based algorithm for power system harmonic estimation. The proposed algorithm is compared with four other algorithms, namely, recursive least squares (RLS), recursive least mean squares (RLMS), Kalman filter (KF), and EnKF. The results show that the EnKF algorithm provides better estimation accuracy compared to the other algorithms.","grid synchronization, total harmonic distortion, reinforcement learning, instantaneous power theory, Ensemble Kalman filter, Recursive least squares, Power system harmonic estimation, Ensemble Kalman filter (EnKF), Recursive least mean squares, PV System, fast Fourier transform (FFT), harmonic estimation, Lyapunov function, recursive least square (RLS), incremental conductance, Adaptive sliding mode control, Fuzzy logic, sliding mode controller, Sliding Mode Control, Grid Integration, Maximum Power Point Tracking, KF, Kalman filter","This paper presents an Adaptive Sliding Mode Control (ASMC) algorithm for grid synchronization of a photovoltaic (PV) system. The ASMC algorithm minimizes the difference between the reference inverter current and the actual inverter current of the grid connected PV system during unbalanced loading, grid voltage distortion and variation in solar irradiance. ||| This paper presents a combined reinforcement learning and sliding mode control scheme for grid integration of a PV system. The proposed scheme uses a reinforcement learning based maximum power point tracking algorithm and a sliding mode control algorithm to inject current to the local non-linear load at a reference value. The performance of the proposed scheme is compared with that of fuzzy logic-sliding mode control and incremental conductance-sliding mode control schemes. ||| A new algorithm for the estimation of harmonics using EnKF is proposed. The performance is assessed with respect to some available harmonic estimation techniques, and the comparison indicates that the proposed method outperforms the existing methods in terms of accuracy and robustness with respect to sudden variations in measured signal amplitudes."
Praveen Kumar Rai,Analgesic activity of synthesized compounds ||| Isoprenaline Induced Model for Myocardial Necrosis,"In an approach to synthesize some potent benzoxazole derivatives, some compounds were synthesized. The details of these compounds are given below- The structures were confirmed using IR and NMR spectroscopy. The potency of synthesized compounds were established using following pharmacological screening- Analgesic activity  Paw edema- Male or female Wistar rats with a body weight between 100 and 150 g are used. The animals are starved overnight. To insure uniform hydration, the rats receive 5 ml of water by stomach tube (controls) or the test drug dissolved or suspended in the same volume. Thirty minutes later, the rats are challenged by a subcutaneous injection of 0.05 ml of 1% solution of carrageenan into the plantar side of the left hind paw. The paw is marked with ink at the level of the lateral malleolus and immersed in mercury up to this mark. The paw volume is measured plethysmographically immediately after injection, again 3 and 6 h, and eventually 24 h after challenge. [3] Analgesic activity Writhing tests- Mice of either sex with a weight between 20 and 25 g are used. Acetic acid in a concentration of 1% (1ml/kg) is used to produce writhing. An aliquot of 0.025 ml of this suspension is injected intraperitoneally. Groups of 6 animals are used for controls and treated mice. Preferably, two groups of 6 mice are used as controls. Test animals are administered the drug or the standard at various pretreatment times prior to Acetic acid administration. The mice are placed individually into glass beakers and five min are allowed to elapse. The mice are then observed for a period of ten min and the number of writhes is recorded for each animal. For scoring purposes, a writhe is indicated by stretching of the abdomen with simultaneous stretching of at least one hind limb. The formula for computing percent inhibition is: average writhes in the control group minus writhes in the drug group divided by writhes in the control group times 100%. The time period with the greatest percent of inhibition is considered the peak time. A dose range is reserved for interesting compounds or those which inhibit writhing more than 70%. Compounds with less than 70% inhibition are considered to have minimal activity. [4] Microbiological screening For both antibacterial and assay compounds were dissolved in absolute ethanol (0.8 mg/ml). Further dilutions of the compounds and standard drugs in the test medium have concentrations of 400, 200, 100, 50, 25, 12.5, 6.25, 3.12, 1.56, 0.78 mg/ml. The minimum inhibitory concentrations (MIC) were determined using the method of two-fold serial dilution. In order to ensure that the solvent ‘per se’ had no effect on bacterial growth, a control test was also performed containing inoculated broth supplemented with only ethanol at the same dilutions used in our experiments and found inactive in culture medium. Antibacterial assay- The cultures were obtained in Nutrient agar broth (Difco) for all the bacteria after 24 h of incubation at 37+1°C. Testing was carried out in Nutrient agar broth at pH 7.4 and the two-fold serial dilution technique was applied. The final inoculums size was 105 CFU/ml. A set of tubes containing only inoculated broth was kept as controls. Ciprofoxacine was taken as standard. After incubation for 24 h at 37+1°C, the last tube with no growth of microorganism was recorded to represent MIC expressed in g/ml. [5] ||| The study used isoprenaline-induced myocardial necrosis as an experimental model to evaluate the cardioprotective effects of various herbal drugs. The pathophysiological changes following ISO administration in rats are comparable to those taking place during MI in humans.","pharmacological screening, Nelumbo nucifera, myocardial necrosis, Benzoxazole, Isoprenaline, benzoxazole derivatives, Cardioprotective Effects, antibacterial assay, Anti-inflammatory activity, cardioprotective effect, Isoproterenol, Herbal Drugs, Analgesic activity, Microbiological screening","The study aimed to synthesize potent benzoxazole derivatives and evaluate their analgesic activity using pharmacological screening. The compounds were synthesized and their structures confirmed using IR and NMR spectroscopy. The potency of the synthesized compounds was established using analgesic activity tests, including paw edema and writhing tests. The results showed that some of the compounds exhibited significant analgesic activity, with one compound showing 63.33% inhibition at a dose of 30 mg/kg. The study also evaluated the antibacterial activity of the compounds using the two-fold serial dilution technique and found that some of the compounds exhibited significant antibacterial activity. The study concluded that the synthesized compounds have potential as analgesic and antibacterial agents. ||| The study aimed to develop a pharmacologic technique for producing myocardial necrosis of standard severity in animals using isoprenaline-induced myocardial necrosis as an experimental model."
Prayag Tiwari,Accurate Trafﬁc Flow Prediction in Heterogeneous Vehicular Networks in an Intelligent Transport System Using a Supervised Non-Parametric Classiﬁer,"Heterogeneous vehicular networks (HETVNETs) evolve from vehicular ad hoc networks (VANETs), which allow vehicles to always be connected so as to obtain safety services within intelligent transportation systems (ITSs). The services and data provided by HETVNETs should be neither interrupted nor delayed. Therefore, Quality of Service (QoS) improvement of HETVNETs is one of the topics attracting the attention of researchers and the manufacturing community.","QoS, SVM, Radial Basis Function, Prediction Accuracy, RBF, internet of vehicles, Support Vector Machines, HETVNET, Vehicular Ad Hoc Network",This paper proposes a prediction model based on support vector machines (SVMs) to improve Quality of Service (QoS) in Heterogeneous Vehicular Networks (HETVNETs). The model uses a radial basis function (RBF) kernel and outperforms other prediction methods in terms of accuracy and computational complexity.
Preeti Jha,A Novel Scalable Apache Spark Based Feature Extraction Approaches for Huge Protein Sequence and their Clustering Performance Analysis,"Genome sequencing projects are rapidly increasing the number of high-dimensional protein sequence datasets. Clustering a high-dimensional protein sequence dataset using traditional machine learning approaches poses many challenges. Many different feature extraction methods exist and are widely used. However, extracting features from millions of protein sequences becomes impractical because they are not scalable with current algorithms. Therefore, there is a need for an efficient feature extraction approach that extracts significant features. We have proposed two scalable feature extraction approaches for extracting features from huge protein sequences using Apache Spark, which are termed 60d-SPF (60-dimensional Scalable Protein Feature) and 6d-SCPSF (6-dimensional Scalable Co-occurrence-based Probability-Speciﬁc Feature). The proposed 60d-SPF and 6d-SCPSF approaches capture the statistical properties of amino acids to create a fixed-length numeric feature vector that represents each protein sequence in terms of 60-dimensional and 6-dimensional features, respectively.","Big Data, protein sequences, Fuzzy Clustering, Scalable Algorithms, Apache Spark Cluster, Feature Extraction, Apache Spark, Huge Protein Sequences","This paper proposes two scalable feature extraction approaches for huge protein sequences using Apache Spark, which are termed 60d-SPF and 6d-SCPSF. The proposed approaches capture the statistical properties of amino acids to create a fixed-length numeric feature vector that represents each protein sequence in terms of 60-dimensional and 6-dimensional features, respectively. The paper also discusses the clustering of huge protein sequences using SRSIO-FCM and SLFCM algorithms."
Preeti Kaur,Hybrid Mobile Learning - Book Chapter 2 - Me and Addisu,"This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the material is concerned, specifically the rights of translation, reprinting, reuse of illustrations, recitation, broadcasting, reproduction on microfilms or in any other physical way, and transmission or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now known or hereafter developed.","extensible and adaptable computing, agile software development, machine learning, computing in education, comparative analysis, user story acceptance tests, Web intelligence, meta-heuristic techniques","This book investigates various challenges in extensible and adaptable methods in computing, including agile software development, data management, machine learning, Web intelligence, and computing in education. It presents elegant solutions for cost-efficient storage of data, transmitting data securely, and processing data in specific applications such as health care. The book also showcases innovative algorithms and applications, including portfolio optimization, disruption classification, and outlier detection, as well as emerging Web applications in dynamic social contexts."
Preeti Nair,The Idealized Heritage Village: Surveying the Public Perception for a Sustainable Development,"A comprehensive site survey was conducted for the area under study forming the historic core, combined with a detailed photo survey of the relevant components in the rural environment. The well documented photo survey of the elevations and places of interest facilitated a better understanding of the identified patterns and their locations.","Heritage Village, Community Participation, Rural Heritage, Public Perception, Settlement pattern, Sustainable Development, Human Perception, Vernacular architecture","The study aimed to investigate the planning tools that can be used to guide new developments, while respecting rural cultural heritage, distinctive characteristics of the traditional buildings, and understanding priorities and needs of villagers related to make alterations and extensions."
Preeti Ranjan Panda,Power Optimization Strategy for Android Applications,"Energy efficiency is a critical factor in mobile systems, and a significant body of recent research efforts has focused on reducing the energy dissipation in mobile hardware and applications. The Android OS Power Manager provides programming interface routines called wakelocks for controlling the activation state of devices on a mobile system.","Data Flow Analysis, Android, Wakelock Placement, Power Optimization, Mobile Systems, Energy Optimization",This paper proposes a data flow analysis based strategy for determining the placement of wakelock statements corresponding to the uses of devices in an application. The proposed optimization strategy shows significant (up to 32%) energy savings with experimental evaluation on a set of Android applications.
Prem Pritam,"Antioxidant Activity, Phenol and Flavonoid Content of Helicteres isora (L.)","Helicteres isora L., commonly known as Indian Screw Tree is a highly valued medicinal plant in South-East Asia. The various phytochemicals like phenols, flavonoids and other antioxidants that impart the medicinal properties in this plant, vary in their composition and concentration in different plant parts. In the present research, the total phenolic content, total flavonoids content and free radical scavenging activity (FRAP and DPPH assay) in fresh and dry sample extracts of leaf, bark, fruit and root of H. isora L., prepared in four different solvents (distilled water, ethanol, methanol and acetone) were studied, and their results compared using Pearson’s Correlation. The plant extracts were also subjected to RP-HPLC for detection and quantitation of naturally occurring phenolic compounds using six phenolic standards (Gallic acid, Vanillin, Catechol, Ferrulic acid, p-coumaric acid and Caffeic acid). The highest total phenolic content (7.22 mg/g GAE) and FRAP value (64.98 mg/g TE) were observed in aqueous dry root extract. The acetone extract of fresh leaf (57.08 mg/g of RE) was found richest in total flavonoids, while the methanolic extract of fresh fruit uniquely exhibited strong free radical scavenging activity as evidenced by the low IC50 value (34.37 mg/ml) in DPPH assay. The RP-HPLC analysis revealed that Catechol and Gallic acid were most abundantly found phenolic compounds in extracts of H. isora L. The total phenolic content showed strong positive correlation with free radical scavenging activity (FRAP and DPPH assays) in both fresh and dry plant parts, suggesting that phenols are the main compounds responsible for the antioxidant activity. The root of H. isora L. was found rich in phenolics and antioxidant capacity indicating its strong potential for medicinal use, followed by fruit, leaf and bark.","Flavonoids, FRAP, DPPH, Phenols, Helicteres isora L., RP-HPLC","The qualitative tests for various phytochemicals revealed presence of saponins, alkaloids, steroids, terpenoids, glycosides, cardiac glycosides, phenols and flavonoids. The glycosides, phenols and flavonoids were present in all of the 32 extracts tested. Steroids and terpenoids were mainly found in dry plant part extracts whereas only few extracts of fresh plant parts, showed their presence. Tannins were uniquely present in only aqueous extract of dry leaf. Steroids were present in all extracts of dry leaf while present only in aqueous extracts of dry fruit, root, and bark. Out of the four plant parts, dry leaf extracts in four solvents, aqueous, ethanol, methanol and acetone, showed presence of all phytochemicals (Table 2). The fresh plant extracts were found to be low in steroids, terpenoids, and tannins while moderate in saponins and alkaloids. The dry plant extracts were found richer in phytochemicals as compared to fresh ones."
Priyanka Bhutani,Format Preserving Encryption for Data Warehouse Security,"This paper proposes a new data security technique known as format preserving encryption or data type preservation. Format preservation provides several distinct benefits that build on solid strong-encryption practices. The main aim of FPE is to encipher the data without the need to modify all of the systems that use that data; such as database field, queries and all the application program.","Data security, Data Warehouse Security, Data warehousing, Feistel Network, Format preserving encryption, Advanced Encryption standard (AES), AES Algorithm","The proposed solution uses a new data security technique known as format preserving encryption or data type preservation. This technique provides several distinct benefits that build on solid strong-encryption practices. The main aim of FPE is to encipher the data without the need to modify all of the systems that use that data; such as database field, queries and all the application program."
Priyanka Manchanda,Bimodal Energy Based Fusion Model for Emotion Recognition,"Multi-sensor information fusion is a rapidly developing research area which forms the backbone of numerous essential technologies such as intelligent robotic control, sensor networks, video and image processing and many more. In this paper, we have developed a novel technique to analyze and correlate human emotions expressed in voice tone & facial expression.","Energy Mapping, Emotion Recognition, Intelligent Systems, Machine Learning, Feature Level Linear Weighted Fusion, Audio and Video Features, Support Vector Machine Classifier, Bimodal Energy Based Fusion Model, Bimodal Fusion",The paper presents a novel approach to fuse heterogeneous datasets obtained from multiple sensors with the aim of analyzing the human’s emotional behavior. The technique uses energy based mapping to overcome the inherent heterogeneity of the recorded bi-modal signal and recognizes the overall emotional component using Support Vector Machine (SVM) classifier with the accuracy 93.06%.
Priyanka Palvai,Lateral Response Reduction of Tall Buildings Using Portal Frame as TMD,"Majority of construction industries are aiming to go for taller and lighter buildings which may result in flexible and slender structures. Hence serviceability and safety become a critical issue during the occurrence of heavy winds and high magnitude earthquakes. Therefore, considerable techniques are adopted to minimize the vibrations caused by these natural responses of the structures. One of the techniques used prominently for tall structures is Tuned Mass Damper (TMD). TMD’s have been very effective in controlling structural vibrations. This study proposes a detailed analysis of a 2D frame structure with a TMD system placed at different levels of the structure in order to evaluate the behaviour of structure for given earthquake ground motions. The results obtained indicate installation of simple frames can decrease the response of the structure during an earthquake and location of TMD is also discussed in detail.","Lateral Response, damping, vibration control, Dynamic Analysis, TMD, Tall Buildings, tuned mass damper",The study presents a numerical modeling and analysis of a 15-storey structure with a TMD installed on the top. The TMD is designed to be tuned to the same natural frequency of the building and is installed on different floors of the building. The study investigates the effectiveness of the TMD in reducing the dynamic response of the building under various excitations.
Prof. B Subudhi,A New MPPT Design Using Grey Wolf Optimization Technique for Photovoltaic System Under Partial Shading Conditions ||| Parameter Extraction of Photovoltaic Module Using BFO Algorithm ||| Position Control of a Flexible Manipulator Using a New Nonlinear Self-Tuning PID Controller,"A new maximum power point tracking (MPPT) design using grey wolf optimization (GWO) technique is proposed in this paper. The proposed GWO-based MPPT algorithm is compared with improved particle swarm optimization (IPSO) and perturb and observe (P&O) algorithms. The simulation results show that the proposed GWO-based MPPT outperforms the other two methods in terms of faster convergence to the global peak (GP), tracking speed, reduced steady-state oscillations, and higher tracking efficiency. ||| This paper presents a new parameter extraction method for photovoltaic modules exploiting Bacterial Foraging Optimization (BFO) technique. In a PV system, validation of the model of a PV module with correctly chosen parameters is essential. An efficient parameter extraction method is required to estimate the parameters of PV module. ||| This paper presents a new nonlinear self-tuning PID controller for position control of a flexible manipulator (FLM). The FLM dynamics are described in a nonlinear form and a new nonlinear self-tuning PID controller is designed to track a reference joint trajectory and simultaneously suppress the link deflection when it is subjected to carry different payloads (parametric uncertainty). The control law proposed in this paper can achieve the above objective in finite time.","BFO, NARMAX, Grey wolf optimization (GWO), Maximum power point tracking, Flexible Manipulator, Parametric Uncertainty, evolutionary techniques, MPPT algorithm, maximum power point tracking (MPPT), photovoltaic (PV), Grey wolf optimization, photovoltaic module, PV module parameters, Flexible-link manipulator, Partial shading, Newton-Raphson method, self-tuning control, Nonlinear Self-Tuning PID Controller, trajectory tracking, BFO algorithm, position control, GWO-based MPPT, parameter extraction, PSO, partial shading conditions (PSCs)","The proposed GWO-based MPPT algorithm is compared with IPSO and P&O algorithms in terms of convergence speed, tracking efficiency, and oscillations. The simulation results show that the proposed GWO-based MPPT outperforms the other two methods. ||| The proposed BFO based parameter extraction method has been tested for different types of PV modules at different test conditions. Analyzing both the simulation and experimental results obtained using BFO; it is found that the module parameters are more accurate compared to that of Newton-Raphson, Particle Swarm Optimization and Enhanced Simulated Annealing methods. ||| The proposed NSPID controller has been implemented in real-time on an experimental set-up. The joint tracking and link deflection performances of the proposed adaptive controller are compared with that of a popular direct adaptive controller (DAC). From the obtained results, it is confirmed that the proposed controller exhibits improved performance over the DAC both in terms of accurate position tracking and quick damping of link deflections when subjected to variable payloads."
Prof. Hamid Reza Naji,International Journal of Computer Science & Information Security,"The International Journal of Computer Science and Information Security is a monthly periodical on research articles in general computer science and information security which provides a distinctive technical perspective on novel technical research work, whether theoretical, applicable, or related to implementation.","Internet security, cryptography, formal methods in information security, wireless communication, web services, networking and technologies, software, intelligent systems, data mining, network security, security infrastructures, innovation technology and management, content protection, information systems, steganography, multimedia systems","The journal covers various topics in computer science and information security, including security infrastructures, network security, and multimedia systems. It provides a platform for researchers to share their work and ideas in these areas."
"Prof. R. Subhas Istitute of Technology, New Delhi",Anomaly Detection in Multiplex Networks,"This paper presents an approach for detecting anomalies in multiplex networks. The proposed algorithm is applied to two datasets, Danio-Rerio and Florentine Marriage, and the results show that the algorithm is effective in detecting anomalies in the networks.","Page Rank Centrality, Anomaly Detection, Gaussian Model, cross-layer anomaly detection, Centrality Measure, Multiplex Network, multiplex networks","The paper proposes a novel approach for detecting anomalies in multiplex networks. The approach is based on computing centrality measures for each node in the network and then using a Gaussian model to compute the probability of each node being anomalous. The algorithm is applied to two datasets, Danio-Rerio and Florentine Marriage, and the results show that the algorithm is effective in detecting anomalies in the networks."
Professor (Dr) Mokhtar Beldjehem,International Journal of Computer Science & Information Security,"The International Journal of Computer Science and Information Security is a monthly periodical on research articles in general computer science and information security which provides a distinctive technical perspective on novel technical research work, whether theoretical, applicable, or related to implementation.","Internet security, cryptography, formal methods in information security, wireless communication, web services, networking and technologies, software, intelligent systems, data mining, network security, security infrastructures, innovation technology and management, content protection, information systems, steganography, multimedia systems","The journal covers various topics in computer science and information security, including security infrastructures, network security, and multimedia systems. It provides a platform for researchers to share their work and ideas in these areas."
Pulkit Mehndiratta,Stylometric Analysis for Authorship Attribution on Twitter,"Authorship Attribution (AA), the science of inferring an author for a given piece of text based on its characteristics is a problem with a long history. In this paper, we study the problem of authorship attribution for forensic purposes and present machine learning techniques and stylometric features of the authors that enable authorship to be determined at rates significantly better than chance for texts of 140 characters or less.","Online Social Media, stylometric analysis, Twitter streaming API, Stylometry Analysis, Authorship Attribution, Twitter client application, author-classiﬁed tweets, Twitter, Machine Learning Classiﬁer",This paper focuses on the problem of identification of the original author for a given tweet from a list of suspected authors for it using stylometric information. Various stylometric features have been taken into consideration for the training and later testing purposes of the machine learning algorithms such as Support Vector Machine (SVM) classiﬁer.
Q. Gao,Iris Detection,"For iris boundary detection, circular summation of intensity approach is used as proposed in [5]. The original grayscale image is blurred using median filter to remove external noise. After filtering, the contrast of image is enhanced to have sharp variation at image boundaries using histogram equalisation as shown in Figure 5(a). This contrast enhanced image is used for finding the outer iris boundary by drawing concentric circles (Figure 5(b) shows an example) of different radii from the pupil center and the intensities lying over the perimeter of the circle are summed up.","Adaptive Threshold, Circular Hough Transform, Spectrum Image, histogram equalisation, iris recognition, circular summation of intensity, Connected Components, Iris detection, pupil boundary, Iris Segmentation",The proposed system has been tested on two publicly available databases BATH and CASIA V3. From experimental analysis it has been observed that the system is capable of handling unconstrained scenarios as well. The system is capable of performing segmentation for unconstrained scenarios in significantly less time compared to Hough transform.
Q. Pan,Iris Detection,"For iris boundary detection, circular summation of intensity approach is used as proposed in [5]. The original grayscale image is blurred using median filter to remove external noise. After filtering, the contrast of image is enhanced to have sharp variation at image boundaries using histogram equalisation as shown in Figure 5(a). This contrast enhanced image is used for finding the outer iris boundary by drawing concentric circles (Figure 5(b) shows an example) of different radii from the pupil center and the intensities lying over the perimeter of the circle are summed up.","Adaptive Threshold, Circular Hough Transform, Spectrum Image, histogram equalisation, iris recognition, circular summation of intensity, Connected Components, Iris detection, pupil boundary, Iris Segmentation",The proposed system has been tested on two publicly available databases BATH and CASIA V3. From experimental analysis it has been observed that the system is capable of handling unconstrained scenarios as well. The system is capable of performing segmentation for unconstrained scenarios in significantly less time compared to Hough transform.
Q. Tian,Iris Detection,"For iris boundary detection, circular summation of intensity approach is used as proposed in [5]. The original grayscale image is blurred using median filter to remove external noise. After filtering, the contrast of image is enhanced to have sharp variation at image boundaries using histogram equalisation as shown in Figure 5(a). This contrast enhanced image is used for finding the outer iris boundary by drawing concentric circles (Figure 5(b) shows an example) of different radii from the pupil center and the intensities lying over the perimeter of the circle are summed up.","Adaptive Threshold, Circular Hough Transform, Spectrum Image, histogram equalisation, iris recognition, circular summation of intensity, Connected Components, Iris detection, pupil boundary, Iris Segmentation",The proposed system has been tested on two publicly available databases BATH and CASIA V3. From experimental analysis it has been observed that the system is capable of handling unconstrained scenarios as well. The system is capable of performing segmentation for unconstrained scenarios in significantly less time compared to Hough transform.
Qi Tian,Endogenous IRAK-M Attenuates Postinfarction Remodeling Through Effects on Macrophages and Fibroblasts,"Quantitative polymerase chain reaction analysis demonstrated significant IRAK-M mRNA upregulation in the infarcted myocardium. The time course of IRAK-M induction showed a biphasic response (Figure 1), characterized by marked early upregulation after 6 hours of reperfusion, followed by a second peak after 7 days of reperfusion (Figure 1A). IRAK-M Is Localized in Infarct Macrophages and Myofibroblasts Dual immunofluorescence was used to study IRAK-M localization in the infarcted myocardium. IRAK-M immunoreactivity in the infarcted heart was localized in Mac2+ infarct macrophages and in spindle-shaped, α–smooth muscle actin–positive myofibroblasts (Figure 1B and 1C). Moreover, infarct myofibroblasts and CD11b+ leukocytes isolated from the infarcted heart after 72 hours of reperfusion exhibited IRAK-M expression (Figure 1D–1G). To study cell-type specific changes in the timing of IRAK-M expression, we assessed IRAK-M mRNA levels in cardiac fibroblasts and CD11b+ leukocytes harvested from the infarcted heart. Isolated fibroblasts had a 3-fold increase in IRAK-M mRNA levels after 24 hours to 72 hours of reperfusion in comparison with control cardiac fibroblasts. When compared with control CD11b+ cells harvested from normal hearts, leukocytes isolated after 6 hours of reperfusion showed a trend toward increased IRAK-M mRNA expression (Figure I in the online-only Data Supplement). IRAK-M Loss Is Associated With Enhanced Adverse Remodeling Despite the Absence of Effects on the Size of the Infarct IRAK-M−null and WT animals had comparable mortality after myocardial infarction (P=NS). Triphenyltetrazolium chloride/Evans blue staining demonstrated that IRAK-M loss does not affect the size of the infarct after 1 hour of ischemia and 24 hours of reperfusion (Figure 1H–1J). Two independent techniques, echocardiographic imaging (Figure 2A–2G; Table I in the online-only Data Supplement) and quantitative morphometry (Figure 2H–2L), demonstrated that IRAK-M loss was associated with enhanced adverse remodeling after myocardial infarction. Systolic and diastolic chamber dimensions measured through echocardiography (left ventricular end-diastolic dimension, left ventricular end-systolic dimension, left ventricular end-systolic volume, and left ventricular end-diastolic volume; Figure 2A–2G) and morphometrically-derived left ventricular end-diastolic volume and left ventricular end-diastolic dimension (Figure 2H–2L) were significantly higher in IRAK-M−null mice after 7 and 28 days of reperfusion, indicating increased chamber dilation. Left ventricular mass was also significantly higher in infarcted IRAK-M−null hearts, suggesting accentuated hypertrophic remodeling. Increased adverse remodeling in the absence of IRAK-M was associated with reduced fractional shortening (FS), reflecting worse systolic dysfunction (Figure 2D). Because acute infarct size was comparable between WT and IRAK-M−null mice (Figure 1H–1J), accentuated adverse remodeling in IRAK-M−null hearts was not a result of more extensive cardiomyocyte injury. Moreover, scar size after 7 to 28 days of reperfusion was comparable between IRAK-M−/− and WT animals (Figure 2I). IRAK-M−/− Mice Have Enhanced Postinfarction Inflammation Exhibiting Increased Myocardial Cytokine mRN","metalloproteinases, cytokines, immune system, macrophages, cardiac remodeling","This study investigates the role of Interleukin-1 receptor-associated kinase (IRAK)-M in myocardial infarction.  Key findings include: 

* IRAK-M mRNA is significantly upregulated in the infarcted myocardium, with a biphasic response.
* IRAK-M is localized in macrophages and myofibroblasts within the infarcted heart.
* IRAK-M loss is associated with enhanced adverse remodeling after myocardial infarction, characterized by increased chamber dilation and hypertrophy, despite no effect on infarct size.
* IRAK-M−/− mice exhibit increased postinfarction inflammation with elevated myocardial cytokine mRNA levels."
Qiao et. al.,Rumour Source Detection Using Game Theory,"Social networks have become a critical part of our lives as they enable us to interact with a lot of people. These networks have become the main sources for creating, sharing and also extracting information regarding various subjects. But all this information may not be true and may contain a lot of unverified rumours that have the potential of spreading incorrect information to the masses, which may even lead to situations of widespread panic. Thus, it is of great importance to identify those nodes and edges that play a crucial role in a network in order to find the most influential sources of rumour spreading. Generally, the basic idea is to classify the nodes and edges in a network with the highest criticality. Most of the existing work regarding the same focuses on using simple centrality measures which focus on the individual contribution of a node in a network. Game-theoretic approaches such as Shapley Value (SV) algorithms suggest that individual marginal contribution should be measured for a given player as the weighted average marginal increase in the yield of any coalition that this player might join. For our experiment, we have played five SV-based games to find the top 10 most influential nodes on three network datasets (Enron, USAir97 and Les Misérables). We have compared our results to the ones obtained by using primitive centrality measures. Our results show that SV-based approach is better at understanding the marginal contribution, and therefore the actual influence, of each node to the entire network.","influential nodes, Jaccard Similarity Coefficient, cooperative game, Rumour Source Detection (RSD), centrality measures, network analysis, Shapley Value (SV), Game-Theory, Network Centrality",This paper aims to identify the most influential nodes in a network that are the primary sources of rumour propagation. The authors propose a game-theoretic approach using the Shapley Value algorithm to find the most influential nodes. They compare their results with primitive centrality measures and show that the SV-based approach is better at understanding the marginal contribution of each node to the entire network.
Qingling Caib,Convergence Analyses on Sparse Feedforward Neural Networks via Group Lasso Regularization,"In this paper, a new variant of feedforward neural networks has been proposed for a class of nonsmooth optimization problems. The penalty term of the presented neural networks stems from the Group Lasso method which selects hidden variables in a grouped manner.","Feedforward neural networks, Clarke gradient, Non-differentiability, Group Lasso, Convergence",The paper proposes a new variant of feedforward neural networks for nonsmooth optimization problems using Group Lasso regularization. The convergence analysis shows that the gradient of the smoothing error function approaches zero and the weight sequence converges to a fixed point.
Qingquan Changc,Convergence Analyses on Sparse Feedforward Neural Networks via Group Lasso Regularization,"In this paper, a new variant of feedforward neural networks has been proposed for a class of nonsmooth optimization problems. The penalty term of the presented neural networks stems from the Group Lasso method which selects hidden variables in a grouped manner.","Feedforward neural networks, Clarke gradient, Non-differentiability, Group Lasso, Convergence",The paper proposes a new variant of feedforward neural networks for nonsmooth optimization problems using Group Lasso regularization. The convergence analysis shows that the gradient of the smoothing error function approaches zero and the weight sequence converges to a fixed point.
R. Adhikari,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
R. Agrawal,Secure Robust and Imperceptible Algorithm for Watermarking Relational Databases,"This paper proposes a secure robust and imperceptible algorithm for watermarking relational databases. The algorithm divides the embedding algorithm into three phases: Watermark preparator, watermark position detector, and watermark embedder. The ownership identification issue is resolved by embedding owner's identity as watermark in Preparator phase.","imperceptible algorithm, Ownership identification, robust algorithm, Relational Database, watermarking, Watermark, Copyright protection, Proof of ownership, relational databases","The paper proposes a new robust secure and imperceptible embedding mechanism to resolve the two important concerns namely; owner identification and proof of ownership. The proposed mechanism involves encoding and decoding on numerical attribute of relational database in three phases; 1)Watermark preparator, 2)Watermark position detector and 3) Watermark Embedder or Detector."
R. Cheruku,Selector: PSO as model selector for dual stage diabetes network,"This paper proposes a novel approach for selecting the optimal model for a dual-stage diabetes network using Particle Swarm Optimization (PSO). The proposed method, called Selector, combines the advantages of Probabilistic Neural Network (PNN) and Radial Basis Function Neural Network (RBFNN) to achieve high accuracy in classification tasks. The PSO-based clustering algorithm is used to determine the optimal number of hidden layer neurons in the RBFNN and PNN models. Experimental results on the PID dataset show that the proposed method outperforms other state-of-the-art methods in terms of accuracy and computational efficiency.","optimal number of clusters, PNN, Dual-stage diabetes network, Diabetes classification, Particle Swarm Optimization, Probabilistic Neural Network, RBFNN, highly dense regions, Radial Basis Function Neural Network, Model selection",This paper proposes a dual-stage diabetes network (Dia-Net) that combines optimized probabilistic neural network (OPNN) and optimized radial basis function neural network (ORBFNN) in the first stage and linear support vector machine in the second stage. Particle swarm optimization-based clustering is employed to reduce the complexity of Dia-Net.
R. Chin,Unique Local Features in Lip Images for Recognition,"The experiments are carried out from images taken with a camera that is used for the regular use. And the color features of a lip are not explored in the proposed research. Still the recognition system exploits the grayscale local features of a lip images and eﬃciently matches it with local features of another lip image. If the color properties of a lip image is explored for recognition along with local features, the accuracy values would increase further.","grayscale features, Lip Pattern Recognition, SIFT, lip recognition, color features, Biometric, Local Feature Extraction, local features, SURF",The paper presents the results of experiments on lip recognition using local features. The recognition system exploits the grayscale local features of lip images and achieves high accuracy. The authors suggest that exploring color properties of lip images could further improve the accuracy.
R. Coward,Unique Local Features in Lip Images for Recognition,"The experiments are carried out from images taken with a camera that is used for the regular use. And the color features of a lip are not explored in the proposed research. Still the recognition system exploits the grayscale local features of a lip images and eﬃciently matches it with local features of another lip image. If the color properties of a lip image is explored for recognition along with local features, the accuracy values would increase further.","grayscale features, Lip Pattern Recognition, SIFT, lip recognition, color features, Biometric, Local Feature Extraction, local features, SURF",The paper presents the results of experiments on lip recognition using local features. The recognition system exploits the grayscale local features of lip images and achieves high accuracy. The authors suggest that exploring color properties of lip images could further improve the accuracy.
R. Dwivedi,A non-invertible cancelable fingerprint template generation based on ridge feature transformation ||| Cancelable Fingerprint Template Generation and Matching,"In a biometric verification system, leakage of biometric data leads to permanent identity loss since original biometric data is inherently linked to a user. Further, various types of attacks on a biometric system may reveal the original template and utility in other applications. To address these security and privacy concerns cancelable biometric has been introduced. Cancelable biometric constructs a protected template from the original biometric template using transformation functions and performs the comparison between templates in the transformed domain. ||| This paper proposes a cancelable fingerprint template generation and matching method. The method involves two tasks: matrix generation and co-prime mapping. The feature matrix is mapped into a high-dimensional matrix to derive the protected template. Co-prime mapping is used to map the feature matrix without overlapping. The method is evaluated using four datasets of FVC2002 database and achieves an EER of 1.82, 1.39, 4.02, and 5.77 for DB1, DB2, DB3, and DB4, respectively.","feature extraction, biometric, alignment-free, Cancelable fingerprint template, privacy, Non-invertible template, Fingerprint verification, Revocability, cancelable biometrics, Cancelable Fingerprint Template, fingerprint, Biometric, minutiae, Fingerprint Matching, Diversity, Ridge feature transformation, Template protection, Co-prime Mapping, security","This paper proposes a novel non-invertible ridge feature transformation method to protect the original fingerprint template information. The proposed method partitions the fingerprint region into a number of sectors with reference to each minutia point employing a ridge-based co-ordinate system. The nearest neighbor minutiae in each sector are identified, and ridge-based features are computed. Further, a cancelable template is generated by applying the Cantor pairing function followed by random projection. ||| A novel cancelable fingerprint template generation method based on coprime mapping transformation is proposed. The method divides the fingerprint region into sectors with respect to each minutiae point and identifies the nearest-neighbor minutiae in each sector. Ridge-based features for all minutiae points are computed and mapped onto co-prime positions of a random matrix to generate the cancelable template."
R. Dziak,Micro-Computed tomography (CT) based assessment of dental regenerative therapy in the canine mandible model,"High-resolution 3D bone-tissue structure measurements may provide information critical to the understanding of the bone regeneration processes and to the bone strength assessment. Tissue engineering studies rely on such nondestructive measurements to monitor bone graft regeneration area. In this study, we measured bone yield, fractal dimension and trabecular thickness through micro-CT slices for different grafts and controls. Eight canines underwent surgery to remove a bone volume (defect) in the canine’s jaw at a total of 44 different locations. We kept 11 defects empty for control and filled the remaining ones with three regenerative materials; NanoGen (NG), a FDA-approved material (n=11), a novel NanoCalcium Sulfate (NCS) material (n=11) and NCS alginate (NCS+alg) material (n=11). After a minimum of four and eight weeks, the canines were sacrificed and the jaw samples were extracted. We used a custom-built micro-CT system to acquire the data volume and developed software to measure the bone yield, fractal dimension and trabecular thickness. The software used a segmentation algorithm based on histograms derived from volumes of interest indicated by the operator. Using bone yield and fractal dimension as indices we are able to differentiate between the control and regenerative material (p<0.005). Regenerative material NCS showed an average 63.15% bone yield improvement over the control sample, NCS+alg showed 55.55% and NanoGen showed 37.5%. The bone regeneration process and quality of bone were dependent upon the position of defect and time period of healing. This study presents one of the first quantitative comparisons using non-destructive Micro-CT analysis for bone regenerative material in a large animal with a critical defect model. Our results indicate that Micro-CT measurement could be used to monitor in-vivo bone regeneration studies for greater regenerative process understanding.","Regenerative Materials, Quantitative Analysis, Bone Regeneration, Micro-CT, LabVIEW","This study investigates the effectiveness of three different bone regenerative materials (NanoGen, NanoCalcium Sulfate, and NanoCalcium Sulfate alginate) in a canine mandible model using micro-computed tomography (micro-CT). The study found that all three materials significantly improved bone regeneration compared to the control group. NanoCalcium Sulfate showed the most significant improvement, followed by NanoCalcium Sulfate alginate and NanoGen. The position of the defect and the healing time period were also found to influence the regeneration process."
R. Espinola,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
R. Goebel,Lecture Notes in Artificial Intelligence 6465,"This work is subject to copyright. All rights are reserved, whether the whole or part of the material is concerned, specifically the rights of translation, reprinting, re-use of illustrations, recitation, broadcasting, reproduction on microfilms or in any other way, and storage in data banks. Duplication of this publication or parts thereof is permitted only under the provisions of the German Copyright Law of September 9, 1965, in its current version, and permission for use must always be obtained from Springer. Violations are liable to prosecution under the German Copyright Law.","Artificial Intelligence, Computational Linguistics, Sanskrit","The 4th International Sanskrit Computational Linguistics Symposium (4i-SCLS) was hosted by the Jawaharlal Nehru University, the premier research University of India during (December 10–12, 2010) at the Special Center for Sanskrit Studies. The event saw excellent response from the scholars, with more than 31 papers received, which were examined by the Program Committee members to shortlist 18 papers for publication presented in this volume."
R. J. Hyndman,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
R. J. Machado,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
R. K. Lenka,Building Scalable Cyber-Physical-Social Networking Infrastructure Using IoT and Low Power Sensors,"Wireless sensors are an important component to develop the Internet of Things (IoT) Sensing infrastructure. There are enormous numbers of sensors connected with each other to form a network (well known as wireless sensor networks) to complete the IoT Infrastructure. These deployed wireless sensors are with limited energy and processing capabilities. The IoT infrastructure becomes a key factor to building cyber-physical-social networking infrastructure, where all these sensing devices transmit data toward the cloud data center. Data routing toward cloud data center using such low power sensor is still a challenging task. In order to prolong the lifetime of the IoT sensing infrastructure and building scalable cyber infrastructure, there is the requirement of sensing optimization and energy efﬁcient data routing. Toward addressing these issues of IoT sensing, this paper proposes a novel rendezvous data routing protocol for low-power sensors. The proposed method divides the sensing area into a number of clusters to lessen the energy consumption with data accumulation and aggregation. As a result, there will be less amount of data stream to the network. Another major reason to select cluster-based data routing is to reduce the control overhead. Finally, the simulation of the proposed method is done in the Castalia simulator to observe the performance. It has been concluded that the proposed method is energy efﬁcient and it prolongs the networks lifetime for scalable IoT infrastructure.","Energy Efficiency, IoT Sensor Devices, WSN-assisted IoT, Network Scalability, hot spot problem, routing protocol, Internet of Things, wireless sensor network, area-based routing, LBDD, Cluster-Based Model, Rendezvous Routing","The paper proposes a new routing protocol for IoT sensor devices, which is based on the concepts of rendezvous routing and LBDD protocols. The protocol is designed to reduce energy consumption and increase network scalability. The proposed protocol is implemented using IoT sensor devices and is shown to be effective in reducing energy consumption and increasing network scalability."
R. L. Milidiu,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
R. Majhi,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
R. P. Rentera,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
R. Radha,Diabetes Classiﬁcation using Radial Basis Function Network by Combining Cluster Validity Index and BAT Optimization with Novel Fitness Function,This paper discusses the use of cluster validity indices for diabetes diagnosis. The authors present a literature survey related to the problem and propose a methodology for identifying the optimal number of clusters. The experimental outcomes confirm the performance of the proposed methodology. The paper also reviews the performance of various neural network-based classifiers on the Pima Indians data set.,"diabetes diagnosis, Optimal number of clusters, Medical Diagnosis, Classiﬁcation, methodology, Diabetes, literature survey, Bat Algorithm, Radial Basis Function Networks, cluster validity indices, neural network-based classifiers","This paper presents a new model based on cluster validity index with radial basis neural network for classiﬁcation of diabetic patients data. The proposed model is tested on Pima Indians Diabetes data set and synthetic data sets, and experimental results proved that our approach performs better in terms of accuracy, sensitivity, speciﬁcity, classiﬁcation time, training time, network complexity and computational time compared to conventional radial basis function neural network."
R. Sion,Secure Robust and Imperceptible Algorithm for Watermarking Relational Databases,"This paper proposes a secure robust and imperceptible algorithm for watermarking relational databases. The algorithm divides the embedding algorithm into three phases: Watermark preparator, watermark position detector, and watermark embedder. The ownership identification issue is resolved by embedding owner's identity as watermark in Preparator phase.","imperceptible algorithm, Ownership identification, robust algorithm, Relational Database, watermarking, Watermark, Copyright protection, Proof of ownership, relational databases","The paper proposes a new robust secure and imperceptible embedding mechanism to resolve the two important concerns namely; owner identification and proof of ownership. The proposed mechanism involves encoding and decoding on numerical attribute of relational database in three phases; 1)Watermark preparator, 2)Watermark position detector and 3) Watermark Embedder or Detector."
R.P. Wildes,Iris Detection,"For iris boundary detection, circular summation of intensity approach is used as proposed in [5]. The original grayscale image is blurred using median filter to remove external noise. After filtering, the contrast of image is enhanced to have sharp variation at image boundaries using histogram equalisation as shown in Figure 5(a). This contrast enhanced image is used for finding the outer iris boundary by drawing concentric circles (Figure 5(b) shows an example) of different radii from the pupil center and the intensities lying over the perimeter of the circle are summed up.","Adaptive Threshold, Circular Hough Transform, Spectrum Image, histogram equalisation, iris recognition, circular summation of intensity, Connected Components, Iris detection, pupil boundary, Iris Segmentation",The proposed system has been tested on two publicly available databases BATH and CASIA V3. From experimental analysis it has been observed that the system is capable of handling unconstrained scenarios as well. The system is capable of performing segmentation for unconstrained scenarios in significantly less time compared to Hough transform.
R.U. Khan,Machine learning techniques for the diagnosis of Alzheimer’s disease: A review,"Alzheimer’s disease is an incurable neurodegenerative disease primarily affecting the elderly population. Efficient automated techniques are needed for early diagnosis of Alzheimers. Many novel approaches are proposed by researchers for classification of Alzheimer’s disease. However, to develop more efficient learning techniques, better understanding of the work done on Alzheimers is needed. Here, we provide a review on 165 papers from 2005-2019 using various feature extraction and machine learning techniques. The machine learning techniques are surveyed under three main categories: support vector machine (SVM), artificial neural network (ANN), and deep learning (DL) and ensemble methods.","Ensemble methods, Support vector machine, Deep learning, Alzheimer’s disease, classification, Artificial neural network, Machine learning","This paper provides a review of 165 papers on machine learning techniques for the diagnosis of Alzheimer’s disease from 2005-2019. The review covers three main categories: support vector machine (SVM), artificial neural network (ANN), and deep learning (DL) and ensemble methods. The paper discusses the importance of efficient automated techniques for early diagnosis of Alzheimers and the need for better understanding of the work done on Alzheimers to develop more efficient learning techniques."
RAO et al.,Antenna Design for UHF RFID Tags: A Review and a Practical Application,"In this paper, an overview of antenna design for passive radio frequency identification (RFID) tags is presented. We discuss various requirements of such designs, outline a generic design process including range measurement techniques and concentrate on one practical application: RFID tag for box tracking in warehouses.","Antennas, antenna design, transponders, radio frequency identification (RFID), tag performance, range measurement, RFID, tags, passive modulated backscatter, UHF","The paper presents a review of antenna design for passive UHF RFID tags, outlining the design process, range measurement techniques, and a performance chart for tag analysis. A specific application example is also presented: a passive UHF tag design for a RFID tag placed on a cardboard box that is being tracked in standard supply chain."
ROHIT BENIWAL,Personality Detection using Kernel-based Ensemble Model for leveraging Social Psychology in Online Networks,"The Asian social networking market dominates the world landscape with the highest consumer penetration rate. Businesses and investors often look for winning strategies to attract consumers to increase revenues from sales, advertisements, and other services offered on social media platforms. Social media engagement and online relational cohesion have often been defined within the frameworks of social psychology and personality identification is a possible way in which social psychology can inform, engage, and learn from social media.","Natural language, MBTI personality type, Personality Psychology, kernel-based soft voting ensemble, Hindi dataset, kernel-based methods, Social Networks, Support Vector Machine, personality detection",The paper proposes a kernel-based soft voting ensemble for personality detection in natural language textual data. The model uses the Support Vector Machine (SVM) with soft voting ensembled kernels to detect different traits of the MBTI personality type in an English and a Hindi dataset. The primary contribution of this work is to develop an efficient kernel-based ensemble model for text-based personality prediction.
ROY,Self-Optimal Clustering Technique Using Optimized Threshold Function,This paper presents a self-optimal clustering technique using optimized threshold function. The proposed method is an advanced version of the traditional IMC method and is similar to it until Step 8. The algorithm is repeated until the threshold function gets converged where the GSI value is maximized.,"global silhouette index, silhouette index, threshold function, improved mountain clustering (IMC), clustering, Expectation maximization algorithm, fuzzy cardinality, interpolation polynomial","The proposed clustering technique is equipped with major changes and modifications in its previous versions of algorithm. SOC is compared with some of the widely used clustering techniques such as K-means, fuzzy C-means, Expectation and Maximization, and K-medoid."
RUCHI MITTAL et al.,AUTOMATED CRYPTOCURRENCIES PRICES PREDICTION USING MACHINE LEARNING,"Currently, Cryptocurrency is one of the trending areas of research among researchers. Many researchers may analyze the cryptocurrency features in several ways such as market price prediction, the impact of cryptocurrency in real life and so on. In this paper, we focus on market price prediction of the number of cryptocurrencies based on their historical trend.","Decentralization, Machine Learning, Cryptocurrency, Price Prediction, Cryptocurrencies, Network, Bitcoin","This paper proposes an approach for the price prediction of multiple cryptocurrencies using multivariate linear regression. The approach starts with data preprocessing, followed by examining the independent features in the dataset, finding the correlation between dependent and independent variables, and finally predicting the costs."
Raaga Varshita Chilakalapallii,Lateral Response Reduction of Tall Buildings Using Portal Frame as TMD,"Majority of construction industries are aiming to go for taller and lighter buildings which may result in flexible and slender structures. Hence serviceability and safety become a critical issue during the occurrence of heavy winds and high magnitude earthquakes. Therefore, considerable techniques are adopted to minimize the vibrations caused by these natural responses of the structures. One of the techniques used prominently for tall structures is Tuned Mass Damper (TMD). TMD’s have been very effective in controlling structural vibrations. This study proposes a detailed analysis of a 2D frame structure with a TMD system placed at different levels of the structure in order to evaluate the behaviour of structure for given earthquake ground motions. The results obtained indicate installation of simple frames can decrease the response of the structure during an earthquake and location of TMD is also discussed in detail.","Lateral Response, damping, vibration control, Dynamic Analysis, TMD, Tall Buildings, tuned mass damper",The study presents a numerical modeling and analysis of a 15-storey structure with a TMD installed on the top. The TMD is designed to be tuned to the same natural frequency of the building and is installed on different floors of the building. The study investigates the effectiveness of the TMD in reducing the dynamic response of the building under various excitations.
Radko Mesiar,On special fuzzy implications,"Special implications were introduced by Hájek and Kohout [Fuzzy implications and generalized quantiﬁers, Int. J. Uncertain. Fuzziness Knowl.-Based Syst. 4 (1996) 225–233] in their investigations on some statistics on marginals. They have either suggested or only partially answered three important questions, especially related to special implications and residuals of t-norms. In this work we investigate these posers in-depth and give complete answers.","Fuzzy connectives, identity principle, special implications, (S,N)-implication, fuzzy implications, Fuzzy implication, Residual of conjunction, exchange principle, 1-Lipschitzianity, Special implication, ordering property","This paper investigates special fuzzy implications, which were introduced by Hájek and Kohout. The authors give a geometric interpretation of the specialty condition and obtain bounds on special implications. They also attempt to answer three problems related to special implications and residuals of t-norms."
Rahul Raman,Direction Estimation for Pedestrian Monitoring System in Smart Cities: An HMM Based Approach,"The paper proposes a novel approach for direction estimation of a moving pedestrian as perceived in a 2-D coordinate of field camera. The proposed direction estimation method is intended for pedestrian monitoring in traffic control systems. Apart from traffic control, direction of motion estimation is also very important in accident avoidance system for smart cars, assisted living systems, in occlusion prediction for seamless tracking in visual surveillance, and so on.","perspective distortion, hidden Markov model, direction estimation, HMM, pedestrian monitoring, Visual surveillance, pedestrian direction estimation, surveillance video, occlusion handling","The proposed method is robust to various issues like illumination changes, environmental factors, partial occlusion, and low resolution of surveillance videos. It can be used alone or with existing methods of orientation estimation over consecutive frames to enhance the direction estimation results."
Rahul Yadav,Adaptive Energy-Aware Algorithms for Minimizing Energy Consumption and SLA Violation in Cloud Computing,"In cloud computing, high energy consumption and service-level agreements (SLAs) violation are the challenging issues considering that the demand for computational power is growing rapidly, thereby requiring large-scale cloud data centers. This paper proposes three adaptive models, namely, gradient descent-based regression (Gdr), maximize correlation percentage (MCP), and bandwidth-aware selection policy (Bw), that can significantly minimize energy consumption and SLA violation.","regression method, energy-efﬁciency, service level agreements, SLA violation, host overloaded detection, energy efficiency, cloud data center, VM consolidation, Cloud computing, meta-heuristic approach, green computing","This paper proposes three adaptive models to minimize energy consumption and SLA violation in cloud computing. The models are based on gradient descent-based regression, maximize correlation percentage, and bandwidth-aware selection policy. The proposed algorithms reduce energy consumption while maintaining the required performance levels in a cloud data center."
"Rajan and Ghosh, 2004",Supervised Heterogeneous Domain Adaptation via Random Forests,This paper proposes a novel approach to heterogeneous domain adaptation using random forests. The algorithm leverages the common label information between the source and target domains as the pivot for knowledge transfer. The proposed algorithm determines the mapping PS between source and target features based on the estimate of the contribution of the features towards creating data partitions having similar label distributions.,"Label Information, Supervised Heterogeneous Domain Adaptation, Feature Mapping, Heterogeneous Domain Adaptation, Random Forests, Knowledge Transfer, Feature Transfer, Domain Adaptation",The paper proposes a novel supervised domain adaptation algorithm (SHDA-RF) that learns the mapping between heterogeneous features of different dimensions. The algorithm uses the shared label distributions present across the domains as pivots for learning a sparse feature transformation. The shared label distributions and the relationship between the feature spaces and the label distributions are estimated in a supervised manner using random forests.
Rajat Gupta,Understanding Helicoverpa armigera Pest Population Dynamics related to Chickpea Crop Using Neural Networks,Insect pests are a major cause of crop loss globally. Pest management will be effective and efficient if we can predict the occurrence of peak activities of a given pest. Research efforts are going on to understand the pest dynamics by applying analytical and other techniques on pest surveillance data sets. In this study we make an effort to understand pest population dynamics using Neural Networks by analyzing  pest surveillance data set of Helicoverpa armigera or Pod borer on chickpea (Cicer arietinum L.)  crop. The results show that neural network method successfully predicts the pest attack incidences for one week in advance.,"Climatic Data, Pest Population Dynamics, Neural Networks, Pest Surveillance Databases, Chickpea Crop, Helicoverpa armigera, Neural Network, Pest Attack Prediction","The experimental results show that it is possible to predict the pest attack with high probability for one week in advance. These predictions would help the farmers in pest management programs by avoiding the crop losses with improved environment quality, as it can avoid unnecessary sprays of chemical pesticides."
Rajeeb Dey,Advances in Intelligent Systems and Computing 757,"The series “Advances in Intelligent Systems and Computing” contains publications on theory, applications, and design methods of Intelligent Systems and Intelligent Computing.","learning paradigms, soft computing, knowledge management, intelligent agents, fuzzy systems, robotics and mechatronics, interactive entertainment, computational intelligence, neural networks, recommender systems, Conference Proceedings, human-centered and human-centric computing, trust management, Mechanical Engineering, ambient intelligence, evolutionary computing, DNA and immune based systems, intelligent control, virtual worlds and society, human-machine teaming, self-organizing and adaptive systems, computational neuroscience, knowledge-based paradigms, artiﬁcial life, Perception and Vision, intelligent data analysis, e-Learning and teaching, social intelligence, cognitive science and systems, Web intelligence and multimedia, intelligent decision making and support, intelligent network security, machine ethics","This volume constitutes a part of the proceedings of ﬁrst International Conference on Innovations in Infrastructure (ICIIF) 2018, which was held on 18–19 May, 2018, in Ahmedabad, India."
Rajeev K. Shakya,A Correlation Model for Sensor Networks,"Wireless sensor networks (WSN) are densely deployed to promise the fine-grain monitoring in various applications. For example, it may be as high as 20 nodes/m3 or more [1]. Due to high density of sensor nodes, spatially correlated information is observed and transmitted by surrounding sensor nodes once an interest of event detected. Thus, there exists spatial correlation among the sensor observations. The spatial correlation brings significant potential advantages along with collaborative nature of the WSN in energy-efficient design of communication protocols. This paper presents a novel spatial correlation model for wireless sensor networks. Based on sensor coverage model and location of sensor nodes, a spatial correlation function is derived to describe the correlation characteristics of measurements observed by sensor nodes. The case studies using correlation function are performed to study the correlation relationship between sensor nodes. Finally, based on case studies, their results, and discussions, a correlated cell construction algorithm is proposed and possible approaches are explored to exploit spatial correlation for efficient medium access and clustering protocols for WSN.","Clustering protocol, spatial correlation, sensor networks, data aggregation, Wireless Sensor Networks, correlation model, MAC protocol, distributed source coding",This paper presents a novel spatial correlation model for wireless sensor networks. The model derives a spatial correlation function to describe the correlation characteristics of measurements observed by sensor nodes. The case studies using correlation function are performed to study the correlation relationship between sensor nodes. A correlated cell construction algorithm is proposed and possible approaches are explored to exploit spatial correlation for efficient medium access and clustering protocols for WSN.
Rajesh Agnihotri,Impact of Eurasian Snow Cover on Indian Summer Monsoon Rainfall over the Northwestern Himalayas,"The entire Indo-Himalayan region from northwest (Kashmir) to northeast (Assam) is facing prevalence of floods and landslides in recent years causing massive loss of property, human and animal lives, infrastructure, and eventually threatening tourist activities substantially. Extremely intense rainfall event of A.D. 2013 (between 15 and 17 June) kicked off mammoth flash floods in the Kedarnath area of Uttarakhand state, resulting in huge socioeconomic losses to the state and country.","Eurasian snow cover, extreme rainfall events, flash floods, gridded data sets, Himalayas, Arctic Oscillation, northwestern Himalayas, Indian summer monsoon rainfall","The study investigates ~100-year-long monthly rainfall and air temperature time series data for a selected grid covering most parts of Uttarakhand state. The results indicate that under warming scenario, JJ rainfall (over AS) may further increase with occasional extreme rainfall spells when AO index (March) is negative."
Rajib Sarkar,Face Detection Algorithm ||| Image Sonification: A Review of Techniques and Applications,"This article discusses a novel approach of multiple-face tracking from low-resolution surveillance videos. The proposed approach approximately detects faces in an image solely using the color information. It detects skin region in an image and finds existence of eye and mouth region in the skin region. If it finds so, it marks the skin region as a face and fits an oriented rectangle to the face. The approach requires low computation and hence can be applied on subsequent frames from a video. ||| With the advent of image and video representation of visual scenes in digital computer, subsequent necessity of vision-substitution representation of a given image is felt. The medium for non-visual representation of an image is chosen to be sound due to well developed auditory sensing ability of human beings and wide availability of cheap audio hardware. Visionary information of an image can be conveyed to blind and partially sighted persons through auditory representation of the image within some of the known limitations of human hearing system.","eye detection, mouth detection, face detection, real-time face tracking, Non-visual image representation, Auditory image, sound visualization, Sonification, image sonification, Image representation, skin detection, low-resolution images, Stereo vision, auditory data, FERET database, videos, color information","The proposed face detection algorithm uses color information to detect faces in images. The algorithm is tested on 1000 randomly chosen 24-bit 512×768 color images from the FERET face database and achieves an accuracy of 96.2%. The algorithm is also found to work efficiently on low-resolution images and videos. ||| Image sonification is a process that converts visual data into sound, allowing people to perceive and understand visual information through sound. The paper reviews the different techniques and applications of image sonification, including the use of color information and the applications in various fields."
Rajiv Ranjan,"Explainable AI (XAI): Core Ideas, Techniques and Solutions","As our dependence on intelligent machines continues to grow, so does the demand for more transparent and interpretable models. In addition, the ability to explain the model generally is now the gold standard for building trust and deployment of Artificial Intelligence (AI) systems in critical domains. Explainable Artificial Intelligence (XAI) aims to provide a suite of machine learning (ML) techniques that enable human users to understand, appropriately trust, and produce more explainable models.","Explainable AI, Stakeholders, Machine Learning, Software toolkits, Programming framework, Bias, Robustness, Interpretable AI, Explainable Artiﬁcial Intelligence, XAI, Decision Making","The paper presents the core ideas, techniques, and solutions of XAI, emphasizing its importance in various phases of the machine learning process. It discusses the stakeholders involved in these phases, including developers, theorists, data scientists, users, consumers, businesses, regulators, and scientists, and highlights the use cases of XAI in detecting bias, scientific understanding, building robust models, and better decision making."
Rajiv Ratn Shah,Virtualization in Wireless Sensor Networks: Fault Tolerant Embedding for Internet of Things,"Recently, virtualization in wireless sensor networks (WSNs) has witnessed significant attention due to the growing service domain for IoT. Related literature on virtualization in WSNs explored resource optimization without considering communication failure in WSNs environments. The failure of a communication link in WSNs impacts many virtual networks running IoT services. In this context, this paper proposes a framework for optimizing fault tolerance in virtualization in WSNs, focusing on heterogeneous networks for service-oriented IoT applications.","Fault Tolerant Embedding, Internet of Things, Virtualization, IoT, Wireless sensor networks","The paper discusses the importance of virtualization in WSNs for IoT applications, focusing on fault-tolerant embedding. It reviews existing proposals on virtualization in WSNs, highlighting their limitations and proposing a new approach to enhance fault tolerance."
Raju Pal,Chaotic Kbest gravitational search algorithm (CKGSA) ||| Improved Gravitational Search Algorithm for COVID-19 Diagnosis ||| Optimal keyframe selection-based lossless video-watermarking technique using IGSA in LWT domain for copyright protection,"Gravitational search algorithm is a popular adaptive search algorithm among nature-inspired algorithms and has been successfully used for optimizing many real-world problems. Gravitational search algorithm uses the law of Newton gravity for finding the optimal solution. The performance of gravitational search algorithm is controlled by exploration and exploitation capabilities and Kbest is one of its parameters that controls this trade-off. In this paper, a novel chaotic Kbest gravitational search algorithm has been proposed that uses the chaotic model in Kbest to balance the exploration and exploitation non-linearly. The proposed algorithm shows better convergence rate at later iterations with high precision and does not trap into local optima. ||| This paper presents a novel variant of the gravitational search algorithm, improved gravitational search algorithm (IGSA), to enhance the vicinity to optimal solutions. The proposed variant is employed to obtain optimal clusters in the proposed clustering method for the CoVID19 diagnosis. An extensive experimental analysis of IGSA has been conducted against 16 metaheuristic algorithms over 17 standard benchmark functions belonging to unimodal and multimodal categories. The results are studied over four different dimensional settings, i.e. 10, 30, 50, and 90. ||| Video piracy is a challenging issue in the modern world. Approximately 90% of newly released films were illegally distributed around the world via the Internet. To overcome this issue, video watermarking is an effective process that integrates a logo in video frames as a watermark. Therefore, this paper presents an efficient lossless video-watermarking scheme based on optimal keyframe selection using an intelligent gravitational search algorithm in linear wavelet transform. This technique obtains color motion and motionless frames from the cover video by the histogram difference method. One-level linear wavelet transform is performed on the chrominance channel of motion frames and a low-frequency sub-band LL opts for watermark embedding. The performance of the proposed technique has been evaluated against 12 video processing attacks in terms of imperceptibility and robustness. Experiments demonstrate that the proposed technique outperforms five state-of-the-art schemes on the considered attacks.","Clustering Method, Chaotic, Kbest, Linear wavelet transform, Chaotic Kbest Gravitational Search Algorithm, Gravitational search algorithm, COVID-19 Diagnosis, optimization algorithm, CoVID19 diagnosis, Clustering, Metaheuristic algorithm, Intelligent gravitational search algorithm, global optimization, Adaptive search algorithm, Video watermarking, Metaheuristic Algorithms","This paper proposes a novel chaotic Kbest gravitational search algorithm (CKGSA) that uses the chaotic model in Kbest to balance exploration and exploitation non-linearly. The proposed algorithm shows better convergence rate at later iterations with high precision and does not trap into local optima. ||| This paper presents a new clustering method for the diagnosis of CoVID19 using medical images. The method employs a novel variant of a gravitational search algorithm to obtain optimal clusters. The performance of the proposed method is compared with recent metaheuristic algorithms using benchmark functions and publicly available CoVID19 medical images. The results demonstrate that the proposed method is outperforming in terms of accuracy, precision, sensitivity, specificity, and F1-score. ||| This paper presents a lossless video-watermarking scheme based on optimal keyframe selection using an intelligent gravitational search algorithm in linear wavelet transform. The technique obtains color motion and motionless frames from the cover video and performs one-level linear wavelet transform on the chrominance channel of motion frames. The performance of the proposed technique has been evaluated against 12 video processing attacks and outperforms five state-of-the-art schemes."
Rama Murthy Garimalla,Distributed Source Coding for Sensor Data Model,"We measure reliability in sensor networks which are dependent on limited resources of individual sensor nodes such has battery capacity, transmission range and channel interference due to simultaneous wireless transmissions.","Sensor Data Reliability, cluster head selection, BER, Slepian & Wolf Coding, Baysian Error, sensor data model, Slepian-Wolf theorem, Cosets, distributed source coding, Huffman Trees","The paper presents a distributed source coding approach for sensor data model, which includes Slepian-Wolf theorem, compression rate, fault rate, and cluster head selection schemes. The approach is designed to reduce the number of bits needed for transmission in sensor networks."
Rama Murthy Garimella,"Abstract Sensor Fusion Problem for Wireless Sensor Network ||| Analysis of Wireless Sensor Networks ||| A Novel Network Architecture for Cognitive Wireless Sensor Network ||| A Novel Routing Algorithm for Vehicular Sensor Networks ||| Cognitive cross-layer multipath probabilistic routing for cognitive networks ||| Design of VASNET: A Novel Topology for VANET ||| Directional Antenna MAC Protocols for Wireless Sensor Networks ||| Distributed Source Coding for Sensor Data Model ||| Doubly Cognitive Architecture Based Cognitive Wireless Sensor Network ||| Estimating Fire Events Using Naive Bayes and Tree Classifiers ||| Event Detection in Soccer Videos Using 3D Convolutional Neural Networks ||| Explicit Rate Matrix of a G/M/1-type Process with 2 Phases at a Level ||| Full-Duplex eNodeB and UE Design for 5G Networks ||| Gibbs-Shannon Entropy and Related Measures: Tsallis Entropy ||| Optimal, Secure Cluster Head Placement Through Source Coding Techniques in Wireless Sensor Networks ||| Performance Evaluation of Entropy and Gini using Threaded and Non Threaded ID3 on Anaemia Dataset ||| Prediction of Willingness of Users in V-MIMO ||| Statistically Assisted Multi Resolution FFT Based CR Architecture ||| Time Optimal Spectrum Sensing: Stochastic Optimization ||| Training Data Compression Algorithms and Reliability in Large Wireless Sensor Networks ||| Understanding Helicoverpa armigera Pest Population Dynamics related to Chickpea Crop Using Neural Networks ||| Wireless Sensor Networks: From Theory to Applications","The accuracy of a system is measured by the deviation of the system’s results from the actual results. Information fusion deals with the combination of information from same source or different sources to obtain improved fused estimate with greater quality or greater relevance. ||| This paper presents an analysis of wireless sensor networks, focusing on the impact of flooding protocols on energy consumption and node involvement. The study compares pure and controlled flooding in binary and nested tree networks, highlighting the effects of depth and interval values on total energy wasted and nodes unnecessarily involved. ||| Recent advances in wireless communications and electronics have enabled the development of low cost, low power, multi-functional sensor nodes that are small in size. These nodes coordinate to perform distributed sensing in various fields such as health, military, home etc. But these small devices in Wireless Sensor Network (WSN) are still limited with some constrains, and efforts are required to increase the lifetime and other performance measures of the network. ||| Recent advances in wireless communications are diffusing into many new applications. The tiny sensor node, which consists of sensing, data processing and communicating components, led to the idea of sensor networks. A sensor network composed of a large number of sensor nodes that are densely deployed either inside the phenomenon or very close to it. The applications envisioned for sensor networks vary from monitoring inhospitable habitats and disaster areas to operating indoors for intrusion detection and equipment monitoring. In most cases the network designer would have little control over the exact deployment of the network. Nowadays Vehicular Networks are drawing lots of attention due to the wide variety of applications that they can provide. These applications include traffic monitoring, positioning, security etc. A lot of research work is being conducted to define the standard for vehicular communication. These include frequency allocation, standards for physical and link layers, routing algorithms, security issues and new applications. In this paper we discuss the disadvantages of the traffic monitoring by traditional methods and by using GPS equipped sensors. Then we propose a new routing protocol for a fixed topology containing both stationary and mobile nodes. We also try to optimize the energy of the sensor nodes. We simulate our routing algorithm in MATLAB and evaluate it for different possible cases. ||| Mobile Ad-hoc NETworks (MANETs) is a set of mobile nodes that can move around arbitrarily, and communicate with others in a multi-hop fashion without any assistance of base stations. With recent advances in Cognitive Radio (CR) technology, it is possible to apply the Dynamic Spectrum Access model in MANETs. This introduces the concept of Cognitive Radio Ad Hoc Networks (CRAHNs). Applying CR techniques provides better throughput, even in congested spectrum along with better propagation characteristics. CRAHN is a kind of intelligent network that is aware of its surrounding environment, and adapts to the transmission or reception parameters to achieve efficient communication without interfering with primary users. Routing in CR environment is a challenging task as the availability of channel is constrained by the presence of primary user. The problem of routing in CRAHNs targets the creation and maintenance of wireless multi-hop paths among cognitive nodes by deciding both the spectrum to be used and the relay nodes of the path. This paper proposes a cognitive cross-layer multipath probabilistic routing for cognitive radio based networks. The proposed solution uses spectrum holes identified by MAC layer, decides the channel to be used and transmit power level for each hop in the path. The proposed solution is implemented in NS2, and performance of the proposed solution is compared with the existing solution from the literature. The paper also shows that the proposed solution outperforms existing solution in terms of packet delivery ratio, average end-to-end delay and energy consumed per data packet. ||| The rapid increase of vehicular traffic and congestion on the highways began hampering the safe and efficient movement of traffic. Consequently, year by year, we see the ascending rate of car accidents and casualties in most of the countries. Therefore, exploiting the new technologies, e.g. wireless sensor networks, is required as a solution of reduction of these saddening and reprehensible statistics. This has motivated us to propose a novel and comprehensive system to utilize Wireless Sensor Networks for vehicular networks. We coin the vehicular network employing wireless Sensor networks as Vehicular Ad Hoc and Sensor Network, or VASNET in short. The proposed VASNET is particularly for highway traffic .VASNET is a self-organizing Ad Hoc and sensor network comprised of a large number of sensor nodes. In VASNET there are two kinds of sensor nodes, some are embedded on the vehicles-vehicular nodes- and others are deployed in predetermined distances besides the highway road, known as Road Side Sensor nodes (RSS). The vehicular nodes are used to sense the velocity of the vehicle for instance. We can have some Base Stations (BS) such as Police Traffic Station, Firefighting Group and Rescue Team. The base stations may be stationary or mobile. VASNET provides capability of wireless communication between vehicular nodes and stationary nodes, to increase safety and comfort for vehicles on the highway roads. In this paper we explain main fundamentals and challenges of VASNET. ||| This paper proposes a directional antenna MAC protocol to overcome the MAC-deadlock, hidden and exposed terminal problem in wireless sensor networks. The proposed protocol uses directional antennas to receive/sending packets only from/to one side at the same time, reducing energy dissipation and increasing throughput. ||| We measure reliability in sensor networks which are dependent on limited resources of individual sensor nodes such has battery capacity, transmission range and channel interference due to simultaneous wireless transmissions. ||| Nowadays scarcity of spectrum availability is increasing highly. Adding cognition to the existing Wireless Sensor Network (WSN) infrastructure will help in this situation. As sensor nodes in WSN are limited with some constrains like power, efforts are required to increase the lifetime and other performance measures of the network. In this paper we propose the idea of Doubly Cognitive WSN. The basic idea is to progressively allocate the sensing resources only to the most promising areas of the spectrum. This work is based on Artificial Neural Network as well as on Support Vector Machine (SVM) concept. As the load of sensing resource is reduced significantly, this approach will save the energy of the nodes, and also reduce the sensing time dramatically. ||| Extracting useful temporal and spatial patterns from sensor data has been seen before, the technical basis of Machine learning with Data mining is studied with the evidence collected uniformly over many years and which allow using users' perspective in collected evidence. ||| This paper presents a novel approach for event detection in soccer videos using 3D convolutional neural networks. The proposed method, called GAWAC, is designed to capture both spatial and temporal dependencies between frames of a video. The model is trained on a large dataset of soccer videos, called Soccer-8k, which contains 7942 action clips of six different soccer actions. The results show that GAWAC outperforms other state-of-the-art models on the Soccer-8k dataset. ||| In this research paper we consider the matrix polynomial equation arising naturally in the equilibrium analysis of a structured G/M/1-type Markov process. We obtain an explicit expression for the unknown rate matrix R being 2 × 2 matrix. ||| This paper proposes a successive interference cancellation with optimal ordering (SSIC-OO) algorithm for uplink and downlink operation in multiple antenna systems. The algorithm estimates the user signal by iteratively canceling out the effect of the strongest user signal from the overall received signal. ||| In this research paper, it is proved that an approximation to Gibbs-Shannon entropy measure naturally leads to Tsallis entropy for the real parameter q = 2. Several interesting measures based on the input as well as output of a discrete memoryless channel are provided and some of the properties of those measures are discussed. ||| In many applications of wireless sensor networks (such as military communications), secure communication, message delay minimization and energy efficiency are crucial. Such requirements constrain special or Important Cluster Head (ICH) placement over the network architecture modeled by a tree. The optimal important cluster head placement problem is formulated and solved using source coding results (providing minimum possible delay and security through prefix-free paths over the tree). Also, through simulations energy efficiency of the proposed approach is established. The reported research is naturally applicable for many applications of Wireless Sensor Networks (WSNs) such as Body Area Networks (BANs). ||| Classification is an important data mining task, and decision trees have emerged as a popular classifier due to their simplicity and relatively low computational complexity. Time required to build a decision tree becomes intractable, as datasets get extremely large. To overcome this problem we proposed a parallel mode of ID3 algorithm. Decision tree building is well-suited for thread-level parallelism as it requires a large number of independent computations. In this paper, we present the analysis and parallel implementation of the ID3 algorithm using Entropy and Gini as heuristics, along data set. ||| In cellular systems, virtual multiple-input multiple-output (V-MIMO) technology promises to achieve performance gains comparable to conventional MIMO. In this paper, we propose cooperative relay selection algorithm based on machine learning techniques. Willingness of user to cooperate in V-MIMO depends on his current battery power, time and day along with incentives offered by service provider. ||| This paper presents a statistically assisted multi resolution FFT based CR architecture. The proposed algorithm adapts the resolution of FFT based on statistical data given by the prediction engine. The prediction engine is trained for the spatial and temporal information of the spectral occupancy. The output of the prediction engine is the probability of a sub band being occupied by the primary user (Poccupied). If Poccupied is low, resolution need not be very fine since most of the spectrum is free. When Poccupied is high, a finer sensing approach is performed by incrementing the observation vector N, thereby increasing the resolution. ||| This paper presents a stochastic optimization approach for time-optimal spectrum sensing. The problem is formulated as a joint optimization of the mean and variance of the spectrum sensing time random variable. ||| With the availability of low-cost sensor nodes there have been many standards developed to integrate and network these nodes to form a reliable network allowing many different types of hardware vendors to coexist. ||| Insect pests are a major cause of crop loss globally. Pest management will be effective and efficient if we can predict the occurrence of peak activities of a given pest. Research efforts are going on to understand the pest dynamics by applying analytical and other techniques on pest surveillance data sets. In this study we make an effort to understand pest population dynamics using Neural Networks by analyzing  pest surveillance data set of Helicoverpa armigera or Pod borer on chickpea (Cicer arietinum L.)  crop. The results show that neural network method successfully predicts the pest attack incidences for one week in advance. ||| This book contains information obtained from authentic and highly regarded sources. Reasonable efforts have been made to publish reliable data and information, but the author and publisher cannot assume responsibility for the validity of all materials or the consequences of their use.","fixed topology, Machine Learning, Neural Networks, Energy Consumption, Vehicular Ad Hoc Networks (VANET), leveling, exposed terminal problem, 3D Convolutional Neural Networks, wireless sensor networks, Network Lifetime, Rate Matrix, Medium Access Control protocol, Vehicular Ad Hoc and Sensor Network (VASNET), Stochastic Optimization, Baysian Error, Fire Weather Index (FWI), Soccer Videos, sensor network, Median, MAC-deadlock, Decision tree, WSN, rough set, Adaptive FFT, Optimal Ordering, Kraft’s inequality, Cognitive Radio Ad Hoc Networks, Cognitive Radio, Data Mining, hidden terminal problem, clustering, Virtual MIMO, Architecture, Helicoverpa armigera, 5G, Entropy Heuristic, Gibbs-Shannon entropy, cluster head selection, Sports Analytics, Wireless Sensor Networks, MANET, security, dynamic spectrum access, Sensor Data Reliability, OFDMA, ANN, Applications, Slepian & Wolf Coding, routing algorithm, topology, Datamining, Tsallis entropy, energy detection, MMSE, Spectrum Sensing, sensor data model, Temporal Patterns, VASNET, Controlled Flooding, distributed source coding, G/M/1-type Process, Integer Programming, Pest Attack Prediction, Vehicular Sensor Networks, spectrum analyser, Threaded ID3, Energy efficiency, Full-Duplex, Parallel data mining, Pareto Front, Slepian-Wolf theorem, Ad hoc networks, Successive Interference Cancellation, VANET, Reliability, Routing protocols, Artificial Neural network, tree construction, Chickpea Crop, ID3, source coding, cluster head placement, Cross layer design, Power Control, Mobile Ad Hoc Networks (MANET), Artificial Neural Network, Theory, WSNs, Doubly Cognitive WSN, Directional-Antenna, SVD, SVM, Climatic Data, adaptive FFT based algorithms, Data Compression, prefix-free path, Wireless Sensor Network, Cosets, Node Involvement, G/M/1-type Markov Process, Parallelism, Source Coding, Huffman coding, Uplink and Downlink Operation, Entropy, Anemia Database, Routing, Global Positioning System (GPS), Energy Efficiency, Dynamic Spectrum Access, Pest Surveillance Databases, Matrix Polynomial Equation, directional antenna, Soccer, Huffman Trees, Fine Grained, Wireless sensor networks, V-MIMO, discrete memoryless channel, Flooding Protocols, BER, Multiple Antenna Systems, energy efficiency, Wireless Sensor Networks (WSN), Tree Classifiers, Cognitive radio, Fire Events, mobile communication, WEKA machine learning framework, Cognitive WSN, Sensor Network, Action Recognition, important cluster head, VANETS, Randomized Switching, Virtual Antenna Array, Localization, Quality of Services, Pure Flooding, Forest fires, Deep Learning, SIC, sectoring, MSTs, SC-FDMA, Probability Model, Naive Bayes, Data Fusion, Spectrum Management, Matrix-Analytic Method, Explicit Solution, UCI Forest Fire Repository, Gini Heuristic, Cognitive Wireless Sensor Network, Gini, Sensor Fusion, Support Vector Machine, SSIC-OO, Prim's algorithm, Cross-Layer Solution, cluster head, TDMA, Pest Population Dynamics, cognitive radio, Prediction Engine, probability mass functions, time-optimal, Neural Network, doubly cognitive radio architecture, Event Detection","This paper proposes a novel Median based sensor fusion function named D function. It is shown that the proposed D function satisfies the lipschitz condition. The paper also presents some of the ideas which can open new areas for research in fusion problem. ||| The paper explores the limitations of wireless sensor networks and proposes solutions to mitigate energy waste and node involvement. The study provides simulation results for binary and nested tree networks, demonstrating the impact of depth and interval values on total energy wasted and nodes unnecessarily involved. ||| The paper presents a method for constructing a sensor network, including sectoring, leveling, clustering, and tree construction. The authors propose a technique for interconnecting MSTs between neighboring sectors and discuss routing and data transmission using TDMA schedules. ||| This paper discusses the disadvantages of traditional traffic monitoring methods and GPS equipped sensors. It proposes a new routing protocol for a fixed topology containing both stationary and mobile nodes, and optimizes the energy of sensor nodes. The routing algorithm is simulated in MATLAB and evaluated for different possible cases. ||| This paper proposes a cognitive cross-layer multipath probabilistic routing for cognitive radio based networks. The proposed solution uses spectrum holes identified by MAC layer, decides the channel to be used and transmit power level for each hop in the path. The proposed solution is implemented in NS2, and performance of the proposed solution is compared with the existing solution from the literature. ||| This paper proposes a novel system, VASNET, to utilize Wireless Sensor Networks for vehicular networks. VASNET is a self-organizing Ad Hoc and sensor network comprised of a large number of sensor nodes, including vehicular nodes and Road Side Sensor nodes. The system provides wireless communication between vehicular nodes and stationary nodes, increasing safety and comfort for vehicles on highway roads. The paper explains the main fundamentals and challenges of VASNET. ||| This paper explores various aspects of medium access control (MAC) protocols in wireless sensor networks. The MAC protocols in wireless sensor network must achieve two main goals at minimum: the creation of sensor network infrastructure and the establishing communication links for data transfer between them, and fairly and efficiently share communication resources between each sensor nodes. ||| The paper presents a distributed source coding approach for sensor data model, which includes Slepian-Wolf theorem, compression rate, fault rate, and cluster head selection schemes. The approach is designed to reduce the number of bits needed for transmission in sensor networks. ||| This paper proposes the idea of Doubly Cognitive WSN, which is based on pattern recognition and two-stage spectrum sensing for cognitive radios. The underlying notion of the idea is to progressively allocate the sensing resources to only the most promising areas of the spectrum, reducing sensing resources and time needed to accurately identify spectrum holes. The proposed approach will save the energy of the spectrum sensing nodes and also reduce the sensing time dramatically. ||| The paper discusses the use of machine learning and datamining algorithms to predict accidental small forest fires. The authors propose a model that uses temporal and spatial patterns from sensor data to forecast fires and help the forest department plan day-to-day schedules. ||| This paper proposes a novel framework for fine-grained action recognition in soccer, which can automatically recognize actions of players in live football games. The framework consists of two modules: Event Detector and Action Classiﬁer. The Event Detector module identiﬁes the desired events and generates a video clip containing the actions surrounding the event. The Action Classiﬁer module classiﬁes the input clip using the GAWAC architecture. The framework and the Soccer-8k dataset are the main contributions of this paper. ||| The paper presents an exact solution for the rate matrix of a structured G/M/1-type Markov process with a small number of phases. The solution is obtained using a symbolic solution of the determinant polynomial equation and the Cayley-Hamilton theorem. The method is applied to a novel approach to energy efficiency of a single-server computing system, and a new randomized regime switching scheme is proposed. ||| The proposed SSIC-OO algorithm is designed to estimate the user signal by iteratively canceling out the effect of the strongest user signal from the overall received signal. The algorithm calculates the received power for all users and estimates the user signal with the highest power. The estimated signal is then used to cancel out its effect from the overall received signal, and the process is repeated until all user signals are estimated. ||| The paper explores the relationship between Gibbs-Shannon Entropy measure and the Tsallis entropy (for q=2) and defines various interesting measures associated with probability mass functions. ||| This letter proposes a novel optimal approach for the sensor placement in WSNs. The main goal is to minimize the average depth of Important Cluster Heads from the base station by reducing the number of hops. Further, it ensures message security and makes the paths from Base Station (BS) to Important Cluster Heads to be prefix-free. ||| The paper presents a parallel mode of ID3 algorithm for decision tree building, using Entropy and Gini as heuristics, and analyzes its performance on an anaemia dataset. The proposed method helps in analyzing two types of anaemia, Iron deficiency anaemia (ID) and B12 deficiency anaemia (B12), and identifies the most significant attributes for determining the transferred, number of frozen embryos, and culture days of embryo. ||| This paper proposes a cooperative relay selection algorithm based on machine learning techniques for virtual MIMO systems. The algorithm predicts potential willing users in the neighborhood of the source user and reduces cooperative node discovery time. The performance of the algorithm is evaluated using metrics such as MSE, accuracy, precision, and recall. ||| This paper focuses on the implementation aspects of spectrum sensing in cognitive radio architectures. The authors propose an adaptive FFT algorithm to reduce the time taken for spectrum sensing, applicable to cognitive radio environment. The algorithm is studied as applied to the well-known energy detection technique and implemented on USRP based on GNU Radio platform. ||| The paper proposes a novel approach to solve the time-optimal spectrum sensing problem using stochastic optimization. The approach is based on the minimization of the mean and variance of the spectrum sensing time random variable. ||| This paper proposes a data compression algorithm for large wireless sensor networks, which optimizes data redundancy and uses a probability model to efficiently compress data at cluster heads. ||| The experimental results show that it is possible to predict the pest attack with high probability for one week in advance. These predictions would help the farmers in pest management programs by avoiding the crop losses with improved environment quality, as it can avoid unnecessary sprays of chemical pesticides. ||| The book focuses on the quality of services in wireless sensor networks, covering various aspects such as data collection, aggregation, and spatial coverage, physical layer and interfacing, routing and transport protocols, and energy-saving approaches."
Ramakrishan Maheshwari,Analysis and modelling of circulating current in two parallel-connected inverters,This paper analyzes the circulating current in parallel-connected inverters and its effects on the system. The circulating current is caused by the difference in the common-mode (CM) voltages of the inverters and is affected by the phase shift of the carrier signals. The paper focuses on the case of asymmetrical regular-sampled pulse-width modulation (RSPWM) and shows that a phase shift of 180° between the carrier signals results in a low total harmonic distortion (THD) in the ac side currents.,"circulating current, high power applications, common-mode voltages, total harmonic distortion, parallel-connected inverters, pulse-width modulation, phase shift, asymmetrical RSPWM",This paper analyzes the circulating current in parallel-connected inverters and its effects on the system. The circulating current is caused by the difference in the common-mode (CM) voltages of the inverters and is affected by the phase shift of the carrier signals. The paper focuses on the case of asymmetrical regular-sampled pulse-width modulation (RSPWM) and shows that a phase shift of 180° between the carrier signals results in a low total harmonic distortion (THD) in the ac side currents.
Ramalinga Swamy Cheruku,Advances in Machine Learning and Data Science—Recent Achievements and Research Directives ||| A Novel Approach to Predict High Blood Pressure Using ABF Function ||| Diabetes-Finder: A Bat Optimized Classification System for Type-2 Diabetes ||| Diabetes Classiﬁcation using Radial Basis Function Network by Combining Cluster Validity Index and BAT Optimization with Novel Fitness Function,"ooperation to publish the proceedings as a volume of “Advances in Machine Learning and Data Science—Recent Achievements and Research Directives.” We wish to extend our gratitude to all the keynote speakers and participants who enabled the success of this year’s edition of LAMDA. ||| High Blood Pressure (HBP) is a state in the biological system of human beings developed due to physical and psychological changes. Nowadays, it is a most prevalent problem in human beings irrespective of age, place, and profession. The HBP victims are increasing rapidly across the globe. HBP is undiagnosed in the majority of the patients because most of the affected people are not aware of it. To overcome this problem, this paper proposes a new approach that uses ABF (Arterial Blood Flow)-function to predict a person is prone to HBP. ||| Type-2 Diabetes is one of the foremost causes for the increase in mortality across the world-wide. In this context, classification systems help doctors by analyzing the disease data. Radial Basis Function Neural Networks (RBFNN) are extensively used as classifier in medical domain because of its non-iterative nature. The size of the RBFNNs hidden-layer increases on par with dataset size. It's difficult to determining the optimal number of neurons in hidden-layer by cost effectively. In this paper, to address this problem, we have proposed Bat-based clustering algorithm. The proposed method experimented on Pima Indians Diabetes dataset and results outperform the competing approaches. ||| This paper discusses the use of cluster validity indices for diabetes diagnosis. The authors present a literature survey related to the problem and propose a methodology for identifying the optimal number of clusters. The experimental outcomes confirm the performance of the proposed methodology. The paper also reviews the performance of various neural network-based classifiers on the Pima Indians data set.","diabetes diagnosis, Medical Diagnosis, Machine Learning, Bat Optimization Algorithm, Data Science, age, Clustering, neural network-based classifiers, cholesterol, High blood pressure, classifier, Recent Achievements, methodology, classification, Type-2 Diabetes Classification, Class by Class Approach, ABF function, Classiﬁcation, Research Directives, Radial Basis Function Networks, RBFNN, prediction, Optimal number of clusters, Diabetes, Pima Indians Diabetes dataset, literature survey, Bat Algorithm, cluster validity indices, Bat Optimization, obesity, data mining","The proceedings of LAMDA 2017, a conference on machine learning and data science, are published as a volume of Advances in Machine Learning and Data Science—Recent Achievements and Research Directives. The editors extend their gratitude to the keynote speakers and participants who made the conference a success. ||| This paper proposes a novel approach that works in two steps. In the first step, for each attribute impact factors are set. The impact factor is a real value which represents the degree of influence of an attribute in elevating blood pressure. Impact factor for each attribute of the selected record is set based on the attribute value and its relationship with class labeled attribute using Pearson correlation coefficient. In the second step, the proposed algorithm calculates the value of class label attribute using impact factor and corresponding attribute value. The class label attribute value is then used to predict whether a person is prone to HBP. ||| This paper proposes a Bat-based clustering algorithm to address the problem of determining the optimal number of neurons in the hidden layer of Radial Basis Function Neural Networks (RBFNN) for Type-2 Diabetes classification. The proposed method is applied in a class-by-class fashion and outperforms competing approaches on the Pima Indians Diabetes dataset. ||| This paper presents a new model based on cluster validity index with radial basis neural network for classiﬁcation of diabetic patients data. The proposed model is tested on Pima Indians Diabetes data set and synthetic data sets, and experimental results proved that our approach performs better in terms of accuracy, sensitivity, speciﬁcity, classiﬁcation time, training time, network complexity and computational time compared to conventional radial basis function neural network."
Ramalinga Swamy Cherukua,Alignment Free Cancellable Fingerprint Templates Using Ellipse Structure,"In this work, a new method for alignment free cancellable fingerprint templates was proposed using ellipse structure. Ellipse was formed by selecting one of the minutiae and core point of the fingerprint as focal points and the farthest minutia as the co-vertex. This method performs well because instead of storing spatial information of the fingerprints such as distance or orientation between minutia, etc., we are storing the ellipse attributes in transformed form such that even though if any stored template got leaked, the original fingerprint information will not be revealed to the attacker. This method also performs well in terms of FAR and FRR. However for the fingerprints which does not possess a core point this method will not be suitable and is the main limitation of this work.","Template protection, Discrete Fourier transform, Fingerprint, Ellipse, cancellable templates, biometric security, fingerprint templates, ellipse structure","The proposed method uses elliptical structures generated from fingerprint minutiae to secure fingerprint templates. The method involves extracting minutiae from fingerprint images, constructing ellipses and extracting feature sets, projecting the feature sets onto a 3D space, generating a binary string, and transforming the binary string into the frequency domain using DFT."
Ramalingaswamy Cheruku,Automatic disease diagnosis using optimised weightless neural networks for low-power wearable devices ||| Dynamic Multi‑layer Ensemble Classification Framework for Location-Based Social Network Venue Classification ||| Survey on Brain-Computer Interface,"Low-power wearable devices for disease diagnosis are used at anytime and anywhere. These are non-invasive and pain-free for the better quality of life. However, these devices are resource constrained in terms of memory and processing capability. Memory constraint allows these devices to store a limited number of patterns and processing constraint provides delayed response. It is a challenging task to design a robust classiﬁcation system under above constraints with high accuracy. In this Letter, to resolve this problem, a novel architecture for weightless neural networks (WNNs) has been proposed. It uses variable sized random access memories to optimise the memory usage and a modiﬁed binary TRIE data structure for reducing the test time. In addition, a bio-inspired-based genetic algorithm has been employed to improve the accuracy. The proposed architecture is experimented on various disease datasets using its software and hardware realisations. The experimental results prove that the proposed architecture achieves better performance in terms of accuracy, memory saving and test time as compared to standard WNNs. It also outperforms in terms of accuracy as compared to conventional neural network-based classiﬁers. ||| Multi-layer ensemble frameworks perform much better as compared to individual classifiers. However, selection of a classifier and its placement, impacts the overall performance of ensemble framework. This problem becomes very difficult, if there are more classifiers and layers. To address these problems in this paper, we design “Binary Particle Swarm Optimization” method for selection and placement of right classifiers in multi-layer ensemble model. Proposed classifier weight-assignment method is implemented to prioritize the selected classifiers. The model is simulated for the classification of social-user check-ins in Location-Based Social Network datasets. The experimental results show that the proposed ensemble model outperforms the state-of-the-art ensemble methods in the literature. It can be used by security firms, high level decision makers and various governmental organizations for tracking malicious users. ||| A brain-computer interface (BCI) provides a way to develop interaction between a brain and a computer. The communication is developed as a result of neural responses generated in the brain because of motor movements or cognitive activities. The means of communication here includes muscular and non-muscular actions. These actions generate brain activities or brain waves that are directed to a hardware device to perform a specific task. BCI initially was developed as the communication device for patients suffering from neuromuscular disorders. Owing to recent advancements in BCI devices—such as passive electrodes, wireless headsets, adaptive software, and decreased costs—it is also being used for developing communication between the general public. The BCI device records brain responses using various invasive and non-invasive acquisition techniques such as electrocorticography (ECoG), electroencephalography (EEG), magnetoencephalography (MEG), and magnetic resonance imaging (MRI). In this article, a survey on these techniques has been provided. The brain response needs to be translated using machine learning and pattern recognition methods to control any application. A brief review of various existing feature extraction techniques and classification algorithms applied on data recorded from the brain has been included in this article. A significant comparative analysis of popular existing BCI techniques is presented and possible future directives are provided.","location-based social network, feature extraction, User-checkins, genetic algorithm, neuron memory search, Location-Based Social Networks, disease diagnosis, Machine learning, fuzzy inference system, electrocorticography, Social-venue classification, Brain Signal Acquisition, classifier selection, classification, venue classification, Dynamic multi-layer ensembles, low-power wearable devices, Neural Tissue, BPSO, electroencephalogram, VVG-RAM, modified TRIE data structure, Electrodes, Brain-computer interface, binary TRIE data structure, Majority voting, TRIE data structure, ensemble classification, weightless neural networks, VG-RAM","A novel architecture for weightless neural networks (WNNs) is proposed to improve the classiﬁcation accuracy, reduce the memory usage, and decrease the test time for low-power wearable devices. The proposed architecture uses variable sized random access memories and a modiﬁed binary TRIE data structure. A bio-inspired-based genetic algorithm is employed to improve the accuracy. The experimental results show that the proposed architecture outperforms the standard WNNs and conventional neural network-based classiﬁers in terms of accuracy, memory saving, and test time. ||| This paper proposes a Dynamic Multi-Layer Ensemble Classification (DMLEC) technique that works on dynamically choosing the classifiers as per the Binary Particle Swarm Optimization (BPSO) using a novel fitness function. In addition, a new classifier weight assignment method is proposed that updates weights for the particular classifiers as per their classification accuracy. The proposed DMLEC is more flexible and can be used over big datasets for classification of various real world problems. ||| This survey provides a comprehensive overview of brain-computer interface (BCI) techniques, including signal acquisition, feature extraction, and classification algorithms. It discusses the recent advancements in BCI devices and their applications in developing communication between the general public. The survey also presents a comparative analysis of popular existing BCI techniques and provides possible future directives."
Ramesh Dharavath,Automatic disease diagnosis using optimised weightless neural networks for low-power wearable devices,"Low-power wearable devices for disease diagnosis are used at anytime and anywhere. These are non-invasive and pain-free for the better quality of life. However, these devices are resource constrained in terms of memory and processing capability. Memory constraint allows these devices to store a limited number of patterns and processing constraint provides delayed response. It is a challenging task to design a robust classiﬁcation system under above constraints with high accuracy. In this Letter, to resolve this problem, a novel architecture for weightless neural networks (WNNs) has been proposed. It uses variable sized random access memories to optimise the memory usage and a modiﬁed binary TRIE data structure for reducing the test time. In addition, a bio-inspired-based genetic algorithm has been employed to improve the accuracy. The proposed architecture is experimented on various disease datasets using its software and hardware realisations. The experimental results prove that the proposed architecture achieves better performance in terms of accuracy, memory saving and test time as compared to standard WNNs. It also outperforms in terms of accuracy as compared to conventional neural network-based classiﬁers.","low-power wearable devices, binary TRIE data structure, TRIE data structure, genetic algorithm, neuron memory search, weightless neural networks, VG-RAM, VVG-RAM, disease diagnosis, modified TRIE data structure","A novel architecture for weightless neural networks (WNNs) is proposed to improve the classiﬁcation accuracy, reduce the memory usage, and decrease the test time for low-power wearable devices. The proposed architecture uses variable sized random access memories and a modiﬁed binary TRIE data structure. A bio-inspired-based genetic algorithm is employed to improve the accuracy. The experimental results show that the proposed architecture outperforms the standard WNNs and conventional neural network-based classiﬁers in terms of accuracy, memory saving, and test time."
Ramveer Singh,A privacy-preserving cancelable iris template generation scheme using decimal encoding and look-up table mapping,"This paper presents a privacy-preserving cancelable iris template generation scheme using decimal encoding and look-up table mapping. The proposed method consists of a number of tasks, including iris image preprocessing, decimal encoding, and look-up table mapping. The experimental results show that the proposed method outperforms existing approaches in terms of recognition accuracy and security.","Cancelable iris template, Cancelable biometrics, Privacy, Decimal encoding, Look-up table mapping, Biometric security, Biometrics, Security, Iris recognition, Iris biometric","The proposed method generates a secure cancelable iris template using decimal encoding and look-up table mapping. The method consists of several tasks, including iris image preprocessing, decimal encoding, and look-up table mapping. The experimental results show that the proposed method outperforms existing approaches in terms of recognition accuracy and security."
Rangaballav Pradhan,A Genetic Algorithm for Solving Fuzzy Shortest Path Problems with Interval Type-2 Fuzzy Arc Lengths ||| The Fuzzy Robust Graph Coloring Problem,"Shortest path problem is one of the most fundamental and well-known optimization problems in graph theory due to its various real-world applications. Fuzzy set can manage the uncertainty, associated with the information of a problem, where conventional mathematical models may fail to reveal satisfactory result. In most cases, shortest path problem in fuzzy graph, called fuzzy shortest path problem, uses type-1 fuzzy set as arc length. The uncertainty associated with the linguistic description of information is not represented properly by type-1 fuzzy set due to inexactness of human perception in the evaluation of membership degrees having crisp values.  An interval type-2 fuzzy set is able to tackle this type of uncertainty. In this paper, we have proposed an algorithmic approach based on genetic algorithm for finding shortest path from a source node to a destination node in a fuzzy graph with interval type-2 fuzzy arc lengths. We have designed a new crossover operator which does not need mutation operation. The purpose of mutation operation has been taken care by the proposed crossover operation. We have compared our algorithm with two other existing genetic algorithms for the fuzzy shortest path problem, where superiority of the proposed algorithm is shown. To the best of our knowledge, no algorithm based on genetic algorithm exists in the literature for fuzzy shortest path problem with interval type-2 fuzzy arc lengths. A numerical example is used to illustrate the effectiveness of the proposed approach. ||| Fuzzy graph model can represent a complex, imprecise and uncertain problem, where classical graph model may fail. In this paper, we propose a fuzzy graph model to represent the examination scheduling problem of a university and introduce a genetic algorithm based method to find the robust solution of the scheduling problem that remains feasible and optimal or close to optimal for all scenarios of the input data.","fuzzy event, fuzzy graph coloring, robust coloring, Genetic algorithm, Type-1 fuzzy set, robustness, genetic algorithm, Fuzzy shortest path problem, Fuzzy graph, Interval type-2 fuzzy set, interval type-2 fuzzy sets, fuzzy probability","This paper proposes a genetic algorithm for solving fuzzy shortest path problems with interval type-2 fuzzy arc lengths. The algorithm uses a new crossover operator that does not require mutation operation, and it has been compared with two existing genetic algorithms for the fuzzy shortest path problem. The results show the superiority of the proposed algorithm, and a numerical example is used to illustrate its effectiveness. ||| The paper proposes a method for graph coloring that can handle uncertain environments, represented by a fuzzy graph model. The examination scheduling problem of a university is considered, where courses are represented by nodes of a graph and every pair of incompatible courses is connected by an edge. The coloring of this graph provides a feasible schedule of the courses and computes the minimum number of time slots. The problem arises if after the examination schedule is published, some students choose a new course that makes the schedule invalid. The proposed method uses a genetic algorithm to find the robust solution of the scheduling problem."
Raseswari Pradhan,A Comparative Study on Maximum Power Point Tracking Techniques for Photovoltaic Power Systems,"This paper provides a comprehensive review of the maximum power point tracking (MPPT) techniques applied to photovoltaic (PV) power system available until January, 2012.","photovoltaic (PV) array, MPPT, Comparative Study, Photovoltaic Power Systems, Maximum power point tracking (MPPT) techniques","The paper discusses various MPPT techniques, including feedback of power variation with voltage and current techniques, perturbation and observation (P&O) and hill-climbing technique, incremental conductance (Inc-Cond) technique, forced oscillation technique, ripple correlation control (RCC) technique, current sweep technique, estimated-perturb-perturb (EPP) technique, and parasitic capacitance technique."
"Rashidi and Cook, 2010",Supervised Heterogeneous Domain Adaptation via Random Forests,This paper proposes a novel approach to heterogeneous domain adaptation using random forests. The algorithm leverages the common label information between the source and target domains as the pivot for knowledge transfer. The proposed algorithm determines the mapping PS between source and target features based on the estimate of the contribution of the features towards creating data partitions having similar label distributions.,"Label Information, Supervised Heterogeneous Domain Adaptation, Feature Mapping, Heterogeneous Domain Adaptation, Random Forests, Knowledge Transfer, Feature Transfer, Domain Adaptation",The paper proposes a novel supervised domain adaptation algorithm (SHDA-RF) that learns the mapping between heterogeneous features of different dimensions. The algorithm uses the shared label distributions present across the domains as pivots for learning a sparse feature transformation. The shared label distributions and the relationship between the feature spaces and the label distributions are estimated in a supervised manner using random forests.
Rashina Hoda,Agile Processes in Software Engineering and Extreme Programming,"The 18th XP conference was held 2017 in the wonderful city of Cologne, Germany. In the spirit of past XP conferences, XP 2017 was a place where researchers and practitioners met to exchange new ideas and present their work. These proceedings contain the full research papers, short research papers, and doctoral symposium papers presented at the conference.","Teams, Reflection, Reflective practice, Levels of reflection, Agile software development, Agile retrospective meeting","The conference featured 46 research papers, with 14 accepted as full research papers and 6 as short research papers. The selected papers cover a wide range of agile techniques and approaches, including empirical studies and technology studies relevant to both researchers and practitioners."
Rashmi Gehib,Cryptocurrency Price Prediction Approach Using ARIMA,"With the increase in popularity of cryptocurrencies, it is becoming extremely crucial to predict what the prices of the currencies are going to be in the future. This paper uses a dataset that consists of over 1500 cryptocurrencies with their prices starting from their initiation till May, 2018. A lot of the effort went into getting the data set ready before predicting the future prices of all the cryptocurrencies, i.e., making sure that the cryptocurrencies were stationary time-series. Beginning with learning about the ARIMA model and the conditions to run the model successfully, first validation of the model is done. An average accuracy of 86.424 is observed for 95% of the currencies are observed. After this validation, forecasting is performed on these cryptocurrencies and the percentage change of the price is calculated.","Price prediction, Cryptocurrency, ARIMA model, ARIMA, stationary time-series, Forecasting","This paper focuses on the performance of all the cryptocurrencies using the ARIMA model for forecasting the future prices. The dataset used consists of over 1500 cryptocurrencies with their prices starting from their initiation till May, 2018. The paper discusses the related work in the area of cryptocurrency and ARIMA model, data preprocessing, employing ARIMA to forecast the required values, and validating the applied model."
Rashmi Ranade,"Antioxidant Activity, Phenol and Flavonoid Content of Helicteres isora (L.)","Helicteres isora L., commonly known as Indian Screw Tree is a highly valued medicinal plant in South-East Asia. The various phytochemicals like phenols, flavonoids and other antioxidants that impart the medicinal properties in this plant, vary in their composition and concentration in different plant parts. In the present research, the total phenolic content, total flavonoids content and free radical scavenging activity (FRAP and DPPH assay) in fresh and dry sample extracts of leaf, bark, fruit and root of H. isora L., prepared in four different solvents (distilled water, ethanol, methanol and acetone) were studied, and their results compared using Pearson’s Correlation. The plant extracts were also subjected to RP-HPLC for detection and quantitation of naturally occurring phenolic compounds using six phenolic standards (Gallic acid, Vanillin, Catechol, Ferrulic acid, p-coumaric acid and Caffeic acid). The highest total phenolic content (7.22 mg/g GAE) and FRAP value (64.98 mg/g TE) were observed in aqueous dry root extract. The acetone extract of fresh leaf (57.08 mg/g of RE) was found richest in total flavonoids, while the methanolic extract of fresh fruit uniquely exhibited strong free radical scavenging activity as evidenced by the low IC50 value (34.37 mg/ml) in DPPH assay. The RP-HPLC analysis revealed that Catechol and Gallic acid were most abundantly found phenolic compounds in extracts of H. isora L. The total phenolic content showed strong positive correlation with free radical scavenging activity (FRAP and DPPH assays) in both fresh and dry plant parts, suggesting that phenols are the main compounds responsible for the antioxidant activity. The root of H. isora L. was found rich in phenolics and antioxidant capacity indicating its strong potential for medicinal use, followed by fruit, leaf and bark.","Flavonoids, FRAP, DPPH, Phenols, Helicteres isora L., RP-HPLC","The qualitative tests for various phytochemicals revealed presence of saponins, alkaloids, steroids, terpenoids, glycosides, cardiac glycosides, phenols and flavonoids. The glycosides, phenols and flavonoids were present in all of the 32 extracts tested. Steroids and terpenoids were mainly found in dry plant part extracts whereas only few extracts of fresh plant parts, showed their presence. Tannins were uniquely present in only aqueous extract of dry leaf. Steroids were present in all extracts of dry leaf while present only in aqueous extracts of dry fruit, root, and bark. Out of the four plant parts, dry leaf extracts in four solvents, aqueous, ethanol, methanol and acetone, showed presence of all phytochemicals (Table 2). The fresh plant extracts were found to be low in steroids, terpenoids, and tannins while moderate in saponins and alkaloids. The dry plant extracts were found richer in phytochemicals as compared to fresh ones."
Ravi Naga Sai Kurapati,Health Assessment and Modal Analysis of Historical Masonry Arch Bridge,"Masonry arch bridges in India indicate the heritage value of the nation. Most of these bridges had been in service for hundreds of years and yet being serviceable even today for transportation purposes indicates the robustness of the design and construction methodology. But, some of these bridges are abandoned due to its deterioration and absence of knowledge to retroﬁt these structures. Lack of proper maintenance and retroﬁtting could eventually damage the structural integrity as these structures are old enough to deteriorate and are prone to repeated weathering and unforeseen natural calamities such as earth-quakes, ﬂoods, etc. In this study, a very old masonry arch bridge ‘Puranapul’ bridge inaugurated in the year 1578 across the river Musi in Hyderabad is considered for investigation of its health through basic visual inspection and non-destructive testing. Furthermore, the same is numerically modeled using the available ﬁnite element analysis software ANSYS in three dimensions for assessing the basic mode shapes of the structure and its behavior in different loading conditions.","modal analysis, Masonry arch bridge, Health assessment, finite element method, dynamic analysis, Heritage structure, Nondestructive testing, Finite element model, seismic behavior, Visual inspection","The paper presents a numerical modeling approach for understanding the behavior of a historical masonry arch bridge. The bridge is analyzed using finite element method and the results are presented in terms of deformations, strains, and stresses. The modal analysis is performed to understand the behavior and characteristics of the bridge under dynamic loads. The dynamic analysis is carried out to simulate the seismic behavior of the bridge and the results show that the bridge is quite adequate for lateral loads."
Ravi Prakash,"Seroprevalence of SARS-CoV-2 Antibodies in Uttar Pradesh, India: A Cross-Sectional Study","Population-based serological antibody test for SARS-CoV-2 infection helps in estimating the exposure in the community. We present the findings of the first district representative seroepidemiological survey conducted between 4 and 10 September 2020 among the population aged 5 years and above in the state of Uttar Pradesh, India. Multi-stage cluster sampling was used to select participants from 495 primary sampling units (villages in rural areas and wards in urban areas) across 11 selected districts to provide district-level seroprevalence disaggregated by place of residence (rural/urban), age (5–17 years/aged 18 +) and gender. A venous blood sample was collected to determine seroprevalence. Of 16,012 individuals enrolled in the study, 22.2% [95% CI 21.5–22.9] equating to about 10.4 million population in 11 districts were already exposed to SARS-CoV-2 infection by mid-September 2020. The overall seroprevalence was significantly higher in urban areas (30.6%, 95% CI 29.4–31.7) compared to rural areas (14.7%, 95% CI 13.9–15.6), and among aged 18 + years (23.2%, 95% CI 22.4–24.0) compared to aged 5–17 years (18.4%, 95% CI 17.0–19.9). No differences were observed by gender. Individuals exposed to a COVID confirmed case or residing in a COVID containment zone had higher seroprevalence (34.5% and 26.0%, respectively). There was also a wide variation (10.7–33.0%) in seropositivity across 11 districts indicating that population exposed to COVID was not uniform at the time of the study. Since about 78% of the population (36.5 million) in these districts were still susceptible to infection, public health measures remain essential to reduce further spread.","COVID-19, Seroprevalence, India, SARS-CoV-2, Heterogeneity, Uttar Pradesh","This study presents the first district-level seroprevalence survey of SARS-CoV-2 infection in Uttar Pradesh, India. Conducted in September 2020, the survey found that 22.2% of the population had been exposed to the virus by that time. Seroprevalence was significantly higher in urban areas and among individuals aged 18 and older. The findings highlight the importance of continued public health measures to reduce further spread of the virus."
Ravi Vadlamani,Applications of machine learning techniques to predict filariasis using socio-economic factors ||| Digital Banking Dimensions and Analytics,"Filariasis is one of the major public health concerns in India. Approximately 600 million people spread across 250 districts of India are at risk of filariasis. To predict this disease, a pilot scale study was carried out in 30 villages of Karimnagar district of Telangana from 2004 to 2007 to collect epidemiological and socio-economic data. The collected data are analysed by employing various machine learning techniques such as Naïve Bayes (NB), logistic model tree, probabilistic neural network, J48 (C4.5), classification and regression tree, JRip and gradient boosting machine. The performances of these algorithms are reported using sensitivity, specificity, accuracy and area under ROC curve (AUC). Among all employed classification methods, NB yielded the best AUC of 64% and was equally statistically significant with the rest of the classifiers. Similarly, the J48 algorithm generated 23 decision rules that help in developing an early warning system to implement better prevention and control efforts in the management of filariasis. ||| Of late, the financial services industry is fast moving away from the traditional paradigm to the sophisticated digital way of dealing and the customer. Both the facets of the financial service industry, viz., the financial service provider and the customer are going through a digital evolution. In particular, banking industry has evolved from just journal and ledger entry paradigm to data and analytics driven banking operations, which subsumes online as well as offline customer behavior. This paper discusses various scenarios in baking, finance services and insurance (BFSI) areas, where big data analytics is turning out to be paramount. The paper also highlights the potential benefits, of the new-age technologies viz., Internet of Things (IoT), Blockchain, Chatbots and robotics.","operational analytics, Machine learning techniques, Predictive classification modelling, Feature subset selection, Financial Services, Chat-bot, risk analytics, Big Data Analytics, Filariasis, mosquito, socio-economic factors, fraud analytics, Insurance, Data balancing, Digital Banking, customer analytics, Hadoop, Socio-economic conditions, IoT, Spark","This study aims to predict filariasis using socio-economic factors and machine learning techniques. A pilot scale study was conducted in 30 villages of Karimnagar district of Telangana from 2004 to 2007 to collect epidemiological and socio-economic data. Various machine learning techniques were employed to analyse the data and predict filariasis. The study found that Naïve Bayes yielded the best AUC of 64% and generated 23 decision rules that help in developing an early warning system to implement better prevention and control efforts in the management of filariasis. ||| The paper explores the eight dimensions of a digital bank, including customer/sales/services, regulator/other banks, internal, technology, data, business process reengineering, analytics, and people. It also discusses the role of analytics in digital banking, including customer analytics, fraud analytics, risk analytics, operational analytics, security analytics, and HR analytics."
"Ravi, Carr, Sagar",Profiling of Internet Banking Users in India,"This paper presents a study on profiling of internet banking users in India. The study used a questionnaire with 58 related questions to collect data from 165 respondents. The data was preprocessed and split into training and test sets. Four predictive models were used to classify internet banking users: Classification and Regression Trees (CART), Logistic Regression, Support Vector Machines (SVM), and Neural Networks. The results showed that CART performed feature selection and identified the most important variables in customers' point of view. The study also presented 17 rules derived from the decision tree constructed with entropy method in CART.","Internet banking, customer adoption, decision tree, profiling, India, customers, entropy method, intelligent techniques",This study presents a profiling of internet banking users in India using a questionnaire with 58 related questions. The data was preprocessed and split into training and test sets. Four predictive models were used to classify internet banking users. The results showed that CART performed feature selection and identified the most important variables in customers' point of view.
RavneetDTU,Improving Neural Machine Translation for Sanskrit-English,"This paper explores approaches that have never before been used for the translation of the Sanskrit language to English. Firstly, a baseline with the Transformer architecture is established. Further, the Transformer model is improved with Dual Learning methodology and gained small improvement on BLEU Score. The best BLEU Score is observed with the Transfer Learning method.","Transformer Architecture, Transfer learning, Neural Machine Translation, Sanskrit-English, Reinforcement Learning",This paper proposes a novel approach to Neural Machine Translation for Sanskrit-English using Reinforcement Learning and Transfer learning. The proposed method outperforms previous approaches and releases monolingual Sanskrit and parallel aligned Sanskrit-English corpora for the research community.
Reena Singh,Isoprenaline Induced Model for Myocardial Necrosis,The study used isoprenaline-induced myocardial necrosis as an experimental model to evaluate the cardioprotective effects of various herbal drugs. The pathophysiological changes following ISO administration in rats are comparable to those taking place during MI in humans.,"Nelumbo nucifera, myocardial necrosis, Cardioprotective Effects, cardioprotective effect, Isoproterenol, Herbal Drugs, Isoprenaline",The study aimed to develop a pharmacologic technique for producing myocardial necrosis of standard severity in animals using isoprenaline-induced myocardial necrosis as an experimental model.
Reinhard Mentele,Myelin-speciﬁc T cells also recognize neuronal autoantigen in a transgenic mouse model of multiple sclerosis,"We describe here the paradoxical development of spontaneous experimental autoimmune encephalomyelitis (EAE) in transgenic mice expressing a myelin oligodendrocyte glycoprotein (MOG)-speciﬁc T cell antigen receptor (TCR) in the absence of MOG. We report that in Mog-deﬁcient mice (Mog–/–), the autoimmune response by transgenic T cells is redirected to a neuronal cytoskeletal self antigen, neuroﬁlament-M (NF-M). Although components of radically different protein classes, the cross-reacting major histocompatibility complex I-Ab–restricted epitope sequences of MOG35–55 and NF-M18–30 share essential TCR contact positions. This pattern of cross-reaction is not speciﬁc to the transgenic TCR but is also commonly seen in MOG35–55–I-Ab–reactive T cells. We propose that in the C57BL/6 mouse, MOG and NF-M response components add up to overcome the general resistance of this strain to experimental induction of autoimmunity. Similar cumulative responses against more than one autoantigen may have a role in spontaneously developing human autoimmune diseases.",,"This study reports the unexpected finding that transgenic mice expressing a myelin oligodendrocyte glycoprotein (MOG)-specific T cell receptor (TCR) develop spontaneous experimental autoimmune encephalomyelitis (EAE) even in the absence of MOG. The researchers discovered that these mice redirect their autoimmune response to a neuronal cytoskeletal protein called neuroﬁlament-M (NF-M). This cross-reactivity between MOG and NF-M is mediated by shared TCR contact positions on their respective epitope sequences. The study suggests that cumulative responses against multiple autoantigens, such as MOG and NF-M, may contribute to the development of spontaneous autoimmune diseases in humans."
Renquan LU,Adaptive event-triggered control for a class of nonlinear systems with periodic disturbances,"This paper investigates the adaptive event-triggered control problem for a class of nonlinear systems subject to periodic disturbances. To reduce the communication burden, a reliable relative threshold strategy is proposed. Fourier series expansion and radial basis function neural network are combined into a function approximator to model suitable time-varying disturbed function of known periods in strict-feedback systems. By combining the Lyapunov stability theory and the backstepping technique, the proposed adaptive control approach ensures that all the signals in the closed-loop system are bounded, and the tracking error can be regulated to a compact set around zero in finite time. Finally, simulation results are presented to verify the effectiveness of the theoretical results.","periodic disturbances, event-triggered control, Fourier series expansion, nonlinear systems, finite time",This paper proposes an adaptive event-triggered control strategy for a class of nonlinear systems with periodic disturbances. The strategy combines Fourier series expansion and radial basis function neural network into a function approximator to estimate unknown nonlinear functions. The proposed control approach ensures that all signals in the closed-loop system are bounded and the tracking error converges to the origin with a small neighborhood in finite time.
Rhishi Pratap Singh,Time Optimal Spectrum Sensing: Stochastic Optimization,This paper presents a stochastic optimization approach for time-optimal spectrum sensing. The problem is formulated as a joint optimization of the mean and variance of the spectrum sensing time random variable.,"Stochastic Optimization, Spectrum Sensing, Pareto Front, Source Coding, time-optimal, Integer Programming",The paper proposes a novel approach to solve the time-optimal spectrum sensing problem using stochastic optimization. The approach is based on the minimization of the mean and variance of the spectrum sensing time random variable.
Richard Furie,BELIMUMAB IN PATIENTS OF BLACK AFRICAN ANCESTRY,"Study design. SELENA–SLEDAI = Safety of Estrogens in Lupus Erythematosus National Assessment–Systemic Lupus Erythemato-sus Disease Activity Index; IV = intravenous.

Randomization and treatment. Using an interactive voice/web response system, patients receiving standard therapy were randomized 2:1 to receive either belimumab 10 mg/kg IV or placebo, which was administered on days 0, 14, and 28 and every 28 days thereafter up to week 48, with a final evaluation at week 52. Randomization was stratified by screening SELENA–SLEDAI score (≤9 versus ≥10), region (US/Canada versus rest of world), and complement level (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]). Detailed randomization data are provided in Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Patients who successfully completed the initial 52-week double-blind phase could enter an optional 6-month open-label extension phase, during which they received belimumab 10 mg/kg IV every 28 days plus standard therapy, irrespective of their previous study assignment. The first dose was given at the week 52 (day 364) visit of the double-blind period (day 1 of the open-label extension phase). Patients who completed the 52-week double-blind phase, but did not enter the 6-month open-label extension phase, were required to return for an additional follow-up visit 8 weeks after their last dose. Patients who withdrew early were required to return for an exit visit 4 weeks after their last dose and a follow-up visit 8 weeks after their last dose.

The original protocol plan was to randomize 816 patients, providing ≥90% power to detect ≥12% absolute improvement in the SRI response rate in the belimumab group compared with the placebo group at a 5% significance level. Due to enrollment challenges, a revised sample size was calculated to include 501 patients (≥334 patients in the belimumab group and ≥167 patients in the placebo group). This sample size provided ≥90% power to detect a minimum 15.55% absolute improvement in SRI–SLEDAI-2K response rate in the belimumab group relative to the placebo group at a 5% significance level (based on the pooled data from efficacy studies BEL112341 and BEL113750) (15,21). These calculations assumed a placebo response rate of 43.95% at week 52.

Study end points and assessments. The primary efficacy end point was the SRI–SLEDAI-2K response rate (defined in the Supplementary Material) at week 52 of the double-blind phase. Unlike in the phase II and phase III studies, the SRI–SLEDAI-2K was selected because of the simplification it offers in proteinuria assessment as compared with the SELENA–SLEDAI proteinuria component; both are clinically meaningful (22). The primary efficacy end point for the open-label extension phase was SRI–SLEDAI-2K response rate at open-label extension week 24. If the open-label extension week 24 data were missing, data from the open-label extension week 28/exit visit were used. This time point is referred to as “open-label extension week 24” throughout the text. Data related to the primary efficacy end point, e.g., the response rate over time, percentage of patients with a durable SRI–SLEDAI-2K response from week 44 through week 52, time to first SRI–SLEDAI-2K response that was maintained through week 52, and duration of longest SRI–SLEDAI-2K response among patients with ≥1 SRI–SLEDAI-2K responses were summarized.

The key secondary end points were SRI–SELENA–SLEDAI at week 52 (open-label extension week 24), time to first severe SLE flare (measured by the SELENA–SLEDAI flare index [SFI]), and proportion of patients whose average prednisone dose had been reduced by ≥25% from baseline to ≤7.5 mg/day during week 40 through week 52 (open-label extension week 28/exit visit), in patients receiving >7.5 mg/day at baseline. Key renal end points included time to first renal flare over 52 weeks and over 28 weeks in the open-label extension, SELENA–SLEDAI–SLEDAI-2K renal domain improvement at week 52, SELENA–SLEDAI–SLEDAI-2K renal domain worsening at week 52, percentage reduction in proteinuria by visit and at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours, and proteinuria shift at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours. Renal flare is defined in the Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Biomarkers measured included percentage changes in serum IgG level, anti-dsDNA antibody level (in those who were anti-dsDNA positive [≥30 IU/ml] at baseline), and complement (C3 and C4) levels from baseline. Safety was evaluated by monitoring adverse events (AEs), serious AEs (SAEs), AEs of special interest, vital signs, clinical laboratory test results, and immunogenicity up to 8 weeks posttreatment and throughout the open-label extension phase.

Data analyses. For the double-blind phase, safety analyses were performed on the safety population, defined as all patients who were randomized and treated with at least 1 dose of investigational product. Data on the safety population were summarized according to the treatment the patient was randomized to receive rather than by the treatment that was received, but both were the same for this study. Efficacy analyses were performed on the modified intent-to-treat (ITT) population, defined as the safety population minus those patients who had any assessment at any of 3 study sites that were excluded from the efficacy analyses before the database lock because of potential Good Clinical Practice noncompliance.

For analysis of the primary and 3 key secondary efficacy end points, a step-down sequential testing procedure was used as described in the Supplementary Material. The following subgroup analyses were performed for the primary analysis (SRI–SLEDAI-2K response at week 52): region (US/Canada versus rest of world), baseline SELENA–SLEDAI–SLEDAI-2K score (≤9 versus ≥10), baseline anti-dsDNA antibody level (≥30 IU/ml versus <30 IU/ml), baseline complement levels (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]), and baseline complement and anti-dsDNA antibody levels (≥1 test finding showing low C3/C4 and anti-dsDNA ≥30 IU/ml versus C3/C4 other and anti-dsDNA ≥30 IU/ml). The odds of an SRI–SLEDAI-2K response with belimumab treatment versus placebo were estimated using logistic regression analysis.

For the open-label extension phase, all patients received belimumab, no formal statistical hypothesis t",,"This study investigated the efficacy and safety of belimumab in patients of Black African ancestry with systemic lupus erythematosus (SLE).  Patients were randomized to receive belimumab or placebo for 52 weeks, followed by an optional 6-month open-label extension phase. The primary efficacy endpoint was the SRI–SLEDAI-2K response rate at week 52.  Key secondary endpoints included SRI–SELENA–SLEDAI at week 52, time to first severe SLE flare, and proportion of patients with a reduction in prednisone dose. Renal and biomarker assessments were also conducted.  The study found that belimumab was effective in improving SLE disease activity and reducing renal flares in patients of Black African ancestry."
Ridhi Nim,Format Preserving Encryption for Data Warehouse Security,"This paper proposes a new data security technique known as format preserving encryption or data type preservation. Format preservation provides several distinct benefits that build on solid strong-encryption practices. The main aim of FPE is to encipher the data without the need to modify all of the systems that use that data; such as database field, queries and all the application program.","Data security, Data Warehouse Security, Data warehousing, Feistel Network, Format preserving encryption, Advanced Encryption standard (AES), AES Algorithm","The proposed solution uses a new data security technique known as format preserving encryption or data type preservation. This technique provides several distinct benefits that build on solid strong-encryption practices. The main aim of FPE is to encipher the data without the need to modify all of the systems that use that data; such as database field, queries and all the application program."
Rikard Holmdahla,ROS deficiency enhanced mannan-induced PsA,"In and joint inflammation using B10Q.Ncf1m1j/m1j mice that have a mutation in the Ncf1 gene (m1j) (the Ncf1 protein also denoted p47phox), and hence reduced ROS production (oxidative burst) (18). As shown in Fig. 1D, Ncf1 mutated mice developed severe joint inflammation within 2 d after mannan injection, which reached the mean maximal disease severity (30 ± 6 points) within 4 d. The frequency of skin lesions was 100%, with more severe cases in B10Q.Ncf1m1j/m1j mice (Fig. 1E), whereas B10.Q mice had a significantly milder disease course. Multiple Exposures to Mannan Induced a Relapsing Disease. Next, we examined the effect of multiple mannan injections in B10Q and B10Q.Ncf1m1j/m1j mice. We boosted mice twice with mannan on days 7 and 14 after disease initiation. Repetitive injections of mannan reproduced the arthritis phenotype, which reached the maximum severity level on days 9 and 17, similar to the first injection (Fig. 1F). A more severe disease course was observed in B10Q.Ncf1m1j/m1j mice than in B10Q mice (P < 0.05 and P < 0.01, respectively). Interestingly, Ps skin scaling returned only after the second mannan injection (on day 16), but the skin peeled off even more quickly than the first time (Fig. 1G). Moreover, from day 11 onward, B10Q.Ncf1m1j/m1j mice started to develop pruritus on the body, predominantly on the back and above the eye (Fig. S1E). Pruritus was only evident in B10Q.Ncf1m1j/m1j mice, but flaky skin on the tail and alopecia all over the leg was observed in both of the mouse strains. We also observed genetic heterogeneity in disease susceptibility (Fig. Fig. 1. ROS deficiency enhanced mannan-induced PsA. The arthritic joint phenotype and Ps-like skin lesions in the front (A) and hind (B) paws of B10Q.Ncf1m1j/m1j mice are shown. (C) Ps-like skin scaling in diseased B10Q.Ncf1m1j/m1j mouse ear compared with naive mouse ear. Mean arthritis (D) and Ps lesion (E) severity in B10Q (n = 5) and B10Q.Ncf1m1j/m1j (n = 5) mice after a single i.p. mannan injection. Mean arthritis (F) and Ps lesion (G) severity in B10Q (n = 5) and B10Q.Ncf1m1j/m1j (n = 5) mice after repetitive mannan injections (days 7 and 14). (H) Mannan-induced mean maximum arthritis scores ± SEM in different mouse strains: B10Q (n = 8), B10Q.Ncf1m1j/m1j (n = 9), B10RIII (n = 10), B10RIII.Ncf1m1j/m1j (n = 9), B10P (n = 3), B10P.Ncf1m1j/m1j (n = 9), BALB/cByJ/Q (n = 10), BALB/cByJ/Q.Ncf1m1j/m1j (n = 8), BALB/cByJ (n = 5), BALB/cByJ.Ncf1m1j/m1j (n = 7), C57BL/6NJ (n = 8), and C57BL/6NJ.Ncf1m1j/m1j (n = 7). Significance was calculated by comparing the maximal disease severity of B10Q and B10Q.Ncf1m1j/m1j mice with all of the other strains in their respective groups. *P < 0.05; **P < 0.01; ***P < 0.001. E3670 | www.pnas.org/cgi/doi/10.1073/pnas.1405798111 Khmaladze et al. Downloaded from https://www.pnas.org by 122.184.65.228 on February 22, 2023 from IP address 122.184.65.228.","autoimmune disease, Ncf1, animal model","This study identifies a new mechanism for psoriasis (Ps) and psoriasis arthritis (PsA) development in mice. A single injection of mannan, a component of baker's yeast, induced Ps and PsA-like symptoms. This effect was exacerbated in mice lacking reactive oxygen species (ROS), but improved when ROS production was restored in macrophages.  Blocking IL-17A, a cytokine produced by gamma delta T cells, completely prevented disease. The study suggests that mannan activates macrophages, leading to TNF-α secretion and stimulation of IL-17A production by gamma delta T cells. This, in turn, drives neutrophil infiltration and inflammation, mimicking Ps and PsA. This new mouse model could be valuable for testing new therapies for Ps and PsA."
Rinky Ahuja,Optimal Feature Level Fusion Based IRIS and Fingerprint Multimodal Biometric System using Improved Multi Kernel SVM,"The modern society attained secured mechanism to lead their processes in different applications such as airports, hospitals, banks, autonomous and non-autonomous institutions, etc with the improvement of biometric system. Nowadays, biometric technique is employed for human identification process based iris, fingerprint, ear and palm etc. In order to render the effective biometric system we have improved multi-model biometric recognition established on iris and fingerprint. Our work is established on three modules such as recognition module, pre-processing module, and feature extraction module. Then, in the feature extraction module, we processed feature extraction established on changed Local Binary Pattern (MLBP) feature and GLCM features. Fish Swarm optimization algorithm is applied for processing feature level fusion. For recognition, developed Multi Kernel Support vector machine (IMKSVM is inaugurated. In the document, several kernels are integrated to give shape to an innovative hybrid kernel which incredibly improves the classification task of segregating the training data. By way of offering the hybrid kernel, the SVMs gainfully achieve the flexibility to pick the appropriate shape of the threshold, for which it is not essential that it is linear and possesses the identical functional shape for the entire data, in view of its non-parametric function and local operation. We estimated our suggested technique with existing technique therefore; we get better recognition accuracy and successfully implemented our technique in MATLAB platform.","feature extraction, fusion techniques, Fish Swarm Optimization, cancelable score fusion, Reorganization, relevance vector machine, GLCM Feature, bin-based classifier, Preprocessing, multimodal biometric systems, Local Binary Pattern, Biometric System","This paper presents an optimal feature level fusion based IRIS and fingerprint multimodal biometric system using improved multi kernel SVM. The system is established on three modules: recognition module, pre-processing module, and feature extraction module. The feature extraction module uses changed Local Binary Pattern (MLBP) feature and GLCM features. Fish Swarm optimization algorithm is applied for processing feature level fusion. The system is implemented in MATLAB platform and achieves better recognition accuracy compared to existing techniques."
Rishabh Doshi,Early Detection of Alzheimer’s Disease using Deep Learning Models and Word Embeddings,"Alzheimer’s Disease (AD) is an irrecoverable, progressive neurodegenerative disorder that deteriorates the cognitive and linguistic abilities of a person over time. Ample research has been done on the early detection of AD; it remains a challenging task. Doctors use the patient’s history, laboratory tests, and change in behaviour to diagnose the disease. Natural Language Processing(NLP) techniques can help automate the detection of AD, as Language impairments accompany this disease. This work aims to analyze the effect of different Embedding models on the DementiaBank dataset in order to detect the disease.","Natural Language Processing, Deep Learning, Alzheimer’s Disease, early detection, Cookie theft Description task, Word Embeddings","This paper explores the effect of different embedding algorithms and neural architectures on early detection of Alzheimer’s Disease using the DementiaBank dataset. The study uses both generic and domain-specific Word Embeddings on three deep learning models - CNN, Bidirectional LSTM(BLSTM), and CNN+BLSTM. Results indicate that domain-specific Word Embeddings tend to work better for a specific picture description task like cookie theft description. The study also discusses how results are affected by the use of different Embedding models (Fasttext, Word2Vec, GloVe)."
Ritu Sibal,Hybrid Mobile Learning - Book Chapter 2 - Me and Addisu ||| Vulnerability Discovery Modeling for Open and Closed Source Software,"This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the material is concerned, specifically the rights of translation, reprinting, reuse of illustrations, recitation, broadcasting, reproduction on microfilms or in any other physical way, and transmission or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now known or hereafter developed. ||| With growing concern for security, the researchers began with the quantitative modeling of vulnerabilities termed as vulnerability discovery models (VDM). These models aim at finding the trend of vulnerability discovery with time and facilitate the developers in patch management, optimal resource allocation and assessing associated security risks.","Vulnerability, Open Source, extensible and adaptable computing, agile software development, Ranking, machine learning, Normalized Criteria Distance (NCD), Closed Source, Prediction, computing in education, comparative analysis, user story acceptance tests, Modeling, Web intelligence, meta-heuristic techniques","This book investigates various challenges in extensible and adaptable methods in computing, including agile software development, data management, machine learning, Web intelligence, and computing in education. It presents elegant solutions for cost-efficient storage of data, transmitting data securely, and processing data in specific applications such as health care. The book also showcases innovative algorithms and applications, including portfolio optimization, disruption classification, and outlier detection, as well as emerging Web applications in dynamic social contexts. ||| This paper proposes a new vulnerability discovery model to capture a wide variety of datasets irrespective of their shape accounting for better goodness of fit. The proposed model has been evaluated on three real life datasets each for open and closed source software and the models are ranked based on their suitability to discover vulnerabilities using normalized criteria distance (NCD) technique."
Rizwan Aslam Butt,A Dynamic Congestion Control Scheme for safety applications in vehicular ad hoc networks,"In recent years, various types of applications have emerged from Vehicular Ad hoc Networks (VANETs) for safety, infotainment, rescue and security purposes. Safety applications have their own strict communication requirements, and they require reliable and timely data communication within networks. Due to a variety of network applications, safety applications have been negatively impacted by communication channel congestion issues. Channel congestion leads to packet loss, delay and unreliability issues, and has a serious impact on vehicular traffic, including road accidents, road jams, and wrong traffic decisions. In addressing these issues, this paper's authors have proposed a Dynamic Congestion Control Scheme (DCCS) as a means of reliable and timely data delivery, in safety applications. The proposed scheme is designed for communication channels, as a means of broadcasting safety messages, and to ensure the reliable and timely delivery of messages to all neighbours in a network. The DCCS scheme is designed for inter-vehicle communication, without fixed infrastructure. Comprehensive simulation is conducted, in order to evaluate the performance of a proposed scheme, and to compare it with other state of the art schemes.","Congestion Control, Mobility, Transmit Power Control, MAC Blocking, Safety, Measurement-Based Detection, Urban, VANETs, Congestion, Communication, Vehicular, Control, Broadcasting, Queue Freezing",This paper proposes a Dynamic Congestion Control Scheme (DCCS) for safety applications in Vehicular Ad hoc Networks (VANETs). The scheme detects congestion and controls it by exploiting existing network resources for road traffic safety and cum security. The main objectives of this research are to determine whether a congestion detection scheme will reduce congestion by using realistic weighting factors and whether a congestion control scheme can control congestion through message originated-based queue freezing.
Robert Amor,Agile Processes in Software Engineering and Extreme Programming,"The 18th XP conference was held 2017 in the wonderful city of Cologne, Germany. In the spirit of past XP conferences, XP 2017 was a place where researchers and practitioners met to exchange new ideas and present their work. These proceedings contain the full research papers, short research papers, and doctoral symposium papers presented at the conference.","Teams, Reflection, Reflective practice, Levels of reflection, Agile software development, Agile retrospective meeting","The conference featured 46 research papers, with 14 accepted as full research papers and 6 as short research papers. The selected papers cover a wide range of agile techniques and approaches, including empirical studies and technology studies relevant to both researchers and practitioners."
Robert J. Benschop,First-­in-­Human Study of Bamlanivimab in a Randomized Trial of Hospitalized Patients With COVID-­19,"This first-in-human study in hospitalized patients with COVID-19 was supported by studies assessing in vitro viral neutralization combined with a single-dose non-human primate PK study. The nonclinical safety package to support subsequent studies included tissue cross-reactivity studies on human, rat, and monkey tissues and an in vivo toxicology study.  A complete physical examination was conducted at the screening visit, and one of three bamlanivimab doses or placebo was administered i.v. at the baseline visit (D1) with infusion rates as follows: bamlanivimab 700 mg (50 mL) administered 100 mL/hr for 30 minutes; 2,800 mg (75 mL) administered 100 mL/hr for 45 minutes; and 7,000 mg administered 100 mL/hr for 60 minutes. Placebo infusion was 0.9% normal saline, administered at the same volume and rate as the corresponding bamlanivimab dose cohort. Safety and tolerability were reviewed for sentinel participants up to 24 hours after dosing, at which point the investigators and sponsor team determined whether safety and tolerability were acceptable to continue with dosing subsequent participants. The decision to dose the next cohort was made when all participants from the previous cohort had been dosed and safety data assessed for at least 4 days after the i.v. infusion by the investigators and sponsor team in consultation with an independent safety assessment committee. Blood samples were obtained for assessment of exploratory biomarkers, serology, clinical laboratory assessments, and PD on days 1, 3, 7, 11, 15, 22, and 29, and every 7 days until discharge or day 60, if still an inpatient. Samples for the virology assay were collected using nasopharyngeal (preferred) or mid-turbinate methods. Blood samples obtained for PK analyses were assessed on days 1 (pre-infusion and just before end of infusion), 4, 15, and 29, and follow-up visits up to day 60. Symptom-related physical examinations and assessments of clinical symptoms were performed on days 1, 2, 3, 4, 7, 11, 15, 22, and 29, and the day of discharge from the hospital, with additional follow-up examinations every 7 days thereafter until day 60 if the patient was not discharged from the hospital by day 29. Participants’ clinical status and concurrent procedures of special interest were recorded, including limitation on activities due to COVID-19 and any requirements for the following procedures of special interest, such as ongoing hospital medical care, supplemental oxygen, noninvasive ventilation or a high flow oxygen device, mechanical ventilation, extracorporeal membrane oxygenation, additional organ support, or consciousness status using alert, consciousness, verbal, pain, unresponsive scale. Hospitalization events were recorded, including dates of hospital admission and discharge, admission to the intensive care unit (ICU), discharge from the ICU, and discharge location including to an extended care facility or home. Outcomes The primary objective was to assess safety and tolerability, including adverse events (AEs), serious adverse events (SAEs), and discontinuations due to AEs. Other objectives included PKs (e.g., mean concentration at day 29); PD viral load, area under the response time curve (AUC, from day 1 to day 29), and change from baseline time course; total symptom score; time to symptom resolution; duration of hospitalization; National Institute of Allergy and Infectious Diseases (NIAID), World Health Organization (WHO) scales, and National Early Warning Score (NEWS2); and analysis of viral resistance. Any hypothesis tests were conducted for treatment comparisons without adjustment for multiplicity except for the evaluation of treatment effect on endogenous antibody titers. Success for the trial was claimed using a Bayesian criterion if any of the 3 bamlanivimab doses had at least 60% probability to reduce at least 30% mean AUC (28-day viral load) over placebo.",,"This first-in-human study evaluated the safety, tolerability, pharmacokinetics, clinical course, and viral dynamics of bamlanivimab, a fully human neutralizing monoclonal antibody targeting SARS-CoV-2, in hospitalized patients with moderate to severe COVID-19.  The study found bamlanivimab to be safe and well-tolerated, with no serious adverse events or deaths reported.  Further research is needed to determine the efficacy of bamlanivimab in treating COVID-19."
Rohan Ratwani,Multifunctional HUD with Drowsy Detection and Fog Elimination Mechanism,"People are conscious of the risk of drinking and driving but don't realize the danger of drowsiness. Prior state of art reveals very little work on designing the automated system that measures the driver drowsiness. Our research lodge a system for the drivers and travelers who drive various means of transportation and alerts them when a driver is in a drowsy state. We have amalgamated the HUD (Head-up Display) facilities, drowsy detection system, and fog elimination system altogether to help the driver reach the destination safely by providing navigation, visual indication and many useful applications of mobile phones on HUD. Experimental results reveal that our proposed system is superior to existing HUDs and provide more features for the benefit of drivers.","Facial landmark detection, Fog Elimination, Head-Up Display, Drowsy detection, Drowsiness Detection, Night vision Infrared (IR) camera, Head-Up Display (HUD), OpenCV","The proposed system is a smart camera that uses machine learning algorithm to detect drowsiness in drivers. It captures the face of the driver using a Night vision Infrared (IR) camera and detects the eyes using facial landmark detection technique. The system generates an alert and alarm if the eyes are closed for more than 5 seconds, making it a safe and efficient way to detect drowsiness in drivers."
Rohit Beniwal,"Ontologies for Software Engineering: Past, Present and Future ||| SWOT Analysis of Ontology Driven Software Engineering","Research in recent years has probed integration amongst research field of Software Engineering and Semantic Web technology, addressing the advantages of applying Semantic techniques to the field of Software Engineering. Prolifically published studies have further substantiated the benefits of ontologies to the field of Software Engineering, which clearly motivate us to explore further opportunities available in this collaborated field. This paper is a survey expounding such opportunities while discussing the role of ontologies as a Software Life-Cycle support technology. ||| In the past decade offshoring and outsourcing the software development phenomenon has been undeniably a key software engineering practice. The need to adapt to this new reality is obvious and is bound to have a long lasting influence on the software industry. This fosters the industry and researchers to look for intelligent supporting technologies and tools that can help interconnect and exchange Software Engineering knowledge. A rising trend to exploit ontologies for sharing and reusing information across web is well recognized. We examine the strategic alignment of ontologies to Software Engineering where the former can be used to improve and assist in intelligent software development process. The SWOT (Strengths, Weaknesses, Opportunities, and Threats) analysis is presented giving an insight to the use of ontologies to enrich and enhance Software Engineering processes.","Semantic Web Enabled Software Engineering, Ontology, information sharing, distributed development environments, Support Technology, Ontologies, Software Engineering, Life Cycle, Semantic Web, communication, Ontology Driven, SWOT Analysis, intelligent support tools","The paper explores the use of ontologies in Software Engineering, including upper ontologies, software process ontologies, and domain ontologies. It discusses the potential benefits of using ontologies, such as improved semantic interoperability and better change prediction in requirements specification. ||| The purpose of this study is to utilize the SWOT analysis framework to determine the benefits, impact, challenges, and risks of using ontologies for Software Engineering. This will help in providing an insight to short-term and long-term practical recommendations that can enhance the Software Engineering process and impact businesses/ individuals/ organizations/ groups in a prolific and strategic manner."
Rohit Gavval,Visual Sentiment Analysis of Customer Complaints using SOM,"With the widespread use of social media, companies now have access to a wealth of customer feedback data which has valuable applications to Customer Relationship Management (CRM). Analyzing customer grievances data, is paramount as their speedy non-redressal would lead to customer churn resulting in lower profitability. In this paper, we propose a descriptive analytics framework using Self-organizing feature map (SOM), for Visual Sentiment Analysis of customer complaints. The network learns the inherent grouping of the complaints automatically which can then be visualized too using various techniques. Analytical Customer Relationship Management (ACRM) executives can draw useful business insights from the maps and take timely remedial action. We also propose a high-performance version of the algorithm CUDASOM (CUDA based Self Organizing feature Map) implemented using NVIDIA parallel computing platform, CUDA, which speeds up the processing of high-dimensional text data and generates fast results. The efficacy of the proposed model has been demonstrated on the customer complaints data regarding the products and services of four leading Indian banks. CUDASOM achieved an average speed up of 44 times. Our approach can expand research into intelligent grievance redressal system to provide rapid solutions to the complaining customers.","CUDA, Grievance Redressal, Self-Organizing Map, Visual Sentiment Analysis, Customer Complaints, Self-Organizing Maps, Analytical CRM, SOM","This paper proposes a descriptive analytics framework using Self-organizing feature map (SOM) for Visual Sentiment Analysis of customer complaints. The framework learns the inherent grouping of complaints automatically and can be visualized using various techniques. A high-performance version of the algorithm CUDASOM is also proposed, which speeds up the processing of high-dimensional text data and generates fast results."
Rohtash Kumar,Source parameters and f max in lower Siang region of Arunachal lesser Himalaya,"A data set of 60 local events (1.9≤Mw≤3.6) collected by a temporary digital network deployed in the Siang region of Arunachal Lesser Himalaya during July 2011 to February 2012 is analysed to study the source parameters and fmax. The software EQK_SRC_PARA (Kumar et al. in Int J Geosci 3(5):1142–1149, 2012) that considers Brune’s model with a high-frequency diminution factor (Boore in Bull Seismol Soc Am 73:1865–1894, 1983) has been used to estimate the spectral parameters namely: low-frequency displacement spectral level (Ω0), corner frequency (fc) and fmax. These obtained spectral parameters are used to estimate source parameters, namely: seismic moment, source dimension and stress drop and to study the characteristics of fmax in this region.","Accelerometers, Seismometers, fmax, Lower Siang, Source parameters, Seismicity, Arunachal Lesser Himalaya, Siang region","This study investigates the source parameters and fmax in the lower Siang region of Arunachal Lesser Himalaya using a data set of 60 local events. The results show that fmax has similar behavior as fc to seismic moment, indicating that it is also due to source process. The study also finds that fmax is independent of epicentral distance and focal depth."
Roland S Liblau,Myelin-speciﬁc T cells also recognize neuronal autoantigen in a transgenic mouse model of multiple sclerosis,"We describe here the paradoxical development of spontaneous experimental autoimmune encephalomyelitis (EAE) in transgenic mice expressing a myelin oligodendrocyte glycoprotein (MOG)-speciﬁc T cell antigen receptor (TCR) in the absence of MOG. We report that in Mog-deﬁcient mice (Mog–/–), the autoimmune response by transgenic T cells is redirected to a neuronal cytoskeletal self antigen, neuroﬁlament-M (NF-M). Although components of radically different protein classes, the cross-reacting major histocompatibility complex I-Ab–restricted epitope sequences of MOG35–55 and NF-M18–30 share essential TCR contact positions. This pattern of cross-reaction is not speciﬁc to the transgenic TCR but is also commonly seen in MOG35–55–I-Ab–reactive T cells. We propose that in the C57BL/6 mouse, MOG and NF-M response components add up to overcome the general resistance of this strain to experimental induction of autoimmunity. Similar cumulative responses against more than one autoantigen may have a role in spontaneously developing human autoimmune diseases.",,"This study reports the unexpected finding that transgenic mice expressing a myelin oligodendrocyte glycoprotein (MOG)-specific T cell receptor (TCR) develop spontaneous experimental autoimmune encephalomyelitis (EAE) even in the absence of MOG. The researchers discovered that these mice redirect their autoimmune response to a neuronal cytoskeletal protein called neuroﬁlament-M (NF-M). This cross-reactivity between MOG and NF-M is mediated by shared TCR contact positions on their respective epitope sequences. The study suggests that cumulative responses against multiple autoantigens, such as MOG and NF-M, may contribute to the development of spontaneous autoimmune diseases in humans."
Roland S. Liblau,Cutting Edge: CD8 T Cell-Mediated Demyelination,"We generated mice (DKI) in which the HA coding sequence was introduced in the ubiquitously active Rosa26 locus but where HA transcription was prevented by an upstream LoxP-flanked Stop cassette. The DKI mice were then crossed with the MOGi-Cre mice, which express Cre specifically in oligodendrocytes. The resulting DKI mice excise the Stop cassette due to MOG-controlled Cre expression, leading to restricted HA expression to oligodendrocytes.  We then decided to test whether effector CD8 T cells can mediate oligodendrocyte cell death and demyelination in vivo. Effector T cells were first generated by in vitro activation of Kd:HA512–520 pentamer-specific CD8 T cells obtained from CL4-TCR mice using HA peptide, IL-2, and IL-12. The resulting Tc1 cells produce large amounts of granzyme B (GrB) and IFN-γ and exhibit potent cytotoxicity to HA-loaded target cells in vivo. Next, we transferred these HA-specific Tc1 cells into DKI and control mice. Following i.v. injection of 3 × 107 HA-specific Tc1 cells, but not naive HA-specific CD8 T cells, ~40% of the DKI mice developed an overt monophasic disease peaking at day 8–10 and waning by 4 wk posttransfer. The clinical manifestations included weight loss and, in the more severe cases, tremors, reduced mobility, and difficulty to right when overturned without overt paralysis. Upon histological analysis, all DKI mice injected with Tc1 cells demonstrated clear CNS pathology from day 5 onwards. Inflammatory lesions were never found in control littermates injected in parallel with HA-specific Tc1 cells.",,"This study investigates the role of CD8 T cells in multiple sclerosis (MS) pathogenesis. Researchers generated a mouse model where a model antigen (influenza hemagglutinin) is expressed specifically in oligodendrocytes, the cells responsible for producing myelin in the central nervous system. Transferring activated CD8 T cells specific for this antigen into these mice resulted in inflammatory lesions in the brain, spinal cord, and optic nerve, resembling active MS lesions. These lesions were characterized by CD8 T cell infiltration, loss of oligodendrocytes, demyelination, and microglia activation. This suggests that CD8 T cells can directly contribute to oligodendrocyte death and demyelination in MS, highlighting their potential as therapeutic targets."
Roop Singh,Optimal keyframe selection-based lossless video-watermarking technique using IGSA in LWT domain for copyright protection,"Video piracy is a challenging issue in the modern world. Approximately 90% of newly released films were illegally distributed around the world via the Internet. To overcome this issue, video watermarking is an effective process that integrates a logo in video frames as a watermark. Therefore, this paper presents an efficient lossless video-watermarking scheme based on optimal keyframe selection using an intelligent gravitational search algorithm in linear wavelet transform. This technique obtains color motion and motionless frames from the cover video by the histogram difference method. One-level linear wavelet transform is performed on the chrominance channel of motion frames and a low-frequency sub-band LL opts for watermark embedding. The performance of the proposed technique has been evaluated against 12 video processing attacks in terms of imperceptibility and robustness. Experiments demonstrate that the proposed technique outperforms five state-of-the-art schemes on the considered attacks.","Intelligent gravitational search algorithm, Linear wavelet transform, Video watermarking",This paper presents a lossless video-watermarking scheme based on optimal keyframe selection using an intelligent gravitational search algorithm in linear wavelet transform. The technique obtains color motion and motionless frames from the cover video and performs one-level linear wavelet transform on the chrominance channel of motion frames. The performance of the proposed technique has been evaluated against 12 video processing attacks and outperforms five state-of-the-art schemes.
Ruchi Mittal,Anomaly Detection in Multiplex Networks ||| Classifying the Influential Individuals in Multi-Layer Social Networks ||| Data Mining Techniques for Knowledge Discovery in Environmental Monitoring,"This paper presents an approach for detecting anomalies in multiplex networks. The proposed algorithm is applied to two datasets, Danio-Rerio and Florentine Marriage, and the results show that the algorithm is effective in detecting anomalies in the networks. ||| Nowadays, social media is one of the popular modes of interaction and information diffusion. It is commonly found that the main source of information diffusion is done by some entities and such entities are also called as influencers. An influencer is an entity or individual who has the ability to influence others because of his/her relationship or connection with his/her audience. In this article, we propose a methodology to classify influencers from multi-layer social networks. A multi-layer social network is the same as a single layer social network depict that it includes multiple properties of a node and modeled them into multiple layers. The proposed methodology is a fusion of machine learning techniques (SVM, neural networks and so on) with centrality measures. We demonstrate the proposed algorithm on some real-life networks to validate the effectiveness of the approach in multi-layer systems. ||| The area of sensor network has a long history and many kind of sensor devices are used in various real life applications. Here, we introduce Wireless sensor network which when combine with other areas then plays an important role in analyzing the data of forest temperature, bioinformatics, water contamination, traffic control, telecommunication etc. Due to the advancement in the area of wireless sensor network and their ability to generate large amount of spatial/temporal data, always attract researchers for applying data mining techniques and getting interesting results. Wireless sensor networks in monitoring the environmental activities grows and this attract greater interest and challenge for finding out the patterns from large amount of spatial/temporal datasets. These datasets are generated by sensor nodes which are deployed in some tropical regions or from some wearable sensor nodes which are attached with wild animals in wild life centuries. Sensor networks generate continuous stream of data over time. So, Data mining techniques always plays a vital role for extracting the knowledge form large wireless sensor network data. In this paper, we present the detection of sensor data irregularities, Sensor data clustering, Pattern matching and their interesting results and with these results we can analyze the sensor node data in different ways.","mining, knowledge discovery, Trend Lines, Multi-Layer Networks, pattern matching, Centrality Measure, Social Network, environmental monitoring, Page Rank Centrality, Centrality Measures, wireless sensor network, Gaussian Model, Bottleneck Centrality, sensor networks, sensor node, Anomaly Detection, Multiple Layers, clustering, cross-layer anomaly detection, multiplex networks, Betweenness Centrality, Multiplex Network, data mining","The paper proposes a novel approach for detecting anomalies in multiplex networks. The approach is based on computing centrality measures for each node in the network and then using a Gaussian model to compute the probability of each node being anomalous. The algorithm is applied to two datasets, Danio-Rerio and Florentine Marriage, and the results show that the algorithm is effective in detecting anomalies in the networks. ||| This paper proposes a methodology to classify influencers from multi-layer social networks by fusing machine learning techniques with centrality measures. The proposed approach starts by computing the betweenness centrality, closeness centrality, and degree centrality of each node of the multi-layer network. Next, it identifies the communities in the system and uses the influence capabilities of the target user and his/her friends to see how prone the friends are to getting influenced by the target user and user characteristics. ||| This paper presents the detection of sensor data irregularities, Sensor data clustering, Pattern matching and their interesting results. The authors introduce Wireless sensor network which plays an important role in analyzing the data of forest temperature, bioinformatics, water contamination, traffic control, telecommunication etc. They present the implementation strategies of the data mining techniques which they applied to sensor data and show the results."
Ruchi Mittala,Cryptocurrency Price Prediction Approach Using ARIMA ||| Time Series Prediction of Cryptocurrency Prices Using LSTM Networks,"With the increase in popularity of cryptocurrencies, it is becoming extremely crucial to predict what the prices of the currencies are going to be in the future. This paper uses a dataset that consists of over 1500 cryptocurrencies with their prices starting from their initiation till May, 2018. A lot of the effort went into getting the data set ready before predicting the future prices of all the cryptocurrencies, i.e., making sure that the cryptocurrencies were stationary time-series. Beginning with learning about the ARIMA model and the conditions to run the model successfully, first validation of the model is done. An average accuracy of 86.424 is observed for 95% of the currencies are observed. After this validation, forecasting is performed on these cryptocurrencies and the percentage change of the price is calculated. ||| In the modern era, researchers are predicting prices of various kinds of cryptocurrency to understand their trend in the sector of finance. In this paper, we focus on price prediction of cryptocurrencies based on a period, i.e., for the year 2013 t0 2018. From our research, we have identified the highest prices for bitcoin for historical dates and trained Long Short-Term Memory Networks to learn and predict the highest rate for a future period. Thus, trend analysis of cryptocurrency prices has been done, and neural networks have been leveraged to determine from time series data and predict future values.","Price prediction, Cryptocurrency, cryptocurrency prices, Deep learning, LSTM, ARIMA model, ARIMA, stationary time-series, time series prediction, Long Short-Term Memory Networks, Forecasting","This paper focuses on the performance of all the cryptocurrencies using the ARIMA model for forecasting the future prices. The dataset used consists of over 1500 cryptocurrencies with their prices starting from their initiation till May, 2018. The paper discusses the related work in the area of cryptocurrency and ARIMA model, data preprocessing, employing ARIMA to forecast the required values, and validating the applied model. ||| This paper proposes a scalable algorithm to predict the increase and decrease in Bitcoin prices throughout five years using deep machine learning networks. The approach maintains a high accuracy (>90 percent) and low Root Mean Squared Error. The proposed architecture helps to predict the highest price of cryptocurrency based on the previous date, develop LSTM network and make predictions using LSTM that maintain their state over many sequences, and use LSTM to predict prices using regression and window based framing for prediction."
Ruchi Sharma,h-value touch points between IoT mobile Apps and their users ||| Vulnerability Discovery Modeling for Open and Closed Source Software,"Business models help firms to set a right path to create, grow and retain their business value. While previous research shows that business model affects the performance of entrepreneurial firms, there is still limited understanding about how likely different business model selections of Internet of Things (IoT) startup firms retain their value and whether the venture capital investment intensity does play any role in the business model’s value retention process. ||| With growing concern for security, the researchers began with the quantitative modeling of vulnerabilities termed as vulnerability discovery models (VDM). These models aim at finding the trend of vulnerability discovery with time and facilitate the developers in patch management, optimal resource allocation and assessing associated security risks.","Vulnerability, Open Source, Instrumental variable regression, Business model, Ranking, Value retention, Mobile application, venture capital, Normalized Criteria Distance (NCD), Closed Source, mobile Apps, Modeling, Prediction, China, Internet of things, IoT","This study investigates the impact of e-business models on value retention for start-ups in the Internet of Things (IoT) and Mobile Applications (Apps) business. The study finds that e-efficiency-centred and complementarities-centred e-business models increase value retention, while lock-in centred e-business model reduces value retention. The study also finds that venture capitalist’s involvement moderates the relationship between e-business models and value retention. ||| This paper proposes a new vulnerability discovery model to capture a wide variety of datasets irrespective of their shape accounting for better goodness of fit. The proposed model has been evaluated on three real life datasets each for open and closed source software and the models are ranked based on their suitability to discover vulnerabilities using normalized criteria distance (NCD) technique."
Rudresh Dwivedi,"A novel hybrid score level and decision level fusion scheme for cancelable multi-biometric verification ||| A privacy-preserving cancelable iris template generation scheme using decimal encoding and look-up table mapping ||| Cancelable iris template generation using look-up table mapping ||| Edge Detection Using Fuzzy Logic ||| Explainable AI (XAI): Core Ideas, Techniques and Solutions ||| Generating protected fingerprint template utilizing coprime mapping transformation ||| Title Suppressed Due to Excessive Length","In spite of the benefits of biometric-based authentication systems, there are few concerns raised because of the sensitivity of biometric data to outliers, low performance caused due to intra-class variations and privacy invasion caused by information leakage. To address these issues, we propose a hybrid fusion framework where only the protected modalities are combined to fulfill the requirement of secrecy and performance improvement. ||| This paper presents a privacy-preserving cancelable iris template generation scheme using decimal encoding and look-up table mapping. The proposed method consists of a number of tasks, including iris image preprocessing, decimal encoding, and look-up table mapping. The experimental results show that the proposed method outperforms existing approaches in terms of recognition accuracy and security. ||| This paper presents a novel approach for generating cancelable iris templates for secure iris recognition. The proposed method involves applying circular Hough transformation, normalization using Daugman's rubber sheet model, and local histogram analysis to enhance the iris image. The normalized iris image is then transformed into a 0-1 form of matrix after convolving with quadrature 1-D Gabor filter. The Gabor coefficient values are coded with either 1 or 0 depending on the sign of the coefficient. The Gabor function is represented in Eq. (1). The iris pattern can be affected by rotation, and rotation invariance mechanism is employed by taking 8 images per subject and computing Hamming distances between the reference image and other images by shifting one column. The rotation free templates are shift invariant in comparison to iris code. The rotation invariant templates are transformed into a row vector to make ease in computation. The row vector is created through merging the next row to previous one. A row vector of 1 × 24 is obtained from the iris code of 4 × 6. The row vector is partitioned into a number of blocks of size M. The value of M may be chosen statically or dynamically and different for every image. The decimal vector is constructed by partitioning row vector using a fixed length word of size M. The decimal vector has the same number of positive integers as the number of words in row vector. The conversion of a word from binary to positive integer seize the left most bit as the most significant bit. The decimal vector is mapped to a corresponding word utilizing a look-up table. More than one word can be mapped to the same positive integer, so reverse mapping is very difficult. The look-up table is generated of random values 0 and 1. The minimum size (rows) of the table depends on the value of M. For example if we have word length 4, then the maximum decimal integer is 15. So the table must have entries greater than or equal to 15. There is a possibility that all entries of a particular row or more than one row are 0. In this situation, the use of these entries are vulnerable to privacy invasion, as this makes imposters task easy. Therefore, look-up table should be such that the number of 0's and 1's are approximately same in a randomized manner. The mapping of decimal vector is performed to the corresponding row of the randomly generated look-up table. Then d bits are selected from each row of the look-up table. ||| Image processing supports applications in different fields such as medicine, astronomy, product quality, industrial applications. Edge detection plays important role in segmentation and object identification process. This paper is a review of the various approaches adopted by several authors for edge detection in image processing. ||| As our dependence on intelligent machines continues to grow, so does the demand for more transparent and interpretable models. In addition, the ability to explain the model generally is now the gold standard for building trust and deployment of Artificial Intelligence (AI) systems in critical domains. Explainable Artificial Intelligence (XAI) aims to provide a suite of machine learning (ML) techniques that enable human users to understand, appropriately trust, and produce more explainable models. ||| The identity of a user is permanently lost if biometric data gets compromised since the biometric information is irreplaceable and irrevocable. ||| The objective of an online Mart is to match buyers and sellers, to weigh animals and to oversee their sale. A reliable pricing method can be developed by ML models that can read through historical sales data. However, when AI models suggest or recommend a price, that in itself does not reveal too much (i.e., it acts like a black box) about the qualities and the abilities of an animal. An interested buyer would like to know more about the salient features of an animal before making the right choice based on his requirements. A model capable of explaining the different factors that impact the price point is essential for the needs of the market. It can also inspire confidence in buyers and sellers about the price point offered.","MCW Based Score Level, fusion, biometric, Machine Learning, Cancelable iris template, Software toolkits, DS Theory-Based Decision Fusion, Look-up table mapping, privacy, verification, Neural network, Biometrics, Video Analytics, Multimodal Biometric Authentication, Decision Making, Genetic algorithm, Row Vector, multibiometric system, Fingerprint verification, iris biometric, vision based feature extraction, Internet of Things, Bias, Decimal encoding, Biometric security, Interpretable AI, XAI, Security, Look-up table, Iris biometric, Explainable AI, Decimal Vector, Edge detection, Iris Image Enhancement, Cancelable Iris Templates, decision level fusion, Privacy, Rotation Invariance, Biometric, Robustness, computer vision, cow, Cancelable Transformation, ML based price prediction, Fuzzy logic, Image processing, weight estimation, Stakeholders, Biometric Security, Template protection, Cancelable biometrics, machine learning, Gabor Filter, Programming framework, Explainable Artiﬁcial Intelligence, cancelable, Iris recognition, Secure Iris Recognition, security","The proposed method combines score level fusion at the first level and decision level fusion at the second level to integrate different modalities. Experimental evaluation on three virtual databases shows that the proposed method outperforms existing approaches in terms of performance and security. ||| The proposed method generates a secure cancelable iris template using decimal encoding and look-up table mapping. The method consists of several tasks, including iris image preprocessing, decimal encoding, and look-up table mapping. The experimental results show that the proposed method outperforms existing approaches in terms of recognition accuracy and security. ||| This paper presents a novel approach for generating cancelable iris templates for secure iris recognition. The proposed method involves applying circular Hough transformation, normalization using Daugman's rubber sheet model, and local histogram analysis to enhance the iris image. The normalized iris image is then transformed into a 0-1 form of matrix after convolving with quadrature 1-D Gabor filter. The Gabor coefficient values are coded with either 1 or 0 depending on the sign of the coefficient. The Gabor function is represented in Eq. (1). The iris pattern can be affected by rotation, and rotation invariance mechanism is employed by taking 8 images per subject and computing Hamming distances between the reference image and other images by shifting one column. The rotation free templates are shift invariant in comparison to iris code. The rotation invariant templates are transformed into a row vector to make ease in computation. The row vector is created through merging the next row to previous one. A row vector of 1 × 24 is obtained from the iris code of 4 × 6. The row vector is partitioned into a number of blocks of size M. The value of M may be chosen statically or dynamically and different for every image. The decimal vector is constructed by partitioning row vector using a fixed length word of size M. The decimal vector has the same number of positive integers as the number of words in row vector. The conversion of a word from binary to positive integer seize the left most bit as the most significant bit. The decimal vector is mapped to a corresponding word utilizing a look-up table. More than one word can be mapped to the same positive integer, so reverse mapping is very difficult. The look-up table is generated of random values 0 and 1. The minimum size (rows) of the table depends on the value of M. For example if we have word length 4, then the maximum decimal integer is 15. So the table must have entries greater than or equal to 15. There is a possibility that all entries of a particular row or more than one row are 0. In this situation, the use of these entries are vulnerable to privacy invasion, as this makes imposters task easy. Therefore, look-up table should be such that the number of 0's and 1's are approximately same in a randomized manner. The mapping of decimal vector is performed to the corresponding row of the randomly generated look-up table. Then d bits are selected from each row of the look-up table. ||| The paper presents a comprehensive review of edge detection methods using fuzzy logic, including the use of fuzzy sets, fuzzy inference systems, and fuzzy operators. The authors discuss the advantages and limitations of traditional edge detection methods and propose the use of soft computing approaches for improved performance. ||| The paper presents the core ideas, techniques, and solutions of XAI, emphasizing its importance in various phases of the machine learning process. It discusses the stakeholders involved in these phases, including developers, theorists, data scientists, users, consumers, businesses, regulators, and scientists, and highlights the use cases of XAI in detecting bias, scientific understanding, building robust models, and better decision making. ||| A coprime transformation scheme has been proposed to derive a protected fingerprint template. The method divides the fingerprint region into a number of sectors with respect to each minutiae point and identifies the nearest-neighbor minutiae in each sector. ||| The paper discusses a method for estimating the weight of cows using a machine learning approach. The method involves training a model to predict the weight of cows based on images of their faces. However, the paper notes that the face of a cow is not sufficient for weight estimation and that the model can get biased according to color. The paper also discusses the limitations of the approach and suggests future directions for research."
Rudresh Dwivedi et al.,Deep Learning Techniques for Disease Detection in Fruits and Vegetables,"Plant Diseases are one of the leading reasons of economic shortfalls in agricultural and farming sectors worldwide. It is the most essential element since it reduces crop quantity and quality significantly. Fruits are one of the largest essential nutritional resources from plants. Unfortunately, a variety of conditions might impair both the content and outcome of fruits. As a result, an autonomous Computer Vision (CV) -based approach for reliable Fruit Disease Detection (FDD) is necessary.","Attention mechanisms, Transfer learning, Convolutional neural networks, Computer Vision, Machine Learning, Disease detection, Deep Learning, Fruits and vegetables, Fruit Disease Detection","This paper presents a detailed review of different ML and DL algorithms developed to predict and classify FDs from different fruit images. First, different FDD and classification systems designed by many researchers based on ML and DL algorithms are studied in brief. Then, a detailed analysis is carried out in order to identify the shortcomings of existing algorithms and to provide a novel strategy for properly classifying fruit pathogens."
Rudresh dwivedi,A ﬁngerprint based crypto-biometric system for secure communication ||| Blood Bank Management and Inventory Control Database Management System ||| Generation of an EDS Key Based on a Graphic Image of a Subject’s Face Using the RC4 Algorithm ||| Investigating Approaches for Improving Security in Remote User Authentication Schemes for IoT Paradigm ||| Optimal Feature Level Fusion Based IRIS and Fingerprint Multimodal Biometric System using Improved Multi Kernel SVM,"To ensure the secure transmission of data, cryptography is treated as the most eﬀective solution. Cryptographic key is an important entity in this procedure. In general, randomly generated cryptographic key (of 256 bits) is diﬃcult to remember. However, such a key needs to be stored in a protected place or transported through a shared communication line which, in fact, poses another threat to security. As an alternative, researchers advocate the generation of cryptographic key using the biometric traits of both sender and receiver during the sessions of communication, thus avoiding key storing and at the same time without compromising the strength in security. ||| This paper presents a detailed approach for an efficient blood bank database management system. The database is the single most useful setting for caching data, and it is also an ideal tool for contriving, managing, updating, and modifying data from different angles. The benefits of a well-structured blood bank database are limitless and yield the benefits of improving efficiency and saving time. Here, our motive is centred on this area. India faces a shortage when it comes to the amount of blood donated. The gap in demand and supply in widened due to mismanagement and inefficient databases. We have modelled a well-organized database to try and reduce this gap. Alongside, we have developed an application that reminds donors when they become eligible again, gives locations of nearby blood donation camps, makes requesting blood easier for blood recipients etc. as well as promoting a healthy community.  IOT is used for interlinking the application to the server as well as for inter-application communication. With the help of IOT this collection and exchange of data becomes more efficient. ||| Modern facial recognition algorithms make it possible to identify system users by their appearance with a high level of accuracy. In such cases, an image of the user’s face is converted to parameters that later are used in a recognition process. On the other hand, the obtained parameters can be used as data for pseudo-random number generators. However, the closeness of the sequence generated by such a generator to a truly random one is questionable. This paper proposes a system which is able to authenticate users by their face, and generate pseudo-random values based on the facial image that will later serve to generate an encryption key. The generator of a random value was tested with the NIST Statistical Test Suite. The subsystem of image recognition was also tested under various conditions of taking the image. The test results of the random value generator show a satisfactory level of randomness, i.e., an average of 0.47 random generation (NIST test), with 95% accuracy of the system as a whole. ||| Internet of Things (IoT) is a network of interconnected tiny resource constraint devices. These devices can be sensors, actuators, gateways or other microcontrollers and microprocessors. An intra-device communication (a.c.a. Machine to Machine Communication (M2M)), as well as an inter-device communication in the IoT, must be protected from both, active and passive attackers. Traditional cryptography protocols (i.e. RSA or DES or AES) provides well suited reliable security mechanism in the current internet topology that is built up using highly resource capable devices such as computers and servers. Fundamental different between internet cryptography and IoT cryptography lies in types of devices used to build up the topology. The internet is built up using resource capable devices such as computers and servers while the IoT network is built up using resource constraint devices such as sensors and actuators. Devices in the IoT suffers from copious limitations such as poor battery backup, less processing capabilities and lower storage capabilities. Hence, it is highly erratic and inept at using traditional internet cryptography in IoT communication. ||| The modern society attained secured mechanism to lead their processes in different applications such as airports, hospitals, banks, autonomous and non-autonomous institutions, etc with the improvement of biometric system. Nowadays, biometric technique is employed for human identification process based iris, fingerprint, ear and palm etc. In order to render the effective biometric system we have improved multi-model biometric recognition established on iris and fingerprint. Our work is established on three modules such as recognition module, pre-processing module, and feature extraction module. Then, in the feature extraction module, we processed feature extraction established on changed Local Binary Pattern (MLBP) feature and GLCM features. Fish Swarm optimization algorithm is applied for processing feature level fusion. For recognition, developed Multi Kernel Support vector machine (IMKSVM is inaugurated. In the document, several kernels are integrated to give shape to an innovative hybrid kernel which incredibly improves the classification task of segregating the training data. By way of offering the hybrid kernel, the SVMs gainfully achieve the flexibility to pick the appropriate shape of the threshold, for which it is not essential that it is linear and possesses the identical functional shape for the entire data, in view of its non-parametric function and local operation. We estimated our suggested technique with existing technique therefore; we get better recognition accuracy and successfully implemented our technique in MATLAB platform.","mobile application, feature extraction, Management Information System, digital signature, Fingerprint, NIST test battery, GLCM Feature, perfect forward secrecy, programming, bin-based classifier, crypto-biometric system, Minutiae, digital signatures, Template security, Efficiently Interlinked, Database Management System, authenticity, neural networks, Reorganization, secure communication, Biometric security, Revocability, IoT Applications, Blood-bank, multimodal biometric systems, facial recognition, Security, python, Biometric System, Fish Swarm Optimization, cancelable score fusion, relevance vector machine, Secure Lightweight Key Exchange, computer vision, Cryptography, User-Gateway Paradigm, algorithms, Local Binary Pattern, fusion techniques, Diversity, Database, Real-Time Access, random number generation, Remote User Authentication, security, IOT, MySQL, Preprocessing, cryptography, Blood Banks, IoT","This work addresses the concerns of biometric-based cryptographic key generation, including privacy of biometrics, sharing of biometric data, and generating revocable key from irrevocable biometric. A framework for secure communication between two users using fingerprint based crypto-biometric system has been proposed, which ensures the security of biometric data and perfect forward secrecy using session keys. ||| This paper presents a detailed approach for an efficient blood bank database management system. The database is the single most useful setting for caching data, and it is also an ideal tool for contriving, managing, updating, and modifying data from different angles. The benefits of a well-structured blood bank database are limitless and yield the benefits of improving efficiency and saving time. Here, our motive is centred on this area. India faces a shortage when it comes to the amount of blood donated. The gap in demand and supply in widened due to mismanagement and inefficient databases. We have modelled a well-organized database to try and reduce this gap. Alongside, we have developed an application that reminds donors when they become eligible again, gives locations of nearby blood donation camps, makes requesting blood easier for blood recipients etc. as well as promoting a healthy community.  IOT is used for interlinking the application to the server as well as for inter-application communication. With the help of IOT this collection and exchange of data becomes more efficient. ||| This paper proposes a system for authenticating users by their face and generating pseudo-random values based on facial images. The system uses a combination of mathematical procedures for facial recognition and a pseudo-random number generator. The generator of a random value was tested with the NIST Statistical Test Suite, and the subsystem of image recognition was tested under various conditions of taking the image. The test results show a satisfactory level of randomness and 95% accuracy of the system as a whole. ||| The proposed work aims to propose a highly efficient and computationally reliable authentication mechanism for mutually authenticated session key generation between either User - GateWay (U-GW) or between User - GateWay - Sensing device (U-GW-S) in the constrained IoT environment. ||| This paper presents an optimal feature level fusion based IRIS and fingerprint multimodal biometric system using improved multi kernel SVM. The system is established on three modules: recognition module, pre-processing module, and feature extraction module. The feature extraction module uses changed Local Binary Pattern (MLBP) feature and GLCM features. Fish Swarm optimization algorithm is applied for processing feature level fusion. The system is implemented in MATLAB platform and achieves better recognition accuracy compared to existing techniques."
Rushabh Gandhi,Multifunctional HUD with Drowsy Detection and Fog Elimination Mechanism,"People are conscious of the risk of drinking and driving but don't realize the danger of drowsiness. Prior state of art reveals very little work on designing the automated system that measures the driver drowsiness. Our research lodge a system for the drivers and travelers who drive various means of transportation and alerts them when a driver is in a drowsy state. We have amalgamated the HUD (Head-up Display) facilities, drowsy detection system, and fog elimination system altogether to help the driver reach the destination safely by providing navigation, visual indication and many useful applications of mobile phones on HUD. Experimental results reveal that our proposed system is superior to existing HUDs and provide more features for the benefit of drivers.","Facial landmark detection, Fog Elimination, Head-Up Display, Drowsy detection, Drowsiness Detection, Night vision Infrared (IR) camera, Head-Up Display (HUD), OpenCV","The proposed system is a smart camera that uses machine learning algorithm to detect drowsiness in drivers. It captures the face of the driver using a Night vision Infrared (IR) camera and detects the eyes using facial landmark detection technique. The system generates an alert and alarm if the eyes are closed for more than 5 seconds, making it a safe and efficient way to detect drowsiness in drivers."
S Rudina,Evaluation of the microangiographic fluoroscope (MAF) using generalized system performance metrics,"Cone beam computed tomography (CBCT) systems with rotational gantries that have standard flat panel detectors (FPD) are widely used for the 3D rendering of vascular structures using Feldkamp cone beam reconstruction algorithms. One of the inherent limitations of these systems is limited resolution (<3 lp/mm). There are systems available with higher resolution but their small FOV limits them to small animal imaging only. In this work, we report on region-of-interest (ROI) CBCT with a high resolution CMOS detector (75 μm pixels, 600 μm HR-CsI) mounted with motorized detector changer on a commercial FPD-based C-arm angiography gantry (194 μm pixels, 600 μm HL-CsI). A cylindrical CT phantom and neuro stents were imaged with both detectors. For each detector a total of 209 images were acquired in a rotational protocol. The technique parameters chosen for the FPD by the imaging system were used for the CMOS detector. The anti-scatter grid was removed and the incident scatter was kept the same for both detectors with identical collimator settings. The FPD images were reconstructed for the 10 cm x10 cm FOV and the CMOS images were reconstructed for a 3.84 cm × 3.84 cm FOV. Although the reconstructed images from the CMOS detector demonstrated comparable contrast to the FPD images, the reconstructed 3D images of the neuro stent clearly showed that the CMOS detector improved delineation of smaller objects such as the stent struts (~70 μm) compared to the FPD. Further development and the potential for substantial clinical impact are suggested.",,"This study demonstrates the use of a high-resolution CMOS detector in region-of-interest cone beam computed tomography (ROI CBCT) for improved visualization of small vascular structures. Compared to a standard flat panel detector, the CMOS detector achieved comparable contrast but significantly enhanced spatial resolution, enabling clearer delineation of stent struts. This advancement holds promise for clinical applications requiring high-resolution imaging of vascular anatomy."
S V S Nagesha,Evaluation of the microangiographic fluoroscope (MAF) using generalized system performance metrics,"Cone beam computed tomography (CBCT) systems with rotational gantries that have standard flat panel detectors (FPD) are widely used for the 3D rendering of vascular structures using Feldkamp cone beam reconstruction algorithms. One of the inherent limitations of these systems is limited resolution (<3 lp/mm). There are systems available with higher resolution but their small FOV limits them to small animal imaging only. In this work, we report on region-of-interest (ROI) CBCT with a high resolution CMOS detector (75 μm pixels, 600 μm HR-CsI) mounted with motorized detector changer on a commercial FPD-based C-arm angiography gantry (194 μm pixels, 600 μm HL-CsI). A cylindrical CT phantom and neuro stents were imaged with both detectors. For each detector a total of 209 images were acquired in a rotational protocol. The technique parameters chosen for the FPD by the imaging system were used for the CMOS detector. The anti-scatter grid was removed and the incident scatter was kept the same for both detectors with identical collimator settings. The FPD images were reconstructed for the 10 cm x10 cm FOV and the CMOS images were reconstructed for a 3.84 cm × 3.84 cm FOV. Although the reconstructed images from the CMOS detector demonstrated comparable contrast to the FPD images, the reconstructed 3D images of the neuro stent clearly showed that the CMOS detector improved delineation of smaller objects such as the stent struts (~70 μm) compared to the FPD. Further development and the potential for substantial clinical impact are suggested.",,"This study demonstrates the use of a high-resolution CMOS detector in region-of-interest cone beam computed tomography (ROI CBCT) for improved visualization of small vascular structures. Compared to a standard flat panel detector, the CMOS detector achieved comparable contrast but significantly enhanced spatial resolution, enabling clearer delineation of stent struts. This advancement holds promise for clinical applications requiring high-resolution imaging of vascular anatomy."
S. Andreana,Micro-Computed tomography (CT) based assessment of dental regenerative therapy in the canine mandible model,"High-resolution 3D bone-tissue structure measurements may provide information critical to the understanding of the bone regeneration processes and to the bone strength assessment. Tissue engineering studies rely on such nondestructive measurements to monitor bone graft regeneration area. In this study, we measured bone yield, fractal dimension and trabecular thickness through micro-CT slices for different grafts and controls. Eight canines underwent surgery to remove a bone volume (defect) in the canine’s jaw at a total of 44 different locations. We kept 11 defects empty for control and filled the remaining ones with three regenerative materials; NanoGen (NG), a FDA-approved material (n=11), a novel NanoCalcium Sulfate (NCS) material (n=11) and NCS alginate (NCS+alg) material (n=11). After a minimum of four and eight weeks, the canines were sacrificed and the jaw samples were extracted. We used a custom-built micro-CT system to acquire the data volume and developed software to measure the bone yield, fractal dimension and trabecular thickness. The software used a segmentation algorithm based on histograms derived from volumes of interest indicated by the operator. Using bone yield and fractal dimension as indices we are able to differentiate between the control and regenerative material (p<0.005). Regenerative material NCS showed an average 63.15% bone yield improvement over the control sample, NCS+alg showed 55.55% and NanoGen showed 37.5%. The bone regeneration process and quality of bone were dependent upon the position of defect and time period of healing. This study presents one of the first quantitative comparisons using non-destructive Micro-CT analysis for bone regenerative material in a large animal with a critical defect model. Our results indicate that Micro-CT measurement could be used to monitor in-vivo bone regeneration studies for greater regenerative process understanding.","Regenerative Materials, Quantitative Analysis, Bone Regeneration, Micro-CT, LabVIEW","This study investigates the effectiveness of three different bone regenerative materials (NanoGen, NanoCalcium Sulfate, and NanoCalcium Sulfate alginate) in a canine mandible model using micro-computed tomography (micro-CT). The study found that all three materials significantly improved bone regeneration compared to the control group. NanoCalcium Sulfate showed the most significant improvement, followed by NanoCalcium Sulfate alginate and NanoGen. The position of the defect and the healing time period were also found to influence the regeneration process."
S. Aral,Cost Eﬀective Inﬂuence Maximisation,"In the context of virality prediction, many researchers have leveraged the existence of a core-periphery structure in a network to identify the super-spreaders of information. Topologically, the nodes in the core of a network are the most eﬃcient spreaders. However, these nodes are less susceptible, i.e., unlikely to be inﬂuenced by the periphery nodes. Consequently, large payoﬀs are required to market information (ideas, products, memes, etc.) via them. In this paper, we show the presence of several non-core nodes whose spreading power is close to that of the core nodes.","Virality, Inﬂuence maximisation, Information diﬀusion, cost-effective, Core-periphery structure, information diffusion, social networks, influence maximisation","This paper proposes a cost-eﬀective strategy to make a meme reach the super-spreaders without the need for global information. The proposed hill-climbing based strategy can be eﬀectively used with both, global as well as local characteristics of the nodes in a network. In terms of the cost metric, it outperforms the conventional independent cascade model by more than 5 times for the core and 2 times for the non-core super-spreaders."
S. Bhattacharya,DWT based hybrid ARIMA-FLANN model for financial time series forecasting ||| Secure Robust and Imperceptible Algorithm for Watermarking Relational Databases,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model. ||| This paper proposes a secure robust and imperceptible algorithm for watermarking relational databases. The algorithm divides the embedding algorithm into three phases: Watermark preparator, watermark position detector, and watermark embedder. The ownership identification issue is resolved by embedding owner's identity as watermark in Preparator phase.","imperceptible algorithm, FLANN, wavelet transform, Proof of ownership, Ownership identification, robust algorithm, Relational Database, watermarking, financial time series forecasting, Watermark, Copyright protection, ARIMA, hybrid ARIMA-FLANN model, DWT, relational databases","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy. ||| The paper proposes a new robust secure and imperceptible embedding mechanism to resolve the two important concerns namely; owner identification and proof of ownership. The proposed mechanism involves encoding and decoding on numerical attribute of relational database in three phases; 1)Watermark preparator, 2)Watermark position detector and 3) Watermark Embedder or Detector."
S. C. Gupta,Source parameters and f max in lower Siang region of Arunachal lesser Himalaya,"A data set of 60 local events (1.9≤Mw≤3.6) collected by a temporary digital network deployed in the Siang region of Arunachal Lesser Himalaya during July 2011 to February 2012 is analysed to study the source parameters and fmax. The software EQK_SRC_PARA (Kumar et al. in Int J Geosci 3(5):1142–1149, 2012) that considers Brune’s model with a high-frequency diminution factor (Boore in Bull Seismol Soc Am 73:1865–1894, 1983) has been used to estimate the spectral parameters namely: low-frequency displacement spectral level (Ω0), corner frequency (fc) and fmax. These obtained spectral parameters are used to estimate source parameters, namely: seismic moment, source dimension and stress drop and to study the characteristics of fmax in this region.","Accelerometers, Seismometers, fmax, Lower Siang, Source parameters, Seismicity, Arunachal Lesser Himalaya, Siang region","This study investigates the source parameters and fmax in the lower Siang region of Arunachal Lesser Himalaya using a data set of 60 local events. The results show that fmax has similar behavior as fc to seismic moment, indicating that it is also due to source process. The study also finds that fmax is independent of epicentral distance and focal depth."
S. Chakraverty,An Adaptive ACO-Driven Scheme for Learning Aim Oriented Personalized E-Learning ||| Proposed Framework for Modeling Course Structure in a Personalized E-Learning System,"The e-learning paradigm is now a well-established vehicle of modern education. It caters to a wide spectrum of students with diverse backgrounds who enroll with their own learning aims. A core challenge under this scenario is to generate personalized learning paths so that each student can achieve her learning aim most effectively. ||| A proposal scheme to personalize students’ learning based on her learning aim in an e-learning environment. The system acknowledges a distinct set of students' aims that prioritize various Learning Objects (LOs) such as theory, case studies etc. according to student's Learning Aim (LA).","learning aim, personalized learning, Learning Objects, Learning Aims, e-learning, Concept Perspectives, Course structure, Priority tables, adaptive learning, Dynamic Learning Ability, ontology-based EL-DSS, Personalized E-learning, Personalized e-Learning, Directed Acyclic Graph, Ant Colony Optimization, Learning Success","The proposed scheme is an extension of the weighted directed acyclic precedence Course Graph (CG) that uses the concept of perspectives introduced earlier. The CG is structured into levels, with each level corresponding to a distinct topic or concept. The scheme uses three databases: Maximum Learning Success (MLS), Perspective Aim Contribution Table (PACT), and Learning Object Priority Table (LOPT) to provide personalized learning paths for each student. ||| This paper proposes a framework that emphasizes the significance of user's LA while selecting the LOs as well as adding to the kitty of perspectives for grasping a concept. The system generates an initially optimized path taking into account the priorities of learning objects and the contribution of concept perspectives for different learning aims."
S. Das,An approach for decision making using intuitionistic trapezoidal fuzzy soft set,"Introduction of soft sets by Molodtsov (1999) has evolved a revolution in the decision making paradigm. Researchers have used soft sets with different extensions of fuzzy sets to satisfy the various types of uncertainties involved with real life decision making problems. This paper introduces intuitionistic trapezoidal fuzzy soft set (ITrFSS) by combining intuitionistic trapezoidal fuzzy set (ITrFS) with soft set. Firstly, we generalize the adjustable approach applied to intuitionistic fuzzy soft set (IFSS) based decision making developed by Jiang et al. (2011) and then present an approach to ITrFSS based decision making using threshold ITrFSs and level soft sets.","decision making, Intuitionistic trapezoidal fuzzy soft set, level soft set, Weighted ITrFSSs, Adjustable Approach, intuitionistic trapezoidal fuzzy set, Intuitionistic Trapezoidal Fuzzy Soft Sets",This paper introduces a new approach for decision making using intuitionistic trapezoidal fuzzy soft set. The approach combines intuitionistic trapezoidal fuzzy set with soft set and uses threshold intuitionistic trapezoidal fuzzy sets and level soft sets to make decisions. The paper also proposes weighted intuitionistic trapezoidal fuzzy soft set and applies it to a decision making problem. The outcome of the adjustable approaches based on intuitionistic trapezoidal fuzzy soft set and weighted intuitionistic trapezoidal fuzzy soft set is validated using closeness coefficient measure. Two illustrative examples are provided to show the feasibility of the proposed approaches in real life decision making problems.
S. Dey,Cancelable Fingerprint Template Generation and Matching,"This paper proposes a cancelable fingerprint template generation and matching method. The method involves two tasks: matrix generation and co-prime mapping. The feature matrix is mapped into a high-dimensional matrix to derive the protected template. Co-prime mapping is used to map the feature matrix without overlapping. The method is evaluated using four datasets of FVC2002 database and achieves an EER of 1.82, 1.39, 4.02, and 5.77 for DB1, DB2, DB3, and DB4, respectively.","Template protection, Fingerprint verification, Biometric, Cancelable Fingerprint Template, Co-prime Mapping, Fingerprint Matching",A novel cancelable fingerprint template generation method based on coprime mapping transformation is proposed. The method divides the fingerprint region into sectors with respect to each minutiae point and identifies the nearest-neighbor minutiae in each sector. Ridge-based features for all minutiae points are computed and mapped onto co-prime positions of a random matrix to generate the cancelable template.
S. Du,Cost Eﬀective Inﬂuence Maximisation,"In the context of virality prediction, many researchers have leveraged the existence of a core-periphery structure in a network to identify the super-spreaders of information. Topologically, the nodes in the core of a network are the most eﬃcient spreaders. However, these nodes are less susceptible, i.e., unlikely to be inﬂuenced by the periphery nodes. Consequently, large payoﬀs are required to market information (ideas, products, memes, etc.) via them. In this paper, we show the presence of several non-core nodes whose spreading power is close to that of the core nodes.","Virality, Inﬂuence maximisation, Information diﬀusion, cost-effective, Core-periphery structure, information diffusion, social networks, influence maximisation","This paper proposes a cost-eﬀective strategy to make a meme reach the super-spreaders without the need for global information. The proposed hill-climbing based strategy can be eﬀectively used with both, global as well as local characteristics of the nodes in a network. In terms of the cost metric, it outperforms the conventional independent cascade model by more than 5 times for the core and 2 times for the non-core super-spreaders."
S. H. Leung,Unique Local Features in Lip Images for Recognition,"The experiments are carried out from images taken with a camera that is used for the regular use. And the color features of a lip are not explored in the proposed research. Still the recognition system exploits the grayscale local features of a lip images and eﬃciently matches it with local features of another lip image. If the color properties of a lip image is explored for recognition along with local features, the accuracy values would increase further.","grayscale features, Lip Pattern Recognition, SIFT, lip recognition, color features, Biometric, Local Feature Extraction, local features, SURF",The paper presents the results of experiments on lip recognition using local features. The recognition system exploits the grayscale local features of lip images and achieves high accuracy. The authors suggest that exploring color properties of lip images could further improve the accuracy.
S. K. Goyal,"A Bi-Objective Fuzzy Transportation Problem with Vehicle Cost, Volume and Weight Capacity ||| A Framework for Prioritizing Attributes in Selecting and Evaluating Automation Projects","Generally, in transportation problem, full vehicles (e.g., light commercial vehicles, medium duty and heavy duty trucks, etc.) are to be booked, and transportation cost of a vehicle has to be paid irrespective of the fulülment of the capacity of the vehicle. Besides the transportation cost, total time that includes travel time of a vehicle, loading and unloading times of products is also an important issue. Also, instead of a single item, diðerent types of items may need to be transported from some sources to destinations through diðerent types of conveyances. The optimal transportation policy may be aðected by many other issues like volume and weight of per unit of product, unavailability of suðicient number of certain types of vehicles, etc. ||| This paper presents a framework for prioritizing attributes in selecting and evaluating automation projects. The framework involves identifying a group of professionals, identifying attributes, supplying the selected attributes to the professionals, and deriving goals. The framework is illustrated in Figure 1. The application of the framework in the Indian industry is explained in the following sections. An Indian survey was conducted to identify the potential attributes relating to Indian manufacturing industry and to use the framework to obtain a list of prioritized attributes.","Credibility theory, project evaluation, bi-objective optimization, Chance-constrained programming, fuzzy programming technique, Indian Manufacturing Industry, factory automation, Solid transportation problem, fuzzy transportation problem, Attribute Prioritization, Automation Projects, Indian survey","The paper presents a bi-objective fuzzy transportation problem with vehicle cost, volume and weight capacity. The problem is formulated as a fuzzy linear programming problem and solved using the fuzzy programming technique. The results show that the fuzzy programming technique can be used to solve bi-objective fuzzy transportation problems effectively. ||| The paper presents a framework for prioritizing attributes in selecting and evaluating automation projects. The framework involves identifying a group of professionals, identifying attributes, supplying the selected attributes to the professionals, and deriving goals. The framework is illustrated in Figure 1. The application of the framework in the Indian industry is explained in the following sections. An Indian survey was conducted to identify the potential attributes relating to Indian manufacturing industry and to use the framework to obtain a list of prioritized attributes."
S. K. Gupta,"A Bi-Objective Fuzzy Transportation Problem with Vehicle Cost, Volume and Weight Capacity","Generally, in transportation problem, full vehicles (e.g., light commercial vehicles, medium duty and heavy duty trucks, etc.) are to be booked, and transportation cost of a vehicle has to be paid irrespective of the fulülment of the capacity of the vehicle. Besides the transportation cost, total time that includes travel time of a vehicle, loading and unloading times of products is also an important issue. Also, instead of a single item, diðerent types of items may need to be transported from some sources to destinations through diðerent types of conveyances. The optimal transportation policy may be aðected by many other issues like volume and weight of per unit of product, unavailability of suðicient number of certain types of vehicles, etc.","Credibility theory, bi-objective optimization, Chance-constrained programming, fuzzy programming technique, Solid transportation problem, fuzzy transportation problem","The paper presents a bi-objective fuzzy transportation problem with vehicle cost, volume and weight capacity. The problem is formulated as a fuzzy linear programming problem and solved using the fuzzy programming technique. The results show that the fuzzy programming technique can be used to solve bi-objective fuzzy transportation problems effectively."
S. K. Pal et al.,Deep learning in multi-object detection and tracking: state of the art,"Object detection and tracking is one of the most important and challenging branches in computer vision, and have been widely applied in various fields, such as health-care monitoring, autonomous driving, anomaly detection, and so on. With the rapid development of deep learning (DL) networks and GPU’s computing power, the performance of object detectors and trackers has been greatly improved. To understand the main development status of object detection and tracking pipeline thoroughly, in this survey, we have critically analyzed the existing DL network-based methods of object detection and tracking and described various benchmark datasets. This includes the recent development in granulated DL models. Primarily, we have provided a comprehensive overview of a variety of both generic object detection and specific object detection models. We have enlisted various comparative results for obtaining the best detector, tracker, and their combination. Moreover, we have listed the traditional and new applications of object detection and tracking showing its developmental trends. Finally, challenging issues, including the relevance of granular computing, in the said domain are elaborated as a future scope of research, together with some concerns. An extensive bibliography is also provided.","Multi-object tracking, Deep learning, Video analysis, Multi-object detection, Object tracking, Deep learning (DL), Granular computing, Object detection, Machine learning","This paper provides a comprehensive overview of the current state of object detection and tracking using deep learning (DL) networks. It discusses the rapid development of DL networks and GPU’s computing power, which has greatly improved the performance of object detectors and trackers. The paper also provides a critical analysis of existing DL network-based methods of object detection and tracking, and describes various benchmark datasets. It highlights the recent development in granulated DL models and provides a comprehensive overview of generic and specific object detection models. The paper also discusses the traditional and new applications of object detection and tracking, and elaborates on the challenging issues in the domain, including the relevance of granular computing."
S. K. Singh,Automatic Modulation Classiﬁcation using S-transform based Features ||| Grey Wolf Optimization Algorithm for Economic Load Dispatch,"Automatic Modulation Classiﬁcation plays a signif-icant role in Cognitive Radio to identify the modulation format of the primary user. In this paper, we present the Stockwell trans-form (S-transform) based features extraction for classiﬁcation of different digital modulation schemes using different classiﬁers such as Neural Network (NN), Support Vector Machine (SVM), Linear Discriminant Analysis (LDA), Naive Bayes (NB), k-Nearest Neighbor (k-NN). The S - transform provides time-frequency or spatial-frequency localization of a signal. This property of S-transform gives good discriminant features for different mod-ulation schemes. ||| This article presents a new evolutionary optimization approach named grey wolf optimization (GWO), which is based on the behaviour of grey wolves, for the optimal operating strategy of economic load dispatch (ELD). Nonlinear characteristics of generators like ramp rate limits, valve point discontinuities and prohibited operating zones are considered in the problem. GWO method does not require any information about the gradient of the objective function, while searching for an optimum solution. The GWO algorithm concept, appears to be a robust and reliable optimization algorithm is applied to the nonlinear ELD problems. The proposed algorithm is implemented and tested on four test systems having 10, 40, 80 and 140 units. The results confirm the potential and effectiveness of the proposed algorithm compared to various other methods available in the literature. The outcome is very encouraging and proves that the GWO is a very effective optimization technique for solving various ELD problems.","k-Nearest Neighbor, Grey wolf optimization, Economic load dispatch, Naive Bayes, Evolutionary algorithm, Cognitive Radio, digital modulation schemes, classification, Automatic Modulation Classiﬁcation, Linear Discriminant Analysis, AMC, Neural Network, Valve point loading, Prohibited zone, Support Vector Machine, Power Systems, S-transform","This paper presents a method for automatic modulation classiﬁcation using S-transform based features. The method uses different classiﬁers such as Neural Network, Support Vector Machine, Linear Discriminant Analysis, Naive Bayes, and k-Nearest Neighbor to classify different digital modulation schemes. The results are compared with wavelet transform based features and show that S-transform based features outperform wavelet transform based features with better classiﬁcation accuracy and less computational complexity. ||| The article presents a new evolutionary optimization approach named grey wolf optimization (GWO) for the optimal operating strategy of economic load dispatch (ELD). The GWO algorithm concept is applied to the nonlinear ELD problems and tested on four test systems. The results confirm the potential and effectiveness of the proposed algorithm compared to various other methods available in the literature."
S. K. Sunkara,Micro-Computed tomography (CT) based assessment of dental regenerative therapy in the canine mandible model,"High-resolution 3D bone-tissue structure measurements may provide information critical to the understanding of the bone regeneration processes and to the bone strength assessment. Tissue engineering studies rely on such nondestructive measurements to monitor bone graft regeneration area. In this study, we measured bone yield, fractal dimension and trabecular thickness through micro-CT slices for different grafts and controls. Eight canines underwent surgery to remove a bone volume (defect) in the canine’s jaw at a total of 44 different locations. We kept 11 defects empty for control and filled the remaining ones with three regenerative materials; NanoGen (NG), a FDA-approved material (n=11), a novel NanoCalcium Sulfate (NCS) material (n=11) and NCS alginate (NCS+alg) material (n=11). After a minimum of four and eight weeks, the canines were sacrificed and the jaw samples were extracted. We used a custom-built micro-CT system to acquire the data volume and developed software to measure the bone yield, fractal dimension and trabecular thickness. The software used a segmentation algorithm based on histograms derived from volumes of interest indicated by the operator. Using bone yield and fractal dimension as indices we are able to differentiate between the control and regenerative material (p<0.005). Regenerative material NCS showed an average 63.15% bone yield improvement over the control sample, NCS+alg showed 55.55% and NanoGen showed 37.5%. The bone regeneration process and quality of bone were dependent upon the position of defect and time period of healing. This study presents one of the first quantitative comparisons using non-destructive Micro-CT analysis for bone regenerative material in a large animal with a critical defect model. Our results indicate that Micro-CT measurement could be used to monitor in-vivo bone regeneration studies for greater regenerative process understanding.","Regenerative Materials, Quantitative Analysis, Bone Regeneration, Micro-CT, LabVIEW","This study investigates the effectiveness of three different bone regenerative materials (NanoGen, NanoCalcium Sulfate, and NanoCalcium Sulfate alginate) in a canine mandible model using micro-computed tomography (micro-CT). The study found that all three materials significantly improved bone regeneration compared to the control group. NanoCalcium Sulfate showed the most significant improvement, followed by NanoCalcium Sulfate alginate and NanoGen. The position of the defect and the healing time period were also found to influence the regeneration process."
S. Kohli,Trust evaluation of websites: a comprehensive study,"People rely heavily on internet to fulfil even the minuscule of their need. According to a survey, 41% of time spent on web is for finding some information from search engines or reading some information. This is majorly due to easily accessible, cost effective and perceived high value information. But, this perceived high value information can prove fatal, if consumed without any authoritarian checks; especially if related to issues like health. Some template is necessitated to measure trustworthiness of such information. This paper explores a novel approach to quantify trust in such information-led websites. Analytical data is collected for various informational websites using similarweb.com and trust is modelled for these websites using human behaviour as an aggregate. Analytical data is believed to capture actual behaviour of each and every visitor visiting the website for information; thus making the study reliable and dependable. Results have been compared with some other acceptable studies and have found to be encouraging.","user satisfaction, medical trust, online interaction, health information, web analytics, trustworthiness, search engine optimization, web trust, social networks, content trust, trust","The paper discusses the concept of trust in social networks and its application in evaluating the trustworthiness of websites. It explores various aspects of trust, including its propagative nature, aggregative nature, subjective nature, asymmetric nature, and self-reinforcing nature. The authors also examine different approaches to trust representation, information sources, and trust evaluation models. The paper concludes by highlighting the importance of trust in search engine optimization and proposes a methodology for quantifying trust using web analytical tools."
S. Kundu,"A Bi-Objective Fuzzy Transportation Problem with Vehicle Cost, Volume and Weight Capacity","Generally, in transportation problem, full vehicles (e.g., light commercial vehicles, medium duty and heavy duty trucks, etc.) are to be booked, and transportation cost of a vehicle has to be paid irrespective of the fulülment of the capacity of the vehicle. Besides the transportation cost, total time that includes travel time of a vehicle, loading and unloading times of products is also an important issue. Also, instead of a single item, diðerent types of items may need to be transported from some sources to destinations through diðerent types of conveyances. The optimal transportation policy may be aðected by many other issues like volume and weight of per unit of product, unavailability of suðicient number of certain types of vehicles, etc.","Credibility theory, bi-objective optimization, Chance-constrained programming, fuzzy programming technique, Solid transportation problem, fuzzy transportation problem","The paper presents a bi-objective fuzzy transportation problem with vehicle cost, volume and weight capacity. The problem is formulated as a fuzzy linear programming problem and solved using the fuzzy programming technique. The results show that the fuzzy programming technique can be used to solve bi-objective fuzzy transportation problems effectively."
S. M. Atalla,Secure Robust and Imperceptible Algorithm for Watermarking Relational Databases,"This paper proposes a secure robust and imperceptible algorithm for watermarking relational databases. The algorithm divides the embedding algorithm into three phases: Watermark preparator, watermark position detector, and watermark embedder. The ownership identification issue is resolved by embedding owner's identity as watermark in Preparator phase.","imperceptible algorithm, Ownership identification, robust algorithm, Relational Database, watermarking, Watermark, Copyright protection, Proof of ownership, relational databases","The paper proposes a new robust secure and imperceptible embedding mechanism to resolve the two important concerns namely; owner identification and proof of ownership. The proposed mechanism involves encoding and decoding on numerical attribute of relational database in three phases; 1)Watermark preparator, 2)Watermark position detector and 3) Watermark Embedder or Detector."
S. Mitra,Gesture Recognition,"Hand Gesture detection is now getting a lot of attention because it has a lot of uses and the specialty to connect with machines around efficiently by human interaction to computers. In this we are trying to make a knowhow of hand gesture detection system. The problems of hand gesture detection system are also discussed in this. Conclusion of results, methods, data and difference between different phases are also mentioned. Pros and cons are also discussed. In this project we are trying to understand how the image processing works and how can we use it to make a hand gesture detection system so that we can operate the computer without any physical contact with the machine itself. There are many researches that are done before and are still undergoing. Many big companies are currently working on this technology so that they can make their products even more useful that they are now because this technology has very high scope in the upcoming future. The people that are not mentally stable or weak from mind can also benefit by technology and can operate the computer. We can use this technology to make the computer even more accessible for humans.","Feature Extract, Tools for classification, Neural Networks, Posture of Hand, Gesture, Interaction of human with computer (HCI), Phases of recognition, brightness factor matching, fuzzy c-means clustering algorithm, gesture recognition",The main motive to build a hand gesture detection system is to make an interaction between human and computer that can be done by recognizing gestures for controlling robots or a simple computer. How do we make this system is understood and interpreted by the computer. The interaction of humans with computer is also called as man-machine interaction (MMI). Since A computer is insignificant if it not being utilized by human. There are some features that should be looked before we design this system. The function of the system and the use of the system. Function means the things that the system gives to its user and use means the scope of the system that it can be used efficiently. The system which has these both properties is known as powerful system.
S. Nagaraju,Mobility assisted localization for mission critical Wireless Sensor Network applications using hybrid area exploration approach,"This paper discusses the mobility-assisted localization in wireless sensor networks. The proposed localization scheme employs a distributed localization scheme based on RSSI and path-loss model. The mobility model is classified into four categories, and the proposed scheme employs the third category, where mobile anchor nodes are used to localize static sensor nodes. The path planning model is further divided into static and dynamic path planning. The static path planning model requires terrain information beforehand, while the dynamic path planning scheme determines the path dynamically based on the demands and density of the unknown nodes.","Localization, Frontier, path-loss model, Area exploration algorithm, Mobility model, mobility-assisted localization, path planning, RSSI, Max-gain, Wireless sensor networks","The paper proposes a mobility-assisted localization scheme for wireless sensor networks, which employs a distributed localization scheme based on RSSI and path-loss model. The scheme uses mobile anchor nodes to localize static sensor nodes and employs a path planning model to determine the trajectory of the mobile anchor nodes. The paper discusses the advantages and drawbacks of the proposed scheme and compares it with other existing schemes."
S. Nedunuri et al.,Investigation of Crack Properties Using Image Processing: An User Interface,"This research work focuses on processing the images of concrete walls to identify cracks with the help of a Graphic User Interface (GUI) created using MATLAB Guide. The developed GUI gives the length, width and type of the crack as outputs to an input image of a concrete wall. It uses image processing techniques to arrive at the output.","GUI, Image processing, Cracks, crack detection, Length and width of the crack, Cracks on concrete walls, Crack detection GUI","The paper proposes a technique to identify cracks in concrete walls using image processing and a Graphic User Interface (GUI). The GUI is developed using MATLAB Guide and gives the length, width and type of the crack as outputs to an input image of a concrete wall. The accuracy of the technique is 92.947% for length and 78.09% for width."
S. P. Borgatti,Cost Eﬀective Inﬂuence Maximisation,"In the context of virality prediction, many researchers have leveraged the existence of a core-periphery structure in a network to identify the super-spreaders of information. Topologically, the nodes in the core of a network are the most eﬃcient spreaders. However, these nodes are less susceptible, i.e., unlikely to be inﬂuenced by the periphery nodes. Consequently, large payoﬀs are required to market information (ideas, products, memes, etc.) via them. In this paper, we show the presence of several non-core nodes whose spreading power is close to that of the core nodes.","Virality, Inﬂuence maximisation, Information diﬀusion, cost-effective, Core-periphery structure, information diffusion, social networks, influence maximisation","This paper proposes a cost-eﬀective strategy to make a meme reach the super-spreaders without the need for global information. The proposed hill-climbing based strategy can be eﬀectively used with both, global as well as local characteristics of the nodes in a network. In terms of the cost metric, it outperforms the conventional independent cascade model by more than 5 times for the core and 2 times for the non-core super-spreaders."
S. Parui,YASS: Yet Another Suﬃx Stripper,"This paper presents a set of string distance measures for clustering the lexicon. The main intuition behind defining these distances was to reward long matching prefixes, and to penalize an early mismatch.","string distance measures, morphological variants, information retrieval, resource-poor languages, clustering, lexicon clustering, Bengali language, equivalence classes, stemming","The paper proposes a set of string distance measures for clustering words into homogeneous groups, with the goal of representing an equivalence class consisting of morphological variants of a single root word."
S. R. S. Iyengar,Modeling Memetics using Edge Diversity,"The study of meme propagation and the prediction of meme trajectory are emerging areas of interest in the field of complex networks research. In addition to the properties of the meme itself, the structural properties of the underlying network decides the speed and the trajectory of the propagating meme.","meme virality, information propagation, meme propagation models, meme propagation, social network analysis, complex networks research, social networks, viral marketing, influence maximisation",The paper proposes a framework for studying meme propagation patterns using a synthetic network and a spreading model based on the diversity of edges in the network. The framework is validated against the real-world spreading of the Higgs boson meme on Twitter.
S. Ramakrishnan,Wireless Sensor Networks: From Theory to Applications,"This book contains information obtained from authentic and highly regarded sources. Reasonable efforts have been made to publish reliable data and information, but the author and publisher cannot assume responsibility for the validity of all materials or the consequences of their use.","Quality of Services, Applications, Wireless Sensor Networks, Theory, WSNs","The book focuses on the quality of services in wireless sensor networks, covering various aspects such as data collection, aggregation, and spatial coverage, physical layer and interfacing, routing and transport protocols, and energy-saving approaches."
S. Rudin,Micro-Computed tomography (CT) based assessment of dental regenerative therapy in the canine mandible model,"High-resolution 3D bone-tissue structure measurements may provide information critical to the understanding of the bone regeneration processes and to the bone strength assessment. Tissue engineering studies rely on such nondestructive measurements to monitor bone graft regeneration area. In this study, we measured bone yield, fractal dimension and trabecular thickness through micro-CT slices for different grafts and controls. Eight canines underwent surgery to remove a bone volume (defect) in the canine’s jaw at a total of 44 different locations. We kept 11 defects empty for control and filled the remaining ones with three regenerative materials; NanoGen (NG), a FDA-approved material (n=11), a novel NanoCalcium Sulfate (NCS) material (n=11) and NCS alginate (NCS+alg) material (n=11). After a minimum of four and eight weeks, the canines were sacrificed and the jaw samples were extracted. We used a custom-built micro-CT system to acquire the data volume and developed software to measure the bone yield, fractal dimension and trabecular thickness. The software used a segmentation algorithm based on histograms derived from volumes of interest indicated by the operator. Using bone yield and fractal dimension as indices we are able to differentiate between the control and regenerative material (p<0.005). Regenerative material NCS showed an average 63.15% bone yield improvement over the control sample, NCS+alg showed 55.55% and NanoGen showed 37.5%. The bone regeneration process and quality of bone were dependent upon the position of defect and time period of healing. This study presents one of the first quantitative comparisons using non-destructive Micro-CT analysis for bone regenerative material in a large animal with a critical defect model. Our results indicate that Micro-CT measurement could be used to monitor in-vivo bone regeneration studies for greater regenerative process understanding.","Regenerative Materials, Quantitative Analysis, Bone Regeneration, Micro-CT, LabVIEW","This study investigates the effectiveness of three different bone regenerative materials (NanoGen, NanoCalcium Sulfate, and NanoCalcium Sulfate alginate) in a canine mandible model using micro-computed tomography (micro-CT). The study found that all three materials significantly improved bone regeneration compared to the control group. NanoCalcium Sulfate showed the most significant improvement, followed by NanoCalcium Sulfate alginate and NanoGen. The position of the defect and the healing time period were also found to influence the regeneration process."
S. Rudina,Quantitative Comparison of a High Resolution Micro-Angiographic Fluoroscopic (MAF) Detector with a Standard Flat Panel Detector (FPD) Using the New Metric of Generalized Measured Relative Object Detectability (GM-ROD),"A novel amorphous selenium (a-Se) direct detector with CMOS readout has been designed, and relative detector performance investigated. The detector features include a 25μm pixel pitch, and 1000μm thick a-Se layer operating at 10V/μm bias field. A simulated detector DQE was determined, and used in comparative calculations of the Relative Object Detectability (ROD) family of prewhitening matched-filter (PWMF) observer and non-prewhitening matched filter (NPWMF) observer model metrics to gauge a-Se detector performance against existing high resolution micro-angiographic fluoroscopic (MAF) detectors and a standard flat panel detector (FPD). The PWMF-ROD or ROD metric compares two x-ray imaging detectors in their relative abilities in imaging a given object by taking the integral over spatial frequencies of the Fourier transform of the detector DQE weighted by an object function, divided by the comparable integral for a different detector. The generalized-ROD (G-ROD) metric incorporates clinically relevant parameters (focal-spot size, magnification, and scatter) to show the degradation in imaging performance for detectors that are part of an imaging chain. Preliminary ROD calculations using simulated spheres as the object predicted superior imaging performance by the a-Se detector as compared to existing detectors. New PWMF-G-ROD and NPWMF-G-ROD results still indicate better performance by the a-Se detector in an imaging chain over all sphere sizes for various focal spot sizes and magnifications, although a-Se performance advantages were degraded by focal spot blurring. Nevertheless, the a-Se technology has great potential to provide breakthrough abilities such as visualization of fine details including of neuro-vascular perforator vessels and of small vascular devices.","Comparative metrics, generalized metrics, micro-angiography, DQE, Detector Performance, relative object detectability, Microangiography, CMOS, Flat Panel Detector, amorphous selenium","This paper presents a comparative study of a novel amorphous selenium (a-Se) direct detector with existing high resolution micro-angiographic fluoroscopic (MAF) detectors and a standard flat panel detector (FPD). The study utilizes the Relative Object Detectability (ROD) family of metrics, including the generalized-ROD (G-ROD) metric, to assess the performance of these detectors in imaging small objects.  The results indicate that the a-Se detector exhibits superior imaging performance compared to existing detectors, particularly in terms of resolving fine details.  While focal spot blurring can degrade the performance advantage of the a-Se detector, its potential for breakthrough imaging capabilities in neuro-vascular applications is highlighted."
S. S. Iyengar,Adaptive Type-2 Fuzzy Approach for Filtering Salt and Pepper Noise in Grayscale Images ||| Data Mining Through Linked Data and APIs,"This paper presents a novel approach for removing salt and pepper noise from images using Type-2 fuzzy filter. The proposed approach uses two different methods for designing the upper and lower membership functions of the Type-2 fuzzy set. The first method uses distinct means and same variance, while the second method uses distinct means and variances. The proposed approach is compared with the existing methods using various images and the results show that it outperforms the existing methods in terms of noise removal and image quality. ||| Linked Data has emerged as a popular method for representing structured data. One of the prime aims is to convert today’s web of documents into a web of data where the data is machine-readable as well as processable. This research paper focuses on the data mining techniques used for mining the raw data. However, these techniques are cumbersome and can be optimized using Linked Data. Hence, we discuss the data mining techniques with Linked Data that may play a pivotal role in future in extracting meaningful information from unstructured or semi-structured data.","membership functions, peak signal-noise-ratio (PSNR), Type-2 fuzzy filter, Linked Data, Social Media Data Mining, Web of Data, Type-1 fuzzy set, image denoising, Data Mining, Type-2 fuzzy set, Knowledge Discovery, Semantic Web, APIs, KDD, salt and pepper noise, Mean of k-middle","The proposed approach uses a Type-2 fuzzy filter to remove salt and pepper noise from images. The filter uses two different methods for designing the upper and lower membership functions of the Type-2 fuzzy set. The first method uses distinct means and same variance, while the second method uses distinct means and variances. The proposed approach is compared with the existing methods using various images and the results show that it outperforms the existing methods in terms of noise removal and image quality. ||| The paper explores the application of Linked Data and APIs in data mining, presenting a six-step process for knowledge discovery and discussing the Linked Data Application Architecture (LDAA) and its limitations. It proposes an improved architecture using APIs and presents an example of the Open PHACTS platform. The paper also discusses the use of tools for mining the web of Linked Data and social media analytics using Linked Data."
S. S. Iyer,Automatic Modulation Classiﬁcation using S-transform based Features,"Automatic Modulation Classiﬁcation plays a signif-icant role in Cognitive Radio to identify the modulation format of the primary user. In this paper, we present the Stockwell trans-form (S-transform) based features extraction for classiﬁcation of different digital modulation schemes using different classiﬁers such as Neural Network (NN), Support Vector Machine (SVM), Linear Discriminant Analysis (LDA), Naive Bayes (NB), k-Nearest Neighbor (k-NN). The S - transform provides time-frequency or spatial-frequency localization of a signal. This property of S-transform gives good discriminant features for different mod-ulation schemes.","k-Nearest Neighbor, Naive Bayes, Cognitive Radio, digital modulation schemes, classification, Automatic Modulation Classiﬁcation, Linear Discriminant Analysis, AMC, Neural Network, Support Vector Machine, S-transform","This paper presents a method for automatic modulation classiﬁcation using S-transform based features. The method uses different classiﬁers such as Neural Network, Support Vector Machine, Linear Discriminant Analysis, Naive Bayes, and k-Nearest Neighbor to classify different digital modulation schemes. The results are compared with wavelet transform based features and show that S-transform based features outperform wavelet transform based features with better classiﬁcation accuracy and less computational complexity."
S. S. Rao,Parameter Extraction of Photovoltaic Module Using BFO Algorithm,"This paper presents a new parameter extraction method for photovoltaic modules exploiting Bacterial Foraging Optimization (BFO) technique. In a PV system, validation of the model of a PV module with correctly chosen parameters is essential. An efficient parameter extraction method is required to estimate the parameters of PV module.","evolutionary techniques, BFO, PV module parameters, photovoltaic module, Newton-Raphson method, parameter extraction, PSO, BFO algorithm","The proposed BFO based parameter extraction method has been tested for different types of PV modules at different test conditions. Analyzing both the simulation and experimental results obtained using BFO; it is found that the module parameters are more accurate compared to that of Newton-Raphson, Particle Swarm Optimization and Enhanced Simulated Annealing methods."
S. Senthilkumar,Adaptive Type-2 Fuzzy Approach for Filtering Salt and Pepper Noise in Grayscale Images,"This paper presents a novel approach for removing salt and pepper noise from images using Type-2 fuzzy filter. The proposed approach uses two different methods for designing the upper and lower membership functions of the Type-2 fuzzy set. The first method uses distinct means and same variance, while the second method uses distinct means and variances. The proposed approach is compared with the existing methods using various images and the results show that it outperforms the existing methods in terms of noise removal and image quality.","membership functions, peak signal-noise-ratio (PSNR), Type-2 fuzzy filter, Type-1 fuzzy set, image denoising, Type-2 fuzzy set, salt and pepper noise, Mean of k-middle","The proposed approach uses a Type-2 fuzzy filter to remove salt and pepper noise from images. The filter uses two different methods for designing the upper and lower membership functions of the Type-2 fuzzy set. The first method uses distinct means and same variance, while the second method uses distinct means and variances. The proposed approach is compared with the existing methods using various images and the results show that it outperforms the existing methods in terms of noise removal and image quality."
S. Sunkara,Micro-Computed tomography (CT) based assessment of dental regenerative therapy in the canine mandible model,"High-resolution 3D bone-tissue structure measurements may provide information critical to the understanding of the bone regeneration processes and to the bone strength assessment. Tissue engineering studies rely on such nondestructive measurements to monitor bone graft regeneration area. In this study, we measured bone yield, fractal dimension and trabecular thickness through micro-CT slices for different grafts and controls. Eight canines underwent surgery to remove a bone volume (defect) in the canine’s jaw at a total of 44 different locations. We kept 11 defects empty for control and filled the remaining ones with three regenerative materials; NanoGen (NG), a FDA-approved material (n=11), a novel NanoCalcium Sulfate (NCS) material (n=11) and NCS alginate (NCS+alg) material (n=11). After a minimum of four and eight weeks, the canines were sacrificed and the jaw samples were extracted. We used a custom-built micro-CT system to acquire the data volume and developed software to measure the bone yield, fractal dimension and trabecular thickness. The software used a segmentation algorithm based on histograms derived from volumes of interest indicated by the operator. Using bone yield and fractal dimension as indices we are able to differentiate between the control and regenerative material (p<0.005). Regenerative material NCS showed an average 63.15% bone yield improvement over the control sample, NCS+alg showed 55.55% and NanoGen showed 37.5%. The bone regeneration process and quality of bone were dependent upon the position of defect and time period of healing. This study presents one of the first quantitative comparisons using non-destructive Micro-CT analysis for bone regenerative material in a large animal with a critical defect model. Our results indicate that Micro-CT measurement could be used to monitor in-vivo bone regeneration studies for greater regenerative process understanding.","Regenerative Materials, Quantitative Analysis, Bone Regeneration, Micro-CT, LabVIEW","This study investigates the effectiveness of three different bone regenerative materials (NanoGen, NanoCalcium Sulfate, and NanoCalcium Sulfate alginate) in a canine mandible model using micro-computed tomography (micro-CT). The study found that all three materials significantly improved bone regeneration compared to the control group. NanoCalcium Sulfate showed the most significant improvement, followed by NanoCalcium Sulfate alginate and NanoGen. The position of the defect and the healing time period were also found to influence the regeneration process."
S. Suresh,Adaptive Type-2 Fuzzy Approach for Filtering Salt and Pepper Noise in Grayscale Images,"This paper presents a novel approach for removing salt and pepper noise from images using Type-2 fuzzy filter. The proposed approach uses two different methods for designing the upper and lower membership functions of the Type-2 fuzzy set. The first method uses distinct means and same variance, while the second method uses distinct means and variances. The proposed approach is compared with the existing methods using various images and the results show that it outperforms the existing methods in terms of noise removal and image quality.","membership functions, peak signal-noise-ratio (PSNR), Type-2 fuzzy filter, Type-1 fuzzy set, image denoising, Type-2 fuzzy set, salt and pepper noise, Mean of k-middle","The proposed approach uses a Type-2 fuzzy filter to remove salt and pepper noise from images. The filter uses two different methods for designing the upper and lower membership functions of the Type-2 fuzzy set. The first method uses distinct means and same variance, while the second method uses distinct means and variances. The proposed approach is compared with the existing methods using various images and the results show that it outperforms the existing methods in terms of noise removal and image quality."
S. Tyagi,Adopting Test Automation on Agile Development Projects,This paper discusses the adoption of test automation on agile development projects. The authors conducted a study on 35 participants from various agile projects and analyzed their data using the Grounded Theory method. The study identified the core category of 'Adopting Test Automation' and its related categories such as 'Quality work delivery' and 'Manage changing requirements'. The authors also presented an example of the open coding process and selective coding process used in the study.,"Test driven development, Agile Development, Test automation, Quality Work Delivery, Manage Changing Requirements, Agile software development, Grounded theory",The study aimed to explore the adoption of test automation on agile development projects. The authors used the Grounded Theory method to analyze the data collected from 35 participants. The study identified the core category of 'Adopting Test Automation' and its related categories. The authors also presented an example of the open coding process and selective coding process used in the study.
S. V. Setlur Nagesh,Micro-Computed tomography (CT) based assessment of dental regenerative therapy in the canine mandible model,"High-resolution 3D bone-tissue structure measurements may provide information critical to the understanding of the bone regeneration processes and to the bone strength assessment. Tissue engineering studies rely on such nondestructive measurements to monitor bone graft regeneration area. In this study, we measured bone yield, fractal dimension and trabecular thickness through micro-CT slices for different grafts and controls. Eight canines underwent surgery to remove a bone volume (defect) in the canine’s jaw at a total of 44 different locations. We kept 11 defects empty for control and filled the remaining ones with three regenerative materials; NanoGen (NG), a FDA-approved material (n=11), a novel NanoCalcium Sulfate (NCS) material (n=11) and NCS alginate (NCS+alg) material (n=11). After a minimum of four and eight weeks, the canines were sacrificed and the jaw samples were extracted. We used a custom-built micro-CT system to acquire the data volume and developed software to measure the bone yield, fractal dimension and trabecular thickness. The software used a segmentation algorithm based on histograms derived from volumes of interest indicated by the operator. Using bone yield and fractal dimension as indices we are able to differentiate between the control and regenerative material (p<0.005). Regenerative material NCS showed an average 63.15% bone yield improvement over the control sample, NCS+alg showed 55.55% and NanoGen showed 37.5%. The bone regeneration process and quality of bone were dependent upon the position of defect and time period of healing. This study presents one of the first quantitative comparisons using non-destructive Micro-CT analysis for bone regenerative material in a large animal with a critical defect model. Our results indicate that Micro-CT measurement could be used to monitor in-vivo bone regeneration studies for greater regenerative process understanding.","Regenerative Materials, Quantitative Analysis, Bone Regeneration, Micro-CT, LabVIEW","This study investigates the effectiveness of three different bone regenerative materials (NanoGen, NanoCalcium Sulfate, and NanoCalcium Sulfate alginate) in a canine mandible model using micro-computed tomography (micro-CT). The study found that all three materials significantly improved bone regeneration compared to the control group. NanoCalcium Sulfate showed the most significant improvement, followed by NanoCalcium Sulfate alginate and NanoGen. The position of the defect and the healing time period were also found to influence the regeneration process."
S. V. Setlur Nagesha,Quantitative Comparison of a High Resolution Micro-Angiographic Fluoroscopic (MAF) Detector with a Standard Flat Panel Detector (FPD) Using the New Metric of Generalized Measured Relative Object Detectability (GM-ROD),"A novel amorphous selenium (a-Se) direct detector with CMOS readout has been designed, and relative detector performance investigated. The detector features include a 25μm pixel pitch, and 1000μm thick a-Se layer operating at 10V/μm bias field. A simulated detector DQE was determined, and used in comparative calculations of the Relative Object Detectability (ROD) family of prewhitening matched-filter (PWMF) observer and non-prewhitening matched filter (NPWMF) observer model metrics to gauge a-Se detector performance against existing high resolution micro-angiographic fluoroscopic (MAF) detectors and a standard flat panel detector (FPD). The PWMF-ROD or ROD metric compares two x-ray imaging detectors in their relative abilities in imaging a given object by taking the integral over spatial frequencies of the Fourier transform of the detector DQE weighted by an object function, divided by the comparable integral for a different detector. The generalized-ROD (G-ROD) metric incorporates clinically relevant parameters (focal-spot size, magnification, and scatter) to show the degradation in imaging performance for detectors that are part of an imaging chain. Preliminary ROD calculations using simulated spheres as the object predicted superior imaging performance by the a-Se detector as compared to existing detectors. New PWMF-G-ROD and NPWMF-G-ROD results still indicate better performance by the a-Se detector in an imaging chain over all sphere sizes for various focal spot sizes and magnifications, although a-Se performance advantages were degraded by focal spot blurring. Nevertheless, the a-Se technology has great potential to provide breakthrough abilities such as visualization of fine details including of neuro-vascular perforator vessels and of small vascular devices.","Comparative metrics, generalized metrics, micro-angiography, DQE, Detector Performance, relative object detectability, Microangiography, CMOS, Flat Panel Detector, amorphous selenium","This paper presents a comparative study of a novel amorphous selenium (a-Se) direct detector with existing high resolution micro-angiographic fluoroscopic (MAF) detectors and a standard flat panel detector (FPD). The study utilizes the Relative Object Detectability (ROD) family of metrics, including the generalized-ROD (G-ROD) metric, to assess the performance of these detectors in imaging small objects.  The results indicate that the a-Se detector exhibits superior imaging performance compared to existing detectors, particularly in terms of resolving fine details.  While focal spot blurring can degrade the performance advantage of the a-Se detector, its potential for breakthrough imaging capabilities in neuro-vascular applications is highlighted."
S. Vaithyanathan,Sentiment Analysis of Training Programmes,"Sentiment analysis found various applications in banking, financial, service, and insurance sector. In order to increase return on investment, services industry needs to improve customer satisfaction at any cost.  In this regard, we proposed to analyze customer reviews on the basis of sentiment score. We analyzed a set of credible text reviews collected on 270 training programmes posted by 2688 participants in an organization. In order to evaluate the efficacy of the proposed approach, we computed correlation coefficient between sentiment score obtained from the unstructured reviews and the overall numerical rating assigned by all participants. Further, we employed visualization techniques to visualize different aspects of the programmes.","programme rating, Text Mining, Visualization, Training Programmes, participants' feedback, Customer Reviews, Sentiment analysis","The paper proposes a sentiment analysis approach to analyze customer reviews on the basis of sentiment score. The approach is divided into five sections: data collection, text preprocessing, sentiment score computation, evaluation, and visualization. The paper presents the results of the proposed approach and discusses the future directions of work."
S. Wang,TWO-STAGE AUTHENTICATION FOR WIRELESS NETWORKS USING DUAL SIGNATURE AND SYMMETRIC KEY PROTOCOL,"Wired networks differ from wireless networks in that they can support computationally intensive security protocols, have high bandwidth and offer high reliability. Strong authentication schemes can be applied to wired networks. Wireless networks on the other hand suffer from packet losses and bit errors, often have low bandwidth and have resource constraints such as computation overhead and storage.","Wireless Networks, Security, Symmetric Key Encryption, Authentication, Mutual Authentication, IKE Strong Authentication, Multi-server Environment",This paper proposes a secure dynamic id based remote user authentication scheme for multi-server environment. The scheme uses a dynamic id to authenticate users and provides security against various attacks. The scheme is efficient and can be used in various applications.
S.Chakraverty,Biclustering Algorithm for E-Gov Services,"With the widespread and proactive participation of citizens through various e-governance applications, democracy in the modern era has acquired an entirely new dimension The shear diversity of e-governance users has spurred on a fresh interest in designing adaptable e-governance systems. The first step in meeting this challenge is to develop a fast and versatile automated technique to categorize users on the basis of a similarity in their online identities and behaviors. In this paper we employ a modified version of the Cheng and Church Biclustering algorithm, hitherto used primarily in the field of Genetics, to extend its applicability to a classification of e-governance users. Taking a different route from conventional approaches, we tap a variety of dynamically varying parameters that characterize the online behavior of users with a view to improving the cohesiveness of user clusters. These include the navigation patterns of a user, her access frequency and the interactivity level during her web experience. We adopt two strategies for clustering. A single level strategy categorizes users on all the three parameters taken together using the Cheng and Church (CC) algorithm. We also employ a two level clustering strategy that first finds biclusters on the basis of individual parameters using CC and then the uses cluster ids to classify the users at a second level by and K-Means clustering. An analysis of the granularity of clusters and execution time for different strategies and datasets reveals that the single level strategy is useful in categorizing experienced users who have attained a degree of familiarity with the portal and are able to change their behavior frequently. Such a group of users is quite variegated. On the other hand, the two level strategy provides a better way to classify beginners who show very slow changes and are more uniform in their web interactions.","E-Gov Services, Threshold, single levels strategy and two level strategy, Biclustering, Mean Square Residue, e-governance, CC Biclustering Algorithm","This paper proposes the most appropriate clustering strategies for differently evolving user bases. The users' online behavior is captured with a comprehensive set of attributes including navigation path, frequency of accessing each page and the interactivity level sustained by users during their web interaction. We present a comparative analysis of single level and two level clustering strategies by employing three techniques: Cheng and Church biclustering, K-Means clustering and a combination of the two. Our experiments investigate the impact on execution time, quality and number of clusters when the base dataset of users' web behaviors is changed with minor modifications and major modifications."
S.K. Pal,Object Extraction Based on Rough Entropy,"This paper presents a method of object enhancement/extraction based on the principle of minimizing the roughness of both object and background regions, i.e., maximizing RET. The determination of T* by maximization of rough entropy or minimization of roughness depends on the granule size.","Image segmentation, granule size, Set approximation, Entropy, rough entropy, Rough sets, Granules, object extraction",This paper addresses the problem of image object extraction in the framework of rough sets and granular computing. A measure called 'rough entropy of image' is defined based on the concept of image granules. Its maximization results in minimization of roughness in both object and background regions; thereby determining the threshold of partitioning.
S.R.S. Iyengar,Shifting Behaviour of Users: Towards Understanding the Fundamental Law of Social Networks,"Social Networking Sites (SNSs) are powerful marketing and communication tools. There are hundreds of SNSs that have entered and exited the market over time. The coexistence of multiple SNSs is a rarely observed phenomenon. Most coexisting SNSs either serve different purposes for its users or have cultural differences among them. The introduction of a new SNS with a better set of features can lead to the demise of an existing SNS, as observed in the transition from Orkut to Facebook. The paper proposes a model for analyzing the transition of users from one SNS to another, when a new SNS is introduced in the system. The game theoretic model proposed considers two major factors in determining the success of a new SNS. The first being time that an old SNS gets to stabilise. We study whether the time that a SNS like Facebook received to monopolize its reach had a distinguishable effect. The second factor is the set of features showcased by the new SNS. The results of the model are also experimentally verified with data collected by means of a survey.","game theory, Game Theoretic Model, Diffusive Shift, Social Networking Sites, modeling, social networking, Cascading Pattern",This paper proposes a model for analyzing the transition of users from one Social Networking Site (SNS) to another when a new SNS is introduced in the system. The model considers two major factors in determining the success of a new SNS: the time an old SNS gets to stabilize and the set of features showcased by the new SNS. The results of the model are experimentally verified with data collected by means of a survey.
SABAH TAZEEN,MSGR: A Mode-Switched Grid-Based Sustainable Routing Protocol for Wireless Sensor Networks,"A Wireless Sensor Network (WSN) consists of enormous amount of sensor nodes. These sensor nodes sense the changes in physical parameters from the sensing range and forward the information to the sink nodes or the base station. Since sensor nodes are driven with limited power batteries, prolonging the network lifetime is difficult and very expensive, especially for hostile locations. Therefore, routing protocols for WSN must strategically distribute the dissipation of energy, so as to increase the overall lifetime of the system.","mobile sink, grid-based routing, energy efficiency, grid head, scalability, Wireless sensor networks","The paper presents a comprehensive review of grid-based routing protocols for WSNs, highlighting their design principles, advantages, and limitations. It also proposes a new mode-switched grid-based sustainable routing protocol, which adapts to changing network conditions to conserve energy and improve network lifetime."
SAMBIT BAKSHI,NPReId Framework for Video Surveillance ||| Palmprint Identification Using an Ensemble of Sparse Representations,"This paper presents a neuromorphic person re-identiﬁcation (NPReId) framework to establish the correspondence among individuals observed across two disjoint camera views. The proposed framework comprises three modules (observation, cognition, and contemplation), inspired by the form-and-color-and-depth (FACADE) theory model of object recognition system. ||| Among various palmprint identification methods proposed in the literature, sparse representation for classification (SRC) is very attractive offering high accuracy. Although SRC has good discriminative ability, its performance strongly depends on the quality of the training data. In particular, SRC suffers from two major problems: lack of training samples per class and large intra-class variations. In fact, palmprint images not only contain identity information but they also have other information, such as illumination and geometrical distortions due to the unconstrained conditions and the movement of the hand. In this case, the sparse representation assumption may not hold well in the original space since samples from different classes may be considered from the same class. This paper aims to enhance palmprint identification performance through SRC by proposing a simple yet efficient method based on an ensemble of sparse representations through an ensemble of discriminative dictionaries satisfying SRC assumption.","person re-identification, recognition, sparse representations, sparse representation, FACADE theory, ensemble learning, palmprint identification, 2D-PCA, 2D-LDA, Surveillance, video surveillance, consensus clustering, Biometrics, palmprint, person re-identiﬁcation, NPReId","The proposed NPReId framework comprises three interactive modules – observation, cognition, and contemplation. The observation module suppresses the background and extracts the chromatic and texture details from the segmented pedestrian. The cognition module projects the psychological result of observation to learn the underlying pedestrian signature. The results of observation and cognition modules are forwarded to the contemplation module that recognizes the correct match for any individual. ||| This paper proposes a new method for palmprint identification using an ensemble of sparse representations. The method aims to enhance the performance of sparse representation for classification (SRC) by proposing a simple yet efficient method based on an ensemble of discriminative dictionaries satisfying SRC assumption. The proposed method is evaluated on two publicly available palmprint data sets and shows very promising results compared with both state-of-the-art holistic and coding methods."
SARIKA,DRIVER ASSISTANCE SYSTEM,"India is home to one of the most underpaid yet overworking drivers. Transporters expect them to work at least twenty or more hours per day continuously without any consideration to their health. This leads them to have bursts of micro sleep, a temporary episode of sleepiness which may last for a smidgen of a second or up to 30 seconds, where the victim fails to react to some stimulus from the environment and becomes unconscious. As a result of this, road accidents have become a common occurrence in India. One solution to this problem is to enhance the vehicles to an extent, so that it is possible to determine the drowsiness of the driver in real time. In this project, we propose a system to assist a driver through detecting drowsiness, distractions and stop signs. The system is easy to understand and the learning curve is minimal. The system is highly robust and can withstand minimal amount of wear and tear. The products assumes that the driver is not blind or deaf. This assumption does not affect the availability of product to mass customers since there are not many driver with visual impairment or hearing impairment. It also assumes that the driver does not drive with either of their eyes closed since driving is not a fun game, since the lives of other passengers is in the drivers hands.","Eye Aspect Ratio, fatigue detection, yawning detection, Region of Interest, drowsiness detection, Mouth Vertical Distance, driver assistance system","The paper proposes a system to assist a driver through detecting drowsiness, distractions and stop signs. The system is easy to understand and the learning curve is minimal. It is highly robust and can withstand minimal amount of wear and tear. The system assumes that the driver is not blind or deaf and does not drive with either of their eyes closed."
SHARMI SANKAR,IoT-Based Wireless Polysomnography Intelligent System for Sleep Monitoring,"Polysomnography (PSG) is considered the gold standard in the diagnosis of obstructive sleep apnea (OSA). The diagnosis of OSA requires an overnight sleep experiment in a laboratory. However, due to limitations in relation to the number of labs and beds available, patients often need to wait a long time before being diagnosed and eventually treated. In addition, the unfamiliar environment and restricted mobility when a patient is being tested with a polysomnogram may disturb their sleep, resulting in an incomplete or corrupted test. Therefore, it is posed that a PSG conducted in the patient’s home would be more reliable and convenient. The Internet of Things (IoT) plays a vital role in the e-Health system. In this paper, we implement an IoT-based wireless polysomnography system for sleep monitoring, which utilizes a battery-powered, miniature, wireless, portable, and multipurpose recorder. A Java-based PSG recording program in the personal computer is designed to save several bio-signals and transfer them into the European data format. These PSG records can be used to determine a patient’s sleep stages and diagnose OSA. This system is portable, lightweight, and has low power-consumption. To demonstrate the feasibility of the proposed PSG system, a comparison was made between the standard PSG-Alice 5 Diagnostic Sleep System and the proposed system. Several healthy volunteer patients participated in the PSG experiment and were monitored by both the standard PSG-Alice 5 Diagnostic Sleep System and the proposed system simultaneously, under the supervision of specialists at the Sleep Laboratory in Taipei Veteran General Hospital. A comparison of the results of the time-domain waveform and sleep stage of the two systems shows that the proposed system is reliable and can be applied in practice. The proposed system can facilitate the long-term tracing and research of personal sleep monitoring at home.","sleep monitoring, wireless, Internet of Things, wireless PSG, JAVA, Polysomnography (PSG), IoT","This paper proposes an IoT-based wireless polysomnography system for sleep monitoring, which utilizes a battery-powered, miniature, wireless, portable, and multipurpose recorder. The system is designed to save several bio-signals and transfer them into the European data format, allowing for the determination of a patient’s sleep stages and diagnosis of OSA. The proposed system is compared to the standard PSG-Alice 5 Diagnostic Sleep System and shows reliable results, making it a viable option for long-term tracing and research of personal sleep monitoring at home."
SOMAYA AL-MAADEED,Palmprint Identification Using an Ensemble of Sparse Representations,"Among various palmprint identification methods proposed in the literature, sparse representation for classification (SRC) is very attractive offering high accuracy. Although SRC has good discriminative ability, its performance strongly depends on the quality of the training data. In particular, SRC suffers from two major problems: lack of training samples per class and large intra-class variations. In fact, palmprint images not only contain identity information but they also have other information, such as illumination and geometrical distortions due to the unconstrained conditions and the movement of the hand. In this case, the sparse representation assumption may not hold well in the original space since samples from different classes may be considered from the same class. This paper aims to enhance palmprint identification performance through SRC by proposing a simple yet efficient method based on an ensemble of sparse representations through an ensemble of discriminative dictionaries satisfying SRC assumption.","sparse representations, sparse representation, ensemble learning, palmprint identification, 2D-PCA, 2D-LDA, Biometrics, palmprint",This paper proposes a new method for palmprint identification using an ensemble of sparse representations. The method aims to enhance the performance of sparse representation for classification (SRC) by proposing a simple yet efficient method based on an ensemble of discriminative dictionaries satisfying SRC assumption. The proposed method is evaluated on two publicly available palmprint data sets and shows very promising results compared with both state-of-the-art holistic and coding methods.
SULABH TYAGI,ROLE OF TRUST IN DISTRIBUTED AGILE SOFTWARE DEVELOPMENT TEAMS - A LIGHT WEIGHT SYSTEMATIC LITERATURE REVIEW,"This systematic literature review aims to investigate the role of trust in distributed agile software development teams. We identified 16 studies that mentioned the role of trust in distributed agile software development in one way or another. Fourteen are primary studies and two are secondary studies. The studies were classified based on different research methods used, database sources, and year of publication. The results show that trust is a crucial ingredient for blending agility with distributed software development. Trust among distributed team members is important to bridge spatial, temporal, and socio-cultural distances, it’s important for them to work together as one team. Trust fuels team performance and contribute in building an effective and cohesive team.","Agile Software Development, systematic literature review, Books, Journals, Peer Reviewed Conferences, distributed agile software development, trust",This study aims to investigate the role of trust in distributed agile software development teams. The results show that trust is a crucial ingredient for blending agility with distributed software development.
SUMAN KUMAR CHOUDHURY,NPReId Framework for Video Surveillance,"This paper presents a neuromorphic person re-identiﬁcation (NPReId) framework to establish the correspondence among individuals observed across two disjoint camera views. The proposed framework comprises three modules (observation, cognition, and contemplation), inspired by the form-and-color-and-depth (FACADE) theory model of object recognition system.","person re-identification, recognition, FACADE theory, Surveillance, video surveillance, consensus clustering, person re-identiﬁcation, NPReId","The proposed NPReId framework comprises three interactive modules – observation, cognition, and contemplation. The observation module suppresses the background and extracts the chromatic and texture details from the segmented pedestrian. The cognition module projects the psychological result of observation to learn the underlying pedestrian signature. The results of observation and cognition modules are forwarded to the contemplation module that recognizes the correct match for any individual."
SURAJ SHARMA,MSGR: A Mode-Switched Grid-Based Sustainable Routing Protocol for Wireless Sensor Networks,"A Wireless Sensor Network (WSN) consists of enormous amount of sensor nodes. These sensor nodes sense the changes in physical parameters from the sensing range and forward the information to the sink nodes or the base station. Since sensor nodes are driven with limited power batteries, prolonging the network lifetime is difficult and very expensive, especially for hostile locations. Therefore, routing protocols for WSN must strategically distribute the dissipation of energy, so as to increase the overall lifetime of the system.","mobile sink, grid-based routing, energy efficiency, grid head, scalability, Wireless sensor networks","The paper presents a comprehensive review of grid-based routing protocols for WSNs, highlighting their design principles, advantages, and limitations. It also proposes a new mode-switched grid-based sustainable routing protocol, which adapts to changing network conditions to conserve energy and improve network lifetime."
SWAMY et al.,"Optimal, Secure Cluster Head Placement Through Source Coding Techniques in Wireless Sensor Networks","In many applications of wireless sensor networks (such as military communications), secure communication, message delay minimization and energy efficiency are crucial. Such requirements constrain special or Important Cluster Head (ICH) placement over the network architecture modeled by a tree. The optimal important cluster head placement problem is formulated and solved using source coding results (providing minimum possible delay and security through prefix-free paths over the tree). Also, through simulations energy efficiency of the proposed approach is established. The reported research is naturally applicable for many applications of Wireless Sensor Networks (WSNs) such as Body Area Networks (BANs).","cluster head, Kraft’s inequality, energy efficiency, important cluster head, prefix-free path, source coding, cluster head placement, Huffman coding, security, Wireless sensor networks","This letter proposes a novel optimal approach for the sensor placement in WSNs. The main goal is to minimize the average depth of Important Cluster Heads from the base station by reducing the number of hops. Further, it ensures message security and makes the paths from Base Station (BS) to Important Cluster Heads to be prefix-free."
Sabine Desbois,Cutting Edge: CD8 T Cell-Mediated Demyelination,"We generated mice (DKI) in which the HA coding sequence was introduced in the ubiquitously active Rosa26 locus but where HA transcription was prevented by an upstream LoxP-flanked Stop cassette. The DKI mice were then crossed with the MOGi-Cre mice, which express Cre specifically in oligodendrocytes. The resulting DKI mice excise the Stop cassette due to MOG-controlled Cre expression, leading to restricted HA expression to oligodendrocytes.  We then decided to test whether effector CD8 T cells can mediate oligodendrocyte cell death and demyelination in vivo. Effector T cells were first generated by in vitro activation of Kd:HA512–520 pentamer-specific CD8 T cells obtained from CL4-TCR mice using HA peptide, IL-2, and IL-12. The resulting Tc1 cells produce large amounts of granzyme B (GrB) and IFN-γ and exhibit potent cytotoxicity to HA-loaded target cells in vivo. Next, we transferred these HA-specific Tc1 cells into DKI and control mice. Following i.v. injection of 3 × 107 HA-specific Tc1 cells, but not naive HA-specific CD8 T cells, ~40% of the DKI mice developed an overt monophasic disease peaking at day 8–10 and waning by 4 wk posttransfer. The clinical manifestations included weight loss and, in the more severe cases, tremors, reduced mobility, and difficulty to right when overturned without overt paralysis. Upon histological analysis, all DKI mice injected with Tc1 cells demonstrated clear CNS pathology from day 5 onwards. Inflammatory lesions were never found in control littermates injected in parallel with HA-specific Tc1 cells.",,"This study investigates the role of CD8 T cells in multiple sclerosis (MS) pathogenesis. Researchers generated a mouse model where a model antigen (influenza hemagglutinin) is expressed specifically in oligodendrocytes, the cells responsible for producing myelin in the central nervous system. Transferring activated CD8 T cells specific for this antigen into these mice resulted in inflammatory lesions in the brain, spinal cord, and optic nerve, resembling active MS lesions. These lesions were characterized by CD8 T cell infiltration, loss of oligodendrocytes, demyelination, and microglia activation. This suggests that CD8 T cells can directly contribute to oligodendrocyte death and demyelination in MS, highlighting their potential as therapeutic targets."
Sachin Chaudhary,Time Optimal Spectrum Sensing: Stochastic Optimization,This paper presents a stochastic optimization approach for time-optimal spectrum sensing. The problem is formulated as a joint optimization of the mean and variance of the spectrum sensing time random variable.,"Stochastic Optimization, Spectrum Sensing, Pareto Front, Source Coding, time-optimal, Integer Programming",The paper proposes a novel approach to solve the time-optimal spectrum sensing problem using stochastic optimization. The approach is based on the minimization of the mean and variance of the spectrum sensing time random variable.
Sachindra Sahu,"MOTIVATING CHILD DEVELOPMENT AND ERADICATION OF CHILD LABOR BY PROMPT EFFORTS BY US, SOCIETY AND GOVERNMENT","One of the menacing curses that our nation is facing today is child labor. Lack of economy and basic education has been monitored as a cause for majority of child labor activities. It is being generally realized that, child labor especially in hazardous occupation is one of the worst social evil and has to be eliminated at the earliest. Government has been taking various pro-active measures to tackle this problem. However, considering the magnitude and extent of the problem and that it is essentially a socio-economic problem inextricably linked to poverty and illiteracy, it requires concerted efforts from all sections of the society to make a dent in the problem.","government schemes, government, illiteracy, child labor, education, menacing, eradication, awareness","The paper discusses the menace of child labor in India and proposes a plan to eradicate it through education, financial support, and awareness. The plan involves collecting donations, providing financial assistance to underprivileged families, and setting up schools for primary education. The authors aim to make children skillful by imparting professional education and provide alternative employment opportunities."
"Sachithra Lokuge of RMIT University, Australia; Thilini Ariyachandra of Xavier University, USA; and Saj Kumar, Vice President of Internet-of-things at SAP","The Next Wave of CRM Innovation: Implications for Research, Teaching, and Practice","Globalization and customers’ ever-changing needs have created a hyper-competitive market. As a result, customer relationship management (CRM) has become a core topic of interest among both practitioners and academics. Further, over the years, with the advancements in the technology landscape, such as digital technologies, CRM has improved in myriad ways. This paper summarizes a panel discussion on CRM innovations held at the 2016 Pacific Asia Conference on Information Systems (PACIS 2016) in Chiyai, Taiwan. The panel discussed CRM fundamentals and how traditional CRM systems work in organizations. Then, the panel focused on the advancement in technology landscape such as big data, analytics, Internet of things, and artificial intelligence and how such technologies have transformed innovations in the CRM landscape. Finally, the panel highlighted the limitations in the current CRM curricula in the universities and how the curriculum today needs to reflect such advancements to enhance the union between the CRM curricula and the industry needs. Further, this paper provides future research ideas for academia and contributes to research interests on CRM in general.","Big Data, CRM Curriculum, Customer Relationship Management, Internet of Things, Artificial Intelligence, CRM, IoT","This paper discusses the next wave of CRM innovation and its implications for research, teaching, and practice. It summarizes a panel discussion on CRM innovations held at the 2016 Pacific Asia Conference on Information Systems (PACIS 2016) in Chiyai, Taiwan. The panel discussed CRM fundamentals, the advancement in technology landscape, and the limitations in the current CRM curricula. The paper provides future research ideas for academia and contributes to research interests on CRM in general."
Saira Sheikh,BELIMUMAB IN PATIENTS OF BLACK AFRICAN ANCESTRY,"Study design. SELENA–SLEDAI = Safety of Estrogens in Lupus Erythematosus National Assessment–Systemic Lupus Erythemato-sus Disease Activity Index; IV = intravenous.

Randomization and treatment. Using an interactive voice/web response system, patients receiving standard therapy were randomized 2:1 to receive either belimumab 10 mg/kg IV or placebo, which was administered on days 0, 14, and 28 and every 28 days thereafter up to week 48, with a final evaluation at week 52. Randomization was stratified by screening SELENA–SLEDAI score (≤9 versus ≥10), region (US/Canada versus rest of world), and complement level (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]). Detailed randomization data are provided in Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Patients who successfully completed the initial 52-week double-blind phase could enter an optional 6-month open-label extension phase, during which they received belimumab 10 mg/kg IV every 28 days plus standard therapy, irrespective of their previous study assignment. The first dose was given at the week 52 (day 364) visit of the double-blind period (day 1 of the open-label extension phase). Patients who completed the 52-week double-blind phase, but did not enter the 6-month open-label extension phase, were required to return for an additional follow-up visit 8 weeks after their last dose. Patients who withdrew early were required to return for an exit visit 4 weeks after their last dose and a follow-up visit 8 weeks after their last dose.

The original protocol plan was to randomize 816 patients, providing ≥90% power to detect ≥12% absolute improvement in the SRI response rate in the belimumab group compared with the placebo group at a 5% significance level. Due to enrollment challenges, a revised sample size was calculated to include 501 patients (≥334 patients in the belimumab group and ≥167 patients in the placebo group). This sample size provided ≥90% power to detect a minimum 15.55% absolute improvement in SRI–SLEDAI-2K response rate in the belimumab group relative to the placebo group at a 5% significance level (based on the pooled data from efficacy studies BEL112341 and BEL113750) (15,21). These calculations assumed a placebo response rate of 43.95% at week 52.

Study end points and assessments. The primary efficacy end point was the SRI–SLEDAI-2K response rate (defined in the Supplementary Material) at week 52 of the double-blind phase. Unlike in the phase II and phase III studies, the SRI–SLEDAI-2K was selected because of the simplification it offers in proteinuria assessment as compared with the SELENA–SLEDAI proteinuria component; both are clinically meaningful (22). The primary efficacy end point for the open-label extension phase was SRI–SLEDAI-2K response rate at open-label extension week 24. If the open-label extension week 24 data were missing, data from the open-label extension week 28/exit visit were used. This time point is referred to as “open-label extension week 24” throughout the text. Data related to the primary efficacy end point, e.g., the response rate over time, percentage of patients with a durable SRI–SLEDAI-2K response from week 44 through week 52, time to first SRI–SLEDAI-2K response that was maintained through week 52, and duration of longest SRI–SLEDAI-2K response among patients with ≥1 SRI–SLEDAI-2K responses were summarized.

The key secondary end points were SRI–SELENA–SLEDAI at week 52 (open-label extension week 24), time to first severe SLE flare (measured by the SELENA–SLEDAI flare index [SFI]), and proportion of patients whose average prednisone dose had been reduced by ≥25% from baseline to ≤7.5 mg/day during week 40 through week 52 (open-label extension week 28/exit visit), in patients receiving >7.5 mg/day at baseline. Key renal end points included time to first renal flare over 52 weeks and over 28 weeks in the open-label extension, SELENA–SLEDAI–SLEDAI-2K renal domain improvement at week 52, SELENA–SLEDAI–SLEDAI-2K renal domain worsening at week 52, percentage reduction in proteinuria by visit and at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours, and proteinuria shift at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours. Renal flare is defined in the Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Biomarkers measured included percentage changes in serum IgG level, anti-dsDNA antibody level (in those who were anti-dsDNA positive [≥30 IU/ml] at baseline), and complement (C3 and C4) levels from baseline. Safety was evaluated by monitoring adverse events (AEs), serious AEs (SAEs), AEs of special interest, vital signs, clinical laboratory test results, and immunogenicity up to 8 weeks posttreatment and throughout the open-label extension phase.

Data analyses. For the double-blind phase, safety analyses were performed on the safety population, defined as all patients who were randomized and treated with at least 1 dose of investigational product. Data on the safety population were summarized according to the treatment the patient was randomized to receive rather than by the treatment that was received, but both were the same for this study. Efficacy analyses were performed on the modified intent-to-treat (ITT) population, defined as the safety population minus those patients who had any assessment at any of 3 study sites that were excluded from the efficacy analyses before the database lock because of potential Good Clinical Practice noncompliance.

For analysis of the primary and 3 key secondary efficacy end points, a step-down sequential testing procedure was used as described in the Supplementary Material. The following subgroup analyses were performed for the primary analysis (SRI–SLEDAI-2K response at week 52): region (US/Canada versus rest of world), baseline SELENA–SLEDAI–SLEDAI-2K score (≤9 versus ≥10), baseline anti-dsDNA antibody level (≥30 IU/ml versus <30 IU/ml), baseline complement levels (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]), and baseline complement and anti-dsDNA antibody levels (≥1 test finding showing low C3/C4 and anti-dsDNA ≥30 IU/ml versus C3/C4 other and anti-dsDNA ≥30 IU/ml). The odds of an SRI–SLEDAI-2K response with belimumab treatment versus placebo were estimated using logistic regression analysis.

For the open-label extension phase, all patients received belimumab, no formal statistical hypothesis t",,"This study investigated the efficacy and safety of belimumab in patients of Black African ancestry with systemic lupus erythematosus (SLE).  Patients were randomized to receive belimumab or placebo for 52 weeks, followed by an optional 6-month open-label extension phase. The primary efficacy endpoint was the SRI–SLEDAI-2K response rate at week 52.  Key secondary endpoints included SRI–SELENA–SLEDAI at week 52, time to first severe SLE flare, and proportion of patients with a reduction in prednisone dose. Renal and biomarker assessments were also conducted.  The study found that belimumab was effective in improving SLE disease activity and reducing renal flares in patients of Black African ancestry."
Sairam Neridu,Impact on structural behavior due to installation of billboard,"Installation of billboards on various structures adjacent to busy roads has become common practice as they provide high economic to the local municipal corporation or private business organisations. Till recent, design of billboards and its installation on a structure was of less importance, but recent large wind cyclones had led to the collapse of billboards and structural cracks. This incident has raised doubts in structural engineering community for the resistance of buildings with billboards during earthquakes.","structural response, modal analysis, time history analysis, Building with billboard, structural behavior, time period","This study aims to understand the change in behavior of existing structure after installation of billboard. The study considers a G+2 structure with billboard located at Raidurg, Hyderabad and carries out dynamic analysis for three different ground motions to understand the change in its behavior with and without billboard."
Saisujay Masina,Quantifying Influential Communities in Information Diffusion Dynamics,This paper studies the information diffusion process in networks and quantifies influential communities. The authors propose a method to study the intertwining of community structure and core-periphery structure.,"community structure, core-periphery structure, k-shell decomposition, networks, information diffusion, coreness, entropy",The paper investigates the information diffusion process in networks and proposes a method to quantify influential communities. The authors show that core nodes are densely packed in the same community and that the core-periphery structure and community structure are intertwined.
Saleem Iqbal,A Dynamic Congestion Control Scheme for safety applications in vehicular ad hoc networks,"In recent years, various types of applications have emerged from Vehicular Ad hoc Networks (VANETs) for safety, infotainment, rescue and security purposes. Safety applications have their own strict communication requirements, and they require reliable and timely data communication within networks. Due to a variety of network applications, safety applications have been negatively impacted by communication channel congestion issues. Channel congestion leads to packet loss, delay and unreliability issues, and has a serious impact on vehicular traffic, including road accidents, road jams, and wrong traffic decisions. In addressing these issues, this paper's authors have proposed a Dynamic Congestion Control Scheme (DCCS) as a means of reliable and timely data delivery, in safety applications. The proposed scheme is designed for communication channels, as a means of broadcasting safety messages, and to ensure the reliable and timely delivery of messages to all neighbours in a network. The DCCS scheme is designed for inter-vehicle communication, without fixed infrastructure. Comprehensive simulation is conducted, in order to evaluate the performance of a proposed scheme, and to compare it with other state of the art schemes.","Congestion Control, Mobility, Transmit Power Control, MAC Blocking, Safety, Measurement-Based Detection, Urban, VANETs, Congestion, Communication, Vehicular, Control, Broadcasting, Queue Freezing",This paper proposes a Dynamic Congestion Control Scheme (DCCS) for safety applications in Vehicular Ad hoc Networks (VANETs). The scheme detects congestion and controls it by exploiting existing network resources for road traffic safety and cum security. The main objectives of this research are to determine whether a congestion detection scheme will reduce congestion by using realistic weighting factors and whether a congestion control scheme can control congestion through message originated-based queue freezing.
Samanvaya Chandra,A NEURAL STOCK PRICE PREDICTOR USING QUANTITATIVE DATA,"Financial forecasting is an example of a signal processing problem which is challenging due to small sample sizes, high noise, non-stationarity, and non-linearity. Neural networks have been very successful in a number of signal processing applications. We discuss fundamental limitations and inherent difficulties when using neural networks for the processing of high noise, small sample size signals. Financial forecasting employing neural networks is a highly significant area for exploratory study. It has long been known that exact prediction is more of an art than a science but attempts can be made to recognize trends and patterns which should help in predicting correctly within an order of magnitude. Our approach uses a typical back propagation neural net and employs various formulas on quantitative data. We picked our training stocks from different categories having varying prices and volumes; this enabled a better analysis while generalizing our findings. While it has not been possible to provide exact predictions, a definite trend is evident in most cases. Statistically-oriented projections of the significance of these findings using standard regression analysis techniques show our approach to be simple yet effective. The historical data was obtained over a time period of 40 days for major stocks on New York Stock Exchange (NYSE). This data was used to train the network while trying out various parameter values and techniques which are discussed below","artificial intelligence and neural networks, Financial forecasting, stock prediction","This paper explores the use of neural networks for stock price prediction. The authors discuss the challenges of financial forecasting, including noise, small sample sizes, and non-linearity. They propose a back propagation neural network approach that uses quantitative data, such as market capitalization, beta coefficient, and earnings per share. The network is trained on historical data from the New York Stock Exchange and shows promising results in identifying trends and patterns. While exact predictions are not possible, the authors demonstrate the potential of neural networks as a practical forecasting tool for individual investors."
Samarjit Kar,Interval-Valued Intuitionistic Fuzzy Soft Sets and Matrices ||| MAXIMISING ACCURACY AND EFFICIENCY OF INTERVAL-VALUED INTUITIONISTIC FUZZY SOFT SETS,"A noticeable progress has been found in decision making problems since the introduction of soft set theory by Molodtsov in 1999. It is found that classical soft sets are not suitable to deal with imprecise parameters whereas fuzzy soft sets (FSS) are proved to be useful. Use of intuitionistic fuzzy soft sets (IFSS) is more effective in environment where arguments are presented using membership and non-membership values. In this paper we propose an algorithmic approach for multiple attribute group decision making problems using interval-valued intuitionistic fuzzy soft matrix (IVIFSM). IVIFSM is the matrix representation of interval-valued intuitionistic fuzzy soft set (IVIFSS), where IVIFSS is a natural combination of interval-valued intuitionistic fuzzy set and soft set theory. Firstly, we propose the concept of IVIFSM. Then an algorithm is developed to find out the desired alternative(s) based on product interval-valued intuitionistic fuzzy soft matrix, combined choice matrix, and score values of the set of alternatives. Finally, a practical example has been demonstrated to show the effectiveness of the proposed algorithm. ||| This article proposes an algorithmic approach for multiple attribute group decision making (MAGDM) problems using interval-valued intuitionistic fuzzy soft matrix (IVIFSM) and confident weight of experts. We propose a novel concept for assigning confident weights to the experts based on cardinals of interval-valued intuitionistic fuzzy soft sets (IVIFSSs). The confident weight is assigned to each of the experts based on their preferred attributes and opinions, which reduces the chances of biasness.","interval-valued intuitionistic fuzzy soft set, Interval-valued intuitionistic fuzzy sets, Confident weight of experts, Multiple attribute group decision making, Interval-valued intuitionistic fuzzy soft sets, Decision-making, interval-valued intuitionistic fuzzy soft matrix, Interval-valued intuitionistic fuzzy soft matrix, Fuzzy Soft Sets, Interval-Valued Intuitionistic Fuzzy Soft Matrices, choice matrix, Fuzzy Soft Matrices, Interval-Valued Intuitionistic Fuzzy Soft Sets",This paper proposes an algorithmic approach for multiple attribute group decision making problems using interval-valued intuitionistic fuzzy soft matrix (IVIFSM). The proposed approach uses combined choice matrix for individual decision maker by incorporating the choice parameters of the set of experts. The score and accuracy values are calculated to yield the desired alternative(s). ||| The proposed algorithm mainly focuses on the choice parameters/attributes of various experts and computes the confident weight of an expert based on her prescribed opinions. We have used cardinals of IVIFSS for measuring the weight. The proposed confident weight also reduces the chance of biasing.
Sambeet Mishra,A Novel Approach to Derive the Current Harmonics Present in Circulating Currents and Its Necessary Controller to Suppress the Same in a Five Level MMC,"This paper presents a novel approach to derive the current harmonics present in circulating currents and its necessary controller to suppress the same in a five level modular multilevel converter (MMC). The instantaneous voltage across the capacitors are denoted as Vc1, Vc2, Vc3, Vc4…VcN Also, the voltage distribution across the capacitors is considered as unequal.","experimental approach, modular multilevel converter, MMC, Controller, Current Harmonics, harmonic mitigation, Circulating Currents","This paper presents a new harmonic mitigation scheme for modular multilevel converters, which is an experimental approach. The proposed controller is effective and easy to implement for modular multilevel inverters."
Sambit Bakshi,Direction Estimation for Pedestrian Monitoring System in Smart Cities: An HMM Based Approach ||| Evaluation of Background Subtraction for Object Detection Vis-a-Vis Mitigating Challenging Scenarios ||| Image Sonification: A Review of Techniques and Applications,"The paper proposes a novel approach for direction estimation of a moving pedestrian as perceived in a 2-D coordinate of field camera. The proposed direction estimation method is intended for pedestrian monitoring in traffic control systems. Apart from traffic control, direction of motion estimation is also very important in accident avoidance system for smart cars, assisted living systems, in occlusion prediction for seamless tracking in visual surveillance, and so on. ||| Background subtraction is a popular technique for detecting objects moving across a fixed camera view. The performance of this paradigm is influenced by various challenges, such as object relocation, illumination change, cast shadows, waving background, camera shake, bootstrapping, camouflage, and so on. In this paper, we present a synopsis on the evolution of the background subtraction techniques over the last two decades. The different ways of mathematical modeling are taken into consideration to categorize the methods. We also evaluate the performance of some of the state-of-the-art techniques vis-a-vis the challenges associated. Eleven different algorithms of background subtraction have been simulated on thirty-four image sequences collected from five benchmark datasets. For each image sequence, seven performance metrics are evaluated and an exhaustive comparative analysis has been made to derive inferences. The potential findings in the result analysis are presented for future exploration. The obtained image and video results are uploaded at https://sites.google.com/site/soaBSevaluation. ||| With the advent of image and video representation of visual scenes in digital computer, subsequent necessity of vision-substitution representation of a given image is felt. The medium for non-visual representation of an image is chosen to be sound due to well developed auditory sensing ability of human beings and wide availability of cheap audio hardware. Visionary information of an image can be conveyed to blind and partially sighted persons through auditory representation of the image within some of the known limitations of human hearing system.","object detection, challenging scenarios, learning model, direction estimation, HMM, Sonification, image sonification, pedestrian monitoring, fuzzy model, Stereo vision, perspective distortion, background subtraction, sound visualization, Auditory image, non-parametric model, shadow removal model, foreground extraction, auditory data, background maintenance, background modeling, hidden Markov model, low-rank sparse decomposition, non-recursive buffer-based subtraction, pedestrian direction estimation, color information, surveillance video, Video surveillance, occlusion handling, Non-visual image representation, shadow removal, Image representation, Visual surveillance","The proposed method is robust to various issues like illumination changes, environmental factors, partial occlusion, and low resolution of surveillance videos. It can be used alone or with existing methods of orientation estimation over consecutive frames to enhance the direction estimation results. ||| This paper evaluates the performance of background subtraction techniques for object detection in challenging scenarios. The authors present a synopsis of the evolution of background subtraction techniques over the last two decades and evaluate the performance of eleven state-of-the-art algorithms on thirty-four image sequences collected from five benchmark datasets. The results reveal some key findings in background subtraction methodologies and are available at https://sites.google.com/site/soaBSevaluation. ||| Image sonification is a process that converts visual data into sound, allowing people to perceive and understand visual information through sound. The paper reviews the different techniques and applications of image sonification, including the use of color information and the applications in various fields."
Samdarshi Abhijeet,Time Optimal Spectrum Sensing: Stochastic Optimization,This paper presents a stochastic optimization approach for time-optimal spectrum sensing. The problem is formulated as a joint optimization of the mean and variance of the spectrum sensing time random variable.,"Stochastic Optimization, Spectrum Sensing, Pareto Front, Source Coding, time-optimal, Integer Programming",The paper proposes a novel approach to solve the time-optimal spectrum sensing problem using stochastic optimization. The approach is based on the minimization of the mean and variance of the spectrum sensing time random variable.
Sanatan Sukhija,Cost Effective Influence Maximisation ||| Label Space Driven Heterogeneous Transfer Learning with Web Induced Alignment ||| Leveraging Network Similarity Measures for Recommendation Systems ||| Quantifying Influential Communities in Information Diffusion Dynamics,"In the context of virality prediction, many researchers have leveraged the existence of a core-periphery structure in a network to identify the super-spreaders of information. Topologically, the nodes in the core of a network are the most eﬃcient spreaders. However, these nodes are less susceptible, i.e., unlikely to be inﬂuenced by the periphery nodes. Consequently, large payoﬀs are required to market information (ideas, products, memes, etc.) via them. In this paper, we show the presence of several non-core nodes whose spreading power is close to that of the core nodes. ||| Heterogeneous Transfer Learning (HTL) algorithms leverage knowledge from a heterogeneous source domain to perform a task in a target domain. We present a novel HTL algorithm that works even where there are no shared features, instance correspondences and further, the two domains do not have identical labels. ||| With the growth of e-commerce websites, efficient recommendation systems are desired to reduce the turnaround time for servicing a customer. This study focuses on understanding the various techniques and algorithms that are used to model real-life recommendation systems. We present a recommendation engine for Amazon products that uses collaborative filtering (CF). Given a list of users and their reviews of Amazon products, our CF-based recommendation engine generates a ranked list of the top k products for individual users. The generated recommendations are based on the preferences of similar users and past purchases. ||| This paper studies the information diffusion process in networks and quantifies influential communities. The authors propose a method to study the intertwining of community structure and core-periphery structure.","Heterogeneous Transfer Learning, Information diﬀusion, cost-effective, model-based CF, collaborative filtering, matrix factorization, social networks, similarity metrics, Label Space Driven, Virality, bipartite graph, recommendation systems, k-shell decomposition, coreness, core-periphery structure, Amazon electronics reviews, Inﬂuence maximisation, Core-periphery structure, information diffusion, entropy, recommendation system, Web Induced Alignment, singular value decomposition, community structure, memory-based CF, networks, influence maximisation",A cost-effective information diffusion strategy has been proposed that only requires the neighborhood information (friendship connections) of a node to make a meme go viral. Digital marketing agencies with a limited advertising budget can use the proposed strategy to popularise their product. ||| The proposed algorithm utilizes the inter-label space semantic similarities to improve the joint alignment of the data from the source and target domains in the common space. ||| This paper presents a recommendation engine for Amazon products that uses collaborative filtering (CF). The engine generates a ranked list of the top k products for individual users based on the preferences of similar users and past purchases. The authors also propose a graph-based recommendation technique that generates a list of the most similar products using network-based local similarity metrics. ||| The paper investigates the information diffusion process in networks and proposes a method to quantify influential communities. The authors show that core nodes are densely packed in the same community and that the core-periphery structure and community structure are intertwined.
Sandipan Patra,Development of a Smart Energy Community by Coupling Neighbouring Community Microgrids for Enhanced Power Sharing Using Customised Droop Control,"This paper proposes an enhanced PM-based droop control strategy for power sharing in CMGs. The proposed strategy achieves symmetric and asymmetric power-sharing through a PM-based droop control, enabling efficient coupling of neighboring CMGs. The control strategy also includes an enhanced frequency regulation method without using a secondary controller, maintaining the system frequency within an acceptable range.","power management, droop control, power sharing, energy community, parallel inverter, CMGs, interconnected system, community microgrids, frequency regulation, PM-based droop control","The proposed PM-based droop control strategy is validated through laboratory-scale CMG testing, demonstrating its effectiveness in maintaining system frequency and voltage within acceptable ranges. The control strategy is also shown to be efficient in power sharing, enabling the coupling of neighboring CMGs. The proposed method has the potential to improve the reliability and efficiency of CMG-based power systems."
Sangeeta Vaibhav Meena,Recent Developments in Plant Leaf Disease Identification and Classification,"In the modern era, deep learning techniques have emerged as powerful tools in image recognition. Convolutional Neural Networks, one of the deep learning tools, have attained an impressive outcome in this area. The effectiveness of Convolutional Neural Networks in image recognition motivates the researchers to extend its applications in the field of agriculture for recognition of plant species, yield management, weed detection, soil, and water management, fruit counting, diseases, and pest detection, evaluating the nutrient status of plants, and much more.","leaf, deep learning models, disease, survey, deep learning, machine learning models, plant leaf disease identification, agriculture, convolutional neural networks","This manuscript presents a survey of the existing literature in applying deep Convolutional Neural Networks to predict plant diseases from leaf images. It presents an exemplary comparison of the pre-processing techniques, Convolutional Neural Network models, frameworks, and optimization techniques applied to detect and classify plant diseases using leaf images as a data set."
Sanjiv Narayan,Power Optimization Strategy for Android Applications,"Energy efficiency is a critical factor in mobile systems, and a significant body of recent research efforts has focused on reducing the energy dissipation in mobile hardware and applications. The Android OS Power Manager provides programming interface routines called wakelocks for controlling the activation state of devices on a mobile system.","Data Flow Analysis, Android, Wakelock Placement, Power Optimization, Mobile Systems, Energy Optimization",This paper proposes a data flow analysis based strategy for determining the placement of wakelock statements corresponding to the uses of devices in an application. The proposed optimization strategy shows significant (up to 32%) energy savings with experimental evaluation on a set of Android applications.
Sankar K. Pal,"Active Support Vector Learning for Pixel Classification ||| Data Mining in Soft Computing Framework ||| Multispectral Image Segmentation Using the Rough-Set-Initialized EM Algorithm ||| Pattern Recognition Algorithms for Data Mining: Scalability, Knowledge Discovery, and Soft Granular Computing","This paper presents an active support vector learning algorithm for pixel classification in remote sensing images. The algorithm is based on the principle of breaking down the large quadratic programming problem into a series of smaller problems, and identifying the support vectors while discarding the non-support vectors. ||| The present article provides a survey of the available literature on data mining using soft computing. A categorization has been provided based on the different soft computing tools and their hybridizations used, the data mining function implemented, and the preference criterion selected by the model. ||| The problem of segmentation of multispectral satellite images is addressed. An integration of rough-set-theoretic knowledge extraction, the Expectation Maximization (EM) algorithm, and minimal spanning tree (MST) clustering is described. ||| This book contains information obtained from authentic and highly regarded sources. Reprinted material is quoted with permission, and sources are indicated. A wide variety of references are listed. Reasonable efforts have been made to publish reliable data and information, but the author and the publisher cannot assume responsibility for the validity of all materials or for the consequences of their use.","rough knowledge encoding, Semi-supervised learning, knowledge discovery, Soft granular computing, granular computing, genetic algorithms, Clustering, Rough Sets, Image segmentation, Rough Set Theory, Data mining, Hybrid Approach, neural networks, Image Segmentation, Active Learning, Knowledge discovery, minimal spanning tree, Scalability, Data Mining, mixture modeling, Pattern recognition, Support Vector Machine, rule extraction, Fuzzy Logic, Fuzzy logic, Remote Sensing, Pixel Classification, Query support vector machine, Soft Computing, Knowledge Discovery in Databases, neuro-fuzzy computing, rough sets, Mixture Models, Transductive learning","The paper proposes an active support vector learning algorithm for pixel classification in remote sensing images, which uses a smaller number of labeled samples and has a substantial improvement in performance compared to the conventional support vector machine. ||| Data mining is a form of knowledge discovery essential for solving problems in a specific domain. Individual data sets may be gathered and studied collectively for purposes other than those for which they were originally created. ||| The paper presents a method for multispectral image segmentation using the rough-set-initialized EM algorithm. The method integrates rough-set-theoretic knowledge extraction, the EM algorithm, and MST clustering to address the problem of segmentation of multispectral satellite images. ||| The book covers various aspects of pattern recognition algorithms for data mining, including scalability, knowledge discovery, and soft granular computing. It discusses different perspectives of data mining, scaling pattern recognition algorithms to large data sets, and the significance of soft computing in KDD."
Santosh Kumar Vishwakarma,Automated Cryptanalysis of Substitution Ciphers using Swarm Intelligence Techniques,"This paper presents a comparative analysis of various swarm intelligence techniques for automated cryptanalysis of substitution ciphers. The techniques used include particle swarm optimization (PSO), bees algorithm, ant colony optimization, firefly algorithm, and cuckoo search. The results show that the cuckoo search technique is the most effective, with an average number of key elements correctly recovered of 26.17 out of 27, and a mean performance time of 0.137 seconds.","Bees Algorithm, Automated Cryptanalysis, Firefly Algorithm, Substitution Ciphers, Particle Swarm Optimization, Swarm Intelligence, Ant Colony Optimization, Classical Substitution Cipher, Cuckoo Search","This paper presents a comparative analysis of various swarm intelligence techniques for automated cryptanalysis of substitution ciphers. The results show that the cuckoo search technique is the most effective, with an average number of key elements correctly recovered of 26.17 out of 27, and a mean performance time of 0.137 seconds."
Sanya Yadav,"Earthquake Precursory Research at MPGO, Ghuttu","The paper discusses earthquake precursory research at MPGO, Ghuttu, focusing on radon emanation variation as a parameter.","radon emanation, Ghuttu, MPGO, compiler construction, bootstrapping, cross-compilation, earthquake precursory research","The authors discuss the merits and demerits of bootstrapping and cross-compilation approaches in compiler construction, highlighting their suitability for different computer architectures and programming languages."
"Sara K. Sahl, MPH",Cardiac Neonatal Lupus: Maternal and Fetal Risk Factors for Mortality,"Background: Cardiac neonatal lupus (CNL) is a serious complication of maternal anti-Ro/SSA and anti-La/SSB antibodies.  We sought to identify maternal and fetal risk factors for mortality in infants with CNL.

Methods and Results: We retrospectively analyzed data from 325 infants with CNL born to 297 mothers. Overall, 57 deaths (17.5%) occurred. Hydrops, carditis, and EFE were associated with increased mortality in both in utero and postnatal deaths. Maternal diagnosis of SLE and/or SS was associated with increased mortality in the overall analysis and in utero deaths.  Whites were less likely to die than minorities.

Conclusions: Hydrops, carditis, EFE, and maternal SLE and/or SS are significant risk factors for mortality in infants with CNL.","mortality, morbidity, cardiomyopathy, antibodies, heart block","This study investigates maternal and fetal risk factors for mortality in infants with cardiac neonatal lupus (CNL).  Key findings include the significant association of hydrops, carditis, EFE, and maternal SLE and/or SS with increased mortality. Additionally, white infants were found to have a lower mortality rate compared to minorities."
Satbir Jain,Ensuring Data Security in Databases Using Format Preserving Encryption ||| MUTUAL LEARNING IN TREE PARITY MACHINES USING CUCKOO SEARCH ALGORITHM FOR SECURE PUBLIC KEY EXCHANGE,"In the current scenario data security has become an important issue with the growth of digital media. Many users and the applications are accessing the data both from inside and outside the database. Hence, the database as well as data within these databases has become the key target for most of the attackers. Many cryptographic schemes have been designed to solve this problem. Encryption plays an important role in providing the data confidentiality to data stored within the databases. But, the problem in adopting the standard encryption methods is that they may cause a damage to the existing schema as well as to the underlying applications or database as the output length is different from the input length and it also changes the format of data. This paper proposes a Format Preserving Encryption method by accumulating with Advance encryption standard(AES), eXclusive OR operation and a translation method for 16 digit numeric data. Format preserving encryption technique is used to minimizes the databases changes by preserving the format as well as the length of the input data. ||| In Neural Cryptography, Artificial Neural Networks are used for the process of key generation and encryption. Tree Parity Machine (TPM) is a single layer neural network that approaches symmetric key exchange using the process of mutual learning. This method is exploited to design a secure key exchange protocol, where the sender and the receiver TPMs are synchronized to obtain an identically tuned weight vectors in both the networks.","numeric data, Database, Data Length, Data security, Mutual Learning, Neural Synchronisation, Neural Networks, Advanced encryption standard(AES), Secure Public Key Exchange, Format preserving encryption, Tree Parity Machine, Cuckoo Search Algorithm, Security, Key Exchange, AES","This paper proposes a Format Preserving Encryption method to ensure data security in databases. The proposed method accumulates Advance encryption standard(AES), eXclusive OR operation, and a translation method for 16-digit numeric data. The technique minimizes database changes by preserving the format and length of the input data. ||| This paper proposes a novel approach for the process of synchronisation in Tree Parity Machines using Cuckoo Search Algorithm for secure public key exchange. The results show that using CS algorithm for weight vector initialisation decreases the number of iterations significantly, resulting in ~30% decrease on an average. The effect of CS algorithm was observed by changing the weight range from 4 to 7 with N = 3, K = 100, and the results show that using CS, the synchronisation steps are decreased tremendously i.e. >50% decrease is observed."
Sathvik Nimmaneni,Quantifying Influential Communities in Information Diffusion Dynamics,This paper studies the information diffusion process in networks and quantifies influential communities. The authors propose a method to study the intertwining of community structure and core-periphery structure.,"community structure, core-periphery structure, k-shell decomposition, networks, information diffusion, coreness, entropy",The paper investigates the information diffusion process in networks and proposes a method to quantify influential communities. The authors show that core nodes are densely packed in the same community and that the core-periphery structure and community structure are intertwined.
Satish Chand,Energy-Efficient Node Scheduling Mechanism for Target Coverage Problem in Wireless Sensor Networks ||| Improved-Coverage Preserving Clustering Protocol in Wireless Sensor Networks ||| Maximising network lifetime for target coverage problem in wireless sensor networks,"In wireless sensors networks, the sensor nodes are densely deployed. Owing to this excessive deployment of sensor nodes, each target is covered by multiple sensors at a time. To prolong the network lifetime, the authors can schedule the sensor activity in such a way that only a subset of sensor nodes, called cover set, is sufficient enough to cover all the targets. In this study, they propose an energy-efficient scheduling algorithm based on learning automata for target coverage problem. The learning automata-based technique helps a sensor node to select its appropriate state (either active or sleep). To prove the effectiveness of their proposed scheduling method, they conduct a detailed set of simulations and compare the performance of their algorithm with the existing algorithms. ||| Coverage maintenance for longer period is crucial problem in wireless sensor network (WSNs) due to limited inbuilt battery in sensors. Coverage maintenance can be prolonged by using the network energy efficiently, which can be done by keeping sufficient number of sensors in sensor covers. There has been discussed a Coverage-Preserving Clustering Protocol (CPCP) to increase the network lifetime in clustered WSNs. It selects sensors for various roles such as cluster heads and sensor cover members by considering various coverage aware cost metrics. In this paper, we propose a new heuristic called Improved-Coverage-Preserving Clustering Protocol (I-CPCP) to maximize the total network lifetime. In our proposed method, minimal numbers of sensor are selected to construct a sensor covers based on various coverage aware cost metrics. These cost metrics are evaluated by using residual energy of a sensor and their coverage. The simulation results show that our method has longer network lifetime as compared to generic CPCP. ||| Target coverage problem is one of the important problems in wireless sensor network in which each target should be covered by at least one sensor. All the sensors are organised into different groups called sensor cover in such a way that each cover can monitor all the targets for a fixed duration. By keeping one sensor cover active at a time while others in sleep mode, sensors batteries can be utilised in efficient way. This helps in prolonging the network lifetime. In this study, the authors propose a new energy-efficient heuristic to schedule the sensors in different non-disjoint sensor covers which helps to maximise network lifetime.","energy-efficient scheduling, coverage aware cost metrics, sensor networks, clustering protocol, sensor roles, clustering, energy-efficient node scheduling, target coverage problem, learning automata, network lifetime, energy-efficient heuristic, wireless sensor networks, energy-efficiency, coverage","This paper proposes an energy-efficient scheduling algorithm based on learning automata for target coverage problem in wireless sensor networks. The algorithm helps a sensor node to select its appropriate state (either active or sleep) to prolong the network lifetime. The effectiveness of the proposed scheduling method is proven through simulations and comparison with existing algorithms. ||| The paper proposes a Coverage Preserving Clustering Protocol (CPCP) to decide the roles of sensors for various activities in wireless sensor networks. The protocol estimates the total energy available to cover each point in the network area and considers various parameters like residual energy, number of 1-hop neighbouring sensor nodes, number of n-hop neighbouring sensor nodes and distance from the base station. The authors also discuss various coverage aware cost metrics to decide the roles of sensors for various activities. ||| The authors propose a new energy-efficient heuristic to schedule the sensors in different non-disjoint sensor covers which helps to maximise network lifetime. The heuristic identifies all the critical targets (least covered) and the critical sensors (covering critical targets). The critical targets, covered by minimum number of sensors, will be the targets that become uncovered first. Utilising critical sensors efficiently will help to increase the network lifetime."
Saurabh Agrawal,Support Vector Machines for Pattern Recognition,We propose a novel approach for content based color image classification using Support Vector Machine (SVM). Traditional classification approaches deal poorly on content based image classification tasks being one of the reasons of high dimensionality of the feature space.,"Pattern Recognition, image classification, color image histogram, Knowledge Discovery, Data Mining, Support Vector Machines, Support Vector Machine",The paper proposes a novel approach for content based color image classification using Support Vector Machine (SVM). The approach uses color image histograms as features and is found to be efficient and insensitive to small changes in camera viewpoint.
Savita,Cardiovascular Disease Detection Model,"This paper proposes a cardiovascular disease detection model that uses a combination of techniques such as Naïve Bayes, neural network, and feature selection to achieve high accuracy rates. The model is implemented using a virtual environment in Python and uses a decision tree classifier to classify patients as infected or disinfected. The results show that the proposed model can obtain infected persons from the training data with low losses, which can help doctors in real-time to categorize patients based on certain characteristics.","cardiovascular disease detection, Machine Learning, feature selection, Classification, decision tree classifier, Coronary Artery Diseases, Optimization Techniques",The proposed model uses a combination of techniques to achieve high accuracy rates in cardiovascular disease detection. The model is implemented using a virtual environment in Python and uses a decision tree classifier to classify patients as infected or disinfected. The results show that the proposed model can obtain infected persons from the training data with low losses.
Savita Yadav,Human Behavior and Emerging Technologies ||| Video-chatting with young children,"Children now get access to smartphones at an early age and gradually acquire skills to use different types of smartphone apps. We developed a mathematical model for the ability and interest of children to use smartphone apps. The model can be used to determine the level of difficulty of apps and identify niche app, i.e. apps that are designed specifically to be used by a narrow age range of children. ||| We conducted a study in New Delhi in February 2017 to check the interest and ability of children younger than 2 years with regard to video-chatting.","suitability, children, mathematical model, psychomotor abilities, interest, applicability, ability, video-chatting, young children, smartphone apps, screen-based devices","The model uses a Gaussian function to represent the interest of children in an app and a parabola to represent the most important skill required to use the app. The parameters c and A are used to determine the applicability and suitability of an app, respectively. The study analyzed several smartphone apps and found that most of them do not take into account the psychomotor abilities of children, leading to a mismatch between the skills required to use the app and the skills possessed by children. The study suggests that developers should identify the target age group and ensure that using the app requires only the skills that children of that age group possess. ||| The study found that only a small proportion of parents feel the need for, and engage in, video-chatting with their children. The behaviour of a child towards video-chatting varies with time and context, but there are some salient trends in their behaviour."
Seba Susan,Fuzzy Classification Scheme for MFCC Audio Features,"Mel-frequency Cepstral coefficients (MFCC) are popular features extracted from speech data for speaker identification. The speech signal is fragmented into frames and the MFCC features extracted from each frame show some temporal redundancy which forms the basis of the fuzzy classifier proposed in this paper. We propose a fuzzy nearest neighbor classifier that defines a frame prototype for each training audio sample using a weighted mean technique with the weights being probability values, and the class label for each test sample is decided from fuzzy membership functions involving the frame prototypes. The classification results of the proposed classifier on audio samples from the VidTIMIT database show a superior performance to the Nearest Neighbor classifier, GMM, HMM and MLP neural networks. It is observed that the execution time of the fuzzy classifier is a very small fraction of the time taken by the HMM and neural network classifiers and the training database is significantly reduced due to the use of frame prototypes instead of actual frames.","MFCC, Mel-frequency cepstral coeffecients, fuzzy classification, fuzzy classifer, audio features, Gaussian fuzzy membership functions",This paper proposes a fuzzy nearest neighbor classifier for speaker identification using Mel-frequency Cepstral coefficients (MFCC) features. The classifier defines a frame prototype for each training audio sample using a weighted mean technique and decides the class label for each test sample from fuzzy membership functions involving the frame prototypes. The proposed classifier outperforms other classifiers in terms of execution time and training database size.
"Sebastiani, Fabrizio",Automated Genre Classiﬁcation of Books Using Machine Learning and Natural Language Processing,"In today's world due to ever-increasing demand to make computers perform tasks of humans, machine learning is used. It is a tedious task to manually read the entire book and classify it based on its genre. Novice writers find it troublesome to figure out the genre of their book, which can affect its reach to the right audience.","Natural Language Processing, Genre Classification, Machine Learning, AdaBoost, NLP, text categorization, Principle Component Analysis (PCA), WordNet, TF-IDF, Decision Tree","The proposed method gains knowledge from a large number of words from the books and transforms them into a feature matrix. During transformation, the size of the initial matrix is reduced using Wordnet and Principle Component Analysis. Then, the AdaBoost classifier is applied to predict the genres of the books."
Seemandhar Jain,Cube Sampled K-Prototype Algorithm for Clustering,This paper proposes a novel algorithm called Cube Sampled K-Prototype for clustering mixed data types. The algorithm integrates the K-Means and K-Modes algorithms and uses cube sampling to reduce the computational complexity. The proposed algorithm is compared with other clustering algorithms and shows better performance in terms of clustering accuracy.,"Mixed Data Types, Cube Sampling, Principal Component Analysis, K-Prototype Clustering, Clustering Accuracy, Sampling, Clustering, K-Prototype",This paper proposes a probabilistic sampling technique called cube sampling along with K-Prototype clustering. Cube sampling is used because of its accurate sample selection. The novelty of this work is in obtaining the crucial inclusion probabilities for cube sampling using Principal Component Analysis (PCA).
Shagufta Anjum,Leveraging Network Similarity Measures for Recommendation Systems,"With the growth of e-commerce websites, efficient recommendation systems are desired to reduce the turnaround time for servicing a customer. This study focuses on understanding the various techniques and algorithms that are used to model real-life recommendation systems. We present a recommendation engine for Amazon products that uses collaborative filtering (CF). Given a list of users and their reviews of Amazon products, our CF-based recommendation engine generates a ranked list of the top k products for individual users. The generated recommendations are based on the preferences of similar users and past purchases.","bipartite graph, Amazon electronics reviews, recommendation systems, memory-based CF, model-based CF, collaborative filtering, recommendation system, matrix factorization, singular value decomposition, similarity metrics",This paper presents a recommendation engine for Amazon products that uses collaborative filtering (CF). The engine generates a ranked list of the top k products for individual users based on the preferences of similar users and past purchases. The authors also propose a graph-based recommendation technique that generates a list of the most similar products using network-based local similarity metrics.
Shajy Isac,"Seroprevalence of SARS-CoV-2 Antibodies in Uttar Pradesh, India: A Cross-Sectional Study","Population-based serological antibody test for SARS-CoV-2 infection helps in estimating the exposure in the community. We present the findings of the first district representative seroepidemiological survey conducted between 4 and 10 September 2020 among the population aged 5 years and above in the state of Uttar Pradesh, India. Multi-stage cluster sampling was used to select participants from 495 primary sampling units (villages in rural areas and wards in urban areas) across 11 selected districts to provide district-level seroprevalence disaggregated by place of residence (rural/urban), age (5–17 years/aged 18 +) and gender. A venous blood sample was collected to determine seroprevalence. Of 16,012 individuals enrolled in the study, 22.2% [95% CI 21.5–22.9] equating to about 10.4 million population in 11 districts were already exposed to SARS-CoV-2 infection by mid-September 2020. The overall seroprevalence was significantly higher in urban areas (30.6%, 95% CI 29.4–31.7) compared to rural areas (14.7%, 95% CI 13.9–15.6), and among aged 18 + years (23.2%, 95% CI 22.4–24.0) compared to aged 5–17 years (18.4%, 95% CI 17.0–19.9). No differences were observed by gender. Individuals exposed to a COVID confirmed case or residing in a COVID containment zone had higher seroprevalence (34.5% and 26.0%, respectively). There was also a wide variation (10.7–33.0%) in seropositivity across 11 districts indicating that population exposed to COVID was not uniform at the time of the study. Since about 78% of the population (36.5 million) in these districts were still susceptible to infection, public health measures remain essential to reduce further spread.","COVID-19, Seroprevalence, India, SARS-CoV-2, Heterogeneity, Uttar Pradesh","This study presents the first district-level seroprevalence survey of SARS-CoV-2 infection in Uttar Pradesh, India. Conducted in September 2020, the survey found that 22.2% of the population had been exposed to the virus by that time. Seroprevalence was significantly higher in urban areas and among individuals aged 18 and older. The findings highlight the importance of continued public health measures to reduce further spread of the virus."
Shampa Chakraverty,"Analyzing emotion based movie recommender system using fuzzy emotion features ||| An Extended Version of WordNet Incorporating Technical Terms and Subject Specific Words/Phrases ||| A Fragile Watermarking Scheme for Decision Systems ||| Emotion Analysis in Twitter ||| Enriching Topic Coherence on Reviews for Cross-Domain Recommendation ||| Evaluating the Learning Perspectives of Students on the Basis of Class Notes ||| Genetic Algorithm-Based Approach for Teaching Programming ||| KELDEC: A System for Mining Knowledge Sources from Images ||| Ownership and Tamper Detection of Relational Data: Framework, Techniques and Security Analysis ||| Visual Tools for Teaching Programming ||| Watermarking Categorical Data: Algorithm and Robustness Analysis","User generated contents like reviews and comments contain both the information about a given product and also the opinions asserted by the user. With the surge in internet usage, there is a cascade of user generated data such a reviews and comments. People share their experiences, opinions, sentiments and emotions by writing reviews and comments for products they purchase online or after watching a movie, reading books etc. These user generated data contains emotion lexicons such as happiness, sadness, and surprise. Analysis of such emotion can provide a new aspect for recommending new items based on their emotional preferences. In this work, we extract the emotions from this user generated data using the lexical ontology, WordNet and information from the domain of psychology. These extracted emotions can be used for recommendations. Evaluation on emotion prediction further verifies the effectiveness of the proposed model in comparison to traditional rating based item similarity model. We further compare this with fuzziness in emotion features. ||| WordNet is a huge repository being used as a tool in various fields. With an increasing number of applications referring to WordNet as a dictionary, several attempts have been made to update it. The paper proposes to extend the huge repository by adding words and relationships derived from students’ class notes through wikidata. These terms can be phrases, technical terms or any subject specific terminology appearing in students’ notes of a specific subject. Although various WordNet enriching techniques are available, it is for the first time that subject specific terminology is being added. The resulting version of WordNet has some very common phrases and technical terms along with the generic terms. Making subject specific and generic terms available in a hierarchy can improve the accuracy of various applications like text summarization and clustering for text belonging to a specific domain. ||| The wheels of modern society are driven by multitudes of databases that serve as repositories of valuable information. Several applications can fruitfully learn from special repositories called Decision Systems.DS are databases that contain records of objects described by condition attributes and labeled by decision attributes that categorize them into distinct classes. Rough Set Theory can be applied to derive high quality classification rules from them to predict accurate decisions on freshly gathered data. For security, it is necessary to protect this core information from vulnerabilities in the Internet. No prior work is done on watermarked protection of Decision Systems. To fulfill this gap, we propose a new fragile and blind watermarking scheme for tamper detection in Decision Systems which detects even the slightest integrity losses that may damage the classificatory information encapsulated within a Decision System. ||| The ever-increasing amount of text generated by Twitter users contains a wealth of information about the users’ state of mind. Over the years, researchers have tapped upon this resource and proposed a number of lexicons and techniques for analyzing the polarity of sentiments expressed by tweets. However, we need to delve deeper to extract the emotions conveyed by them – a research direction that had not received adequate attention so far. ||| This paper proposes a novel approach for cross-domain recommendation (CDR) that leverages topic coherence between domains to improve recommendation accuracy. The proposed approach, called TC-CDR, consists of nine modules that work together to recommend items from a target domain to a user in a source domain. The approach uses a combination of natural language processing and machine learning techniques to extract semantic features from user reviews and item descriptions, and then uses these features to compute topic coherence between domains. The proposed approach is evaluated on two real-world datasets, Movielens and Bookcrossing, and is shown to outperform state-of-the-art CDR methods in terms of recommendation accuracy. ||| This paper aims to evaluate the learning perspectives of students on the basis of class notes taken while the teacher is teaching in class. Homogenous and heterogeneous groups are formed on the basis of learning perspectives. ||| Pair programming is an approach where two programmers work to solve one programming problem sitting shoulder to shoulder on a computer. Several studies indicating numerous benefits of using pair programming as a teaching strategy exist. However, only a few of them take into consideration the mechanism followed for pair formation. With an aim to study the impact of pair programming on undergraduate students, we try to make the pairs compatible with a genetic algorithm‐based approach. Using a genetic algorithm, the system ensures that every pair in the class gets a particular combination of skills and personality traits. We also developed a desktop application to assign programming exercises to students dynamically. To assess the efficacy of pair programming in introductory programming course, a formal pair programming experiment was run at Netaji Subhas University of Technology. The pair programming experiment involved a total 171 undergraduate students from a computer engineering course. At the end of the program, we assessed the programming abilities of every student. We also analyzed the impact of a genetic algorithm‐based pairing mechanism. On the basis of assessments, it is observed that pair programming is a successful pedagogical tool for facilitating active learning of introductory programming courses. Responses to survey garnered from undergraduate students hint that the genetic algorithm approach leads to compatible pairs. ||| KELDEC is a system that mines knowledge sources from images by extracting technical phrases and using them to scout for relevant websites. The system uses a combination of natural language processing and machine learning techniques to identify relevant websites and rank them based on their semantic similarity to the image and the class notes. ||| Databases play a pivotal role in all domains of technology, encompassing data mining, medical records, stock market data, e-commerce etc. With this elevated need for databases and their wide distribution in the web sphere, their security has become a major concern today. It is in this context that watermarked protection of databases has started receiving increasing attention from researchers. ||| Courses on computer programming are included in the curricula of almost all engineering disciplines. We surveyed the research literature and identified the techniques that are commonly used by instructors for teaching these courses. We observed that visual programming and game-based learning can enhance computational thinking and problem-solving skills in students and may be used to introduce them to programming. Robot programming may be used to attract students to programming, but the success of this technique is subjected to the availability of robots. Pair and collaborative programming allows students to learn from one another and write efficient programs. Assessment systems help instructors in evaluating programs written by students and provide them with timely feedback. Furthermore, an analysis of citations showed that Scratch is the most researched tool for teaching programming. ||| The importance of watermarking digital databases has increased by leaps and bounds due to the high vulnerability of digital assets to piracy attempts when they traverse through the internet. To deter piracy, we propose a robust watermarking scheme for relational databases containing categorical data that resolves ownership issues.","Rough Set theory, robustness analysis, genetic algorithm, Content based recommender system, Collaborative recommender system, Subject Specific Words/Phrases, pair programming, watermarking, explicit semantic analysis, game-based learning, digital watermarking, top N recommendation, reducts, relational database, Decision Systems, ownership, computer science education, categorical data, algorithm, topic coherence, robot programming, visual programming, Image analysis, piracy detection, Collaborative learning environments, machine learning, Collaborative Learning, heterogeneous grouping, security, Programming Exercises, technical phrases, ownership proof, Fragile Watermarking, Learning Perspectives, Web content mining, programming, rules, English WordNet, Hyponym enrichment, Technical Terms, teaching, introductory programming, Wikidata, Homogenous Grouping, Lexicon, watermarked protection, Psychology, Emotion analysis, image mining, pair and collaborative programming, Reducts and Rules, pointwise mutual information, knowledge source, databases, WordNet, sentiment analysis, collaborative learning, relational databases, topic modeling, database protection, Class Notes, KELDEC, Twitter, natural language processing, tamper detection, cross-domain recommendation, copyright issues, Tamper Detection, recommender systems, visual tools, Emotion Analysis, WorldNet, Information security, Personalized mobile learning, Educational recommender system, assessment system, movie recommendation, emotion based recommendation, Pair Formation, Classroom learning points, homogeneous grouping, semantic similarity","This paper proposes a new item based recommender system using both CF and CBF based approaches to recommend items using emotions. Emotions are extracted from user generated data using lexical ontology, WordNet and information from the domain of psychology. The extracted emotions are used for recommendations and evaluated on emotion prediction. The proposed model is compared with traditional rating based item similarity model and fuzziness in emotion features. ||| The paper proposes a novel hyponym enrichment in WordNet by enriching the database with subject related technical terms. This is important since the database has not been updated for a long time now. To the best of our knowledge, we are the first to use wikidata for adding subject specific terms and relationships to WordNet. ||| This paper proposes a fragile and blind watermarking scheme for tamper detection in Decision Systems. The scheme detects even the slightest integrity losses that may damage the classificatory information encapsulated within a Decision System. The technique characterizes the type of attack and then localizes the perturbation upto an attribute’s value level. In case of alteration in reducts, proposed technique can recover the original value. ||| This paper proposes a novel Emotion Analysis lexicon that was compiled by integrating information from the domain of psychology, the lexical ontology WordNet, and a set of emoticons and slangs commonly used in web jargon. The lexicon is used to find the predominant emotions carried by tweets originating from three different cities and analyzed how they evolve with time. ||| The proposed TC-CDR approach uses a combination of natural language processing and machine learning techniques to extract semantic features from user reviews and item descriptions, and then uses these features to compute topic coherence between domains. The approach is evaluated on two real-world datasets, Movielens and Bookcrossing, and is shown to outperform state-of-the-art CDR methods in terms of recommendation accuracy. ||| The study evaluates the learning perspectives of students on the basis of class notes taken while the teacher is teaching in class. The study uses a quasi-experimental design and involves 194 undergraduate students from the seventh semester of the computer engineering department. The study finds that homogenous and heterogeneous grouping methods have different effects on student learning outcomes. ||| This paper studies the usefulness of pair programming as a method to teach an introductory programming course. The contributions of the study are the following: Keeping in mind the role of personality traits in determining the success of pair programming, we use a blend of skills and personality‐based pairing mechanism. A five‐factor model comprising of skill levels of students, personality type, and attitude toward programming is considered for pairing students. To minimize conflicts and automate the pair formation, we propose a novel genetic algorithm‐based approach. The experiment was conducted for one semester covering the entire course syllabus to analyze the effects of pair programming better. ||| The KELDEC system is designed to extract technical phrases from images and use them to recommend relevant websites to users. The system uses a combination of natural language processing and machine learning techniques to identify relevant websites and rank them based on their semantic similarity to the image and the class notes. ||| The paper proposes a robust watermarking model for relational databases to detect piracy and ownership. The model consists of a watermark preparator, a watermark embedder, and a watermark extractor. The watermark preparator selects and secures the watermark with a secret key, while the watermark embedder embeds the watermark into the database. The model also discusses the importance of usability constraints and the selection of candidate attributes and bit positions for embedding the watermark. ||| The paper reviews the use of visual tools for teaching programming, including the development of various visual tools and their widespread use in teaching programming courses. It also discusses the use of game-based approaches and pair and collaborative programming for teaching programming. ||| The paper proposes a technique for watermarking categorical data, which involves embedding a watermark in the database by re-arranging the tuples partition-wise. The technique is entirely distortion free and provides a high level of security against attacks."
Shankaracharya,Diabetes Classiﬁcation using Radial Basis Function Network by Combining Cluster Validity Index and BAT Optimization with Novel Fitness Function,This paper discusses the use of cluster validity indices for diabetes diagnosis. The authors present a literature survey related to the problem and propose a methodology for identifying the optimal number of clusters. The experimental outcomes confirm the performance of the proposed methodology. The paper also reviews the performance of various neural network-based classifiers on the Pima Indians data set.,"diabetes diagnosis, Optimal number of clusters, Medical Diagnosis, Classiﬁcation, methodology, Diabetes, literature survey, Bat Algorithm, Radial Basis Function Networks, cluster validity indices, neural network-based classifiers","This paper presents a new model based on cluster validity index with radial basis neural network for classiﬁcation of diabetic patients data. The proposed model is tested on Pima Indians Diabetes data set and synthetic data sets, and experimental results proved that our approach performs better in terms of accuracy, sensitivity, speciﬁcity, classiﬁcation time, training time, network complexity and computational time compared to conventional radial basis function neural network."
Shantanu Rajora,Deep Sparse Representation Classifier for Facial Recognition  and Detection System,"This paper proposes a two-layer Convolutional Neural Network (CNN) to learn the high-level features which utilizes to the face identification via sparse representation. Feature extraction plays a vital role in real-world pattern recognition and classification tasks. The details description of the given input face image, significantly improve the performance of the facial recognition system. Sparse Representation Classifier (SRC) is a popular face classifier that sparsely represents the face image by a subset of training data, which is known as insensitive to the choice of feature space. The proposed method shows the performance improvement of SRC via a precisely selected feature exactor. The experimental results show that the proposed method outperform other methods on given datasets.","Sparse Feature Extraction, Convolutional neural network, Deep learning, CNN, Sparse representation classifier, Face recognition, Support Vector Machines, Feature extraction","This paper presents a robust face recognition framework based on the combination of sparse feature extraction using Convolutional Neural Networks (CNNs) and Support Vector Machines (SVMs). The proposed framework is evaluated on four widely used face datasets, including Extended YALE B database, AR database, MIT faces database, and ORL faces database. The experimental results show that the proposed framework outperforms the state-of-the-art methods in terms of recognition rate."
Sharif et al.,Deformation Adjustment with Single Real Signature Image for Biometric Verification Using CNN,"Signature verification is the widely used biometric verification method for maintaining individual privacy. It is generally used in legal documents and in financial transactions. A vast range of research has been done so far to tackle different system issues, but there are various hot issues that remain unaddressed. The scale and orientation of the signatures are some issues to address, and the deformation of the signature within the genuine examples is the most critical for the verification system.","biometric authentication, Single real signature image, soft biometrics, deep learning, hard biometrics, CNN, Signature verification, Deformation adjustment, Biometric verification, writer-independent","This work proposes a two-phase system requiring only one target signature image to verify a query signature image. It takes care of the target signature's scaling, orientation, and spatial translation in the first phase. The second phase uses this transformed sample image and verifies the given sample as the target signature with the help of another deep neural network."
Sharmi Sankar,Accurate Trafﬁc Flow Prediction in Heterogeneous Vehicular Networks in an Intelligent Transport System Using a Supervised Non-Parametric Classiﬁer,"Heterogeneous vehicular networks (HETVNETs) evolve from vehicular ad hoc networks (VANETs), which allow vehicles to always be connected so as to obtain safety services within intelligent transportation systems (ITSs). The services and data provided by HETVNETs should be neither interrupted nor delayed. Therefore, Quality of Service (QoS) improvement of HETVNETs is one of the topics attracting the attention of researchers and the manufacturing community.","QoS, SVM, Radial Basis Function, Prediction Accuracy, RBF, internet of vehicles, Support Vector Machines, HETVNET, Vehicular Ad Hoc Network",This paper proposes a prediction model based on support vector machines (SVMs) to improve Quality of Service (QoS) in Heterogeneous Vehicular Networks (HETVNETs). The model uses a radial basis function (RBF) kernel and outperforms other prediction methods in terms of accuracy and computational complexity.
Shashank Singh,Genetic variability and associations studies for yield and its component traits in potato (Solanum tuberosum L.),"The present investigation was conducted during growing season of 2017-18. Data collected on tuber yield and its components were subjected for analysis of variability parameters, correlation coefficient and genetic advance. The estimates of analysis of variance were significant for the all parameters. The analysis of genetic variance revealed that the sufficient variability was present in experimental material. The Phenotypic coefficient of variation (PCV) was slightly higher in magnitude than genotypic coefficient of variation (GCV) for all the parameters. The high heritability estimates in broad sense was recorded in weight of ‘C’ grade tubers per hill, number of stems per hill, yield of tubers per hill (kg plant-1), number of leaves per plant, weight of ‘A’ grade tubers per hill, weight of ‘B’ grade tubers per hill, number of ‘C’ grade tubers per hill, weight of ‘D’ grade tubers per hill. The high heritability estimates coupled with high genetic advance was recorded for the parameters number of ‘D’ grade tubers per hill, weight of ‘D’ grade tubers per hill, weight of ‘C’ grade tubers per hill, number of ‘B’ grade tubers per hill, weight of ‘B’ grade tubers per hill and yield of tubers per hill (kg plot-1).","potato, Genetic variability, Correlation coefficient, Solanum tuberosum L., Genetic advance, correlation","The study aimed to investigate the genetic variability and associations studies for yield and its component traits in potato (Solanum tuberosum L.). The results showed significant differences among genotypes for all the characters studied, with sufficient variability present in genotypes. The high heritability estimates and genetic advance were recorded for several parameters, indicating the potential for selection and breeding of high-yielding cultivars."
Shaunak Singh,Genetic variability and associations studies for yield and its component traits in potato (Solanum tuberosum L.),"The present investigation was conducted during growing season of 2017-18. Data collected on tuber yield and its components were subjected for analysis of variability parameters, correlation coefficient and genetic advance. The estimates of analysis of variance were significant for the all parameters. The analysis of genetic variance revealed that the sufficient variability was present in experimental material. The Phenotypic coefficient of variation (PCV) was slightly higher in magnitude than genotypic coefficient of variation (GCV) for all the parameters. The high heritability estimates in broad sense was recorded in weight of ‘C’ grade tubers per hill, number of stems per hill, yield of tubers per hill (kg plant-1), number of leaves per plant, weight of ‘A’ grade tubers per hill, weight of ‘B’ grade tubers per hill, number of ‘C’ grade tubers per hill, weight of ‘D’ grade tubers per hill. The high heritability estimates coupled with high genetic advance was recorded for the parameters number of ‘D’ grade tubers per hill, weight of ‘D’ grade tubers per hill, weight of ‘C’ grade tubers per hill, number of ‘B’ grade tubers per hill, weight of ‘B’ grade tubers per hill and yield of tubers per hill (kg plot-1).","potato, Genetic variability, Correlation coefficient, Solanum tuberosum L., Genetic advance, correlation","The study aimed to investigate the genetic variability and associations studies for yield and its component traits in potato (Solanum tuberosum L.). The results showed significant differences among genotypes for all the characters studied, with sufficient variability present in genotypes. The high heritability estimates and genetic advance were recorded for several parameters, indicating the potential for selection and breeding of high-yielding cultivars."
"Shi and Yu, 2012",Supervised Heterogeneous Domain Adaptation via Random Forests,This paper proposes a novel approach to heterogeneous domain adaptation using random forests. The algorithm leverages the common label information between the source and target domains as the pivot for knowledge transfer. The proposed algorithm determines the mapping PS between source and target features based on the estimate of the contribution of the features towards creating data partitions having similar label distributions.,"Label Information, Supervised Heterogeneous Domain Adaptation, Feature Mapping, Heterogeneous Domain Adaptation, Random Forests, Knowledge Transfer, Feature Transfer, Domain Adaptation",The paper proposes a novel supervised domain adaptation algorithm (SHDA-RF) that learns the mapping between heterogeneous features of different dimensions. The algorithm uses the shared label distributions present across the domains as pivots for learning a sparse feature transformation. The shared label distributions and the relationship between the feature spaces and the label distributions are estimated in a supervised manner using random forests.
Shikha Gupta,Ensuring Data Security in Databases Using Format Preserving Encryption ||| Format Preserving Encryption for Data Warehouse Security ||| MUTUAL LEARNING IN TREE PARITY MACHINES USING CUCKOO SEARCH ALGORITHM FOR SECURE PUBLIC KEY EXCHANGE,"In the current scenario data security has become an important issue with the growth of digital media. Many users and the applications are accessing the data both from inside and outside the database. Hence, the database as well as data within these databases has become the key target for most of the attackers. Many cryptographic schemes have been designed to solve this problem. Encryption plays an important role in providing the data confidentiality to data stored within the databases. But, the problem in adopting the standard encryption methods is that they may cause a damage to the existing schema as well as to the underlying applications or database as the output length is different from the input length and it also changes the format of data. This paper proposes a Format Preserving Encryption method by accumulating with Advance encryption standard(AES), eXclusive OR operation and a translation method for 16 digit numeric data. Format preserving encryption technique is used to minimizes the databases changes by preserving the format as well as the length of the input data. ||| This paper proposes a new data security technique known as format preserving encryption or data type preservation. Format preservation provides several distinct benefits that build on solid strong-encryption practices. The main aim of FPE is to encipher the data without the need to modify all of the systems that use that data; such as database field, queries and all the application program. ||| In Neural Cryptography, Artificial Neural Networks are used for the process of key generation and encryption. Tree Parity Machine (TPM) is a single layer neural network that approaches symmetric key exchange using the process of mutual learning. This method is exploited to design a secure key exchange protocol, where the sender and the receiver TPMs are synchronized to obtain an identically tuned weight vectors in both the networks.","Neural Networks, Advanced encryption standard(AES), Cuckoo Search Algorithm, AES Algorithm, numeric data, Data Warehouse Security, Neural Synchronisation, Data warehousing, Format preserving encryption, Security, Key Exchange, Data security, Mutual Learning, Feistel Network, Tree Parity Machine, AES, Database, Data Length, Secure Public Key Exchange, Advanced Encryption standard (AES)","This paper proposes a Format Preserving Encryption method to ensure data security in databases. The proposed method accumulates Advance encryption standard(AES), eXclusive OR operation, and a translation method for 16-digit numeric data. The technique minimizes database changes by preserving the format and length of the input data. ||| The proposed solution uses a new data security technique known as format preserving encryption or data type preservation. This technique provides several distinct benefits that build on solid strong-encryption practices. The main aim of FPE is to encipher the data without the need to modify all of the systems that use that data; such as database field, queries and all the application program. ||| This paper proposes a novel approach for the process of synchronisation in Tree Parity Machines using Cuckoo Search Algorithm for secure public key exchange. The results show that using CS algorithm for weight vector initialisation decreases the number of iterations significantly, resulting in ~30% decrease on an average. The effect of CS algorithm was observed by changing the weight range from 4 to 7 with N = 3, K = 100, and the results show that using CS, the synchronisation steps are decreased tremendously i.e. >50% decrease is observed."
Shikha Jain,EMIA: Emotion Model for Intelligent Agent ||| Event Perception and Appraisal Process and Its Formalization,"Emotions play a significant role in human cognitive processes such as attention, motivation, learning, memory, and decision making. Many researchers have worked in the field of incorporating emotions in a cognitive agent. However, each model has its own merits and demerits. Moreover, most studies on emotion focus on steady-state emotions than emotion switching. Thus, in this article, a domain-independent computational model of emotions for intelligent agent is proposed that have modules for emotion elicitation, emotion regulation, and emotion transition. ||| This paper presents a formalization of the event perception and appraisal process in an artificial intelligence system. The system uses a set of fuzzy sets to represent the appraisal variables, which are used to elicit emotions in response to events. The paper describes the architecture of the system, the event perception and appraisal process, and the formalization of the appraisal process. It also presents an example of how the system can be used to determine the linguistic values of the appraisal variables.","emotion elicitation, emotion transition, artificial intelligence, Emotion, Emotion modeling, emotion regulation, Event Perception, appraisal process, EMIA, Emotions, fuzzy sets, experiential learning, Scherer theory, Event Appraisal, emotion modeling, OCC theory","The article proposes a domain-independent computational model of emotion modeling for intelligent agent (EMIA) situated in a virtual environment. It uses the concept of a fuzzy classifier to model more flexible and adaptive emotional behavior of an agent. The model addresses the computation of the type of emotion as well as its level of intensity. It also has an emotion transition module that takes into consideration the elicitation of emotions based on a previous emotional state. ||| The paper presents a formalization of the event perception and appraisal process in an artificial intelligence system, using fuzzy sets to represent the appraisal variables and elicit emotions in response to events."
Shikhar Agnihotri,KELDEC: A System for Mining Knowledge Sources from Images,KELDEC is a system that mines knowledge sources from images by extracting technical phrases and using them to scout for relevant websites. The system uses a combination of natural language processing and machine learning techniques to identify relevant websites and rank them based on their semantic similarity to the image and the class notes.,"knowledge source, Educational recommender system, Personalized mobile learning, Web content mining, KELDEC, Classroom learning points, Image analysis, image mining, semantic similarity, technical phrases",The KELDEC system is designed to extract technical phrases from images and use them to recommend relevant websites to users. The system uses a combination of natural language processing and machine learning techniques to identify relevant websites and rank them based on their semantic similarity to the image and the class notes.
Shimpi Singh Jadon,Hybrid Artiﬁcial Bee Colony Algorithm with Diﬀerential Evolution ||| Spider Monkey Optimization algorithm for numerical optimization,"Artiﬁcial Bee Colony (ABC) and Diﬀerential Evolution (DE) are two very popular and ef- ﬁcient meta-heuristic algorithms. However, both algorithms have been applied to various science and engineering optimization problems, extensively, the algorithms suﬀer from premature convergence, unbal- anced exploration-exploitation, and sometimes slow convergence speed. Hybridization of ABC and DE may provide a platform for developing a meta-heuristic algorithm with better convergence speed and a better balance between exploration and exploitation capabilities. ||| Swarm intelligence is one of the most promising area for the researchers in the field of numerical optimization. Researchers have developed many algorithms by simulating the swarming behavior of various creatures like ants, honey bees, fish, birds and the findings are very motivating. In this paper, a new approach for numerical optimization is proposed by modeling the foraging behavior of spider monkeys.","Swarm intelligence, Fission–fusion social system, Spider Monkey Optimization algorithm, Artiﬁcial Bee Colony, Optimization, Hybridization, Swarm intelligence based algorithm, foraging behavior, fission-fusion social structure, Hybrid Algorithm, Spider monkey optimization, Diﬀerential Evolution, stochastic optimization","This paper proposes a hybrid version of ABC and DE, which also incorporates the modiﬁcation in the position update equation of ABC. The proposed hybrid algorithm is named as HABCDE. In HABCDE, the employed, onlooker and scout bee phases of ABC are modiﬁed. ||| This paper proposes a new swarm intelligence algorithm based on the foraging behavior of spider monkeys. The foraging behavior of spider monkeys shows that these monkeys fall in the category of fission–fusion social structure (FFSS) based animals. Thus the proposed optimization algorithm which is based on foraging behavior of spider monkeys is explained better in terms of FFSS."
Shiping Wen,Adaptive Lag Synchronization of Memristive Neural Networks with Unknown Connection Weights,"This paper investigates the adaptive lag synchronization of memristive neural networks with unknown connection weights. A new fuzzy model is proposed to simplify memristive systems, and the idea of PDC is applied to achieve synchronization between subsystems. The adaptive lag synchronization algorithm is designed, and the update law for the connection weights and controller gain is derived. The stability of the closed-loop system is analyzed, and the synchronization error is shown to be globally exponentially convergent to zero.","Adaptive lag synchronization, neural networks, memristor, synchronization error, memristive neural networks, PDC, fuzzy model, unknown connection weights, pseudorandom number generator (PRNG)","This paper presents a new approach to the adaptive lag synchronization of memristive neural networks with unknown connection weights. The proposed fuzzy model simplifies the memristive systems, and the PDC idea is applied to achieve synchronization between subsystems. The adaptive lag synchronization algorithm is designed, and the update law for the connection weights and controller gain is derived. The stability of the closed-loop system is analyzed, and the synchronization error is shown to be globally exponentially convergent to zero."
Shiti Cui,Reservoir Characterization and Productivity Forecast Based on Knowledge Interaction Neural Network,"The reservoir characterization aims to provide the analysis and quantification of the injection-production relationship, which is the fundamental work for production management. The connectivity between injectors and producers is dominated by geological properties, especially permeability. However, the permeability parameters are very heterogenous in oil reservoirs, and expensive to collect by well logging. The commercial simulators enable to get accurate simulation but require sufficient geological properties and consume excessive computation resources.","knowledge interaction neural network, machine learning, productivity prediction, reservoir characterization, Productivity Forecast, Physical Knowledge, embedded model","The goal of this study is to improve the accuracy and stableness of the inter-well connectivity characterization and enhance the prediction precision on well productivity, by combining the physical knowledge with machine learning techniques. An innovative neural network is proposed to handle the reservoir characterization and productivity forecast problems, in which the material balance equation is embedded via three high transparent modules, thereby ensuring the physical sense of model parameters."
Shiv Prakash,Virtualization in Wireless Sensor Networks: Fault Tolerant Embedding for Internet of Things,"Recently, virtualization in wireless sensor networks (WSNs) has witnessed significant attention due to the growing service domain for IoT. Related literature on virtualization in WSNs explored resource optimization without considering communication failure in WSNs environments. The failure of a communication link in WSNs impacts many virtual networks running IoT services. In this context, this paper proposes a framework for optimizing fault tolerance in virtualization in WSNs, focusing on heterogeneous networks for service-oriented IoT applications.","Fault Tolerant Embedding, Internet of Things, Virtualization, IoT, Wireless sensor networks","The paper discusses the importance of virtualization in WSNs for IoT applications, focusing on fault-tolerant embedding. It reviews existing proposals on virtualization in WSNs, highlighting their limitations and proposing a new approach to enhance fault tolerance."
Shivendra Pratap Singh,"Analgesic activity of synthesized compounds ||| Estimate of variability, heritability and genetic advance with respect to yield and yield contributing characters in field pea (Pisum sativum L.) ||| Genetic variability and associations studies for yield and its component traits in potato (Solanum tuberosum L.) ||| Isoprenaline Induced Model for Myocardial Necrosis ||| Study the modern biochemical analysis techniques of proteins and alkaline phasphtase enzyme system from biological sample chicken liver","In an approach to synthesize some potent benzoxazole derivatives, some compounds were synthesized. The details of these compounds are given below- The structures were confirmed using IR and NMR spectroscopy. The potency of synthesized compounds were established using following pharmacological screening- Analgesic activity  Paw edema- Male or female Wistar rats with a body weight between 100 and 150 g are used. The animals are starved overnight. To insure uniform hydration, the rats receive 5 ml of water by stomach tube (controls) or the test drug dissolved or suspended in the same volume. Thirty minutes later, the rats are challenged by a subcutaneous injection of 0.05 ml of 1% solution of carrageenan into the plantar side of the left hind paw. The paw is marked with ink at the level of the lateral malleolus and immersed in mercury up to this mark. The paw volume is measured plethysmographically immediately after injection, again 3 and 6 h, and eventually 24 h after challenge. [3] Analgesic activity Writhing tests- Mice of either sex with a weight between 20 and 25 g are used. Acetic acid in a concentration of 1% (1ml/kg) is used to produce writhing. An aliquot of 0.025 ml of this suspension is injected intraperitoneally. Groups of 6 animals are used for controls and treated mice. Preferably, two groups of 6 mice are used as controls. Test animals are administered the drug or the standard at various pretreatment times prior to Acetic acid administration. The mice are placed individually into glass beakers and five min are allowed to elapse. The mice are then observed for a period of ten min and the number of writhes is recorded for each animal. For scoring purposes, a writhe is indicated by stretching of the abdomen with simultaneous stretching of at least one hind limb. The formula for computing percent inhibition is: average writhes in the control group minus writhes in the drug group divided by writhes in the control group times 100%. The time period with the greatest percent of inhibition is considered the peak time. A dose range is reserved for interesting compounds or those which inhibit writhing more than 70%. Compounds with less than 70% inhibition are considered to have minimal activity. [4] Microbiological screening For both antibacterial and assay compounds were dissolved in absolute ethanol (0.8 mg/ml). Further dilutions of the compounds and standard drugs in the test medium have concentrations of 400, 200, 100, 50, 25, 12.5, 6.25, 3.12, 1.56, 0.78 mg/ml. The minimum inhibitory concentrations (MIC) were determined using the method of two-fold serial dilution. In order to ensure that the solvent ‘per se’ had no effect on bacterial growth, a control test was also performed containing inoculated broth supplemented with only ethanol at the same dilutions used in our experiments and found inactive in culture medium. Antibacterial assay- The cultures were obtained in Nutrient agar broth (Difco) for all the bacteria after 24 h of incubation at 37+1°C. Testing was carried out in Nutrient agar broth at pH 7.4 and the two-fold serial dilution technique was applied. The final inoculums size was 105 CFU/ml. A set of tubes containing only inoculated broth was kept as controls. Ciprofoxacine was taken as standard. After incubation for 24 h at 37+1°C, the last tube with no growth of microorganism was recorded to represent MIC expressed in g/ml. [5] ||| The present investigation entitled “Estimate of variability, heritability and genetic advance with respect to yield and yield contributing characters in field pea (Pisum sativum L.)” for 10 characters. The experiment comprising of 23 genotypes of pea were grown in a Randomized Block Design (RBD), with three replications at Research Farm, Department of Genetics & Plant Breeding, Post Graduate College, Ghazipur, during rabi season of 2017-2018, plant to plant and row to row distance was kept 10 cm and 45 cm, respectively. ||| The present investigation was conducted during growing season of 2017-18. Data collected on tuber yield and its components were subjected for analysis of variability parameters, correlation coefficient and genetic advance. The estimates of analysis of variance were significant for the all parameters. The analysis of genetic variance revealed that the sufficient variability was present in experimental material. The Phenotypic coefficient of variation (PCV) was slightly higher in magnitude than genotypic coefficient of variation (GCV) for all the parameters. The high heritability estimates in broad sense was recorded in weight of ‘C’ grade tubers per hill, number of stems per hill, yield of tubers per hill (kg plant-1), number of leaves per plant, weight of ‘A’ grade tubers per hill, weight of ‘B’ grade tubers per hill, number of ‘C’ grade tubers per hill, weight of ‘D’ grade tubers per hill. The high heritability estimates coupled with high genetic advance was recorded for the parameters number of ‘D’ grade tubers per hill, weight of ‘D’ grade tubers per hill, weight of ‘C’ grade tubers per hill, number of ‘B’ grade tubers per hill, weight of ‘B’ grade tubers per hill and yield of tubers per hill (kg plot-1). ||| The study used isoprenaline-induced myocardial necrosis as an experimental model to evaluate the cardioprotective effects of various herbal drugs. The pathophysiological changes following ISO administration in rats are comparable to those taking place during MI in humans. ||| The objective of the study was the biochemical analysis of proteins and Alkaline Phosphatase enzyme system from biological sample Chicken Liver using modern biochemical analysis techniques, including protein extraction, fractionation and electrophoresis separation technique and enzyme analysis.","Benzoxazole, heritability, Genetic variability, Pisum sativum L., Correlation coefficient, benzoxazole derivatives, Biochemical analysis, antibacterial assay, acid phosphatase, correlation, alkaline phosphatase, field pea, Microbiological screening, Isoprenaline, Amino acids, genetic advance, Solanum tuberosum L., Isoproterenol, Proteins, pharmacological screening, potato, myocardial necrosis, yield contributing characters, proteases, Anti-inflammatory activity, Nelumbo nucifera, Enzymes, Cardioprotective Effects, peroxidases, cardioprotective effect, Herbal Drugs, Genetic advance, Protein chains, Analgesic activity","The study aimed to synthesize potent benzoxazole derivatives and evaluate their analgesic activity using pharmacological screening. The compounds were synthesized and their structures confirmed using IR and NMR spectroscopy. The potency of the synthesized compounds was established using analgesic activity tests, including paw edema and writhing tests. The results showed that some of the compounds exhibited significant analgesic activity, with one compound showing 63.33% inhibition at a dose of 30 mg/kg. The study also evaluated the antibacterial activity of the compounds using the two-fold serial dilution technique and found that some of the compounds exhibited significant antibacterial activity. The study concluded that the synthesized compounds have potential as analgesic and antibacterial agents. ||| The estimates of genotypic coefficient of variation (GCV) and phenotypic coefficient of variation (PCV) and environmental coefficient of variation (ECV) showed a wide range. The high estimates of genotypic coefficient of variation (GCV) were observed for plant height, biological yield per plant, number of pods per plant, seed yield per plant, number, 100 seed weight. The high estimates of phenotypic coefficient of variation (PCV) were observed for seed yield per pod, number of pods per plant, biological yield per plant, harvest index, plant height. ||| The study aimed to investigate the genetic variability and associations studies for yield and its component traits in potato (Solanum tuberosum L.). The results showed significant differences among genotypes for all the characters studied, with sufficient variability present in genotypes. The high heritability estimates and genetic advance were recorded for several parameters, indicating the potential for selection and breeding of high-yielding cultivars. ||| The study aimed to develop a pharmacologic technique for producing myocardial necrosis of standard severity in animals using isoprenaline-induced myocardial necrosis as an experimental model. ||| The paper discusses the biochemical analysis of proteins and alkaline phosphatase enzyme system from chicken liver using modern biochemical analysis techniques. It covers topics such as protein synthesis, structure, and purification, and highlights the importance of proteins in living organisms."
Shraddha Khapra,Genetic Algorithm-Based Approach for Teaching Programming,"Pair programming is an approach where two programmers work to solve one programming problem sitting shoulder to shoulder on a computer. Several studies indicating numerous benefits of using pair programming as a teaching strategy exist. However, only a few of them take into consideration the mechanism followed for pair formation. With an aim to study the impact of pair programming on undergraduate students, we try to make the pairs compatible with a genetic algorithm‐based approach. Using a genetic algorithm, the system ensures that every pair in the class gets a particular combination of skills and personality traits. We also developed a desktop application to assign programming exercises to students dynamically. To assess the efficacy of pair programming in introductory programming course, a formal pair programming experiment was run at Netaji Subhas University of Technology. The pair programming experiment involved a total 171 undergraduate students from a computer engineering course. At the end of the program, we assessed the programming abilities of every student. We also analyzed the impact of a genetic algorithm‐based pairing mechanism. On the basis of assessments, it is observed that pair programming is a successful pedagogical tool for facilitating active learning of introductory programming courses. Responses to survey garnered from undergraduate students hint that the genetic algorithm approach leads to compatible pairs.","introductory programming, pair programming, genetic algorithm, Pair Formation, collaborative learning, Programming Exercises","This paper studies the usefulness of pair programming as a method to teach an introductory programming course. The contributions of the study are the following: Keeping in mind the role of personality traits in determining the success of pair programming, we use a blend of skills and personality‐based pairing mechanism. A five‐factor model comprising of skill levels of students, personality type, and attitude toward programming is considered for pairing students. To minimize conflicts and automate the pair formation, we propose a novel genetic algorithm‐based approach. The experiment was conducted for one semester covering the entire course syllabus to analyze the effects of pair programming better."
Shu Jiang,A new method for rock brittleness evaluation in tight oil formation from conventional logs and petrophysical data,"Brittleness is a critical indicator for hydraulic fracturing candidate screening in unconventional reservoirs. Current rock brittleness estimation models are often inferred from mechanical parameters and mineralogical data, which primarily use empirical equations. However, the absence of shear sonic velocity data and insufficient mineral data sometimes restricts its wide application. In this article, our objective is to illustrate the application of a data-driven approach for rock brittleness estimation that employs computational intelligence technologies (multilayer perception and radial basis function models) that use conventional well logs as inputs.","Rock brittleness, Multilayer perception, production, brittleness, Computational intelligence, Hydraulic fracturing, Tight oil, oil and gas exploration, rock mechanics, Radial basis function","The paper reviews the current state of brittleness calculation methods and their limitations, highlighting the need for a universally applicable model. It discusses the importance of mineral composition, strain rate, temperature, pore pressure, saturation, and stress state in controlling rock brittleness."
Shubhra Jyoti,Analysing the Performance of Novel Activation Functions on Deep Learning Architectures,"Deep learning is a cutting-edge technology that functions similarly to the human nervous system. Neural networks are at the heart of Deep Learning. Neural networks are made up of numerous layers, in-cluding the input layer, which accepts raw data as input, hidden layers, which process the input data, and a final layer, the output layer, which provides the result. Its workflow pattern is comparable to machine learn-ing [2], [11], allowing us to gain hands-on expertise with this technology, speed up our work, and allow us to make several efforts without hav-ing to develop a basic Machine learning algorithm from scratch. In the case of deep learning, there are several neural networks to choose from. The majority of Deep Learning architectures are built on neural networks such as CNN, RNN, and others. Deep neural network activation function development is often guided by set goals and gradual steps toward tack-ling specific challenges. The primary goal of this study is to examine the performance of innovative activation functions (SBAF parabola [6] [16], AReLU [7], Leaky ReLU, SWISH) on deep learning architectures such as CNN, DENSENET, etc. On deep learning architectures, our study will compare the classification performance of the aforementioned activation functions.","Redundancy, Network reliability, Robotics, Embedded systems","This paper explores the performance of novel activation functions (SBAF parabola, AReLU, Leaky ReLU, SWISH) on deep learning architectures like CNN and DENSENET. The study aims to compare the classification accuracy of these activation functions on various computer vision datasets."
Shusen Yang,A Cost-Efficient Communication Framework For Battery Switch Based Electric Vehicle Charging,"This paper proposes a battery switch service for electric vehicles (EVs) using a publish/subscribe (P/S) communication paradigm. The system consists of road side units (RSUs), electric vehicles (EVs), and charging stations (CSs). RSUs act as brokers to bridge the information flow from CSs to EVs, while EVs and CSs interact through RSUs. The system enables efficient radio resource utilization and alleviates interference to EVs.","Electric Vehicles, publish/subscribe, road side units, Smart Cities, Communication Framework, Charging Management, Battery Switch, charging stations","This article presents a cost-efﬁcient communication framework for battery switch based electric vehicle charging. The framework is provisioned to support the EV charging service and considers urban travel uncertainties, e.g., trafﬁc congestions and drivers’ preferences. Results demonstrate a guidance for the provisioning of P/S communication framework to improve EV drivers’ experience, e.g., charging waiting time and total trip duration."
Siddharth Gupta,Map-reduce-based tournament empowered whale optimization algorithm for recommendation,"In the era of Web 2.0, the data are growing immensely and is assisting E-commerce websites for better decision-making. Collaborative filtering, one of the prominent recommendation approaches, performs recommendation by finding similarity. However, this approach fails in managing large-scale datasets. To mitigate the same, an efficient map-reduce-based clustering recommendation system is presented. The proposed method uses a novel variant of the whale optimization algorithm, tournament selection empowered whale optimization algorithm, to attain the optimal clusters.","tournament empowered WOA, Map-reduce, Recommendation system, Clustering, Whale optimization algorithm, Big data, map-reduce architecture","This paper presents a novel meta-heuristic-based recommendation system for the big data environment. The proposed method uses a novel variant of the whale optimization algorithm, tournament selection empowered whale optimization algorithm, to attain the optimal clusters. The clustering efficiency of the proposed method is measured on four large-scale datasets in terms of F-measure and computation time."
Siddiqi & Shekaran,Characterizing relatedness of web and requirements engineering,"Web and Requirements Engineering have been well-recognized as two individual active areas of research in the past. Convergence between these two notable areas has been a point-of-discussion in recent years and offers new avenues of research. This paper explores this alliance from two perspectives; firstly, where Requirement Engineering can be viewed as a process for Web application development as it primarily concerns with adapting the Requirement Engineering process to the Web applications which are special in characteristics as compared to traditional software applications and secondly, where Web can be viewed as a supporting technology for improving the requirements engineering process and enabling new capabilities.","Web Applications, Web 3.0, Web 2.0, SWOT Analysis, Web application, Requirements engineering","The paper explores the relationship between Web and Requirements Engineering from two perspectives, highlighting the need for a more extensive and efficient Requirements Engineering process for Web applications, and the potential of Web technologies to support and improve the requirements engineering process."
"Silva Filho, A. C., et al. (2015)",Quantum-inspired evolutionary approach for selection of optimal parameters of fuzzy clustering,"Recently, Fuzzy c-Means (FCM) algorithm is most widely used because of its efficiency and simplicity. However, FCM is sensitive to the initialization of fuzziness factor (m) and the number of clusters (c) due to which it easily trapped in local optima. A selection of these parameters is a critical issue because an adverse selection can blur the clusters in the data.","Fuzzy clustering, Cluster validity index, Quantum-Inspired Evolutionary Fuzzy c-Means, Fuzzy c-Means algorithm, Fuzzy c-Means, Quantum computing","This paper proposes a hybrid fuzzy clustering algorithm, Quantum-Inspired Evolutionary Fuzzy c-Means (QIE–FCM), which uses the merits of quantum computing for finding the global optimal value of m and its corresponding value of c in the FCM. The proposed approach improves the way of initialization of the fuzziness factor (m) in the FCM and provides the diversity in selecting the optimal value of m and c from a large quantum search space."
Simon Guerard,ROS deficiency enhanced mannan-induced PsA,"In and joint inflammation using B10Q.Ncf1m1j/m1j mice that have a mutation in the Ncf1 gene (m1j) (the Ncf1 protein also denoted p47phox), and hence reduced ROS production (oxidative burst) (18). As shown in Fig. 1D, Ncf1 mutated mice developed severe joint inflammation within 2 d after mannan injection, which reached the mean maximal disease severity (30 ± 6 points) within 4 d. The frequency of skin lesions was 100%, with more severe cases in B10Q.Ncf1m1j/m1j mice (Fig. 1E), whereas B10.Q mice had a significantly milder disease course. Multiple Exposures to Mannan Induced a Relapsing Disease. Next, we examined the effect of multiple mannan injections in B10Q and B10Q.Ncf1m1j/m1j mice. We boosted mice twice with mannan on days 7 and 14 after disease initiation. Repetitive injections of mannan reproduced the arthritis phenotype, which reached the maximum severity level on days 9 and 17, similar to the first injection (Fig. 1F). A more severe disease course was observed in B10Q.Ncf1m1j/m1j mice than in B10Q mice (P < 0.05 and P < 0.01, respectively). Interestingly, Ps skin scaling returned only after the second mannan injection (on day 16), but the skin peeled off even more quickly than the first time (Fig. 1G). Moreover, from day 11 onward, B10Q.Ncf1m1j/m1j mice started to develop pruritus on the body, predominantly on the back and above the eye (Fig. S1E). Pruritus was only evident in B10Q.Ncf1m1j/m1j mice, but flaky skin on the tail and alopecia all over the leg was observed in both of the mouse strains. We also observed genetic heterogeneity in disease susceptibility (Fig. Fig. 1. ROS deficiency enhanced mannan-induced PsA. The arthritic joint phenotype and Ps-like skin lesions in the front (A) and hind (B) paws of B10Q.Ncf1m1j/m1j mice are shown. (C) Ps-like skin scaling in diseased B10Q.Ncf1m1j/m1j mouse ear compared with naive mouse ear. Mean arthritis (D) and Ps lesion (E) severity in B10Q (n = 5) and B10Q.Ncf1m1j/m1j (n = 5) mice after a single i.p. mannan injection. Mean arthritis (F) and Ps lesion (G) severity in B10Q (n = 5) and B10Q.Ncf1m1j/m1j (n = 5) mice after repetitive mannan injections (days 7 and 14). (H) Mannan-induced mean maximum arthritis scores ± SEM in different mouse strains: B10Q (n = 8), B10Q.Ncf1m1j/m1j (n = 9), B10RIII (n = 10), B10RIII.Ncf1m1j/m1j (n = 9), B10P (n = 3), B10P.Ncf1m1j/m1j (n = 9), BALB/cByJ/Q (n = 10), BALB/cByJ/Q.Ncf1m1j/m1j (n = 8), BALB/cByJ (n = 5), BALB/cByJ.Ncf1m1j/m1j (n = 7), C57BL/6NJ (n = 8), and C57BL/6NJ.Ncf1m1j/m1j (n = 7). Significance was calculated by comparing the maximal disease severity of B10Q and B10Q.Ncf1m1j/m1j mice with all of the other strains in their respective groups. *P < 0.05; **P < 0.01; ***P < 0.001. E3670 | www.pnas.org/cgi/doi/10.1073/pnas.1405798111 Khmaladze et al. Downloaded from https://www.pnas.org by 122.184.65.228 on February 22, 2023 from IP address 122.184.65.228.","autoimmune disease, Ncf1, animal model","This study identifies a new mechanism for psoriasis (Ps) and psoriasis arthritis (PsA) development in mice. A single injection of mannan, a component of baker's yeast, induced Ps and PsA-like symptoms. This effect was exacerbated in mice lacking reactive oxygen species (ROS), but improved when ROS production was restored in macrophages.  Blocking IL-17A, a cytokine produced by gamma delta T cells, completely prevented disease. The study suggests that mannan activates macrophages, leading to TNF-α secretion and stimulation of IL-17A production by gamma delta T cells. This, in turn, drives neutrophil infiltration and inflammation, mimicking Ps and PsA. This new mouse model could be valuable for testing new therapies for Ps and PsA."
Simon J. Conway,Opposing Actions of Fibroblast and Cardiomyocyte Smad3 Signaling in the Infarcted Myocardium,"Transforming growth factor (TGF)–βs are highly pleiotropic mediators with critical roles in regulating cellular phenotype and function in embryonic development, tissue homeostasis, and disease. Normal tissues contain stores of latent TGF-β bound to the extracellular matrix through its association with a large binding protein, the latent TGF-β binding protein. Tissue injury is associated with marked induction of TGF-β isoforms and activation of TGF-β signaling cascades. Parenchymal cells, extravasated leukocytes, and platelets synthesize and release large amounts of TGF-β in the injury site. Reactive oxygen species, proteases, matricellular proteins, and integrins cooperate to trigger the release of bioactive TGF-β from the latent stores. Subsequent binding of the active TGF-β dimer to the type II TGF-β receptor, followed by transphosphorylation of the type I receptor, triggers the TGF-β signaling response. The cellular effects of TGF-β are mediated through a canonical pathway involving a series of intracellular effectors, the Smads, or through activation of noncanonical signaling cascades. Activation of TGF-β signaling induces phosphorylation of the receptor-activated Smads, Smad2 and Smad3, which can form heteromeric complexes with the common Smad, Smad4. These complexes are transported to the nucleus, where they regulate gene transcription. TGF–β receptors and Smads are ubiquitously expressed by all cell types. Thus, all cells are responsive to the actions of TGF-β. Cardiac injury is associated with the marked induction of TGF-β and activation of TGF-β cascades. Our laboratory and other investigators have documented activation of Smad2 and Smad3 signaling in the infarcted myocardium, localized in both cardiomyocytes and interstitial cells. In isolated cardiac fibroblasts, Smad3 signaling accentuates myofibroblast transdifferentiation and stimulates a matrix-preserving program. In a model of reperfused infarction, global loss of Smad3 attenuated remodeling after infarction. However, considering the ubiquitous expression of Smad3 in all cell types, the cell biological basis for the actions of Smad3 in the infarcted heart remains unknown. Our study dissects the cell-specific actions of Smad3 signaling in the infarcted myocardium by developing and studying mice with cell-specific loss of Smad3 in activated fibroblasts and cardiomyocytes. It is surprising that fibroblast-specific loss of Smad3 worsened remodeling after infarction, resulting in accentuated chamber dilation. The deleterious consequences of fibroblast-specific Smad3 loss reflected unrestrained fibroblast proliferation, defective scar remodeling, and perturbed organization of myofibroblast arrays in the border zone. Smad3 signaling regulated fibroblast function, activating integrin-mediated nicotinamide adenine dinucleotide phosphate (NADPH) oxidase (NOX)–2 expression. In contrast, cardiomyocyte-specific loss of Smad3 protected the infarcted heart from dysfunction after infarction. The protective effects of cardiomyocyte-specific Smad3 loss were associated with attenuated cardiomyocyte apoptosis in remodeling myocardium and accompanied by decreased NOX2 levels, reduced nitrosative stress, and decreased matrix metalloproteinase (MMP)–2 expression.","SMAD, fibroblast, heart failure, cardiomyocyte, remodeling","This study investigates the role of Smad3 in cardiac fibroblasts following myocardial infarction. Using a mouse model with fibroblast-specific Smad3 deletion (FS3KO), the researchers found that loss of Smad3 in fibroblasts exacerbated dilative remodeling and worsened systolic dysfunction after both reperfused and nonreperfused infarction.  While acute infarct size was not affected, FS3KO mice exhibited larger scars, increased myofibroblast density, and enhanced myofibroblast proliferation. These findings suggest that Smad3 plays a protective role in cardiac fibroblasts and its loss contributes to adverse cardiac remodeling after infarction."
Singh et al.,A Novel Blockchain-Based Healthcare System Design and Performance Benchmarking on a Multi-Hosted Testbed,"As a result of the proliferation of digital and network technologies in all facets of modern society, including the healthcare systems, the widespread adoption of Electronic Healthcare Records (EHRs) has become the norm. At the same time, Blockchain has been widely accepted as a potent solution for addressing security issues in any untrusted, distributed, decentralized application and has thus seen a slew of works on Blockchain-enabled EHRs. However, most such prototypes ignore the performance aspects of proposed designs. In this paper, a prototype for a Blockchain-based EHR has been presented that employs smart contracts with Hyperledger Fabric 2.0, which also provides a unified performance analysis with Hyperledger Caliper 0.4.2.","Multi-party healthcare framework, On-chain and off-chain storing scheme, RAFT orderer, Hyperledger Fabric, Blockchain, Electronic Healthcare Records (EHR), RAFT ordering services, Gossip protocol","This paper presents a novel Blockchain-based healthcare system design and performance benchmarking on a multi-hosted testbed. The proposed framework within the multi-host instances continues to behave more successfully with high throughput, low latency, and low utilization of resources for opening, querying, and transferring transactions into a healthcare Blockchain network."
Sirisha Lakshmi Vavilala,"Antioxidant Activity, Phenol and Flavonoid Content of Helicteres isora (L.)","Helicteres isora L., commonly known as Indian Screw Tree is a highly valued medicinal plant in South-East Asia. The various phytochemicals like phenols, flavonoids and other antioxidants that impart the medicinal properties in this plant, vary in their composition and concentration in different plant parts. In the present research, the total phenolic content, total flavonoids content and free radical scavenging activity (FRAP and DPPH assay) in fresh and dry sample extracts of leaf, bark, fruit and root of H. isora L., prepared in four different solvents (distilled water, ethanol, methanol and acetone) were studied, and their results compared using Pearson’s Correlation. The plant extracts were also subjected to RP-HPLC for detection and quantitation of naturally occurring phenolic compounds using six phenolic standards (Gallic acid, Vanillin, Catechol, Ferrulic acid, p-coumaric acid and Caffeic acid). The highest total phenolic content (7.22 mg/g GAE) and FRAP value (64.98 mg/g TE) were observed in aqueous dry root extract. The acetone extract of fresh leaf (57.08 mg/g of RE) was found richest in total flavonoids, while the methanolic extract of fresh fruit uniquely exhibited strong free radical scavenging activity as evidenced by the low IC50 value (34.37 mg/ml) in DPPH assay. The RP-HPLC analysis revealed that Catechol and Gallic acid were most abundantly found phenolic compounds in extracts of H. isora L. The total phenolic content showed strong positive correlation with free radical scavenging activity (FRAP and DPPH assays) in both fresh and dry plant parts, suggesting that phenols are the main compounds responsible for the antioxidant activity. The root of H. isora L. was found rich in phenolics and antioxidant capacity indicating its strong potential for medicinal use, followed by fruit, leaf and bark.","Flavonoids, FRAP, DPPH, Phenols, Helicteres isora L., RP-HPLC","The qualitative tests for various phytochemicals revealed presence of saponins, alkaloids, steroids, terpenoids, glycosides, cardiac glycosides, phenols and flavonoids. The glycosides, phenols and flavonoids were present in all of the 32 extracts tested. Steroids and terpenoids were mainly found in dry plant part extracts whereas only few extracts of fresh plant parts, showed their presence. Tannins were uniquely present in only aqueous extract of dry leaf. Steroids were present in all extracts of dry leaf while present only in aqueous extracts of dry fruit, root, and bark. Out of the four plant parts, dry leaf extracts in four solvents, aqueous, ethanol, methanol and acetone, showed presence of all phytochemicals (Table 2). The fresh plant extracts were found to be low in steroids, terpenoids, and tannins while moderate in saponins and alkaloids. The dry plant extracts were found richer in phytochemicals as compared to fresh ones."
Sivasubramaniam Janarthan et al.,Deep Learning Techniques for Disease Detection in Fruits and Vegetables,"Plant Diseases are one of the leading reasons of economic shortfalls in agricultural and farming sectors worldwide. It is the most essential element since it reduces crop quantity and quality significantly. Fruits are one of the largest essential nutritional resources from plants. Unfortunately, a variety of conditions might impair both the content and outcome of fruits. As a result, an autonomous Computer Vision (CV) -based approach for reliable Fruit Disease Detection (FDD) is necessary.","Attention mechanisms, Transfer learning, Convolutional neural networks, Computer Vision, Machine Learning, Disease detection, Deep Learning, Fruits and vegetables, Fruit Disease Detection","This paper presents a detailed review of different ML and DL algorithms developed to predict and classify FDs from different fruit images. First, different FDD and classification systems designed by many researchers based on ML and DL algorithms are studied in brief. Then, a detailed analysis is carried out in order to identify the shortcomings of existing algorithms and to provide a novel strategy for properly classifying fruit pathogens."
Siwei Jiang,Consistencies and Contradictions of Performance Metrics in Multiobjective Optimization,"An important consideration of Multiobjective Optimization (MOO) is the quantitative metrics used for defining the optimality of different solution sets, which is also the basic principle for the design and evaluation of MOO algorithms.","Diversity, Capacity, Multiobjective Optimization, Hypervolume, Performance Metrics, Convergence","This paper investigates the relationships among representative group metrics in Multiobjective Optimization, including Generational Distance (GD), ϵ-indicator (I1ϵ+), Spread (∆), Generalized Spread (∆∗), Inverted Generational Distance (IGD) and Hypervolume (HV). Experimental results indicated that these six metrics show high consistencies when Pareto fronts (PFs) are convex, whereas they show certain contradictions on concave PFs."
Sk. Kamaruddin,Credit Card Fraud Detection using Big Data Analytics: Use of PSOAANN based One-Class Classification,"This paper presents a hybrid model called PSOAANN, which combines the strengths of Auto-Associative Neural Network (AANN) and Particle Swarm Optimization (PSO). The proposed model is used for one-class classification, where the goal is to identify the minority class in a dataset. The PSOAANN model is trained on negative samples and learns the characteristics of the majority class. The model is then tested on positive samples, and the relative error is computed for each feature. If the relative error is greater than a threshold value, the sample is classified as belonging to the positive class.","Particle swarm optimization, AANN, Auto-encoder, One-class classification, PSOAANN, PSO, Auto-associative neural network, Single class classification, hybrid model",This paper presents a study on credit card fraud detection using one-class classification approach in big data paradigm. The proposed methodology involves a hybrid architecture of Particle Swarm Optimization and Auto-Associative Neural Network for one-class classification in Spark computational framework. The results show that the proposed approach is effective in detecting credit card fraud.
Smiti Singhal,"Explainable AI (XAI): Core Ideas, Techniques and Solutions ||| Title Suppressed Due to Excessive Length","As our dependence on intelligent machines continues to grow, so does the demand for more transparent and interpretable models. In addition, the ability to explain the model generally is now the gold standard for building trust and deployment of Artificial Intelligence (AI) systems in critical domains. Explainable Artificial Intelligence (XAI) aims to provide a suite of machine learning (ML) techniques that enable human users to understand, appropriately trust, and produce more explainable models. ||| The objective of an online Mart is to match buyers and sellers, to weigh animals and to oversee their sale. A reliable pricing method can be developed by ML models that can read through historical sales data. However, when AI models suggest or recommend a price, that in itself does not reveal too much (i.e., it acts like a black box) about the qualities and the abilities of an animal. An interested buyer would like to know more about the salient features of an animal before making the right choice based on his requirements. A model capable of explaining the different factors that impact the price point is essential for the needs of the market. It can also inspire confidence in buyers and sellers about the price point offered.","Machine Learning, Software toolkits, Video Analytics, Decision Making, vision based feature extraction, Internet of Things, Bias, Interpretable AI, XAI, Explainable AI, cow, Robustness, computer vision, ML based price prediction, weight estimation, Stakeholders, machine learning, Programming framework, Explainable Artiﬁcial Intelligence","The paper presents the core ideas, techniques, and solutions of XAI, emphasizing its importance in various phases of the machine learning process. It discusses the stakeholders involved in these phases, including developers, theorists, data scientists, users, consumers, businesses, regulators, and scientists, and highlights the use cases of XAI in detecting bias, scientific understanding, building robust models, and better decision making. ||| The paper discusses a method for estimating the weight of cows using a machine learning approach. The method involves training a model to predict the weight of cows based on images of their faces. However, the paper notes that the face of a cow is not sufficient for weight estimation and that the model can get biased according to color. The paper also discusses the limitations of the approach and suggests future directions for research."
Sommerville & Kotonya,Characterizing relatedness of web and requirements engineering,"Web and Requirements Engineering have been well-recognized as two individual active areas of research in the past. Convergence between these two notable areas has been a point-of-discussion in recent years and offers new avenues of research. This paper explores this alliance from two perspectives; firstly, where Requirement Engineering can be viewed as a process for Web application development as it primarily concerns with adapting the Requirement Engineering process to the Web applications which are special in characteristics as compared to traditional software applications and secondly, where Web can be viewed as a supporting technology for improving the requirements engineering process and enabling new capabilities.","Web Applications, Web 3.0, Web 2.0, SWOT Analysis, Web application, Requirements engineering","The paper explores the relationship between Web and Requirements Engineering from two perspectives, highlighting the need for a more extensive and efficient Requirements Engineering process for Web applications, and the potential of Web technologies to support and improve the requirements engineering process."
Somnath Dey,A novel hybrid score level and decision level fusion scheme for cancelable multi-biometric verification ||| A privacy-preserving cancelable iris template generation scheme using decimal encoding and look-up table mapping ||| Cancelable iris template generation using look-up table mapping ||| Generating protected fingerprint template utilizing coprime mapping transformation,"In spite of the benefits of biometric-based authentication systems, there are few concerns raised because of the sensitivity of biometric data to outliers, low performance caused due to intra-class variations and privacy invasion caused by information leakage. To address these issues, we propose a hybrid fusion framework where only the protected modalities are combined to fulfill the requirement of secrecy and performance improvement. ||| This paper presents a privacy-preserving cancelable iris template generation scheme using decimal encoding and look-up table mapping. The proposed method consists of a number of tasks, including iris image preprocessing, decimal encoding, and look-up table mapping. The experimental results show that the proposed method outperforms existing approaches in terms of recognition accuracy and security. ||| This paper presents a novel approach for generating cancelable iris templates for secure iris recognition. The proposed method involves applying circular Hough transformation, normalization using Daugman's rubber sheet model, and local histogram analysis to enhance the iris image. The normalized iris image is then transformed into a 0-1 form of matrix after convolving with quadrature 1-D Gabor filter. The Gabor coefficient values are coded with either 1 or 0 depending on the sign of the coefficient. The Gabor function is represented in Eq. (1). The iris pattern can be affected by rotation, and rotation invariance mechanism is employed by taking 8 images per subject and computing Hamming distances between the reference image and other images by shifting one column. The rotation free templates are shift invariant in comparison to iris code. The rotation invariant templates are transformed into a row vector to make ease in computation. The row vector is created through merging the next row to previous one. A row vector of 1 × 24 is obtained from the iris code of 4 × 6. The row vector is partitioned into a number of blocks of size M. The value of M may be chosen statically or dynamically and different for every image. The decimal vector is constructed by partitioning row vector using a fixed length word of size M. The decimal vector has the same number of positive integers as the number of words in row vector. The conversion of a word from binary to positive integer seize the left most bit as the most significant bit. The decimal vector is mapped to a corresponding word utilizing a look-up table. More than one word can be mapped to the same positive integer, so reverse mapping is very difficult. The look-up table is generated of random values 0 and 1. The minimum size (rows) of the table depends on the value of M. For example if we have word length 4, then the maximum decimal integer is 15. So the table must have entries greater than or equal to 15. There is a possibility that all entries of a particular row or more than one row are 0. In this situation, the use of these entries are vulnerable to privacy invasion, as this makes imposters task easy. Therefore, look-up table should be such that the number of 0's and 1's are approximately same in a randomized manner. The mapping of decimal vector is performed to the corresponding row of the randomly generated look-up table. Then d bits are selected from each row of the look-up table. ||| The identity of a user is permanently lost if biometric data gets compromised since the biometric information is irreplaceable and irrevocable.","MCW Based Score Level, fusion, biometric, Cancelable iris template, DS Theory-Based Decision Fusion, Look-up table mapping, privacy, verification, Biometrics, Multimodal Biometric Authentication, Row Vector, multibiometric system, Fingerprint verification, iris biometric, Decimal encoding, Biometric security, Security, Look-up table, Iris biometric, Decimal Vector, Iris Image Enhancement, Cancelable Iris Templates, decision level fusion, Privacy, Rotation Invariance, Biometric, Cancelable Transformation, Biometric Security, Template protection, Cancelable biometrics, Gabor Filter, cancelable, Iris recognition, Secure Iris Recognition, security","The proposed method combines score level fusion at the first level and decision level fusion at the second level to integrate different modalities. Experimental evaluation on three virtual databases shows that the proposed method outperforms existing approaches in terms of performance and security. ||| The proposed method generates a secure cancelable iris template using decimal encoding and look-up table mapping. The method consists of several tasks, including iris image preprocessing, decimal encoding, and look-up table mapping. The experimental results show that the proposed method outperforms existing approaches in terms of recognition accuracy and security. ||| This paper presents a novel approach for generating cancelable iris templates for secure iris recognition. The proposed method involves applying circular Hough transformation, normalization using Daugman's rubber sheet model, and local histogram analysis to enhance the iris image. The normalized iris image is then transformed into a 0-1 form of matrix after convolving with quadrature 1-D Gabor filter. The Gabor coefficient values are coded with either 1 or 0 depending on the sign of the coefficient. The Gabor function is represented in Eq. (1). The iris pattern can be affected by rotation, and rotation invariance mechanism is employed by taking 8 images per subject and computing Hamming distances between the reference image and other images by shifting one column. The rotation free templates are shift invariant in comparison to iris code. The rotation invariant templates are transformed into a row vector to make ease in computation. The row vector is created through merging the next row to previous one. A row vector of 1 × 24 is obtained from the iris code of 4 × 6. The row vector is partitioned into a number of blocks of size M. The value of M may be chosen statically or dynamically and different for every image. The decimal vector is constructed by partitioning row vector using a fixed length word of size M. The decimal vector has the same number of positive integers as the number of words in row vector. The conversion of a word from binary to positive integer seize the left most bit as the most significant bit. The decimal vector is mapped to a corresponding word utilizing a look-up table. More than one word can be mapped to the same positive integer, so reverse mapping is very difficult. The look-up table is generated of random values 0 and 1. The minimum size (rows) of the table depends on the value of M. For example if we have word length 4, then the maximum decimal integer is 15. So the table must have entries greater than or equal to 15. There is a possibility that all entries of a particular row or more than one row are 0. In this situation, the use of these entries are vulnerable to privacy invasion, as this makes imposters task easy. Therefore, look-up table should be such that the number of 0's and 1's are approximately same in a randomized manner. The mapping of decimal vector is performed to the corresponding row of the randomly generated look-up table. Then d bits are selected from each row of the look-up table. ||| A coprime transformation scheme has been proposed to derive a protected fingerprint template. The method divides the fingerprint region into a number of sectors with respect to each minutiae point and identifies the nearest-neighbor minutiae in each sector."
Somyadeep Shrivastava,Cost Effective Influence Maximisation,"In the context of virality prediction, many researchers have leveraged the existence of a core-periphery structure in a network to identify the super-spreaders of information. Topologically, the nodes in the core of a network are the most eﬃcient spreaders. However, these nodes are less susceptible, i.e., unlikely to be inﬂuenced by the periphery nodes. Consequently, large payoﬀs are required to market information (ideas, products, memes, etc.) via them. In this paper, we show the presence of several non-core nodes whose spreading power is close to that of the core nodes.","Virality, Inﬂuence maximisation, Information diﬀusion, cost-effective, Core-periphery structure, information diffusion, social networks, influence maximisation",A cost-effective information diffusion strategy has been proposed that only requires the neighborhood information (friendship connections) of a node to make a meme go viral. Digital marketing agencies with a limited advertising budget can use the proposed strategy to popularise their product.
Song,A Computational Intelligence Based Online Data Imputation Method: An Application For Banking,"All the imputation techniques proposed so far in literature for data imputation are offline techniques as they require a number of iterations to learn the characteristics of data during training and they also consume a lot of computational time. Hence, these techniques are not suitable for applications that require the imputation to be performed on demand and near real-time. The paper proposes a computational intelligence based architecture for online data imputation and extended versions of an existing offline data imputation method as well.","computational intelligence, K-Means clustering, Evolving Clustering Method (ECM), banking, K-Medoids clustering, General Regression Neural Network (GRNN), GRNN, Imputation, MLP, online data imputation, Data Imputation","The proposed online imputation technique has 2 stages. In stage 1, Evolving Clustering Method (ECM) is used to replace the missing values with cluster centers, as part of the local learning strategy. Stage 2 refines the resultant approximate values using a General Regression Neural Network (GRNN) as part of the global approximation strategy."
Song Zheng,Chaos in fractional-order discrete neural networks with application to image encryption,"In this paper, a three-dimensional fractional-order (FO) discrete Hopfield neural network (FODHNN) in the left Caputo discrete delta’s sense is proposed, the dynamic behavior and synchronization of FODHNN are studied, and the system is applied to image encryption. First, FODHNN is shown to exhibit rich nonlinear dynamics behaviors. Phase portraits, bifurcation diagrams and Lyapunov exponents are carried out to verify chaotic dynamics in this system. Moreover, by using stability theorem of FO discrete linear systems, a suitable control scheme is designed to achieve synchronization of the FODHNN. Finally, image encryption system based on the chaotic FODHNN is presented. Some security analysis and tests are given to show the effective of the encryption system.","Fractional-order discrete Hopfield neural networks, Lyapunov exponent, Chaotic dynamics, Fractional-order discrete systems, Synchronization, Image encryption, Jacobian matrix algorithm, Neural networks","This paper presents a chaotic dynamics analysis of fractional-order discrete Hopfield neural networks (FODHNNs). The FODHNNs are derived from a 3D-neuron fractional-order continuous Hopfield-type neural networks proposed in Zhang, Qi, and Wang (2010). The dynamic behavior, synchronization, and image encryption application of FODHNNs are explored. Numerical solutions of FODHNNs are needed to be presented. The maximum Lyapunov exponent (LE) of the dynamical system is an important index that characterizes the rate of separation of infinitesimally close trajectories. The Jacobian matrix algorithm for Lyapunov exponents of the discrete fractional maps proposed in Wu and Baleanu (2015b) is employed to calculate the LE of FODHNNs."
Soumya,Analysing the Performance of Novel Activation Functions on Deep Learning Architectures,"Deep learning is a cutting-edge technology that functions similarly to the human nervous system. Neural networks are at the heart of Deep Learning. Neural networks are made up of numerous layers, in-cluding the input layer, which accepts raw data as input, hidden layers, which process the input data, and a final layer, the output layer, which provides the result. Its workflow pattern is comparable to machine learn-ing [2], [11], allowing us to gain hands-on expertise with this technology, speed up our work, and allow us to make several efforts without hav-ing to develop a basic Machine learning algorithm from scratch. In the case of deep learning, there are several neural networks to choose from. The majority of Deep Learning architectures are built on neural networks such as CNN, RNN, and others. Deep neural network activation function development is often guided by set goals and gradual steps toward tack-ling specific challenges. The primary goal of this study is to examine the performance of innovative activation functions (SBAF parabola [6] [16], AReLU [7], Leaky ReLU, SWISH) on deep learning architectures such as CNN, DENSENET, etc. On deep learning architectures, our study will compare the classification performance of the aforementioned activation functions.","Redundancy, Network reliability, Robotics, Embedded systems","This paper explores the performance of novel activation functions (SBAF parabola, AReLU, Leaky ReLU, SWISH) on deep learning architectures like CNN and DENSENET. The study aims to compare the classification accuracy of these activation functions on various computer vision datasets."
Soumya Mohapatra,KELDEC: A System for Mining Knowledge Sources from Images,KELDEC is a system that mines knowledge sources from images by extracting technical phrases and using them to scout for relevant websites. The system uses a combination of natural language processing and machine learning techniques to identify relevant websites and rank them based on their semantic similarity to the image and the class notes.,"knowledge source, Educational recommender system, Personalized mobile learning, Web content mining, KELDEC, Classroom learning points, Image analysis, image mining, semantic similarity, technical phrases",The KELDEC system is designed to extract technical phrases from images and use them to recommend relevant websites to users. The system uses a combination of natural language processing and machine learning techniques to identify relevant websites and rank them based on their semantic similarity to the image and the class notes.
Sowmini Devi Veeramachaneni,A Hinge-Loss based Codebook Transfer for Cross-Domain Recommendation with Nonoverlapping Data ||| Transfer of codebook latent factors for cross-domain recommendation with non-overlapping data,"Recommender systems(RS), especially collaborative ﬁltering(CF) based RS, has been playing an impor-tant role in many e-commerce applications. As the information being searched over the internet is rapidly increasing, users often face the diﬃculty of ﬁnding items of his/her own interest and RS often provides help in such tasks. Recent studies show that, as the item space increases, and the number of items rated by the users become very less, issues like sparsity arise. To mitigate the sparsity problem, transfer learning techniques are being used wherein the data from dense domain(source) is considered in order to predict the missing entries in the sparse domain(target). ||| The paper proposes a method for cross-domain recommendation using codebook latent factors. The method involves filling missing entries in the source rating matrix, co-clustering to obtain the rating pattern at the cluster-level, processing the codebook, and transferring the codebook latent features to the target domain.","codebook latent factors, Matrix Factorisation, Codebook, codebook transfer, co-clustering, non-overlapping data, Cross-Domain Recommendation, matrix factorization, Collaborative Filtering, Transfer Learning","This paper proposes a transfer learning approach for cross-domain recommendation when both domains have no overlap of users and items. The transferring of knowledge from source to target domain is done in a novel way using co-clustering technique to obtain the codebook (cluster-level rating pattern) of source domain and hinge loss function to transfer the learnt codebook of the source domain to target. ||| This paper proposes a novel transfer learning approach for cross-domain recommendation, wherein the cluster-level rating pattern(codebook) of the source domain is obtained via a co-clustering technique. The Maximum Margin Matrix factorization(MMMF) technique is applied on the codebook to learn the user and item latent features of codebook. Prediction of the target rating matrix is achieved by introducing these latent features in a novel way into the optimisation function."
Specht,A Computational Intelligence Based Online Data Imputation Method: An Application For Banking,"All the imputation techniques proposed so far in literature for data imputation are offline techniques as they require a number of iterations to learn the characteristics of data during training and they also consume a lot of computational time. Hence, these techniques are not suitable for applications that require the imputation to be performed on demand and near real-time. The paper proposes a computational intelligence based architecture for online data imputation and extended versions of an existing offline data imputation method as well.","computational intelligence, K-Means clustering, Evolving Clustering Method (ECM), banking, K-Medoids clustering, General Regression Neural Network (GRNN), GRNN, Imputation, MLP, online data imputation, Data Imputation","The proposed online imputation technique has 2 stages. In stage 1, Evolving Clustering Method (ECM) is used to replace the missing values with cluster centers, as part of the local learning strategy. Stage 2 refines the resultant approximate values using a General Regression Neural Network (GRNN) as part of the global approximation strategy."
Spence,Typeface size and weight and word location inüluence on relative size judgments in tag clouds,"This paper focuses on viewers’ perception of the relative size of words presented in tag clouds. Tag clouds are a type of visualization that displays the contents of a document as a cluster (cloud) of key words (tags) with frequency (importance) indicated by tag word features such as size or color, with variation of size within a tag cloud being the most common indicator of tag importance. Prior studies have shown that word size is the most inüluential factor of tag importance and tag memory. Systematic biases in relative size perception in tag clouds are therefore likely to have important implications for viewer understanding of tag cloud visualizations.","layout, typeface size, size judgment, perception, psychophysics, perceptual biases, tag cloud, search tasks, tag clouds","The study focuses on documenting systematic biases in relative size judgment in tag clouds while varying typeface weight and the location of the target tag word pair under comparison. The results provide a first report of systematic biases in relative size judgment in tag clouds, suggest that simple power-law scaling models developed for simple displays containing 1-2 objects on a blank background, may be applicable to relative size judgments in complex tag clouds."
Sree Satya Venkat Meka,Health Assessment and Modal Analysis of Historical Masonry Arch Bridge,"Masonry arch bridges in India indicate the heritage value of the nation. Most of these bridges had been in service for hundreds of years and yet being serviceable even today for transportation purposes indicates the robustness of the design and construction methodology. But, some of these bridges are abandoned due to its deterioration and absence of knowledge to retroﬁt these structures. Lack of proper maintenance and retroﬁtting could eventually damage the structural integrity as these structures are old enough to deteriorate and are prone to repeated weathering and unforeseen natural calamities such as earth-quakes, ﬂoods, etc. In this study, a very old masonry arch bridge ‘Puranapul’ bridge inaugurated in the year 1578 across the river Musi in Hyderabad is considered for investigation of its health through basic visual inspection and non-destructive testing. Furthermore, the same is numerically modeled using the available ﬁnite element analysis software ANSYS in three dimensions for assessing the basic mode shapes of the structure and its behavior in different loading conditions.","modal analysis, Masonry arch bridge, Health assessment, finite element method, dynamic analysis, Heritage structure, Nondestructive testing, Finite element model, seismic behavior, Visual inspection","The paper presents a numerical modeling approach for understanding the behavior of a historical masonry arch bridge. The bridge is analyzed using finite element method and the results are presented in terms of deformations, strains, and stresses. The modal analysis is performed to understand the behavior and characteristics of the bridge under dynamic loads. The dynamic analysis is carried out to simulate the seismic behavior of the bridge and the results show that the bridge is quite adequate for lateral loads."
Sreedhar Madichetty,A Standalone BLDC Based Solar Air Cooler with MPP Tracking for Improved Efﬁciency ||| Comparative Study of DC and Induction Motors for Electric Vehicle Propulsion ||| Development of a Smart Energy Community by Coupling Neighbouring Community Microgrids for Enhanced Power Sharing Using Customised Droop Control ||| Double Deadbeat Plus Repetitive Control Scheme for Microgrid System ||| Route Towards Road Freight Electrification in India: Examining Battery Electric Truck Powertrain and Energy Consumption ||| SMES application in electrical power and energy systems,"This article proposes the idea of using Solar Energy (SE) as a source of power for designing and developing a standalone air-cooling system. This type of application is particularly suited for rural areas that have a considerable amount of solar radiation and have no access to grid systems. ||| This paper presents a comparative study of DC and induction motors for electric vehicle propulsion. The characteristics of the traction effort with respect to speed are discussed, and the advantages and disadvantages of each type of motor are highlighted. The paper also discusses the use of vector control and multiphase pole-changing IM drive to improve the performance of induction motors. ||| This paper proposes an enhanced PM-based droop control strategy for power sharing in CMGs. The proposed strategy achieves symmetric and asymmetric power-sharing through a PM-based droop control, enabling efficient coupling of neighboring CMGs. The control strategy also includes an enhanced frequency regulation method without using a secondary controller, maintaining the system frequency within an acceptable range. ||| Parallel connection of converters is a convenient choice when system capacity is to be increased. Parallel-connected voltage source converters, especially neutral point clamped converters, are one of the best choices for its range. However, with the parallel connectivity, the converter possesses a circulating current in its legs, which consequently threatens the safe operation of the system. ||| Medium-duty/heavy-duty trucks (MD/HDTs) are yet to be included in India’s electric mobility plans. With the improvement of electric vehicle (EV) technologies, there is a growing interest in battery-electric trucks (BETs) from original equipment manufacturers (OEMs). The time is opportune to consider electrification as a future direction for road freight in India. Accordingly, this article presents the results of an energy consumption simulation study of a BET under Indian conditions. This study specifically considered an MDBET over a domestic drive cycle. These energy consumption figures can facilitate future studies that analyze the technical and practical feasibility of BETs in the country. In addition, the article provides the requisite groundwork for BET modeling for a simulation study by reviewing available EV powertrain systems and components. Appropriate powertrain considerations are thereby obtained for a typical medium-duty/heavy-duty battery-electric truck (MD/HDBET) in the Indian context. ||| This paper discusses the application of Superconducting Magnetic Energy Storage (SMES) in electrical power and energy systems. SMES is used to enhance the frequency regulation, power delivery, and power quality in microgrid systems. The paper presents the results of a study on the implementation of SMES in a microgrid system with a 1.6 MJ SMES and a 3-MVA wind farm. The results show that SMES can effectively reduce the total harmonic distortion (THD) in the system and maintain a constant DC link voltage during sudden changes in factory load.","Electric truck, Microgrid systems, plug-in hybrid electrical vehicles, vector control, droop control, Battery Electric Trucks, CMGs, Circulating currents, frequency regulation, Parallel-connected inverters, superconducting magnetic energy storage, Road Freight Electrification, electric vehicle propulsion, BLDC motor, PV System, repetitive control scheme, power sharing, India, SMES, microgrids, parallel inverter, efficiency, PM-based droop control, propulsion systems, solar air cooler, microgrid, vehicle powertrain, Repetitive control, parallel converters, medium-duty battery electric truck, electric motors, DC motors, multiphase pole-changing IM drive, MPP tracking, power delivery, Deadbeat control, power management, electric vehicles, Powertrain Topology, power quality, energy consumption, BLDC Pump, Deadbeat control (DB) scheme, energy community, BLDC, induction motors, interconnected system, community microgrids, BLDC air blower, heavy-duty battery electric truck","The proposed system consists of a PV array, a boost converter, a BLDC drive, and a solar air cooler. The system is designed to operate in a standalone mode, where the PV array generates power and the boost converter boosts the input voltage to the required operating quantity. The BLDC drive is used to control the speed of the BLDC motor, which drives the solar air cooler. ||| The paper discusses the trends in electric motors and their selection for electric vehicle propulsion systems. It reviews the various types of motors that can be used in electric traction, including DC, induction, switched reluctance, permanent magnet brushless AC motors and permanent magnet brushless DC motors. The paper also presents a detailed review of existing motors and the application of power electronic techniques to EVs, and recommendations for some new designs of brushless DC motors. ||| The proposed PM-based droop control strategy is validated through laboratory-scale CMG testing, demonstrating its effectiveness in maintaining system frequency and voltage within acceptable ranges. The control strategy is also shown to be efficient in power sharing, enabling the coupling of neighboring CMGs. The proposed method has the potential to improve the reliability and efficiency of CMG-based power systems. ||| This paper proposes a double deadbeat plus repetitive control scheme to mitigate circulating currents in parallel-connected voltage source converters. The proposed scheme combines the advantages of deadbeat control and repetitive control to achieve high operating bandwidth and stability. ||| This paper explores the powertrain and energy consumption of battery electric trucks in India, with a focus on the route towards road freight electrification. The authors discuss the advantages and disadvantages of different powertrain topologies and identify the near-wheel transmission with a two-speed gear reduction powered by two electric motors as the optimum transmission topology for medium- and heavy-duty battery electric trucks. ||| The paper discusses the application of SMES in electrical power and energy systems, particularly in microgrid systems. SMES is used to enhance the frequency regulation, power delivery, and power quality in these systems. The results of a study on the implementation of SMES in a microgrid system are presented, showing the effectiveness of SMES in reducing THD and maintaining a constant DC link voltage during sudden changes in factory load."
Srikanth Munjuluri,Statistically Assisted Multi Resolution FFT Based CR Architecture,"This paper presents a statistically assisted multi resolution FFT based CR architecture. The proposed algorithm adapts the resolution of FFT based on statistical data given by the prediction engine. The prediction engine is trained for the spatial and temporal information of the spectral occupancy. The output of the prediction engine is the probability of a sub band being occupied by the primary user (Poccupied). If Poccupied is low, resolution need not be very fine since most of the spectrum is free. When Poccupied is high, a finer sensing approach is performed by incrementing the observation vector N, thereby increasing the resolution.","spectrum analyser, energy detection, adaptive FFT based algorithms, Spectrum Sensing, Prediction Engine, Cognitive Radio, doubly cognitive radio architecture, Adaptive FFT, dynamic spectrum access","This paper focuses on the implementation aspects of spectrum sensing in cognitive radio architectures. The authors propose an adaptive FFT algorithm to reduce the time taken for spectrum sensing, applicable to cognitive radio environment. The algorithm is studied as applied to the well-known energy detection technique and implemented on USRP based on GNU Radio platform."
Srinivas Mandalika,Distributed Source Coding for Sensor Data Model,"We measure reliability in sensor networks which are dependent on limited resources of individual sensor nodes such has battery capacity, transmission range and channel interference due to simultaneous wireless transmissions.","Sensor Data Reliability, cluster head selection, BER, Slepian & Wolf Coding, Baysian Error, sensor data model, Slepian-Wolf theorem, Cosets, distributed source coding, Huffman Trees","The paper presents a distributed source coding approach for sensor data model, which includes Slepian-Wolf theorem, compression rate, fault rate, and cluster head selection schemes. The approach is designed to reduce the number of bits needed for transmission in sensor networks."
Srinivasa Rao Mutheneni,Applications of machine learning techniques to predict filariasis using socio-economic factors,"Filariasis is one of the major public health concerns in India. Approximately 600 million people spread across 250 districts of India are at risk of filariasis. To predict this disease, a pilot scale study was carried out in 30 villages of Karimnagar district of Telangana from 2004 to 2007 to collect epidemiological and socio-economic data. The collected data are analysed by employing various machine learning techniques such as Naïve Bayes (NB), logistic model tree, probabilistic neural network, J48 (C4.5), classification and regression tree, JRip and gradient boosting machine. The performances of these algorithms are reported using sensitivity, specificity, accuracy and area under ROC curve (AUC). Among all employed classification methods, NB yielded the best AUC of 64% and was equally statistically significant with the rest of the classifiers. Similarly, the J48 algorithm generated 23 decision rules that help in developing an early warning system to implement better prevention and control efforts in the management of filariasis.","Filariasis, mosquito, socio-economic factors, Socio-economic conditions, Machine learning techniques, Predictive classification modelling, Data balancing, Feature subset selection",This study aims to predict filariasis using socio-economic factors and machine learning techniques. A pilot scale study was conducted in 30 villages of Karimnagar district of Telangana from 2004 to 2007 to collect epidemiological and socio-economic data. Various machine learning techniques were employed to analyse the data and predict filariasis. The study found that Naïve Bayes yielded the best AUC of 64% and generated 23 decision rules that help in developing an early warning system to implement better prevention and control efforts in the management of filariasis.
Sriram Kumaraswamy,Applications of machine learning techniques to predict filariasis using socio-economic factors,"Filariasis is one of the major public health concerns in India. Approximately 600 million people spread across 250 districts of India are at risk of filariasis. To predict this disease, a pilot scale study was carried out in 30 villages of Karimnagar district of Telangana from 2004 to 2007 to collect epidemiological and socio-economic data. The collected data are analysed by employing various machine learning techniques such as Naïve Bayes (NB), logistic model tree, probabilistic neural network, J48 (C4.5), classification and regression tree, JRip and gradient boosting machine. The performances of these algorithms are reported using sensitivity, specificity, accuracy and area under ROC curve (AUC). Among all employed classification methods, NB yielded the best AUC of 64% and was equally statistically significant with the rest of the classifiers. Similarly, the J48 algorithm generated 23 decision rules that help in developing an early warning system to implement better prevention and control efforts in the management of filariasis.","Filariasis, mosquito, socio-economic factors, Socio-economic conditions, Machine learning techniques, Predictive classification modelling, Data balancing, Feature subset selection",This study aims to predict filariasis using socio-economic factors and machine learning techniques. A pilot scale study was conducted in 30 villages of Karimnagar district of Telangana from 2004 to 2007 to collect epidemiological and socio-economic data. Various machine learning techniques were employed to analyse the data and predict filariasis. The study found that Naïve Bayes yielded the best AUC of 64% and generated 23 decision rules that help in developing an early warning system to implement better prevention and control efforts in the management of filariasis.
Srishti Sharma,Aspect Term Extraction using Domain Ontology for Sarcasm Detection ||| Emotion Analysis in Twitter ||| Fake News Detection Through ML and Deep Learning ||| Fuzzy Classification Scheme for MFCC Audio Features,"Various aspects or characteristic features of an entity come into interplay to create an underlying fabric upon which sentiments blossom. In multi aspect Sentiment Analysis (SA), potentially related aspects of an entity under review are discussed in a single piece of text such as an online review. In this work, we use domain ontologies for enabling multi-aspect Sentiment Analysis. Since, domain ontologies contain the entire domain knowledge, they assist in enhanced aspect identification and detection of the latent or hidden aspects in a review document. We illustrate our approach by developing a system named Ontology driven Multi Aspect Sentiment Analysis (OMASA) system. We provide hotel reviews as input to this system and identify the panorama of explicitly expressed and latent aspects in a review using hotel domain ontology. After detecting the aspects, we link them with the corresponding opinions to gauge the sentiment pertaining to the aspects extracted. OMASA first computes sentiment scores for every aspect of the hotel. It then evaluates the overall sentiment score. On comparing with the baseline, the experimental results of OMASA show a marked improvement in the aspect level evaluation metrics Δaspect2 and ρaspect after detecting the hidden aspects. This shows that OMASA has the potential to identify the latent aspects in text thereby improving the quality of SA. ||| The ever-increasing amount of text generated by Twitter users contains a wealth of information about the users’ state of mind. Over the years, researchers have tapped upon this resource and proposed a number of lexicons and techniques for analyzing the polarity of sentiments expressed by tweets. However, we need to delve deeper to extract the emotions conveyed by them – a research direction that had not received adequate attention so far. ||| This paper discusses the detection of fake news through machine learning and deep learning algorithms. The authors present a proposed approach for fake news detection using decision tree, XGBoost, and LSTM algorithms. The paper also discusses the preprocessing of data, feature extraction, and the training and testing of the classifiers. The results show that the decision tree algorithm achieves a prediction accuracy of 99.67% for fake news detection. ||| Mel-frequency Cepstral coefficients (MFCC) are popular features extracted from speech data for speaker identification. The speech signal is fragmented into frames and the MFCC features extracted from each frame show some temporal redundancy which forms the basis of the fuzzy classifier proposed in this paper. We propose a fuzzy nearest neighbor classifier that defines a frame prototype for each training audio sample using a weighted mean technique with the weights being probability values, and the class label for each test sample is decided from fuzzy membership functions involving the frame prototypes. The classification results of the proposed classifier on audio samples from the VidTIMIT database show a superior performance to the Nearest Neighbor classifier, GMM, HMM and MLP neural networks. It is observed that the execution time of the fuzzy classifier is a very small fraction of the time taken by the HMM and neural network classifiers and the training database is significantly reduced due to the use of frame prototypes instead of actual frames.","Sarcasm Detection, Machine Learning, Sentiment Analysis, decision tree, fuzzy classifer, audio features, Classification, Aspect Term Extraction, Sarcasm, Domain Ontology, fuzzy classification, fake news detection, TripAdvisor, WordNet, sentiment analysis, Domain Ontologies, Gaussian fuzzy membership functions, Emotion Analysis, MFCC, LSTM, Social media, News, Lexicon, Amazon, Hotel Domain, Psychology, Hontology, Mel-frequency cepstral coeffecients, XGBoost, Accuracy, deep learning, machine learning, Twitter, Detection","This paper proposes a novel approach for multi-aspect sentiment analysis using domain ontologies. The proposed system, OMASA, uses domain ontologies to identify and extract latent and hidden aspects in a review document. OMASA computes sentiment scores for every aspect of the hotel and evaluates the overall sentiment score, showing a marked improvement in aspect level evaluation metrics compared to the baseline. ||| This paper proposes a novel Emotion Analysis lexicon that was compiled by integrating information from the domain of psychology, the lexical ontology WordNet, and a set of emoticons and slangs commonly used in web jargon. The lexicon is used to find the predominant emotions carried by tweets originating from three different cities and analyzed how they evolve with time. ||| The detection of fake news is an important challenge to researchers. The detection of misinformation is not an easy task for anyone, but quite is a complex for people. Here, we analyze the different fake news detection approaches followed in current scenario and compute the detection process through machine learning and deep leaning algorithms for better accuracy. ||| This paper proposes a fuzzy nearest neighbor classifier for speaker identification using Mel-frequency Cepstral coefficients (MFCC) features. The classifier defines a frame prototype for each training audio sample using a weighted mean technique and decides the class label for each test sample from fuzzy membership functions involving the frame prototypes. The proposed classifier outperforms other classifiers in terms of execution time and training database size."
Stephenson and Zelen,Rumour Source Detection Using Game Theory,"Social networks have become a critical part of our lives as they enable us to interact with a lot of people. These networks have become the main sources for creating, sharing and also extracting information regarding various subjects. But all this information may not be true and may contain a lot of unverified rumours that have the potential of spreading incorrect information to the masses, which may even lead to situations of widespread panic. Thus, it is of great importance to identify those nodes and edges that play a crucial role in a network in order to find the most influential sources of rumour spreading. Generally, the basic idea is to classify the nodes and edges in a network with the highest criticality. Most of the existing work regarding the same focuses on using simple centrality measures which focus on the individual contribution of a node in a network. Game-theoretic approaches such as Shapley Value (SV) algorithms suggest that individual marginal contribution should be measured for a given player as the weighted average marginal increase in the yield of any coalition that this player might join. For our experiment, we have played five SV-based games to find the top 10 most influential nodes on three network datasets (Enron, USAir97 and Les Misérables). We have compared our results to the ones obtained by using primitive centrality measures. Our results show that SV-based approach is better at understanding the marginal contribution, and therefore the actual influence, of each node to the entire network.","influential nodes, Jaccard Similarity Coefficient, cooperative game, Rumour Source Detection (RSD), centrality measures, network analysis, Shapley Value (SV), Game-Theory, Network Centrality",This paper aims to identify the most influential nodes in a network that are the primary sources of rumour propagation. The authors propose a game-theoretic approach using the Shapley Value algorithm to find the most influential nodes. They compare their results with primitive centrality measures and show that the SV-based approach is better at understanding the marginal contribution of each node to the entire network.
Sujata Joshi,"Cardioprotection from ischemia and reperfusion injury by Withania somnifera: A hemodynamic, biochemical and histopathological assessment","The efficacy of Withania somnifera (Ws) to limit myocardial injury after ischemia and reperfusion was explored and compared to that of Vit E, a reference standard known to reduce mortality and infarct size due to myocardial infarction. Wistar rats (150–200 g) were divided into six groups and received orally saline (sham, control group), Ws-50/kg (Ws control and treated group) and Vit E-100 mg/kg (Vit E control and treated group) respectively for 1 month. On the 31st day, rats of the control, Vit E and Ws treated groups were anesthetized and subjected to 45 min occlusion of the LAD coronary artery followed by 60 min reperfusion. Hemodynamic parameters: systolic, diastolic and mean arterial pressure (SAP, DAP, MAP), heart rate (HR), left ventricular end diastolic pressure (LVEDP), left ventricular peak (+)LVdP/dt and (–)LVdP/dt were monitored. Hearts were removed and processed for histopathological and biochemical studies: Myocardial enzyme viz, creatin phosphokinase (CPK), and antioxidant parameters: malondialdehyde (MDA), glutathione (GSH), superoxide dismutase (SOD), catalase (CAT), glu-tathione peroxidase (GSHPx) were estimated. Postischemic reperfusion produced significant cardiac necrosis, depression of left ventricular functions (MAP, LVEDP, (+) and (–)LVdP/dt) and a significant fall in GSH (p < 0.01), SOD, CAT (p < 0.05), LDH and CPK (p < 0.01) as well as an increase in MDA level (p < 0.05) in the control group rats as compared to sham group. The changes in levels of protein and GPx was however, not significant. Ws and Vit E favorably modulated most of the hemo-dynamic, biochemical and histopathological parameters though no significant restoration in GSH, MAP (with Vit E) were ob-served. Ws on chronic administration markedly augmented antioxidants (GSH, GSHPx, SOD, CAT) while Vit E did not stimulate the synthesis of endogenous antioxidants compared to sham. Results indicate that Ws significantly reduced myocardial injury and emphasize the beneficial action of Ws as a cardioprotective agent.","Withania somnifera, adaptogens, Adaptogenic, myocardial infarction, Ischemia-reperfusion injury, Myocardial damage, ischemia, Vitamin E, antioxidants, reperfusion","This study investigated the cardioprotective effects of Withania somnifera (Ws) compared to Vitamin E in a rat model of ischemia and reperfusion induced myocardial injury. Ws significantly reduced myocardial injury, improved hemodynamic parameters, and enhanced antioxidant defense mechanisms. These findings suggest that Ws has potential as a cardioprotective agent."
Sujit Das,Interval-Valued Intuitionistic Fuzzy Soft Sets and Matrices ||| MAXIMISING ACCURACY AND EFFICIENCY OF INTERVAL-VALUED INTUITIONISTIC FUZZY SOFT SETS,"A noticeable progress has been found in decision making problems since the introduction of soft set theory by Molodtsov in 1999. It is found that classical soft sets are not suitable to deal with imprecise parameters whereas fuzzy soft sets (FSS) are proved to be useful. Use of intuitionistic fuzzy soft sets (IFSS) is more effective in environment where arguments are presented using membership and non-membership values. In this paper we propose an algorithmic approach for multiple attribute group decision making problems using interval-valued intuitionistic fuzzy soft matrix (IVIFSM). IVIFSM is the matrix representation of interval-valued intuitionistic fuzzy soft set (IVIFSS), where IVIFSS is a natural combination of interval-valued intuitionistic fuzzy set and soft set theory. Firstly, we propose the concept of IVIFSM. Then an algorithm is developed to find out the desired alternative(s) based on product interval-valued intuitionistic fuzzy soft matrix, combined choice matrix, and score values of the set of alternatives. Finally, a practical example has been demonstrated to show the effectiveness of the proposed algorithm. ||| This article proposes an algorithmic approach for multiple attribute group decision making (MAGDM) problems using interval-valued intuitionistic fuzzy soft matrix (IVIFSM) and confident weight of experts. We propose a novel concept for assigning confident weights to the experts based on cardinals of interval-valued intuitionistic fuzzy soft sets (IVIFSSs). The confident weight is assigned to each of the experts based on their preferred attributes and opinions, which reduces the chances of biasness.","interval-valued intuitionistic fuzzy soft set, Interval-valued intuitionistic fuzzy sets, Confident weight of experts, Multiple attribute group decision making, Interval-valued intuitionistic fuzzy soft sets, Decision-making, interval-valued intuitionistic fuzzy soft matrix, Interval-valued intuitionistic fuzzy soft matrix, Fuzzy Soft Sets, Interval-Valued Intuitionistic Fuzzy Soft Matrices, choice matrix, Fuzzy Soft Matrices, Interval-Valued Intuitionistic Fuzzy Soft Sets",This paper proposes an algorithmic approach for multiple attribute group decision making problems using interval-valued intuitionistic fuzzy soft matrix (IVIFSM). The proposed approach uses combined choice matrix for individual decision maker by incorporating the choice parameters of the set of experts. The score and accuracy values are calculated to yield the desired alternative(s). ||| The proposed algorithm mainly focuses on the choice parameters/attributes of various experts and computes the confident weight of an expert based on her prescribed opinions. We have used cardinals of IVIFSS for measuring the weight. The proposed confident weight also reduces the chance of biasing.
Sukhija et al.,Web-Induced Heterogeneous Transfer Learning with Sample Selection,"This paper proposes a novel approach to heterogeneous transfer learning, which leverages the relatedness of the source and target domains to fill in the void in the target space with missing label data. The proposed method uses a reconstruction error to measure the extent to which the structure of the original source data is preserved in the target domain, and a weighted pairwise distance to measure the mis-alignment between transformed source and target instances. The method also uses a regularizer to prevent over-fitting, and an alternating algorithm to solve the unconstrained optimization problem.","Heterogeneous Transfer Learning, Sample Selection, web-induced heterogeneous transfer learning, reconstruction error, weighted pairwise distance, regularizer, alternating algorithm","The proposed method is an extension of the existing heterogeneous transfer learning algorithms, which assume that the knowledge is transferred to a different but related target domain. The proposed method is more robust and can handle real-world tasks with distant source and target domain data."
Sukumar Mishra,A Standalone BLDC Based Solar Air Cooler with MPP Tracking for Improved Efﬁciency ||| Comparative Study of DC and Induction Motors for Electric Vehicle Propulsion ||| Double Deadbeat Plus Repetitive Control Scheme for Microgrid System,"This article proposes the idea of using Solar Energy (SE) as a source of power for designing and developing a standalone air-cooling system. This type of application is particularly suited for rural areas that have a considerable amount of solar radiation and have no access to grid systems. ||| This paper presents a comparative study of DC and induction motors for electric vehicle propulsion. The characteristics of the traction effort with respect to speed are discussed, and the advantages and disadvantages of each type of motor are highlighted. The paper also discusses the use of vector control and multiphase pole-changing IM drive to improve the performance of induction motors. ||| Parallel connection of converters is a convenient choice when system capacity is to be increased. Parallel-connected voltage source converters, especially neutral point clamped converters, are one of the best choices for its range. However, with the parallel connectivity, the converter possesses a circulating current in its legs, which consequently threatens the safe operation of the system.","Microgrid systems, vector control, Circulating currents, Parallel-connected inverters, electric vehicle propulsion, BLDC motor, PV System, repetitive control scheme, microgrids, efficiency, propulsion systems, solar air cooler, Repetitive control, parallel converters, electric motors, DC motors, multiphase pole-changing IM drive, MPP tracking, Deadbeat control, electric vehicles, BLDC Pump, Deadbeat control (DB) scheme, BLDC, induction motors, BLDC air blower","The proposed system consists of a PV array, a boost converter, a BLDC drive, and a solar air cooler. The system is designed to operate in a standalone mode, where the PV array generates power and the boost converter boosts the input voltage to the required operating quantity. The BLDC drive is used to control the speed of the BLDC motor, which drives the solar air cooler. ||| The paper discusses the trends in electric motors and their selection for electric vehicle propulsion systems. It reviews the various types of motors that can be used in electric traction, including DC, induction, switched reluctance, permanent magnet brushless AC motors and permanent magnet brushless DC motors. The paper also presents a detailed review of existing motors and the application of power electronic techniques to EVs, and recommendations for some new designs of brushless DC motors. ||| This paper proposes a double deadbeat plus repetitive control scheme to mitigate circulating currents in parallel-connected voltage source converters. The proposed scheme combines the advantages of deadbeat control and repetitive control to achieve high operating bandwidth and stability."
Sulabh Tyagi,Development of Reusable Hybrid Test Automation Framework for Web Based Scrum Projects ||| Diurnal Variation of Ozone Levels in Academic Hostel in Delhi,"Web based applications are gaining widespread popularity and most of these applications are being developed using agile development methods mainly scrum. This invariably makes the testing of any web application necessary and important before it goes online. Agile methods advocate automated testing, which is the only way to assure faster thorough testing of any web application. In this paper, authors propose a reusable hybrid test automation framework (RHTAF) using page object model for automated testing of web applications. RHTAF combines the features of both data driven and keyword driven frameworks and developed using Selenium 2.0 tool. The primary focus of this framework is to ensure reusability and maintainability of test scripts so as to speed up the testing process of web applications. ||| Urban air pollution has become a serious environmental problem in the last few decades in most of the developing countries including India. Due to widespread industrialization, rapid urbanization and huge growth in the number of motor vehicles have brought about severe deterioration in the urban air quality. Among the various gaseous pollutants, ozone is one of the important pollutants because of its health as well as climatic impacts. This study investigates the levels of ozone concentration at thirteen different hostels in an academic institute, Delhi. The measurements of ozone were carried out in indoor environments by ozone analyzer (Model S-5014 SIR) for 24 hours.","hostels, Delhi, Regression Testing, Scrum, CPCB, Test Automation, ozone levels, Indoor ozone, Agile Software Development, Scrum Environment, academic hostels, Web Applications, anthropogenic activities, VOCs, Frameworks, diurnal variation, NOx, Reusable Hybrid Test Automation Framework, Page Object Model","This paper proposes a reusable hybrid test automation framework using page object model for automated testing of web applications. The framework combines the features of both data driven and keyword driven frameworks and is developed using Selenium 2.0 tool. The primary focus of this framework is to ensure reusability and maintainability of test scripts so as to speed up the testing process of web applications. ||| The study reveals that the ozone concentration in the entire indoor environment of the JNU campus lies in the range (2.81 to 4.17 ppb for 24 hours) are well below the permissible limits (100 µg/m3 for 8 hours) prescribed by CPCB, India. Also the outdoor ozone concentration is found to lie in the range (13.93 ppb to 78. 15 ppb for 8 hours), which well above the standard (100 µg/m3 for 8 hours) prescribed by CPCB."
Suman Bala,On the Security of Authenticated Group Key Agreement Protocols,"The group key agreement protocol enables to derive a shared session key for the remote members to communicate securely. Recently, several attempts are made to utilize group key agreement protocols for secure multicasting in Internet of Things. This paper contributes to identify the security vulnerabilities in the existing protocols, to avoid them in future constructions. The protocols presented by Gupta and Biswas have been found insecure to ephemeral secret key leakage (ESL) attack and also, malicious insiders can impersonate an honest participant. Additionally, the protocol presented by Tan is also ESL-insecure. We also present a fix to the Tan’s protocol to make it secure.","Insider security, Security Protocols, Authenticated Group Key Agreement, Authentication, Mutual authentication, Group key agreement, Elliptic Curve Cryptography","This paper discusses the security vulnerabilities in existing group key agreement protocols and presents a fix to one of the protocols to make it secure. The authors identify the security vulnerabilities in the protocols presented by Gupta and Biswas and Tan, and present a fix to the Tan’s protocol to make it secure. The paper also discusses the importance of authentication and insider security in group key agreement protocols."
Suman Kumar Choudhury,Evaluation of Background Subtraction for Object Detection Vis-a-Vis Mitigating Challenging Scenarios,"Background subtraction is a popular technique for detecting objects moving across a fixed camera view. The performance of this paradigm is influenced by various challenges, such as object relocation, illumination change, cast shadows, waving background, camera shake, bootstrapping, camouflage, and so on. In this paper, we present a synopsis on the evolution of the background subtraction techniques over the last two decades. The different ways of mathematical modeling are taken into consideration to categorize the methods. We also evaluate the performance of some of the state-of-the-art techniques vis-a-vis the challenges associated. Eleven different algorithms of background subtraction have been simulated on thirty-four image sequences collected from five benchmark datasets. For each image sequence, seven performance metrics are evaluated and an exhaustive comparative analysis has been made to derive inferences. The potential findings in the result analysis are presented for future exploration. The obtained image and video results are uploaded at https://sites.google.com/site/soaBSevaluation.","background modeling, object detection, low-rank sparse decomposition, background subtraction, challenging scenarios, learning model, non-parametric model, shadow removal, non-recursive buffer-based subtraction, fuzzy model, shadow removal model, foreground extraction, background maintenance, Video surveillance",This paper evaluates the performance of background subtraction techniques for object detection in challenging scenarios. The authors present a synopsis of the evolution of background subtraction techniques over the last two decades and evaluate the performance of eleven state-of-the-art algorithms on thirty-four image sequences collected from five benchmark datasets. The results reveal some key findings in background subtraction methodologies and are available at https://sites.google.com/site/soaBSevaluation.
Sumit Kumar,Doubly Cognitive Architecture Based Cognitive Wireless Sensor Network ||| Prediction of Willingness of Users in V-MIMO,"Nowadays scarcity of spectrum availability is increasing highly. Adding cognition to the existing Wireless Sensor Network (WSN) infrastructure will help in this situation. As sensor nodes in WSN are limited with some constrains like power, efforts are required to increase the lifetime and other performance measures of the network. In this paper we propose the idea of Doubly Cognitive WSN. The basic idea is to progressively allocate the sensing resources only to the most promising areas of the spectrum. This work is based on Artificial Neural Network as well as on Support Vector Machine (SVM) concept. As the load of sensing resource is reduced significantly, this approach will save the energy of the nodes, and also reduce the sensing time dramatically. ||| In cellular systems, virtual multiple-input multiple-output (V-MIMO) technology promises to achieve performance gains comparable to conventional MIMO. In this paper, we propose cooperative relay selection algorithm based on machine learning techniques. Willingness of user to cooperate in V-MIMO depends on his current battery power, time and day along with incentives offered by service provider.","mobile communication, Doubly Cognitive WSN, Artificial Neural network, SVM, ANN, Machine Learning, Spectrum Sensing, cognitive radio, Virtual MIMO, Cognitive Wireless Sensor Network, WSN, Artificial Neural Network, Support Vector Machine, V-MIMO, Virtual Antenna Array","This paper proposes the idea of Doubly Cognitive WSN, which is based on pattern recognition and two-stage spectrum sensing for cognitive radios. The underlying notion of the idea is to progressively allocate the sensing resources to only the most promising areas of the spectrum, reducing sensing resources and time needed to accurately identify spectrum holes. The proposed approach will save the energy of the spectrum sensing nodes and also reduce the sensing time dramatically. ||| This paper proposes a cooperative relay selection algorithm based on machine learning techniques for virtual MIMO systems. The algorithm predicts potential willing users in the neighborhood of the source user and reduces cooperative node discovery time. The performance of the algorithm is evaluated using metrics such as MSE, accuracy, precision, and recall."
Sunar Mohammed Farook,Efficient Conjunctive Cooperative Routing Schemes In Divergent Sensor Networks,"Wireless sensor networks are faced by challenges not present in wired networks. Mobility of nodes or lack of fixed infra in wireless sensor networks gives rise to issues like route changes, link failures, and need for change of IP addresses. These reasons require changes at various layers of protocol stack. In such a situation, their lifetime is expected to be extended by cooperative packet forwarding. Albeit a few scientists have learned about collaboration in different WSNs, the greater part of them don't consider the heterogeneity in the qualities of each WSN, for example, battery limit, activity begin time, the quantity of hubs, hubs areas, vitality utilization, parcel measure or potentially information transmission timing, etc. In a heterogeneous situation, gullible lifetime enhancement with participation may not be reasonable. In this paper, we propose a reasonable helpful steering strategy for heterogeneous covered WSNs. It acquaints a vitality pool with keep up the aggregate sum of vitality utilization by helpful sending. The vitality pool assumes a job of merchant for reasonable participation. At last, reenactment results demonstrate the great execution of the proposed strategy.","lifetime improvement, heterogeneous networks, cooperative routing, Wireless Sensor Networks, Fair Routing Overlapped","This paper proposes a cooperative routing scheme for heterogeneous wireless sensor networks. The scheme introduces a power pool to maintain the total amount of power utilization by cooperative forwarding. The power pool acts as a merchant for fair participation. The scheme is evaluated through simulation results, which demonstrate its good performance."
Sundaraja Sitharama Iyengar,Distributed Source Coding for Sensor Data Model,"We measure reliability in sensor networks which are dependent on limited resources of individual sensor nodes such has battery capacity, transmission range and channel interference due to simultaneous wireless transmissions.","Sensor Data Reliability, cluster head selection, BER, Slepian & Wolf Coding, Baysian Error, sensor data model, Slepian-Wolf theorem, Cosets, distributed source coding, Huffman Trees","The paper presents a distributed source coding approach for sensor data model, which includes Slepian-Wolf theorem, compression rate, fault rate, and cluster head selection schemes. The approach is designed to reduce the number of bits needed for transmission in sensor networks."
Sunny Rai,Understanding Metaphors using Emotions,"This paper proposes an emotion-driven metaphor understanding system to identify a range of possible affective senses for a given metaphorical expression. The system uses the web as a corpus to capture context and emotions evoked by a metaphor, enabling the prediction of senses.","emotion-driven, web as corpus, metaphor understanding","The paper presents a novel approach to understanding metaphors by incorporating emotions and using the web as a knowledge source. The proposed system, EMU, extracts properties of the source domain, generates an emotion profile, and selects properties to be transferred to the target domain, enabling the prediction of senses for a given metaphorical expression."
Suresh Kumar Gupta,"Cardioprotection from ischemia and reperfusion injury by Withania somnifera: A hemodynamic, biochemical and histopathological assessment","The efficacy of Withania somnifera (Ws) to limit myocardial injury after ischemia and reperfusion was explored and compared to that of Vit E, a reference standard known to reduce mortality and infarct size due to myocardial infarction. Wistar rats (150–200 g) were divided into six groups and received orally saline (sham, control group), Ws-50/kg (Ws control and treated group) and Vit E-100 mg/kg (Vit E control and treated group) respectively for 1 month. On the 31st day, rats of the control, Vit E and Ws treated groups were anesthetized and subjected to 45 min occlusion of the LAD coronary artery followed by 60 min reperfusion. Hemodynamic parameters: systolic, diastolic and mean arterial pressure (SAP, DAP, MAP), heart rate (HR), left ventricular end diastolic pressure (LVEDP), left ventricular peak (+)LVdP/dt and (–)LVdP/dt were monitored. Hearts were removed and processed for histopathological and biochemical studies: Myocardial enzyme viz, creatin phosphokinase (CPK), and antioxidant parameters: malondialdehyde (MDA), glutathione (GSH), superoxide dismutase (SOD), catalase (CAT), glu-tathione peroxidase (GSHPx) were estimated. Postischemic reperfusion produced significant cardiac necrosis, depression of left ventricular functions (MAP, LVEDP, (+) and (–)LVdP/dt) and a significant fall in GSH (p < 0.01), SOD, CAT (p < 0.05), LDH and CPK (p < 0.01) as well as an increase in MDA level (p < 0.05) in the control group rats as compared to sham group. The changes in levels of protein and GPx was however, not significant. Ws and Vit E favorably modulated most of the hemo-dynamic, biochemical and histopathological parameters though no significant restoration in GSH, MAP (with Vit E) were ob-served. Ws on chronic administration markedly augmented antioxidants (GSH, GSHPx, SOD, CAT) while Vit E did not stimulate the synthesis of endogenous antioxidants compared to sham. Results indicate that Ws significantly reduced myocardial injury and emphasize the beneficial action of Ws as a cardioprotective agent.","Withania somnifera, adaptogens, Adaptogenic, myocardial infarction, Ischemia-reperfusion injury, Myocardial damage, ischemia, Vitamin E, antioxidants, reperfusion","This study investigated the cardioprotective effects of Withania somnifera (Ws) compared to Vitamin E in a rat model of ischemia and reperfusion induced myocardial injury. Ws significantly reduced myocardial injury, improved hemodynamic parameters, and enhanced antioxidant defense mechanisms. These findings suggest that Ws has potential as a cardioprotective agent."
Suryanaryana Murty Upadhyayula,Applications of machine learning techniques to predict filariasis using socio-economic factors,"Filariasis is one of the major public health concerns in India. Approximately 600 million people spread across 250 districts of India are at risk of filariasis. To predict this disease, a pilot scale study was carried out in 30 villages of Karimnagar district of Telangana from 2004 to 2007 to collect epidemiological and socio-economic data. The collected data are analysed by employing various machine learning techniques such as Naïve Bayes (NB), logistic model tree, probabilistic neural network, J48 (C4.5), classification and regression tree, JRip and gradient boosting machine. The performances of these algorithms are reported using sensitivity, specificity, accuracy and area under ROC curve (AUC). Among all employed classification methods, NB yielded the best AUC of 64% and was equally statistically significant with the rest of the classifiers. Similarly, the J48 algorithm generated 23 decision rules that help in developing an early warning system to implement better prevention and control efforts in the management of filariasis.","Filariasis, mosquito, socio-economic factors, Socio-economic conditions, Machine learning techniques, Predictive classification modelling, Data balancing, Feature subset selection",This study aims to predict filariasis using socio-economic factors and machine learning techniques. A pilot scale study was conducted in 30 villages of Karimnagar district of Telangana from 2004 to 2007 to collect epidemiological and socio-economic data. Various machine learning techniques were employed to analyse the data and predict filariasis. The study found that Naïve Bayes yielded the best AUC of 64% and generated 23 decision rules that help in developing an early warning system to implement better prevention and control efforts in the management of filariasis.
Susan W. Burriss,BELIMUMAB IN PATIENTS OF BLACK AFRICAN ANCESTRY,"Study design. SELENA–SLEDAI = Safety of Estrogens in Lupus Erythematosus National Assessment–Systemic Lupus Erythemato-sus Disease Activity Index; IV = intravenous.

Randomization and treatment. Using an interactive voice/web response system, patients receiving standard therapy were randomized 2:1 to receive either belimumab 10 mg/kg IV or placebo, which was administered on days 0, 14, and 28 and every 28 days thereafter up to week 48, with a final evaluation at week 52. Randomization was stratified by screening SELENA–SLEDAI score (≤9 versus ≥10), region (US/Canada versus rest of world), and complement level (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]). Detailed randomization data are provided in Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Patients who successfully completed the initial 52-week double-blind phase could enter an optional 6-month open-label extension phase, during which they received belimumab 10 mg/kg IV every 28 days plus standard therapy, irrespective of their previous study assignment. The first dose was given at the week 52 (day 364) visit of the double-blind period (day 1 of the open-label extension phase). Patients who completed the 52-week double-blind phase, but did not enter the 6-month open-label extension phase, were required to return for an additional follow-up visit 8 weeks after their last dose. Patients who withdrew early were required to return for an exit visit 4 weeks after their last dose and a follow-up visit 8 weeks after their last dose.

The original protocol plan was to randomize 816 patients, providing ≥90% power to detect ≥12% absolute improvement in the SRI response rate in the belimumab group compared with the placebo group at a 5% significance level. Due to enrollment challenges, a revised sample size was calculated to include 501 patients (≥334 patients in the belimumab group and ≥167 patients in the placebo group). This sample size provided ≥90% power to detect a minimum 15.55% absolute improvement in SRI–SLEDAI-2K response rate in the belimumab group relative to the placebo group at a 5% significance level (based on the pooled data from efficacy studies BEL112341 and BEL113750) (15,21). These calculations assumed a placebo response rate of 43.95% at week 52.

Study end points and assessments. The primary efficacy end point was the SRI–SLEDAI-2K response rate (defined in the Supplementary Material) at week 52 of the double-blind phase. Unlike in the phase II and phase III studies, the SRI–SLEDAI-2K was selected because of the simplification it offers in proteinuria assessment as compared with the SELENA–SLEDAI proteinuria component; both are clinically meaningful (22). The primary efficacy end point for the open-label extension phase was SRI–SLEDAI-2K response rate at open-label extension week 24. If the open-label extension week 24 data were missing, data from the open-label extension week 28/exit visit were used. This time point is referred to as “open-label extension week 24” throughout the text. Data related to the primary efficacy end point, e.g., the response rate over time, percentage of patients with a durable SRI–SLEDAI-2K response from week 44 through week 52, time to first SRI–SLEDAI-2K response that was maintained through week 52, and duration of longest SRI–SLEDAI-2K response among patients with ≥1 SRI–SLEDAI-2K responses were summarized.

The key secondary end points were SRI–SELENA–SLEDAI at week 52 (open-label extension week 24), time to first severe SLE flare (measured by the SELENA–SLEDAI flare index [SFI]), and proportion of patients whose average prednisone dose had been reduced by ≥25% from baseline to ≤7.5 mg/day during week 40 through week 52 (open-label extension week 28/exit visit), in patients receiving >7.5 mg/day at baseline. Key renal end points included time to first renal flare over 52 weeks and over 28 weeks in the open-label extension, SELENA–SLEDAI–SLEDAI-2K renal domain improvement at week 52, SELENA–SLEDAI–SLEDAI-2K renal domain worsening at week 52, percentage reduction in proteinuria by visit and at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours, and proteinuria shift at week 52 and open-label extension week 24 and week 28/exit visit among those with baseline proteinuria >0.5 gm/24 hours. Renal flare is defined in the Supplementary Material (http://onlinelibrary.wiley.com/doi/10.1002/art.41900/abstract).

Biomarkers measured included percentage changes in serum IgG level, anti-dsDNA antibody level (in those who were anti-dsDNA positive [≥30 IU/ml] at baseline), and complement (C3 and C4) levels from baseline. Safety was evaluated by monitoring adverse events (AEs), serious AEs (SAEs), AEs of special interest, vital signs, clinical laboratory test results, and immunogenicity up to 8 weeks posttreatment and throughout the open-label extension phase.

Data analyses. For the double-blind phase, safety analyses were performed on the safety population, defined as all patients who were randomized and treated with at least 1 dose of investigational product. Data on the safety population were summarized according to the treatment the patient was randomized to receive rather than by the treatment that was received, but both were the same for this study. Efficacy analyses were performed on the modified intent-to-treat (ITT) population, defined as the safety population minus those patients who had any assessment at any of 3 study sites that were excluded from the efficacy analyses before the database lock because of potential Good Clinical Practice noncompliance.

For analysis of the primary and 3 key secondary efficacy end points, a step-down sequential testing procedure was used as described in the Supplementary Material. The following subgroup analyses were performed for the primary analysis (SRI–SLEDAI-2K response at week 52): region (US/Canada versus rest of world), baseline SELENA–SLEDAI–SLEDAI-2K score (≤9 versus ≥10), baseline anti-dsDNA antibody level (≥30 IU/ml versus <30 IU/ml), baseline complement levels (≥1 test finding showing low C3/C4 [less than the lower limit of normal] versus C3/C4 other [the lower limit of normal or above]), and baseline complement and anti-dsDNA antibody levels (≥1 test finding showing low C3/C4 and anti-dsDNA ≥30 IU/ml versus C3/C4 other and anti-dsDNA ≥30 IU/ml). The odds of an SRI–SLEDAI-2K response with belimumab treatment versus placebo were estimated using logistic regression analysis.

For the open-label extension phase, all patients received belimumab, no formal statistical hypothesis t",,"This study investigated the efficacy and safety of belimumab in patients of Black African ancestry with systemic lupus erythematosus (SLE).  Patients were randomized to receive belimumab or placebo for 52 weeks, followed by an optional 6-month open-label extension phase. The primary efficacy endpoint was the SRI–SLEDAI-2K response rate at week 52.  Key secondary endpoints included SRI–SELENA–SLEDAI at week 52, time to first severe SLE flare, and proportion of patients with a reduction in prednisone dose. Renal and biomarker assessments were also conducted.  The study found that belimumab was effective in improving SLE disease activity and reducing renal flares in patients of Black African ancestry."
Sushil Kumar,Towards Precision Agriculture: IoT-Enabled Intelligent Irrigation Systems Using Deep Learning Neural Network ||| Virtualization in Wireless Sensor Networks: Fault Tolerant Embedding for Internet of Things,"This paper presents a deep learning NN-based IoT-enabled intelligent irrigation system for precision agriculture (DLiSA). An LSTM RNN model is employed to predict volumetric soil moisture content of the next day based on the historical temporal dynamics of climate and soil. The proposed model uses a closed-loop approach, which takes feedback from soil sensors and climate sensors that keeps its functionality higher in the unpredicted climate of any region. ||| Recently, virtualization in wireless sensor networks (WSNs) has witnessed significant attention due to the growing service domain for IoT. Related literature on virtualization in WSNs explored resource optimization without considering communication failure in WSNs environments. The failure of a communication link in WSNs impacts many virtual networks running IoT services. In this context, this paper proposes a framework for optimizing fault tolerance in virtualization in WSNs, focusing on heterogeneous networks for service-oriented IoT applications.","Volumetric Soil Moisture Content, Deep Learning Neural Network, Fault Tolerant Embedding, Deep Learning, Internet of Things, Precision Agriculture, Sensor, Long Short Term Memory, Virtualization, IoT-enabled Intelligent Irrigation Systems, LSTM RNN model, IoT, Wireless sensor networks","The proposed DLiSA system consists of a smart irrigation model and associated sensing IoT network model deployed on farmland. The system uses a closed-loop approach to predict volumetric soil moisture content of the next day based on historical temporal dynamics of climate and soil. The performance of DLiSA is compared with state-of-the-art algorithms subject to the prediction of soil moisture content, soil water deficit, and water volume irrigated over a month. ||| The paper discusses the importance of virtualization in WSNs for IoT applications, focusing on fault-tolerant embedding. It reviews existing proposals on virtualization in WSNs, highlighting their limitations and proposing a new approach to enhance fault tolerance."
Sushma Hans,An Adaptive ACO-Driven Scheme for Learning Aim Oriented Personalized E-Learning ||| Proposed Framework for Modeling Course Structure in a Personalized E-Learning System,"The e-learning paradigm is now a well-established vehicle of modern education. It caters to a wide spectrum of students with diverse backgrounds who enroll with their own learning aims. A core challenge under this scenario is to generate personalized learning paths so that each student can achieve her learning aim most effectively. ||| A proposal scheme to personalize students’ learning based on her learning aim in an e-learning environment. The system acknowledges a distinct set of students' aims that prioritize various Learning Objects (LOs) such as theory, case studies etc. according to student's Learning Aim (LA).","learning aim, personalized learning, Learning Objects, Learning Aims, e-learning, Concept Perspectives, Course structure, Priority tables, adaptive learning, Dynamic Learning Ability, ontology-based EL-DSS, Personalized E-learning, Personalized e-Learning, Directed Acyclic Graph, Ant Colony Optimization, Learning Success","The proposed scheme is an extension of the weighted directed acyclic precedence Course Graph (CG) that uses the concept of perspectives introduced earlier. The CG is structured into levels, with each level corresponding to a distinct topic or concept. The scheme uses three databases: Maximum Learning Success (MLS), Perspective Aim Contribution Table (PACT), and Learning Object Priority Table (LOPT) to provide personalized learning paths for each student. ||| This paper proposes a framework that emphasizes the significance of user's LA while selecting the LOs as well as adding to the kitty of perspectives for grasping a concept. The system generates an initially optimized path taking into account the priorities of learning objects and the contribution of concept perspectives for different learning aims."
Sushmita Mitra,Data Mining in Soft Computing Framework,"The present article provides a survey of the available literature on data mining using soft computing. A categorization has been provided based on the different soft computing tools and their hybridizations used, the data mining function implemented, and the preference criterion selected by the model.","knowledge discovery, neural networks, Soft Computing, genetic algorithms, Data Mining, Knowledge Discovery in Databases, neuro-fuzzy computing, rough sets, rule extraction, Fuzzy logic",Data mining is a form of knowledge discovery essential for solving problems in a specific domain. Individual data sets may be gathered and studied collectively for purposes other than those for which they were originally created.
T Huang,Synchronization of delayed chaotic systems with parameter mismatches by using intermittent linear state feedback,This paper investigates the synchronization of coupled chaotic systems with time delay in the presence of parameter mismatches by using intermittent linear state feedback control. Quasi-synchronization criteria are obtained by means of a Lyapunov function and the differential inequality method. Numerical simulations on the chaotic systems are presented to demonstrate the effectiveness of the theoretical results.,"parameter mismatches, time delay, synchronization, intermittent linear state feedback, chaotic systems, intermittent feedback control","The paper studies the synchronization of non-identical chaotic systems with delays in the presence of parameter mismatches using intermittent control. Some criteria for synchronization of the drive-response chaotic systems with delays up to a relatively small error bound are derived by means of a Lyapunov function, differential inequality and linear matrix inequality. Numerical simulations are presented to validate the effectiveness of the theoretical results."
T. Acharya,Gesture Recognition,"Hand Gesture detection is now getting a lot of attention because it has a lot of uses and the specialty to connect with machines around efficiently by human interaction to computers. In this we are trying to make a knowhow of hand gesture detection system. The problems of hand gesture detection system are also discussed in this. Conclusion of results, methods, data and difference between different phases are also mentioned. Pros and cons are also discussed. In this project we are trying to understand how the image processing works and how can we use it to make a hand gesture detection system so that we can operate the computer without any physical contact with the machine itself. There are many researches that are done before and are still undergoing. Many big companies are currently working on this technology so that they can make their products even more useful that they are now because this technology has very high scope in the upcoming future. The people that are not mentally stable or weak from mind can also benefit by technology and can operate the computer. We can use this technology to make the computer even more accessible for humans.","Feature Extract, Tools for classification, Neural Networks, Posture of Hand, Gesture, Interaction of human with computer (HCI), Phases of recognition, brightness factor matching, fuzzy c-means clustering algorithm, gesture recognition",The main motive to build a hand gesture detection system is to make an interaction between human and computer that can be done by recognizing gestures for controlling robots or a simple computer. How do we make this system is understood and interpreted by the computer. The interaction of humans with computer is also called as man-machine interaction (MMI). Since A computer is insignificant if it not being utilized by human. There are some features that should be looked before we design this system. The function of the system and the use of the system. Function means the things that the system gives to its user and use means the scope of the system that it can be used efficiently. The system which has these both properties is known as powerful system.
T. J. Hsieh,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
T. M. Choi,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
T. PRASANNA KUMARI,Real-Time Monitoring System for Aquaculture,The idea behind building up the real-time monitoring system is to lessen the manual fish farming which uses more work powers. There are sensors which measure water parameters and control those to keep aquarium clean and fishes healthy. Farmers are given alert messages if the water parameters exceed and also remedial actions are performed before he reached to the Aquarium. This device is useful for fishes as well as other Aqua life also. By using this we can save the aqua life.,"Fish Farming, IOT, Sensors, Sensor Networks, Arduino, Water Parameters, Real-Time Monitoring, GSM, Aquaculture",The proposed method aims at continuously monitoring the harmful gases and relative humidity in a cost effective way by polling sensor at fixed interval of time. Arduino processes data and will be updated continuously on the system.
T. Sairam,Liquid crystal films on curved surfaces: An entropic sampling study,"We report a Monte Carlo study of the phase transition in liquid crystals using the Wang-Landau algorithm. We compute the representative density of states of the film under consideration and make the system perform an energy-uniform random walk by biasing the walk against its own density of states. We then extract the canonical ensembles by simultaneously applying two biasing probabilities to the microstates, one according to the density of states and the other due to the assumed statistical distribution corresponding to the temperature under consideration. We adopt this procedure in reporting the following equilibrium properties of the film under different boundary conditions.","curved substrates, Monte Carlo simulation, Monte Carlo study, phase transition, liquid crystals, nematic thin film, Wang-Landau algorithm","We study the phase transition in liquid crystals using the Wang-Landau algorithm and report the equilibrium properties of the film under different boundary conditions. We find that the temperature at which the transition takes place is not the same as the temperature near which the uniaxial phase actually forms, and that the surface anchoring seems to be too strong for the elastic response of the nematic medium to force a uniaxial order above a certain threshold value."
T. Tan,Iris Detection,"For iris boundary detection, circular summation of intensity approach is used as proposed in [5]. The original grayscale image is blurred using median filter to remove external noise. After filtering, the contrast of image is enhanced to have sharp variation at image boundaries using histogram equalisation as shown in Figure 5(a). This contrast enhanced image is used for finding the outer iris boundary by drawing concentric circles (Figure 5(b) shows an example) of different radii from the pupil center and the intensities lying over the perimeter of the circle are summed up.","Adaptive Threshold, Circular Hough Transform, Spectrum Image, histogram equalisation, iris recognition, circular summation of intensity, Connected Components, Iris detection, pupil boundary, Iris Segmentation",The proposed system has been tested on two publicly available databases BATH and CASIA V3. From experimental analysis it has been observed that the system is capable of handling unconstrained scenarios as well. The system is capable of performing segmentation for unconstrained scenarios in significantly less time compared to Hough transform.
T. Tuytelaars,Unique Local Features in Lip Images for Recognition,"The experiments are carried out from images taken with a camera that is used for the regular use. And the color features of a lip are not explored in the proposed research. Still the recognition system exploits the grayscale local features of a lip images and eﬃciently matches it with local features of another lip image. If the color properties of a lip image is explored for recognition along with local features, the accuracy values would increase further.","grayscale features, Lip Pattern Recognition, SIFT, lip recognition, color features, Biometric, Local Feature Extraction, local features, SURF",The paper presents the results of experiments on lip recognition using local features. The recognition system exploits the grayscale local features of lip images and achieves high accuracy. The authors suggest that exploring color properties of lip images could further improve the accuracy.
T. Zhou,Cost Eﬀective Inﬂuence Maximisation,"In the context of virality prediction, many researchers have leveraged the existence of a core-periphery structure in a network to identify the super-spreaders of information. Topologically, the nodes in the core of a network are the most eﬃcient spreaders. However, these nodes are less susceptible, i.e., unlikely to be inﬂuenced by the periphery nodes. Consequently, large payoﬀs are required to market information (ideas, products, memes, etc.) via them. In this paper, we show the presence of several non-core nodes whose spreading power is close to that of the core nodes.","Virality, Inﬂuence maximisation, Information diﬀusion, cost-effective, Core-periphery structure, information diffusion, social networks, influence maximisation","This paper proposes a cost-eﬀective strategy to make a meme reach the super-spreaders without the need for global information. The proposed hill-climbing based strategy can be eﬀectively used with both, global as well as local characteristics of the nodes in a network. In terms of the cost metric, it outperforms the conventional independent cascade model by more than 5 times for the core and 2 times for the non-core super-spreaders."
Tan et. al.,Rumour Source Detection Using Game Theory,"Social networks have become a critical part of our lives as they enable us to interact with a lot of people. These networks have become the main sources for creating, sharing and also extracting information regarding various subjects. But all this information may not be true and may contain a lot of unverified rumours that have the potential of spreading incorrect information to the masses, which may even lead to situations of widespread panic. Thus, it is of great importance to identify those nodes and edges that play a crucial role in a network in order to find the most influential sources of rumour spreading. Generally, the basic idea is to classify the nodes and edges in a network with the highest criticality. Most of the existing work regarding the same focuses on using simple centrality measures which focus on the individual contribution of a node in a network. Game-theoretic approaches such as Shapley Value (SV) algorithms suggest that individual marginal contribution should be measured for a given player as the weighted average marginal increase in the yield of any coalition that this player might join. For our experiment, we have played five SV-based games to find the top 10 most influential nodes on three network datasets (Enron, USAir97 and Les Misérables). We have compared our results to the ones obtained by using primitive centrality measures. Our results show that SV-based approach is better at understanding the marginal contribution, and therefore the actual influence, of each node to the entire network.","influential nodes, Jaccard Similarity Coefficient, cooperative game, Rumour Source Detection (RSD), centrality measures, network analysis, Shapley Value (SV), Game-Theory, Network Centrality",This paper aims to identify the most influential nodes in a network that are the primary sources of rumour propagation. The authors propose a game-theoretic approach using the Shapley Value algorithm to find the most influential nodes. They compare their results with primitive centrality measures and show that the SV-based approach is better at understanding the marginal contribution of each node to the entire network.
Tandra Pal,A Genetic Algorithm for Solving Fuzzy Shortest Path Problems with Interval Type-2 Fuzzy Arc Lengths ||| Interval-Valued Intuitionistic Fuzzy Soft Sets and Matrices ||| MAXIMISING ACCURACY AND EFFICIENCY OF INTERVAL-VALUED INTUITIONISTIC FUZZY SOFT SETS ||| PAL AND PAL: SOGARG: A SELF-ORGANIZED GENETIC ALGORITHM-BASED RULE GENERATION SCHEME FOR FUZZY CONTROLLERS ||| Robust Consensus: A New Measure for Multicriteria Robust Group Decision Making Problems Using Evolutionary Approach ||| The Fuzzy Robust Graph Coloring Problem,"Shortest path problem is one of the most fundamental and well-known optimization problems in graph theory due to its various real-world applications. Fuzzy set can manage the uncertainty, associated with the information of a problem, where conventional mathematical models may fail to reveal satisfactory result. In most cases, shortest path problem in fuzzy graph, called fuzzy shortest path problem, uses type-1 fuzzy set as arc length. The uncertainty associated with the linguistic description of information is not represented properly by type-1 fuzzy set due to inexactness of human perception in the evaluation of membership degrees having crisp values.  An interval type-2 fuzzy set is able to tackle this type of uncertainty. In this paper, we have proposed an algorithmic approach based on genetic algorithm for finding shortest path from a source node to a destination node in a fuzzy graph with interval type-2 fuzzy arc lengths. We have designed a new crossover operator which does not need mutation operation. The purpose of mutation operation has been taken care by the proposed crossover operation. We have compared our algorithm with two other existing genetic algorithms for the fuzzy shortest path problem, where superiority of the proposed algorithm is shown. To the best of our knowledge, no algorithm based on genetic algorithm exists in the literature for fuzzy shortest path problem with interval type-2 fuzzy arc lengths. A numerical example is used to illustrate the effectiveness of the proposed approach. ||| A noticeable progress has been found in decision making problems since the introduction of soft set theory by Molodtsov in 1999. It is found that classical soft sets are not suitable to deal with imprecise parameters whereas fuzzy soft sets (FSS) are proved to be useful. Use of intuitionistic fuzzy soft sets (IFSS) is more effective in environment where arguments are presented using membership and non-membership values. In this paper we propose an algorithmic approach for multiple attribute group decision making problems using interval-valued intuitionistic fuzzy soft matrix (IVIFSM). IVIFSM is the matrix representation of interval-valued intuitionistic fuzzy soft set (IVIFSS), where IVIFSS is a natural combination of interval-valued intuitionistic fuzzy set and soft set theory. Firstly, we propose the concept of IVIFSM. Then an algorithm is developed to find out the desired alternative(s) based on product interval-valued intuitionistic fuzzy soft matrix, combined choice matrix, and score values of the set of alternatives. Finally, a practical example has been demonstrated to show the effectiveness of the proposed algorithm. ||| This article proposes an algorithmic approach for multiple attribute group decision making (MAGDM) problems using interval-valued intuitionistic fuzzy soft matrix (IVIFSM) and confident weight of experts. We propose a novel concept for assigning confident weights to the experts based on cardinals of interval-valued intuitionistic fuzzy soft sets (IVIFSSs). The confident weight is assigned to each of the experts based on their preferred attributes and opinions, which reduces the chances of biasness. ||| The paper discusses various methods for generating fuzzy controllers using genetic algorithms. It presents different approaches to designing fuzzy controllers, including the use of genetic algorithms to determine membership functions and rule sets. ||| In fuzzy group decision making problems, we often use multi-objective evolutionary optimization. The optimizers search through the whole search space and provide a set of nondominated solutions. But, sometimes the decision makers express their prior preferences using fuzzy numbers. In this case, the optimizers search in the preferred soft region and provide solutions with higher consensus. If perturbation in the decision variable space is unavoidable, we also need to search for robust solutions. Again, this perturbation aﬀects the degree of consensus of the solutions. This leads to search for solutions those are robust to their degree of consensus. In this work, we address these issues by redeﬁning consensus and proposing a new measure called robust consensus. We also provide a reformulation mechanism for multiobjective optimization problems. Our experimental results show that the proposed method is capable of ﬁnding robust solutions having robust consensus in the speciﬁed soft region. ||| Fuzzy graph model can represent a complex, imprecise and uncertain problem, where classical graph model may fail. In this paper, we propose a fuzzy graph model to represent the examination scheduling problem of a university and introduce a genetic algorithm based method to find the robust solution of the scheduling problem that remains feasible and optimal or close to optimal for all scenarios of the input data.","interval-valued intuitionistic fuzzy soft set, Interval-valued intuitionistic fuzzy sets, Interval-valued intuitionistic fuzzy soft sets, genetic algorithm, genetic algorithms, interval type-2 fuzzy sets, fuzzy controllers, Interval-Valued Intuitionistic Fuzzy Soft Sets, robust coloring, Genetic algorithm, Type-1 fuzzy set, fuzzy group decision making, rule sets, Fuzzy shortest path problem, Fuzzy Soft Sets, Interval-Valued Intuitionistic Fuzzy Soft Matrices, multiobjective optimization, Confident weight of experts, choice matrix, Fuzzy Soft Matrices, Controllability, genetic algorithm (GA), membership functions, fuzzy event, fuzzy graph coloring, Multiple attribute group decision making, robustness, Decision-making, self-organizing, evolutionary algorithms, Fuzzy graph, interval-valued intuitionistic fuzzy soft matrix, Interval-valued intuitionistic fuzzy soft matrix, Interval type-2 fuzzy set, Consensus, fuzzy probability","This paper proposes a genetic algorithm for solving fuzzy shortest path problems with interval type-2 fuzzy arc lengths. The algorithm uses a new crossover operator that does not require mutation operation, and it has been compared with two existing genetic algorithms for the fuzzy shortest path problem. The results show the superiority of the proposed algorithm, and a numerical example is used to illustrate its effectiveness. ||| This paper proposes an algorithmic approach for multiple attribute group decision making problems using interval-valued intuitionistic fuzzy soft matrix (IVIFSM). The proposed approach uses combined choice matrix for individual decision maker by incorporating the choice parameters of the set of experts. The score and accuracy values are calculated to yield the desired alternative(s). ||| The proposed algorithm mainly focuses on the choice parameters/attributes of various experts and computes the confident weight of an expert based on her prescribed opinions. We have used cardinals of IVIFSS for measuring the weight. The proposed confident weight also reduces the chance of biasing. ||| The paper reviews various methods for generating fuzzy controllers using genetic algorithms. It discusses the use of genetic algorithms to determine membership functions and rule sets, and presents different approaches to designing fuzzy controllers. ||| This paper proposes a new measure called robust consensus for multicriteria robust group decision making problems using evolutionary approach. The proposed method addresses the issues of prior preferences using fuzzy numbers and perturbation in the decision variable space. Experimental results show that the proposed method is capable of finding robust solutions having robust consensus in the specified soft region. ||| The paper proposes a method for graph coloring that can handle uncertain environments, represented by a fuzzy graph model. The examination scheduling problem of a university is considered, where courses are represented by nodes of a graph and every pair of incompatible courses is connected by an edge. The coloring of this graph provides a feasible schedule of the courses and computes the minimum number of time slots. The problem arises if after the examination schedule is published, some students choose a new course that makes the schedule invalid. The proposed method uses a genetic algorithm to find the robust solution of the scheduling problem."
Tang et al.,Ontology Driven Software Development for Automated Documentation,"Recent outsourcing /off-shoring software development practices testify that any development done without a proper sharing mechanism leads to the generation of inconsistent information, which further results in an undesired, error-prone software. Further, with the business process automation, a significant way to minimize human effort involves various development, support and maintenance activities to reuse available information. Thus, reusing and sharing information in a standardized way is the key operative challenges which foster the need to identify and exploit novel knowledge-based frameworks. The proposed research provides a tool-based solution to automate the software documentation process using ontologies. This multi-phase framework has overall six phases where each phase output contributes to the final automated documentation. To evaluate the extent of automated documentation it is compared using free and open source software known as WCopyfind to the existing manual documentation for a Result Management System case study. Preliminary results show a highest automation of 60 percent, which is clearly noteworthy.","Ontology driven, Ontology, software architecture documentation, Software’s documentation, Automatic documentation, technical documentation, ontology driven software development, Semantic Web, automated documentation, Software engineering","The paper presents a framework for ontology driven software development for automated documentation, which is divided into six phases. The framework is designed to capture key concepts of the domain under consideration and generate documentation in both human and machine-understandable forms. The paper also discusses the related work in the field of ontology driven software development and automated documentation."
Tanja Scheikl,Cutting Edge: CD8 T Cell-Mediated Demyelination,"We generated mice (DKI) in which the HA coding sequence was introduced in the ubiquitously active Rosa26 locus but where HA transcription was prevented by an upstream LoxP-flanked Stop cassette. The DKI mice were then crossed with the MOGi-Cre mice, which express Cre specifically in oligodendrocytes. The resulting DKI mice excise the Stop cassette due to MOG-controlled Cre expression, leading to restricted HA expression to oligodendrocytes.  We then decided to test whether effector CD8 T cells can mediate oligodendrocyte cell death and demyelination in vivo. Effector T cells were first generated by in vitro activation of Kd:HA512–520 pentamer-specific CD8 T cells obtained from CL4-TCR mice using HA peptide, IL-2, and IL-12. The resulting Tc1 cells produce large amounts of granzyme B (GrB) and IFN-γ and exhibit potent cytotoxicity to HA-loaded target cells in vivo. Next, we transferred these HA-specific Tc1 cells into DKI and control mice. Following i.v. injection of 3 × 107 HA-specific Tc1 cells, but not naive HA-specific CD8 T cells, ~40% of the DKI mice developed an overt monophasic disease peaking at day 8–10 and waning by 4 wk posttransfer. The clinical manifestations included weight loss and, in the more severe cases, tremors, reduced mobility, and difficulty to right when overturned without overt paralysis. Upon histological analysis, all DKI mice injected with Tc1 cells demonstrated clear CNS pathology from day 5 onwards. Inflammatory lesions were never found in control littermates injected in parallel with HA-specific Tc1 cells.",,"This study investigates the role of CD8 T cells in multiple sclerosis (MS) pathogenesis. Researchers generated a mouse model where a model antigen (influenza hemagglutinin) is expressed specifically in oligodendrocytes, the cells responsible for producing myelin in the central nervous system. Transferring activated CD8 T cells specific for this antigen into these mice resulted in inflammatory lesions in the brain, spinal cord, and optic nerve, resembling active MS lesions. These lesions were characterized by CD8 T cell infiltration, loss of oligodendrocytes, demyelination, and microglia activation. This suggests that CD8 T cells can directly contribute to oligodendrocyte death and demyelination in MS, highlighting their potential as therapeutic targets."
Taous Madi,A Simple Dynamic Decision Making System for Filtering Out DoS Attacks in SDN,The Software Deﬁned Networking (SDN) paradigm is expected to heavily integrate into future networks. Enterprises have already started migrating their networks to SDNs. Billions of smart devices constituting the Internet of Things will be connected to these high speed networks and will be communicating over these networks. The ubiquity of these networks along with the user devices connected to them becomes of paramount importance for the end users. This work presents a SDN switch based module to detect a Denial Of Service attack on the network and its connected components.,"Trafﬁc Filtering, Denial of Service Attacks, SDN, Internet of Things, DoS attacks, packet filtering, Software Deﬁned Networks, decision making system","This paper discusses the different Denial of Service attacks that are possible on Software Deﬁned Networks, along with various methods to identify and detect such attacks, and finally the methods to mitigate these attacks."
Tarang Bansal,Upgradation Of Biogas Using Combined Method Of Alkaline Water Scrubbing And Adsoption Through Carbon Molecular Sieve,"Over the past decade there is increasing demand of energy in rural, urban areas of India. This has led to the depletion of natural resources like coal, wood and kerosene. These sources are inefficient and harmful to the environment. Thus there is an imminent need to replace them with clean, eco-friendly and efficient source of energy.","water scrubbing, pressure swing adsorption, biomethane, Combined Method, Biogas, Alkaline Water Scrubbing, Adsoption Through Carbon Molecular Sieve","The paper discusses the upgradation of biogas using a combined method of alkaline water scrubbing and adsorption through carbon molecular sieve. The method involves the passage of compressed biogas through a cylindrical pipe packed with carbon molecular sieves, which enriches the methane content to 88% or more. The paper also discusses the environmental advantages of biogas, including its renewable nature, ability to reduce greenhouse gas emissions, and potential to replace fossil fuels."
Tarunpreet Bhatia,On the Security of Authenticated Group Key Agreement Protocols,"The group key agreement protocol enables to derive a shared session key for the remote members to communicate securely. Recently, several attempts are made to utilize group key agreement protocols for secure multicasting in Internet of Things. This paper contributes to identify the security vulnerabilities in the existing protocols, to avoid them in future constructions. The protocols presented by Gupta and Biswas have been found insecure to ephemeral secret key leakage (ESL) attack and also, malicious insiders can impersonate an honest participant. Additionally, the protocol presented by Tan is also ESL-insecure. We also present a fix to the Tan’s protocol to make it secure.","Insider security, Security Protocols, Authenticated Group Key Agreement, Authentication, Mutual authentication, Group key agreement, Elliptic Curve Cryptography","This paper discusses the security vulnerabilities in existing group key agreement protocols and presents a fix to one of the protocols to make it secure. The authors identify the security vulnerabilities in the protocols presented by Gupta and Biswas and Tan, and present a fix to the Tan’s protocol to make it secure. The paper also discusses the importance of authentication and insider security in group key agreement protocols."
Tarushi Sharma,A deep learning model for mass screening of COVID-19,"The objective of this research is to develop a convolutional neural network model ‘COVID-Screen-Net’ for multi-class classification of chest X-ray images into three classes viz. COVID-19, bacterial pneumonia, and normal.","COVID-19, deep learning, X-ray, global pandemic, CNN model, Corona",The authors developed a deep learning model ‘COVID-Screen-Net’ for mass screening of COVID-19 from chest X-ray images. The model achieves an average accuracy of 97.71% and a maximum recall of 100%. It outperforms existing systems for screening of COVID-19 and may prove a useful tool for quick and low-cost mass screening of patients.
Tej Pratap Singh,Wound Healing Potential of Raloxifene Nanoemulsion Gel for the Management of Postmenopausal Cutaneous Wounds,"Background: Depletion in estrogen level(s) especially in postmenopausal women is reported to have delayed wound healing effects; hence we have evaluated the wound healing potential of raloxifene in rat model. Objectives: Investigating the wound healing effects of raloxifene nanoemulsion for the management of postmenopausal cutaneous wounds. Materials and Methods: The optimized nanoemulsion gel contains 0.072% raloxifene hydrochloride. Female Wistar rats were used to investigate its wound healing effects. After three months of ovariectomy, wound healing effect was observed in terms of breaking strength, tensile strength, area of wound contraction, wound closure time, hydroxyproline content and histopathological changes. Results: The nanoemulsion gel exhibited better retention (34.31%) than its nanoemulsion. The raloxifene nanoemulsion gel has no erythema and no eschar formation recorded, and it is safe for topical use. In the incision wound model in ovariectomized rats, breaking (898±25g) and tensile strengths (4.47±0.12 g/mm2) in raloxifene treated groups were found to be higher than the untreated control group. Additionally, in ovariectomized rats, wound contraction was found to be 100% in the treated group s following 20 days of post-wounding, where as in control group only 88% was contraction was observed. Also, more hydroxyproline content in raloxifene treated ovariectomized rat was observed that recommend more collagen content than the untreated ovariectomized rat but approximately similar effects to untreated non-ovariectomized rats. Histopathological studies confirmed that the raloxifene treated groups had more re-epithelialization, neo-vascularization, fibroblast proliferation, and collagen deposition than the control group. Conclusion: These results confirms that the raloxifene nanoemulsion gel has significant wound healing potential, as observed in ovariectomized rats, which will be helpful in postmenopausal cutaneous wound healing.","Raloxifene, Histopathology, Ovariectomized, Hydroxyproline, Wound contraction, Postmenopausal Cutaneous Wounds, Postmenopausal, Breaking strength, Nanoemulsion gel, Wound Healing","This study investigates the wound healing potential of raloxifene nanoemulsion gel in postmenopausal cutaneous wounds. The results show that the nanoemulsion gel has significant wound healing potential, as observed in ovariectomized rats, and is safe for topical use. The study suggests that raloxifene nanoemulsion gel can be a good alternative for wound healing in postmenopausal women."
Tejal Shah,"Explainable AI (XAI): Core Ideas, Techniques and Solutions","As our dependence on intelligent machines continues to grow, so does the demand for more transparent and interpretable models. In addition, the ability to explain the model generally is now the gold standard for building trust and deployment of Artificial Intelligence (AI) systems in critical domains. Explainable Artificial Intelligence (XAI) aims to provide a suite of machine learning (ML) techniques that enable human users to understand, appropriately trust, and produce more explainable models.","Explainable AI, Stakeholders, Machine Learning, Software toolkits, Programming framework, Bias, Robustness, Interpretable AI, Explainable Artiﬁcial Intelligence, XAI, Decision Making","The paper presents the core ideas, techniques, and solutions of XAI, emphasizing its importance in various phases of the machine learning process. It discusses the stakeholders involved in these phases, including developers, theorists, data scientists, users, consumers, businesses, regulators, and scientists, and highlights the use cases of XAI in detecting bias, scientific understanding, building robust models, and better decision making."
Thakur et. al.,Effect of Cutting Source and Size on the Poplar (Populus deltoides Marsh.) Nursery Performance,The study investigates the effect of cutting position on rooting and growth of Populus deltoides. The results show that cuttings taken from the basal position exhibit better survival and growth characteristics compared to those taken from the middle and upper positions.,"poplar, rooting, Populus deltoides, cutting position, growth, Nursery","The study aimed to standardize appropriate cutting size and position of cutting collection from donor nursery plants for poplar clones. The results showed that longer cuttings taken from the lower parts of the plant produce better results, but with rise in demand for quality planting stock, the use of longer cuttings from basal portion only is not worthwhile."
Tiina Kelkka,ROS deficiency enhanced mannan-induced PsA,"In and joint inflammation using B10Q.Ncf1m1j/m1j mice that have a mutation in the Ncf1 gene (m1j) (the Ncf1 protein also denoted p47phox), and hence reduced ROS production (oxidative burst) (18). As shown in Fig. 1D, Ncf1 mutated mice developed severe joint inflammation within 2 d after mannan injection, which reached the mean maximal disease severity (30 ± 6 points) within 4 d. The frequency of skin lesions was 100%, with more severe cases in B10Q.Ncf1m1j/m1j mice (Fig. 1E), whereas B10.Q mice had a significantly milder disease course. Multiple Exposures to Mannan Induced a Relapsing Disease. Next, we examined the effect of multiple mannan injections in B10Q and B10Q.Ncf1m1j/m1j mice. We boosted mice twice with mannan on days 7 and 14 after disease initiation. Repetitive injections of mannan reproduced the arthritis phenotype, which reached the maximum severity level on days 9 and 17, similar to the first injection (Fig. 1F). A more severe disease course was observed in B10Q.Ncf1m1j/m1j mice than in B10Q mice (P < 0.05 and P < 0.01, respectively). Interestingly, Ps skin scaling returned only after the second mannan injection (on day 16), but the skin peeled off even more quickly than the first time (Fig. 1G). Moreover, from day 11 onward, B10Q.Ncf1m1j/m1j mice started to develop pruritus on the body, predominantly on the back and above the eye (Fig. S1E). Pruritus was only evident in B10Q.Ncf1m1j/m1j mice, but flaky skin on the tail and alopecia all over the leg was observed in both of the mouse strains. We also observed genetic heterogeneity in disease susceptibility (Fig. Fig. 1. ROS deficiency enhanced mannan-induced PsA. The arthritic joint phenotype and Ps-like skin lesions in the front (A) and hind (B) paws of B10Q.Ncf1m1j/m1j mice are shown. (C) Ps-like skin scaling in diseased B10Q.Ncf1m1j/m1j mouse ear compared with naive mouse ear. Mean arthritis (D) and Ps lesion (E) severity in B10Q (n = 5) and B10Q.Ncf1m1j/m1j (n = 5) mice after a single i.p. mannan injection. Mean arthritis (F) and Ps lesion (G) severity in B10Q (n = 5) and B10Q.Ncf1m1j/m1j (n = 5) mice after repetitive mannan injections (days 7 and 14). (H) Mannan-induced mean maximum arthritis scores ± SEM in different mouse strains: B10Q (n = 8), B10Q.Ncf1m1j/m1j (n = 9), B10RIII (n = 10), B10RIII.Ncf1m1j/m1j (n = 9), B10P (n = 3), B10P.Ncf1m1j/m1j (n = 9), BALB/cByJ/Q (n = 10), BALB/cByJ/Q.Ncf1m1j/m1j (n = 8), BALB/cByJ (n = 5), BALB/cByJ.Ncf1m1j/m1j (n = 7), C57BL/6NJ (n = 8), and C57BL/6NJ.Ncf1m1j/m1j (n = 7). Significance was calculated by comparing the maximal disease severity of B10Q and B10Q.Ncf1m1j/m1j mice with all of the other strains in their respective groups. *P < 0.05; **P < 0.01; ***P < 0.001. E3670 | www.pnas.org/cgi/doi/10.1073/pnas.1405798111 Khmaladze et al. Downloaded from https://www.pnas.org by 122.184.65.228 on February 22, 2023 from IP address 122.184.65.228.","autoimmune disease, Ncf1, animal model","This study identifies a new mechanism for psoriasis (Ps) and psoriasis arthritis (PsA) development in mice. A single injection of mannan, a component of baker's yeast, induced Ps and PsA-like symptoms. This effect was exacerbated in mice lacking reactive oxygen species (ROS), but improved when ROS production was restored in macrophages.  Blocking IL-17A, a cytokine produced by gamma delta T cells, completely prevented disease. The study suggests that mannan activates macrophages, leading to TNF-α secretion and stimulation of IL-17A production by gamma delta T cells. This, in turn, drives neutrophil infiltration and inflammation, mimicking Ps and PsA. This new mouse model could be valuable for testing new therapies for Ps and PsA."
Tingwen HUANG,Adaptive event-triggered control for a class of nonlinear systems with periodic disturbances,"This paper investigates the adaptive event-triggered control problem for a class of nonlinear systems subject to periodic disturbances. To reduce the communication burden, a reliable relative threshold strategy is proposed. Fourier series expansion and radial basis function neural network are combined into a function approximator to model suitable time-varying disturbed function of known periods in strict-feedback systems. By combining the Lyapunov stability theory and the backstepping technique, the proposed adaptive control approach ensures that all the signals in the closed-loop system are bounded, and the tracking error can be regulated to a compact set around zero in finite time. Finally, simulation results are presented to verify the effectiveness of the theoretical results.","periodic disturbances, event-triggered control, Fourier series expansion, nonlinear systems, finite time",This paper proposes an adaptive event-triggered control strategy for a class of nonlinear systems with periodic disturbances. The strategy combines Fourier series expansion and radial basis function neural network into a function approximator to estimate unknown nonlinear functions. The proposed control approach ensures that all signals in the closed-loop system are bounded and the tracking error converges to the origin with a small neighborhood in finite time.
Tingwen Huang,Adaptive Lag Synchronization of Memristive Neural Networks with Unknown Connection Weights ||| Chaos in fractional-order discrete neural networks with application to image encryption ||| Global Exponential Synchronization of Multiple Riemann-Liouville Neural Networks with Time-Varying Impulsive Delays ||| Off-policy Reinforcement Learning for H∞Control Design,"This paper investigates the adaptive lag synchronization of memristive neural networks with unknown connection weights. A new fuzzy model is proposed to simplify memristive systems, and the idea of PDC is applied to achieve synchronization between subsystems. The adaptive lag synchronization algorithm is designed, and the update law for the connection weights and controller gain is derived. The stability of the closed-loop system is analyzed, and the synchronization error is shown to be globally exponentially convergent to zero. ||| In this paper, a three-dimensional fractional-order (FO) discrete Hopfield neural network (FODHNN) in the left Caputo discrete delta’s sense is proposed, the dynamic behavior and synchronization of FODHNN are studied, and the system is applied to image encryption. First, FODHNN is shown to exhibit rich nonlinear dynamics behaviors. Phase portraits, bifurcation diagrams and Lyapunov exponents are carried out to verify chaotic dynamics in this system. Moreover, by using stability theorem of FO discrete linear systems, a suitable control scheme is designed to achieve synchronization of the FODHNN. Finally, image encryption system based on the chaotic FODHNN is presented. Some security analysis and tests are given to show the effective of the encryption system. ||| This paper investigates the global exponential synchronization of multiple Riemann-Liouville neural networks with time-varying impulsive delays. By constructing a suitable Lyapunov function and using the linear matrix inequality (LMI) technique, some sufficient conditions are derived to ensure the global exponential synchronization of the considered neural networks. The obtained results are expressed in terms of the network parameters, impulsive delays, and coupling strengths. Finally, two numerical examples are provided to demonstrate the effectiveness of the proposed synchronization scheme. ||| The H∞control design problem is considered for nonlinear systems with unknown internal system model. An off-policy reinforcement leaning (RL) method is introduced to learn the solution of HJI equation from real system data instead of mathematical system model, and its convergence is proved.","Reinforcement learning, memristor, Lyapunov exponent, Synchronization, fuzzy model, linear matrix inequality, Riemann-Liouville neural networks, Image encryption, neural networks, global exponential synchronization, Chaotic dynamics, synchronization error, Fractional-order discrete systems, Impulse, Jacobian matrix algorithm, Fractional-order discrete Hopfield neural networks, Hamilton-Jacobi-Isaacs equation, Lyapunov function, memristive neural networks, recurrent neural networks, unknown connection weights, H∞control design, synchronization, time-varying delay, Off-policy learning, Neural networks, time-varying impulsive delays, Adaptive lag synchronization, PDC, pseudorandom number generator (PRNG), Neural Network","This paper presents a new approach to the adaptive lag synchronization of memristive neural networks with unknown connection weights. The proposed fuzzy model simplifies the memristive systems, and the PDC idea is applied to achieve synchronization between subsystems. The adaptive lag synchronization algorithm is designed, and the update law for the connection weights and controller gain is derived. The stability of the closed-loop system is analyzed, and the synchronization error is shown to be globally exponentially convergent to zero. ||| This paper presents a chaotic dynamics analysis of fractional-order discrete Hopfield neural networks (FODHNNs). The FODHNNs are derived from a 3D-neuron fractional-order continuous Hopfield-type neural networks proposed in Zhang, Qi, and Wang (2010). The dynamic behavior, synchronization, and image encryption application of FODHNNs are explored. Numerical solutions of FODHNNs are needed to be presented. The maximum Lyapunov exponent (LE) of the dynamical system is an important index that characterizes the rate of separation of infinitesimally close trajectories. The Jacobian matrix algorithm for Lyapunov exponents of the discrete fractional maps proposed in Wu and Baleanu (2015b) is employed to calculate the LE of FODHNNs. ||| This paper presents a study on the global exponential synchronization of multiple Riemann-Liouville neural networks with time-varying impulsive delays. The authors derive sufficient conditions for synchronization using a Lyapunov function and linear matrix inequality (LMI) technique. The results are expressed in terms of network parameters, impulsive delays, and coupling strengths. Two numerical examples are provided to demonstrate the effectiveness of the proposed synchronization scheme. ||| The paper introduces an off-policy reinforcement learning method to solve the H∞control design problem for nonlinear systems with unknown internal system model. The method learns the solution of the Hamilton-Jacobi-Isaacs equation from real system data instead of a mathematical system model, and its convergence is proved. The paper also discusses the relationship between reinforcement learning and control communities, and reviews some existing results on reinforcement learning for optimal control problems."
Tong Wang,A Novel EV Charging Management Scheme Considering Mobility Uncertainty,"This paper proposes a novel EV charging management scheme that considers mobility uncertainty due to traffic jams in a city. The scheme uses a centralized aggregator to manage charging plans for all EVs in the network, and each EV reports its charging reservation to the aggregator, including its expected arrival time and charging time. The aggregator then makes CS-selection decisions based on the reported information and updates the reservations periodically to adjust for mobility uncertainty.","Charging System, Mobility Uncertainty, CS-Selection Decision Making, Traffic Jams, Centralized Aggregator, CS-Selection, Electric Vehicle, Driver's Trip Duration, Electric Vehicle Charging","This paper proposes an EV charging management system that considers drivers' trip duration and mobility uncertainty. The system selects charging stations based on reported EVs' reservation information and parking duration, minimizing trip duration for on-the-move EVs."
Tripathi and Shaji,Delays have Dangerous Ends: Slow HTTP/2 DoS attacks into the Wild and their Real-Time Detection using Event Sequence Analysis,"The robustness principle, written by Jon Postel in an early version of TCP implementation, states that the communicating entities should be liberal while accepting the data. Several entities on the Internet do follow this principle. For instance, in this work, we show that many popular web servers on the Internet are generous as they wait for a substantial time period to receive the remaining portion of an incomplete web request. Unfortunately, this behavior also makes them vulnerable to a class of cyber attacks, commonly known as Slow Rate DoS attacks. HTTP/2, the recent version of HTTP, is recently found vulnerable to these attacks. However, the impact of Slow HTTP/2 DoS attacks on real web servers on the Internet has not been studied yet. Also, to the best of our knowledge, there is no defense scheme known to detect Slow Rate DoS attacks against HTTP/2 in real-time. To bridge these gaps, we first test the behavior of HTTP/2 supporting web servers on the Internet against Slow HTTP/2 DoS attacks. Subsequently, we propose a scheme to detect these attacks in real-time. We show that the proposed detection scheme can detect attacks in real-time with high accuracy and marginal computational overhead.","DDoS attacks, Slow HTTP/2 DoS attacks, HTTP/2, Anomaly detection, DoS, HTTP/2 security, Slow Rate DoS attacks",This paper presents a study on the impact of Slow HTTP/2 DoS attacks on real web servers on the Internet and proposes a real-time detection scheme using event sequence analysis. The study shows that several popular web servers are vulnerable to Slow HTTP/2 DoS attacks and that the proposed detection scheme can detect attacks with high accuracy and marginal computational overhead.
Twinkle Gupta,"Earthquake Precursory Research at MPGO, Ghuttu","The paper discusses earthquake precursory research at MPGO, Ghuttu, focusing on radon emanation variation as a parameter.","radon emanation, Ghuttu, MPGO, compiler construction, bootstrapping, cross-compilation, earthquake precursory research","The authors discuss the merits and demerits of bootstrapping and cross-compilation approaches in compiler construction, highlighting their suitability for different computer architectures and programming languages."
U. Satija,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
U.S.N. Murty,Classiﬁcation of Mammalian and Non-Mammalian Keratin Protein Sequences Using Machine Learning Techniques,"Keratin protein is ubiquitous in most vertebrates and invertebrates, and has several important cellular and extracellular functions that are related to survival and protection. Keratin function has played a significant role in the natural selection of an organism. Hence, it acts as a marker of evolution. Much information about an organism and its evolution can therefore be obtained by investigating this important protein. In the present study, Keratin sequences were extracted from public data repositories and various important sequential, structural and physicochemical properties were computed and used for preparing the dataset. The dataset containing two classes, namely mammals (Class-1) and non-mammals (Class-0), was prepared, and rigorous classiﬁcation analysis was performed. To reduce the complexity of the dataset containing 56 parameters and to achieve improved accuracy, feature selection was done using the t-statistic. The 20 best features (parameters) were selected for further classiﬁcation analysis using computational algorithms which included SVM, KNN, Neural Network, Logistic regression, Meta-modeling, Tree Induction, Rule Induction, Discriminant analysis and Bayesian Modeling. Statistical methods were used to evaluate the output. Logistic regression was found to be the most effective algorithm for classiﬁcation, with greater than 96% accuracy using a 10-fold cross validation analysis. KNN, SVM and Rule Induction algorithms also were found to be efﬁcacious for classiﬁcation.","Data mining, Artiﬁcial Neural Networks (ANN), Meta-modeling, Machine learning techniques, Classiﬁcation, Artiﬁcial Intelligence (AI), Keratin, Logistic regression, Discriminant analysis, Mammalian and non-mammalian origin, Support Vector Machines (SVM), Tree induction, Biological classiﬁcation, Keratin protein sequences, Machine learning, Rule induction",This study aims to classify mammals and non-mammals based on various properties of the Keratin protein molecule. The dataset containing 56 parameters was prepared and feature selection was done using the t-statistic. The 20 best features were selected for further classiﬁcation analysis using computational algorithms. Logistic regression was found to be the most effective algorithm for classiﬁcation with greater than 96% accuracy.
Udit Satija,Blind Spectrum Sensing Using Compressed Sensing and Multi-Antennas ||| ECG Noise Detection and Classification Method ||| Performance Study of Cyclostationary based Digital Modulation Classiﬁcation Schemes,"Cognitive Radios exploit the unutilized spectrum by transmitting opportunistically without disturbing the primary user (PU) or licensed user. So, the sensing should be fast enough that the secondary user (SU) can vacate the spectrum when the PU becomes active. ||| An assessment of electrocardiogram (ECG) signal quality has become an unavoidable ﬁrst step in most holter and ambulatory ECG signal analysis applications. In this paper, we present a simple method for automatically detection and classiﬁcation of ECG noises. ||| This paper presents a comparative study of various classifiers in cyclostationary features. The classifiers considered are Neural Network, Naive Bayes, Linear Discriminant Analysis, k-Nearest Neighbor, Support Vector Machine, and Neuro-Fuzzy. The performance of these classifiers is evaluated using confusion matrix and computational complexity.","Classifiers, ECG noise detection, signal processing, Linear Discriminant Analysis, Compressed Sensing, Wearable ECG monitoring devices, Cyclostationary Features, Neuro-Fuzzy, noise detection, classification, Digital Modulation, k-Nearest Neighbor, Blind Spectrum Sensing, Naive Bayes, Classiﬁcation, ECG, Cognitive Radio, Cyclostationary, Support Vector Machine, ECG classiﬁcation, Multi-Antennas, Neural Network, ECG signal quality","This paper proposes a novel blind spectrum sensing method using compressed sensing, which reduces the number of measurements required for spectrum sensing. The proposed method employs multiple receive antennas and uses compressed sensing at the receiver front end to reduce the complexity of the A/D converter. Simulation results show that the proposed method achieves a good probability of detection in very low SNR even at 50% measurements. ||| The proposed method consists of four major steps: moving average ﬁlter, blocking, feature extraction, and multistage decision-tree algorithm. The dynamic amplitude range and autocorrelation maximum peak features are extracted for each block. The method can achieve an average sensitivity (Se) of 97.88%, positive productivity (+P) of 91.18% and accuracy of 89.06%. ||| This paper studies the performance of digital modulation classiﬁcation technique based on the cyclostationary features and different classiﬁers such as Neural Network, Support Vector Machine, k-Nearest Neighbor, Naive Bayes, Linear Discriminant Analysis and Neuro-Fuzzy classiﬁer."
Unknown,Brain Computer Interface for Micro-controller Driven Robot Based on Emotiv Sensors ||| Forecasting Seasonal Time Series with Functional Link Artiﬁcial Neural Network ||| Intelligent Model for Smartphone Addiction Assessment in University Students using Android Application and Smartphone Addiction Scale ||| Observability-based Sequential Analysis for Redundant Reset Identification ||| Opinion of Engineering Students on the Use of Live Online Lectures after the Pandemic ||| Parallel Computing Strategies for Large-Scale Data Processing ||| Sensory Evaluation of Fennel-Seed Powder Incorporated Hard Candy ||| Small Scale Fading and Modulation Techniques for Wireless Communications,"A Brain Computer Interface (BCI) is developed to navigate a micro-controller based robot using Emotiv sensors. The BCI system has a pipeline of 5 stages- signal acquisition, pre-processing, feature extraction, classification and CUDA inter-facing. It shall aid in serving a prototype for physical movement of neurological patients who are unable to control or operate on their muscular movements. ||| Many economic and business time series exhibit trend and seasonal variations. In this paper, we deal with efficient modeling of time series having seasonality and definitive trends. The traditional statistical models eliminate the effect of trend and seasonality from a time series before making future forecasts. This kind of preprocessing increases the computational cost and may even degrade the forecasting accuracy. Here, we present the effectiveness of Functional Link Artiﬁcial Neural Network (FLANN) model for seasonal time series forecasting, using unprocessed raw data. ||| Smartphones have been owned and used ubiquitously in all facets of society utilized for a wide number of tasks such as calling and messaging, social media, surfing as well as for entertainment. Spending a large amount of time on smartphone might lead to a dependence on it for a variety of purposes. This study uses objective measures of real time smartphone usage features to assess smartphone addiction. A purpose built android application to collect real time smartphone usage has been developed and linear classification models namely Support Vector Machine and Logistic Regression are used to predict smartphone addiction among university students. ||| Resets are required in the design to initialize the hardware for system operation and to force it into a known state for simulation or to recover from an error. ||| The first outbreak of COVID-19 was reported in December 2019 and the disease took the shape of a pandemic in the next few months. Universities around the world imported lessons to their student mostly in online mode in 2020 and 2021. Thirty-five undergraduate computer science students were interviewed about their experience of attending online lectures during the COVID-19 pandemic. A quantitative analysis of their responses revealed that 43% of them felt that they can learn equally well from online and offline lectures, 49% felt that online lectures provide them flexibility which in turn helps them to perform better in academics and 54% felt that professors have improved their online teaching skills since the beginning of the pandemic. Further, a qualitative analysis revealed that students appreciate online lectures for allowing them to access ebooks and digital resources while attending lectures, and making it easier to study topics that require a lot of visualization and ask queries to professors. Consequently, 77% students said that a combination of online and offline lectures may be used in the future with students being allowed to choose how they learn. Alternatively, only online lectures may be scheduled on some days of the week so that students need not travel to the campus on those days. ||| Most of the complex research problems can be formulated as optimization problems. Emergence of big data technologies have also commenced the generation of complex optimization problems with large size. The high computational cost of these problems has rendered the development of optimization algorithms with parallelization. Particle swarm optimization (PSO) algorithm is one of the most popular swarm intelligence-based algorithm, which is enriched with robustness, simplicity and global search capabilities. However, one of the major hindrance with PSO is its susceptibility of getting entrapped in local optima and; alike other evolutionary algorithms the performance of PSO gets deteriorated as soon as the dimension of the problem increases. Hence, several efforts are made to enhance its performance that includes the parallelization of PSO. The basic architecture of PSO inherits a natural parallelism, and receptiveness of fast processing machines has made this task pretty convenient. Therefore, parallelized PSO (PPSO) has emerged as a well-accepted algorithm by the research community. ||| The present study examined the effect of different processing techniques (sun- and tray-drying, and roasting) on fennel seeds and aimed to find the best method for incorporation of powder in the formulation of hard candy to deliver phytochemicals and bio-active compounds that it possesses, thus rendering health benefits. ||| Several transmission modes are defined in IEEE 802.11 a/b/g WLAN standards. A very few transmission modes are considering for IEEE 802.11 a/b/g in physical layer parameters and wireless channel characteristics. In this paper, we evaluated the performance of available transmission modes in IEEE 802.11b [1]. However, the performance analysis can be done straightforward using the evaluation of IEEE 802.11b. The performance of transmission modes are evaluated by calculating the probability of Bit Error Rate (BER) versus the Signal Noise Ratio (SNR) under the frequently used three wireless channel models (AWGN, Rayleigh and Rician) [2]. We consider the data modulation and data rate to analyze the performance that is BER vs. SNR. We also consider multipath received signals. The simulation results had shown the performance of transmission modes under different channel models and the number of antennas. Based on simulation results, we observed that some transmission modes are not efficient in IEEE 802.11b. The evaluation of performance confirms the increase in the coverage area of the physical layer in the 802.11b WLAN devices.","AWGN, linear classification, RTL Power Analysis, Classification, ASIC, MPI, Hard candy, GPU-based, random walk model, Emotiv, Forecasting, Microcontroller, Large-size complex optimization problems, content delivery, parallelization models, Sensory evaluation, Fennel seeds, Observability-based Sequential Analysis, physico-chemical and sensory properties, herbal candy, seasonal time series, Fennel-seed powder, 64-QAM, Modulation techniques, online lecture, Nakagami fading, Signal processing, GPU, Resets, FLANN, Sequential Analysis, Swarm intelligence-based algorithm, EEG signals, professor-student interaction, PPSO algorithms, online lectures, Rician, Rayleigh fading, Redundant Reset Identification, Brain Computer Interface, Optimization, COVID-19 pandemic, functional link artiﬁcial neural network, flexible learning, CPU-based, Routability, Parallel computing, Observability, pandemic, Small scale fading, Support Vector Machine, android application, Smartphone addiction, Ricean fading, Particle swarm optimization, Robot, education, forecasting accuracy, machine learning, large-scale data processing, Rayleigh, 16-QAM, DPSK, Neural Network, processing techniques, Power","The paper presents a brain computer interface system that uses EEG signals to navigate a robot. The system consists of several steps, including fetching and acquisition of brain signals, de-noising methods, extraction of valuable features and its classification, and subsequent classification of signals. ||| The paper presents the FLANN model, which is a single layer feed forward neural network that uses trigonometric expansion to overcome the issue of linearity. The model is evaluated using four real seasonal time series datasets and compared with random walk and ANN models. The results show that FLANN achieves lower forecasting errors than both random walk and ANN. ||| This study aims to use real time smartphone usage data to predict smartphone addiction using supervised machine learning. A purpose built android application has been developed to track real time smartphone usage patterns among multiple attributes such as duration of smartphone use and internet data used over the past 30 days. The applications installed in the smartphone are categorized into nine types namely Social Media, Communication, Entertainment, Productivity, News & Surfing, Gaming, Work, Photos & Camera, and Others. ||| The proposed algorithm was applied on six industrial designs from variety of applications: multi-media, video processing, storage devices and smart-phone. The results show a maximum of 70% reduction in load of reset network, 22% sequential power saving and 2% design area reduction. ||| This study investigated the opinion of undergraduate computer science students in an Indian university on different aspects of online lectures. The students were interviewed and asked, inter alia, whether they would like online lectures to be used even after the pandemic is over. ||| This paper presents a comprehensive and systematic survey of the studies on PPSO algorithms and variants along with their parallelization strategies and applications. The proposed work is a chronological literature review of the available PPSO versions, collected from various internet sources. The PPSO versions include individual variants, application-based, parallelization strategy based and number of problem objectives based variants. Initially, the text is classified at the basis of CPU and GPU implementation. ||| The study utilized Foeniculum vulgare in herbal candy preparation and analyzed its effect on physico-chemical and sensory properties. The results showed that sun-drying is the most effective technique for retaining nutrients in fennel seeds, and the best formulation deemed to be optimized with physico-chemical and sensory characteristics was DF11 (5% fennel-seed powder). ||| This paper evaluates the performance of transmission modes in IEEE 802.11b under various modulation schemes and wireless channel models. The performance is evaluated by calculating the probability of Bit Error Rate (BER) versus the Signal Noise Ratio (SNR) under AWGN, Rayleigh, and Rician channel models. The simulation results show that some transmission modes are not efficient in IEEE 802.11b, and the evaluation of performance confirms the increase in the coverage area of the physical layer in the 802.11b WLAN devices."
Usman Mohammed Joda,Towards Video Streaming in IoT Environments: Vehicular Communication Perspective,"Multimedia oriented Internet of Things (IoT) enables pervasive and real-time communication of video, audio and image data among devices in immediate surroundings. Today’s vehicles have the capability of supporting real time multimedia acquisition. Vehicles with high illuminating infrared cameras and customized sensors can communicate with other on-road devices using dedicated short-range communication (DSRC) and 5G enabled communication technologies. Real time incidence of both urban and highway vehicular traffic environment can be captured and transmitted using vehicle-to-vehicle and vehicle-to-infrastructure communication modes. Video streaming in vehicular IoT (VSV-IoT) environments is in growing stage with several challenges that need to be addressed ranging from limited resources in IoT devices, intermittent connection in vehicular networks, heterogeneous devices, dynamism and scalability in video encoding, bandwidth underutilization in video delivery, and attaining application-precise quality of service in video streaming. In this context, this paper presents a comprehensive review on video streaming in IoT environments focusing on vehicular communication perspective. Specifically, the significance of video streaming in vehicular IoT environments is highlighted focusing on the integration of vehicular communication with 5G enabled IoT technologies, and smart city oriented application areas for VSV-IoT. A taxonomy is presented for the classification of related literature on video streaming in vehicular network environments. Following the taxonomy, critical review of literature is performed focusing on major functional model, strengths and weaknesses. Metrics for video streaming in vehicular IoT environments are derived and comparatively analyzed in terms of their usage and evaluation capabilities. Open research challenges in VSV-IoT are identified as future directions of research in the area. The survey would benefit both IoT and vehicle industry practitioners and researchers, in terms of augmenting understanding of vehicular video streaming and its IoT related trends and issues.","Video streaming, Internet of vehicles, traffic safety, vehicular ad-hoc networks, Vehicular Communication, Intelligent transportation system, Internet of things, IoT","The paper discusses the significance of video streaming in vehicular IoT environments, presents a taxonomy for the classification of literature on video streaming over vehicular ad-hoc networks, derives performance metrics for video streaming in vehicular IoT environments, and identifies open research issues and challenges in vehicular video streaming under IoT environments."
V. Kreinovich,SISO Fuzzy Relational Inference Systems based on Fuzzy Implications are Universal Approximators,"This paper deals with fuzzy relational inference mechanisms as universal approximators. We consider the implicative form of the rule base, where the antecedents of the rules are related to their consequents using a fuzzy implication. We show that fuzzy relational inference mechanisms with singleton input can be used as universal approximators, and we provide a constructive proof of their approximation capability.","T-norms, Fuzzy sets, Fuzzy relational inference mechanisms, Fuzzy Relational Inference, Universal Approximation, Fuzzy Implications",This paper explores the use of fuzzy relational inference mechanisms as universal approximators. We focus on the implicative form of the rule base and show that fuzzy relational inference mechanisms with singleton input can be used to approximate any continuous function. We provide a constructive proof of their approximation capability and discuss the implications of our results.
V. Lakshmi Prasanna,Classiﬁcation of Mammalian and Non-Mammalian Keratin Protein Sequences Using Machine Learning Techniques,"Keratin protein is ubiquitous in most vertebrates and invertebrates, and has several important cellular and extracellular functions that are related to survival and protection. Keratin function has played a significant role in the natural selection of an organism. Hence, it acts as a marker of evolution. Much information about an organism and its evolution can therefore be obtained by investigating this important protein. In the present study, Keratin sequences were extracted from public data repositories and various important sequential, structural and physicochemical properties were computed and used for preparing the dataset. The dataset containing two classes, namely mammals (Class-1) and non-mammals (Class-0), was prepared, and rigorous classiﬁcation analysis was performed. To reduce the complexity of the dataset containing 56 parameters and to achieve improved accuracy, feature selection was done using the t-statistic. The 20 best features (parameters) were selected for further classiﬁcation analysis using computational algorithms which included SVM, KNN, Neural Network, Logistic regression, Meta-modeling, Tree Induction, Rule Induction, Discriminant analysis and Bayesian Modeling. Statistical methods were used to evaluate the output. Logistic regression was found to be the most effective algorithm for classiﬁcation, with greater than 96% accuracy using a 10-fold cross validation analysis. KNN, SVM and Rule Induction algorithms also were found to be efﬁcacious for classiﬁcation.","Data mining, Artiﬁcial Neural Networks (ANN), Meta-modeling, Machine learning techniques, Classiﬁcation, Artiﬁcial Intelligence (AI), Keratin, Logistic regression, Discriminant analysis, Mammalian and non-mammalian origin, Support Vector Machines (SVM), Tree induction, Biological classiﬁcation, Keratin protein sequences, Machine learning, Rule induction",This study aims to classify mammals and non-mammals based on various properties of the Keratin protein molecule. The dataset containing 56 parameters was prepared and feature selection was done using the t-statistic. The 20 best features were selected for further classiﬁcation analysis using computational algorithms. Logistic regression was found to be the most effective algorithm for classiﬁcation with greater than 96% accuracy.
V. Ravi,"Agriculture Extension System in India: A Meta-analysis ||| Detection of Financial Statement Fraud Using Data Mining Techniques ||| Digital Banking Dimensions and Analytics ||| ECM Based Imputation for Missing Data ||| Hybrid Architecture for Sentiment Classification ||| Machine Learning Techniques Applied to Profile Mobile Banking Users in India ||| Profiling of Internet Banking Users in India ||| Sentiment Analysis of Training Programmes ||| The Next Wave of CRM Innovation: Implications for Research, Teaching, and Practice","Agriculture extension system bridges the gap between research labs to a farmer’s field. Agricultural research, education and extension are said to be the most critical for promoting farm productivity and enhancing farmer’s income. The public sector is major extension service provider and the reach of the public extension is limited in India and in addition it is burdened with non-extension responsibilities such as the distribution of subsidies and inputs, with little time left to attend to core extension activities. ||| Recently, high profile cases of financial statement fraud have been dominating the news. This paper uses data mining techniques such as Multilayer Feed Forward Neural Network (MLFF), Support Vector Machines (SVM), Genetic Programming (GP), Group Method of Data Handling (GMDH), Logistic Regression (LR), and Probabilistic Neural Network (PNN) to identify companies that resort to financial statement fraud. Each of these techniques is tested on a dataset involving 202 Chinese companies and compared with and without feature selection. PNN outperformed all the techniques without feature selection, and GP and PNN outperformed others with feature selection and with marginally equal accuracies. ||| Of late, the financial services industry is fast moving away from the traditional paradigm to the sophisticated digital way of dealing and the customer. Both the facets of the financial service industry, viz., the financial service provider and the customer are going through a digital evolution. In particular, banking industry has evolved from just journal and ledger entry paradigm to data and analytics driven banking operations, which subsumes online as well as offline customer behavior. This paper discusses various scenarios in baking, finance services and insurance (BFSI) areas, where big data analytics is turning out to be paramount. The paper also highlights the potential benefits, of the new-age technologies viz., Internet of Things (IoT), Blockchain, Chatbots and robotics. ||| This paper presents a novel approach for imputing missing data using the Expectation-Maximization (ECM) algorithm. The proposed method is based on clustering the complete records and imputing the missing values by the corresponding values of the attribute in the center of the nearest cluster. ||| Evolution of plethora of e-commerce sites resulted in fierce competition among their providers. In order to acquire new and retain existing customers, various producers and market managers effectively employ online feedback analytics tools. Most of the online feedback analysis tools are built using sentiment analysis models. Sentiment analysis evolved in the last one and half decades for review mining process. An important sub-task of sentiment analysis called sentiment classification is used mainly to decide whether a written review is expressing either positive or negative sentiment towards a target entity. In order to have better sentiment classification accuracy, we proposed a hybrid deep learning architecture, which is a hybrid of a two layered Restricted Boltzmann Machine and a Probabilistic Neural Network. The proposed approach yielded better accuracy for five different datasets compared to the state-of-the-art. ||| This paper profiles mobile banking users using machine learning techniques viz. Decision Tree, Logistic Regression, Multilayer Perceptron, and SVM to test a research model with fourteen independent variables and a dependent variable (adoption). A survey was conducted and the results were analysed using these techniques. Using Decision Trees the profile of the mobile banking adopter’s profile was identified. Comparing different machine learning techniques it was found that Decision Trees outperformed the Logistic Regression and Multilayer Perceptron and SVM. Out of all the techniques, Decision Tree is recommended for profiling studies because apart from obtaining high accurate results, it also yields ‘if–then’ classification rules. The classification rules provided here can be used to target potential customers to adopt mobile banking by offering them appropriate incentives. ||| This paper presents a study on profiling of internet banking users in India. The study used a questionnaire with 58 related questions to collect data from 165 respondents. The data was preprocessed and split into training and test sets. Four predictive models were used to classify internet banking users: Classification and Regression Trees (CART), Logistic Regression, Support Vector Machines (SVM), and Neural Networks. The results showed that CART performed feature selection and identified the most important variables in customers' point of view. The study also presented 17 rules derived from the decision tree constructed with entropy method in CART. ||| Sentiment analysis found various applications in banking, financial, service, and insurance sector. In order to increase return on investment, services industry needs to improve customer satisfaction at any cost.  In this regard, we proposed to analyze customer reviews on the basis of sentiment score. We analyzed a set of credible text reviews collected on 270 training programmes posted by 2688 participants in an organization. In order to evaluate the efficacy of the proposed approach, we computed correlation coefficient between sentiment score obtained from the unstructured reviews and the overall numerical rating assigned by all participants. Further, we employed visualization techniques to visualize different aspects of the programmes. ||| Globalization and customers’ ever-changing needs have created a hyper-competitive market. As a result, customer relationship management (CRM) has become a core topic of interest among both practitioners and academics. Further, over the years, with the advancements in the technology landscape, such as digital technologies, CRM has improved in myriad ways. This paper summarizes a panel discussion on CRM innovations held at the 2016 Pacific Asia Conference on Information Systems (PACIS 2016) in Chiyai, Taiwan. The panel discussed CRM fundamentals and how traditional CRM systems work in organizations. Then, the panel focused on the advancement in technology landscape such as big data, analytics, Internet of things, and artificial intelligence and how such technologies have transformed innovations in the CRM landscape. Finally, the panel highlighted the limitations in the current CRM curricula in the universities and how the curriculum today needs to reflect such advancements to enhance the union between the CRM curricula and the industry needs. Further, this paper provides future research ideas for academia and contributes to research interests on CRM in general.","artificial intelligence, Restricted Boltzmann Machine, Evolving Clustering Method, Machine Learning, decision tree, Multilayer Perceptron, operational analytics, Deep learning, entropy method, sentiment classification, Visualization, intelligent techniques, Financial Services, CRM, Manpower, Data mining, Investment, PNN, SVM, Customer Relationship Management, financial statement fraud, Chat-bot, profiling, India, customers, Internet of Things, Agriculture extension, Customer Reviews, Mobile Banking User Profiles, risk analytics, Missing Data, Probabilistic neural network, t-statistic, Big Data Analytics, Big Data, customer adoption, fraud analytics, Farmers Producers' Organizations, GP, fraud detection, Insurance, Dimensionality reduction, Digital Banking, clustering, Online learning, RBM, participants' feedback, ECM, customer analytics, Meta analysis, Imputation, Hadoop, Training Programmes, Neural networks, Decision Tree, Artificial Intelligence, Internet banking, Feature selection, Extension approaches, Logistic Regression, CRM Curriculum, programme rating, Local Learning, Text Mining, Financial fraud detection, ICT, Sentiment analysis, IoT, Spark","The article reviews the agricultural extension system in India to suggest pathways for better extension system in India. The public extension services are highly skewed towards crop husbandry ignoring allied sectors in India. The growth in the High-Value Agriculture sector has been twice or sometimes even thrice that of the crop production. However, Agriculture extension services for such sectors almost nil or unorganized. ||| This paper uses data mining techniques to identify companies that resort to financial statement fraud. The techniques used include Multilayer Feed Forward Neural Network (MLFF), Support Vector Machines (SVM), Genetic Programming (GP), Group Method of Data Handling (GMDH), Logistic Regression (LR), and Probabilistic Neural Network (PNN). The results show that PNN outperformed all the techniques without feature selection, and GP and PNN outperformed others with feature selection and with marginally equal accuracies. ||| The paper explores the eight dimensions of a digital bank, including customer/sales/services, regulator/other banks, internal, technology, data, business process reengineering, analytics, and people. It also discusses the role of analytics in digital banking, including customer analytics, fraud analytics, risk analytics, operational analytics, security analytics, and HR analytics. ||| The paper discusses the problem of missing data in various disciplines and proposes an Evolving Clustering Method (ECM) based imputation method. The authors performed sensitivity analysis of the influence of threshold value (Dthr) on imputation results over 12 datasets and compared the performance of ECM with K-Means+MLP. ||| The proposed architecture is a hybrid of RBM and PNN, which performs dimensionality reduction and sentiment classification in an online learning process. The time complexity of the proposed architecture is O(I*B*n) + O(m), where I is the number of iterations, B is the batch size, and m is the number of samples. ||| This paper studies the various factors that affect the intention of users to adopt mobile banking. The major influential factors have been identified through literature, and a survey was conducted with two hundred respondents in the Indian context. The paper analyses the survey data through the use of machine learning techniques to arrive at the most important and critical success factors that influences the adoption of mobile. ||| This study presents a profiling of internet banking users in India using a questionnaire with 58 related questions. The data was preprocessed and split into training and test sets. Four predictive models were used to classify internet banking users. The results showed that CART performed feature selection and identified the most important variables in customers' point of view. ||| The paper proposes a sentiment analysis approach to analyze customer reviews on the basis of sentiment score. The approach is divided into five sections: data collection, text preprocessing, sentiment score computation, evaluation, and visualization. The paper presents the results of the proposed approach and discusses the future directions of work. ||| This paper discusses the next wave of CRM innovation and its implications for research, teaching, and practice. It summarizes a panel discussion on CRM innovations held at the 2016 Pacific Asia Conference on Information Systems (PACIS 2016) in Chiyai, Taiwan. The panel discussed CRM fundamentals, the advancement in technology landscape, and the limitations in the current CRM curricula. The paper provides future research ideas for academia and contributes to research interests on CRM in general."
V. S. S. Sastry,Liquid crystal films on curved surfaces: An entropic sampling study,"We report a Monte Carlo study of the phase transition in liquid crystals using the Wang-Landau algorithm. We compute the representative density of states of the film under consideration and make the system perform an energy-uniform random walk by biasing the walk against its own density of states. We then extract the canonical ensembles by simultaneously applying two biasing probabilities to the microstates, one according to the density of states and the other due to the assumed statistical distribution corresponding to the temperature under consideration. We adopt this procedure in reporting the following equilibrium properties of the film under different boundary conditions.","curved substrates, Monte Carlo simulation, Monte Carlo study, phase transition, liquid crystals, nematic thin film, Wang-Landau algorithm","We study the phase transition in liquid crystals using the Wang-Landau algorithm and report the equilibrium properties of the film under different boundary conditions. We find that the temperature at which the transition takes place is not the same as the temperature near which the uniaxial phase actually forms, and that the surface anchoring seems to be too strong for the elastic response of the nematic medium to force a uniaxial order above a certain threshold value."
V. Vetrivel,A Novel Fuzzy Rule Based Inference System for Contrast Enhancement,"In this work, we propose a fuzzy inference system based contrast enhancement of gray level images. We propose a new method of generating the fuzzy if-then rules specific to a given image based on the local information available to be used by a fuzzy inference system.","Fuzzy Partition, Histogram Equalisation, partial histogram, contrast enhancement, Fuzzy Inference Systems, fuzzy rule based inference system, Mamdani fuzzy inference system, Image Enhancement, Contrast Stretching, Histogram Matching, Gray level transformations",The paper proposes a fuzzy inference system based contrast enhancement of gray level images. It presents a new method of generating fuzzy if-then rules specific to a given image based on local information available. The method generates a partial histogram and saves on computational costs. The enhanced images from the proposed algorithm are comparable or even better than those obtained from histogram equalization.
VARSHIT BANSAL,DRIVER ASSISTANCE SYSTEM,"India is home to one of the most underpaid yet overworking drivers. Transporters expect them to work at least twenty or more hours per day continuously without any consideration to their health. This leads them to have bursts of micro sleep, a temporary episode of sleepiness which may last for a smidgen of a second or up to 30 seconds, where the victim fails to react to some stimulus from the environment and becomes unconscious. As a result of this, road accidents have become a common occurrence in India. One solution to this problem is to enhance the vehicles to an extent, so that it is possible to determine the drowsiness of the driver in real time. In this project, we propose a system to assist a driver through detecting drowsiness, distractions and stop signs. The system is easy to understand and the learning curve is minimal. The system is highly robust and can withstand minimal amount of wear and tear. The products assumes that the driver is not blind or deaf. This assumption does not affect the availability of product to mass customers since there are not many driver with visual impairment or hearing impairment. It also assumes that the driver does not drive with either of their eyes closed since driving is not a fun game, since the lives of other passengers is in the drivers hands.","Eye Aspect Ratio, fatigue detection, yawning detection, Region of Interest, drowsiness detection, Mouth Vertical Distance, driver assistance system","The paper proposes a system to assist a driver through detecting drowsiness, distractions and stop signs. The system is easy to understand and the learning curve is minimal. It is highly robust and can withstand minimal amount of wear and tear. The system assumes that the driver is not blind or deaf and does not drive with either of their eyes closed."
VERMA,Self-Optimal Clustering Technique Using Optimized Threshold Function,This paper presents a self-optimal clustering technique using optimized threshold function. The proposed method is an advanced version of the traditional IMC method and is similar to it until Step 8. The algorithm is repeated until the threshold function gets converged where the GSI value is maximized.,"global silhouette index, silhouette index, threshold function, improved mountain clustering (IMC), clustering, Expectation maximization algorithm, fuzzy cardinality, interpolation polynomial","The proposed clustering technique is equipped with major changes and modifications in its previous versions of algorithm. SOC is compared with some of the widely used clustering techniques such as K-means, fuzzy C-means, Expectation and Maximization, and K-medoid."
VIKAS YADAV,DRIVER ASSISTANCE SYSTEM,"India is home to one of the most underpaid yet overworking drivers. Transporters expect them to work at least twenty or more hours per day continuously without any consideration to their health. This leads them to have bursts of micro sleep, a temporary episode of sleepiness which may last for a smidgen of a second or up to 30 seconds, where the victim fails to react to some stimulus from the environment and becomes unconscious. As a result of this, road accidents have become a common occurrence in India. One solution to this problem is to enhance the vehicles to an extent, so that it is possible to determine the drowsiness of the driver in real time. In this project, we propose a system to assist a driver through detecting drowsiness, distractions and stop signs. The system is easy to understand and the learning curve is minimal. The system is highly robust and can withstand minimal amount of wear and tear. The products assumes that the driver is not blind or deaf. This assumption does not affect the availability of product to mass customers since there are not many driver with visual impairment or hearing impairment. It also assumes that the driver does not drive with either of their eyes closed since driving is not a fun game, since the lives of other passengers is in the drivers hands.","Eye Aspect Ratio, fatigue detection, yawning detection, Region of Interest, drowsiness detection, Mouth Vertical Distance, driver assistance system","The paper proposes a system to assist a driver through detecting drowsiness, distractions and stop signs. The system is easy to understand and the learning curve is minimal. It is highly robust and can withstand minimal amount of wear and tear. The system assumes that the driver is not blind or deaf and does not drive with either of their eyes closed."
Vadlamani Ravi,A Computational Intelligence Based Online Data Imputation Method: An Application For Banking ||| Classiﬁcation of Mammalian and Non-Mammalian Keratin Protein Sequences Using Machine Learning Techniques ||| Credit Card Fraud Detection using Big Data Analytics: Use of PSOAANN based One-Class Classification ||| Visual Sentiment Analysis of Customer Complaints using SOM,"All the imputation techniques proposed so far in literature for data imputation are offline techniques as they require a number of iterations to learn the characteristics of data during training and they also consume a lot of computational time. Hence, these techniques are not suitable for applications that require the imputation to be performed on demand and near real-time. The paper proposes a computational intelligence based architecture for online data imputation and extended versions of an existing offline data imputation method as well. ||| Keratin protein is ubiquitous in most vertebrates and invertebrates, and has several important cellular and extracellular functions that are related to survival and protection. Keratin function has played a significant role in the natural selection of an organism. Hence, it acts as a marker of evolution. Much information about an organism and its evolution can therefore be obtained by investigating this important protein. In the present study, Keratin sequences were extracted from public data repositories and various important sequential, structural and physicochemical properties were computed and used for preparing the dataset. The dataset containing two classes, namely mammals (Class-1) and non-mammals (Class-0), was prepared, and rigorous classiﬁcation analysis was performed. To reduce the complexity of the dataset containing 56 parameters and to achieve improved accuracy, feature selection was done using the t-statistic. The 20 best features (parameters) were selected for further classiﬁcation analysis using computational algorithms which included SVM, KNN, Neural Network, Logistic regression, Meta-modeling, Tree Induction, Rule Induction, Discriminant analysis and Bayesian Modeling. Statistical methods were used to evaluate the output. Logistic regression was found to be the most effective algorithm for classiﬁcation, with greater than 96% accuracy using a 10-fold cross validation analysis. KNN, SVM and Rule Induction algorithms also were found to be efﬁcacious for classiﬁcation. ||| This paper presents a hybrid model called PSOAANN, which combines the strengths of Auto-Associative Neural Network (AANN) and Particle Swarm Optimization (PSO). The proposed model is used for one-class classification, where the goal is to identify the minority class in a dataset. The PSOAANN model is trained on negative samples and learns the characteristics of the majority class. The model is then tested on positive samples, and the relative error is computed for each feature. If the relative error is greater than a threshold value, the sample is classified as belonging to the positive class. ||| With the widespread use of social media, companies now have access to a wealth of customer feedback data which has valuable applications to Customer Relationship Management (CRM). Analyzing customer grievances data, is paramount as their speedy non-redressal would lead to customer churn resulting in lower profitability. In this paper, we propose a descriptive analytics framework using Self-organizing feature map (SOM), for Visual Sentiment Analysis of customer complaints. The network learns the inherent grouping of the complaints automatically which can then be visualized too using various techniques. Analytical Customer Relationship Management (ACRM) executives can draw useful business insights from the maps and take timely remedial action. We also propose a high-performance version of the algorithm CUDASOM (CUDA based Self Organizing feature Map) implemented using NVIDIA parallel computing platform, CUDA, which speeds up the processing of high-dimensional text data and generates fast results. The efficacy of the proposed model has been demonstrated on the customer complaints data regarding the products and services of four leading Indian banks. CUDASOM achieved an average speed up of 44 times. Our approach can expand research into intelligent grievance redressal system to provide rapid solutions to the complaining customers.","Grievance Redressal, Visual Sentiment Analysis, K-Means clustering, Machine learning techniques, PSOAANN, GRNN, SOM, Machine learning, Data mining, computational intelligence, CUDA, AANN, Auto-encoder, Keratin, K-Medoids clustering, General Regression Neural Network (GRNN), Support Vector Machines (SVM), Biological classiﬁcation, MLP, Data Imputation, Keratin protein sequences, hybrid model, Classiﬁcation, Artiﬁcial Intelligence (AI), One-class classification, Logistic regression, Discriminant analysis, Mammalian and non-mammalian origin, Analytical CRM, Auto-associative neural network, Artiﬁcial Neural Networks (ANN), Imputation, Tree induction, Single class classification, Rule induction, Particle swarm optimization, Self-Organizing Map, Meta-modeling, Customer Complaints, Self-Organizing Maps, Evolving Clustering Method (ECM), banking, PSO, online data imputation","The proposed online imputation technique has 2 stages. In stage 1, Evolving Clustering Method (ECM) is used to replace the missing values with cluster centers, as part of the local learning strategy. Stage 2 refines the resultant approximate values using a General Regression Neural Network (GRNN) as part of the global approximation strategy. ||| This study aims to classify mammals and non-mammals based on various properties of the Keratin protein molecule. The dataset containing 56 parameters was prepared and feature selection was done using the t-statistic. The 20 best features were selected for further classiﬁcation analysis using computational algorithms. Logistic regression was found to be the most effective algorithm for classiﬁcation with greater than 96% accuracy. ||| This paper presents a study on credit card fraud detection using one-class classification approach in big data paradigm. The proposed methodology involves a hybrid architecture of Particle Swarm Optimization and Auto-Associative Neural Network for one-class classification in Spark computational framework. The results show that the proposed approach is effective in detecting credit card fraud. ||| This paper proposes a descriptive analytics framework using Self-organizing feature map (SOM) for Visual Sentiment Analysis of customer complaints. The framework learns the inherent grouping of complaints automatically and can be visualized using various techniques. A high-performance version of the algorithm CUDASOM is also proposed, which speeds up the processing of high-dimensional text data and generates fast results."
Vaibhav Mittal,Proposed Framework for Modeling Course Structure in a Personalized E-Learning System,"A proposal scheme to personalize students’ learning based on her learning aim in an e-learning environment. The system acknowledges a distinct set of students' aims that prioritize various Learning Objects (LOs) such as theory, case studies etc. according to student's Learning Aim (LA).","Learning Objects, Learning Aims, Course structure, Concept Perspectives, Priority tables, Personalized E-learning, Directed Acyclic Graph, Ant Colony Optimization",This paper proposes a framework that emphasizes the significance of user's LA while selecting the LOs as well as adding to the kitty of perspectives for grasping a concept. The system generates an initially optimized path taking into account the priorities of learning objects and the contribution of concept perspectives for different learning aims.
Vaishali Soni,Security vs. Flexibility : Striking a Balance in the Pandemic Era,"An organization’s reputation is largely dependent on the work culture it provides to its employees. This is the reason, “flexibility” is becoming an inherent part of an employer’s support to its employees. Due to the unprecedented outbreak of novel corona virus (COVID-19), most companies have adopted flexibility of working from anywhere, for their employees. This digital transformation took place almost instantaneously. Hence, neither the employees, nor the employers were fully prepared for this situation. This definitely makes our lives convenient. But there exists another side of the coin which is concerned with the security issues pertaining to use of personal networks and devices. The home network devices have not been configured to be secure in line with the employer’s requirements. That is the reason, attackers have a larger surface to get their hands dirty on. This paper exhaustively describes the holistic view of security issues and challenges faced by employees as well as employers in remote working paradigm. This paper emphasizes on the cybersecurity threats which have emerged in this pandemic era. The work presents the challenges faced by the employees as well as their employers in these tough times. Then this paper discusses the sudden rise in volumes of cyber-attacks between January 2020 to March 2020. The company’s evaluation of critical threats in the on-site working paradigm versus the remote working paradigm have also been described. Next, it describes the risks which might occur in the near future of the COVID-19 impacted world. Finally, the paper proposes some of the ways in which employers can strike an efficient balance between flexibility for employees and security of their assets.","COVID-19, cyber attacks, remote working, flexibility, cybersecurity, pandemic, attacks, threats","The COVID-19 pandemic has led to a significant increase in cyber attacks, with various types of attacks including Corona Virus themed MalSpam Emails, Spam Emails, Malware inside Interactive Map, VPN Exploitation, Credential Stuffing, Misconfiguration of Cloud Services, Vishing (or phishing) Attacks, Ransomware Attack, and Data Theft By Employees. Organizations need to work toward inculcating a strong security technological infrastructure to deal with the frequently changing cyber-attacks landscape."
Valentina E. Balas,Advances in Intelligent Systems and Computing 757,"The series “Advances in Intelligent Systems and Computing” contains publications on theory, applications, and design methods of Intelligent Systems and Intelligent Computing.","learning paradigms, soft computing, knowledge management, intelligent agents, fuzzy systems, robotics and mechatronics, interactive entertainment, computational intelligence, neural networks, recommender systems, Conference Proceedings, human-centered and human-centric computing, trust management, Mechanical Engineering, ambient intelligence, evolutionary computing, DNA and immune based systems, intelligent control, virtual worlds and society, human-machine teaming, self-organizing and adaptive systems, computational neuroscience, knowledge-based paradigms, artiﬁcial life, Perception and Vision, intelligent data analysis, e-Learning and teaching, social intelligence, cognitive science and systems, Web intelligence and multimedia, intelligent decision making and support, intelligent network security, machine ethics","This volume constitutes a part of the proceedings of ﬁrst International Conference on Innovations in Infrastructure (ICIIF) 2018, which was held on 18–19 May, 2018, in Ahmedabad, India."
Vasanth Iyer,Distributed Source Coding for Sensor Data Model ||| Training Data Compression Algorithms and Reliability in Large Wireless Sensor Networks,"We measure reliability in sensor networks which are dependent on limited resources of individual sensor nodes such has battery capacity, transmission range and channel interference due to simultaneous wireless transmissions. ||| With the availability of low-cost sensor nodes there have been many standards developed to integrate and network these nodes to form a reliable network allowing many different types of hardware vendors to coexist.","Sensor Data Reliability, Probability Model, cluster head selection, BER, Slepian & Wolf Coding, Baysian Error, Data Compression, Sensor Network, sensor data model, Slepian-Wolf theorem, Wireless Sensor Networks, Cosets, distributed source coding, Reliability, Huffman Trees","The paper presents a distributed source coding approach for sensor data model, which includes Slepian-Wolf theorem, compression rate, fault rate, and cluster head selection schemes. The approach is designed to reduce the number of bits needed for transmission in sensor networks. ||| This paper proposes a data compression algorithm for large wireless sensor networks, which optimizes data redundancy and uses a probability model to efficiently compress data at cluster heads."
Vasanthakumar Namasivayam,"Seroprevalence of SARS-CoV-2 Antibodies in Uttar Pradesh, India: A Cross-Sectional Study","Population-based serological antibody test for SARS-CoV-2 infection helps in estimating the exposure in the community. We present the findings of the first district representative seroepidemiological survey conducted between 4 and 10 September 2020 among the population aged 5 years and above in the state of Uttar Pradesh, India. Multi-stage cluster sampling was used to select participants from 495 primary sampling units (villages in rural areas and wards in urban areas) across 11 selected districts to provide district-level seroprevalence disaggregated by place of residence (rural/urban), age (5–17 years/aged 18 +) and gender. A venous blood sample was collected to determine seroprevalence. Of 16,012 individuals enrolled in the study, 22.2% [95% CI 21.5–22.9] equating to about 10.4 million population in 11 districts were already exposed to SARS-CoV-2 infection by mid-September 2020. The overall seroprevalence was significantly higher in urban areas (30.6%, 95% CI 29.4–31.7) compared to rural areas (14.7%, 95% CI 13.9–15.6), and among aged 18 + years (23.2%, 95% CI 22.4–24.0) compared to aged 5–17 years (18.4%, 95% CI 17.0–19.9). No differences were observed by gender. Individuals exposed to a COVID confirmed case or residing in a COVID containment zone had higher seroprevalence (34.5% and 26.0%, respectively). There was also a wide variation (10.7–33.0%) in seropositivity across 11 districts indicating that population exposed to COVID was not uniform at the time of the study. Since about 78% of the population (36.5 million) in these districts were still susceptible to infection, public health measures remain essential to reduce further spread.","COVID-19, Seroprevalence, India, SARS-CoV-2, Heterogeneity, Uttar Pradesh","This study presents the first district-level seroprevalence survey of SARS-CoV-2 infection in Uttar Pradesh, India. Conducted in September 2020, the survey found that 22.2% of the population had been exposed to the virus by that time. Seroprevalence was significantly higher in urban areas and among individuals aged 18 and older. The findings highlight the importance of continued public health measures to reduce further spread of the virus."
Vasu Saluja,"L,M&A: An Algorithm for Music Lyrics Mining and Sentiment Analysis","Here we propose an open source algorithm, L,M&A(Lyrics, Mine and Analyse) to create a dataset of lyrics of the works of various artists. The aim of this approach is to facilitate the generation of a large data set that can be used for improving accuracy of song recommendation algorithms.","Music Recommendation, Natural Language Processing, algorithm, musicology, Sentiment Analysis, musixmatch, Data Mining, Genius, Lyrics Database, music lyrics mining, Rstudio, genius API","This paper proposes an algorithm to mine lyric data for various artists which can be further utilized to generate a sentiment for individual artists. The employed model is an independent function that requires an artist’s name as primary input and through open-source APIs gathers the required data regarding that artist’s work and then employs our algorithm, L,M&A(Lyrics, Mine and Analyse) to generate a sentiment (based on the different categories of sentiment present in the lexicons used) for that particular artist and is also able to quantitate that sentiment."
Venkata Dilip Kumar,3D FE MODELLING OF BURIED CONTINUOUS PIPELINE EXPOSED TO FAULT MOTION WITH MATERIAL NONLINEARITY AND LARGE DEFORMATION ||| Advances in Intelligent Systems and Computing 757 ||| A Study on Vision Based Method for Damage Detection in Structures ||| Comparison of Different Types of Pylon in Cable-Stayed Bridges ||| Investigation of Crack Properties Using Image Processing: An User Interface,"Pipeline generally extends over long distances traversing through wide variety of different soils, geological conditions and regions with different seismicity. Majority of the past works in the area of pipeline subjected to fault motion is restricted in several ways. There were many analytical models developed in the past for pipeline fault crossing, however, they are of limited usage, for example analytical model developed for pipeline fault crossing can be useful for strike slip fault crossing only. Likewise incorporating the large geometric changes in analytical study is a tricky task; however pipeline subjected to the fault motion itself is a phenomenon of large geometric changes. Especially when pipeline subjected to compression, where in addition to material deformation it also undergoes general as well as local buckling with bending, contradictorily past work mostly assumed that pipeline is under tension. With day by day increasing capacity of computation and advancement in numerical modeling, one can find more facts for pipeline subjected fault motions including cases of pipe under compression as well. In this paper, past work is reviewed for pipeline subjected to large fault motion. A three dimensional FE based numerical model is suggested to carry out pipeline performance of buried pipeline subjected to fault motion. A proposed model includes material nonlinearity, as well as effect of the large geometric changes. For this purpose, three dimensional FE program is developed in MATLAB. Displacement controlled Arc-length technique is implemented to solve the nonlinear behavior. To reduce the computation time of analysis here parallelization tool kit of MATLAB is utilized. ||| The series “Advances in Intelligent Systems and Computing” contains publications on theory, applications, and design methods of Intelligent Systems and Intelligent Computing. ||| To ensure the safety and the usefulness of civil structures, it is fundamental to visually inspect and survey its physical and functional condition. Current techniques in condition and safety assessment of large concrete structures are performed physically promoting to subjective and unreliable outcomes, costly and time-consuming data collection, and safety issues. This paper presents a study on less time consuming and less expensive alternative to the present methods of preliminary assessment for the detection of damages in structures. Henceforth, the focus is set on various vision-based methods for different parameters like cracks, corrosion and spalling which cause damage and deterioration of structures. Thus, a study is made on the current achievements and drawbacks of existing methods as well as open research difficulties are outlined to help both the structural engineers and the computer science researchers in setting a motivation for future research. ||| This study discusses the key design considerations for cable-stayed bridges under gravity loads and earthquake loads. A numerical model of a cable-stayed bridge is formulated for single plane of cables with global coordinates for bridges having different pylon shapes. ||| This research work focuses on processing the images of concrete walls to identify cracks with the help of a Graphic User Interface (GUI) created using MATLAB Guide. The developed GUI gives the length, width and type of the crack as outputs to an input image of a concrete wall. It uses image processing techniques to arrive at the output.","learning paradigms, soft computing, Vision based methods, knowledge management, Buried continuous pipeline, Damage detection, intelligent agents, fuzzy systems, Crack detection GUI, robotics and mechatronics, interactive entertainment, computational intelligence, Displacement controlled Arc-length technique, neural networks, recommender systems, material nonlinearity, human-centered and human-centric computing, trust management, Conference Proceedings, Mechanical Engineering, Quincy Bay view bridge, Time history analysis, cable-stayed bridges, crack detection, ambient intelligence, Length and width of the crack, evolutionary computing, DNA and immune based systems, Structural health assessment, Cracks on concrete walls, numerical model, virtual worlds and society, intelligent control, human-machine teaming, Pylon shape, self-organizing and adaptive systems, Cable-stayed bridge, Fault motion, computational neuroscience, earthquake loads, large deformation, knowledge-based paradigms, Computer based techniques, GUI, Image processing, pipeline performance, finite element method, artiﬁcial life, Perception and Vision, intelligent data analysis, e-Learning and teaching, Convolutional Neural Networks, gravity loads, social intelligence, cognitive science and systems, Cracks, Nonlinear-large deformation FEM, Web intelligence and multimedia, intelligent decision making and support, intelligent network security, machine ethics","This paper presents a three-dimensional finite element model for buried continuous pipelines exposed to fault motion with material nonlinearity and large deformation. The model is developed using isoparametric brick elements and is validated by comparing the load-deflection curve with the results obtained from the commercially available finite element package ANSYS-12. The performance of the pipeline is evaluated for various fault offset, pipeline-fault crossing angle, wall thickness to diameter ratio, and depth of the buried pipeline. ||| This volume constitutes a part of the proceedings of ﬁrst International Conference on Innovations in Infrastructure (ICIIF) 2018, which was held on 18–19 May, 2018, in Ahmedabad, India. ||| This paper presents a study on vision-based methods for damage detection in structures. The focus is on various parameters like cracks, corrosion, and spalling that cause damage and deterioration of structures. The paper outlines the current achievements and drawbacks of existing methods and identifies open research difficulties to motivate future research. ||| The study focuses on the design considerations for cable-stayed bridges under various loads and presents a numerical model for single plane of cables with global coordinates for bridges with different pylon shapes. ||| The paper proposes a technique to identify cracks in concrete walls using image processing and a Graphic User Interface (GUI). The GUI is developed using MATLAB Guide and gives the length, width and type of the crack as outputs to an input image of a concrete wall. The accuracy of the technique is 92.947% for length and 78.09% for width."
Venkata Dilip Kumar Pasupuleti,Health Assessment and Modal Analysis of Historical Masonry Arch Bridge ||| Impact on structural behavior due to installation of billboard ||| Lateral Response Reduction of Tall Buildings Using Portal Frame as TMD ||| Structural Dynamics Virtual Laboratory: A Learning Tool Kit for Young Engineers and Practicing Professionals,"Masonry arch bridges in India indicate the heritage value of the nation. Most of these bridges had been in service for hundreds of years and yet being serviceable even today for transportation purposes indicates the robustness of the design and construction methodology. But, some of these bridges are abandoned due to its deterioration and absence of knowledge to retroﬁt these structures. Lack of proper maintenance and retroﬁtting could eventually damage the structural integrity as these structures are old enough to deteriorate and are prone to repeated weathering and unforeseen natural calamities such as earth-quakes, ﬂoods, etc. In this study, a very old masonry arch bridge ‘Puranapul’ bridge inaugurated in the year 1578 across the river Musi in Hyderabad is considered for investigation of its health through basic visual inspection and non-destructive testing. Furthermore, the same is numerically modeled using the available ﬁnite element analysis software ANSYS in three dimensions for assessing the basic mode shapes of the structure and its behavior in different loading conditions. ||| Installation of billboards on various structures adjacent to busy roads has become common practice as they provide high economic to the local municipal corporation or private business organisations. Till recent, design of billboards and its installation on a structure was of less importance, but recent large wind cyclones had led to the collapse of billboards and structural cracks. This incident has raised doubts in structural engineering community for the resistance of buildings with billboards during earthquakes. ||| Majority of construction industries are aiming to go for taller and lighter buildings which may result in flexible and slender structures. Hence serviceability and safety become a critical issue during the occurrence of heavy winds and high magnitude earthquakes. Therefore, considerable techniques are adopted to minimize the vibrations caused by these natural responses of the structures. One of the techniques used prominently for tall structures is Tuned Mass Damper (TMD). TMD’s have been very effective in controlling structural vibrations. This study proposes a detailed analysis of a 2D frame structure with a TMD system placed at different levels of the structure in order to evaluate the behaviour of structure for given earthquake ground motions. The results obtained indicate installation of simple frames can decrease the response of the structure during an earthquake and location of TMD is also discussed in detail. ||| India has been facing earthquake problems from many centuries which need no introduction. From recent earthquakes, it is very well understood that lack of awareness is one of the major factor for huge casualty losses. While still having the probability of occurrences of earthquakes in India, it becomes very important and need to increase the awareness about the effects of earthquakes among growing  professionals involved in construction by making them understanding the concepts of Structural Dynamics and Earthquake Engineering.","damping, Virtual Lab, Heritage structure, Dynamic Analysis, Nondestructive testing, Tall Buildings, Structural Dynamics, User Interface, modal analysis, structural response, dynamic analysis, Lateral Response, Interactive, vibration control, Building with billboard, TMD, tuned mass damper, structural behavior, time period, Masonry arch bridge, Health assessment, time history analysis, finite element method, Finite element model, seismic behavior, Virtual Laboratory, Visual inspection","The paper presents a numerical modeling approach for understanding the behavior of a historical masonry arch bridge. The bridge is analyzed using finite element method and the results are presented in terms of deformations, strains, and stresses. The modal analysis is performed to understand the behavior and characteristics of the bridge under dynamic loads. The dynamic analysis is carried out to simulate the seismic behavior of the bridge and the results show that the bridge is quite adequate for lateral loads. ||| This study aims to understand the change in behavior of existing structure after installation of billboard. The study considers a G+2 structure with billboard located at Raidurg, Hyderabad and carries out dynamic analysis for three different ground motions to understand the change in its behavior with and without billboard. ||| The study presents a numerical modeling and analysis of a 15-storey structure with a TMD installed on the top. The TMD is designed to be tuned to the same natural frequency of the building and is installed on different floors of the building. The study investigates the effectiveness of the TMD in reducing the dynamic response of the building under various excitations. ||| This paper will detail the use of virtual laboratory in real time environment of structural dynamics. Virtual Laboratory provides a new methodology to convey and learn concepts using the power of visualization of ideas and computations. Virtual labs rely on an active engagement of the learner in the knowledge acquisition process."
Venkata Rajesh Kumar Tavva,Formal Ontology of Punctuators ||| Lecture Notes in Artificial Intelligence 6465,"This paper presents a formal ontology of punctuators, which are used to define the relationships between entities. The ontology is based on three basic punctuators: self-linking, inseparable, and separable. The paper also introduces the concept of abstract of punctuator, which maps the relational context of a punctuator to two abstract entities. ||| This work is subject to copyright. All rights are reserved, whether the whole or part of the material is concerned, specifically the rights of translation, reprinting, re-use of illustrations, recitation, broadcasting, reproduction on microfilms or in any other way, and storage in data banks. Duplication of this publication or parts thereof is permitted only under the provisions of the German Copyright Law of September 9, 1965, in its current version, and permission for use must always be obtained from Springer. Violations are liable to prosecution under the German Copyright Law.","Generative Ontology, Vaiśesika, Punctuator, Entities, Sanskrit, Formal Ontology, Relationships, Artificial Intelligence, Punctuators, Graph Grammar, Computational Linguistics, Generative Grammar","The paper presents a formal ontology of punctuators, which are used to define the relationships between entities. The ontology is based on three basic punctuators: self-linking, inseparable, and separable. The paper also introduces the concept of abstract of punctuator, which maps the relational context of a punctuator to two abstract entities. ||| The 4th International Sanskrit Computational Linguistics Symposium (4i-SCLS) was hosted by the Jawaharlal Nehru University, the premier research University of India during (December 10–12, 2010) at the Special Center for Sanskrit Studies. The event saw excellent response from the scholars, with more than 31 papers received, which were examined by the Program Committee members to shortlist 18 papers for publication presented in this volume."
Venkata Sai Madhu Dinesh Vitakula,Health Assessment and Modal Analysis of Historical Masonry Arch Bridge,"Masonry arch bridges in India indicate the heritage value of the nation. Most of these bridges had been in service for hundreds of years and yet being serviceable even today for transportation purposes indicates the robustness of the design and construction methodology. But, some of these bridges are abandoned due to its deterioration and absence of knowledge to retroﬁt these structures. Lack of proper maintenance and retroﬁtting could eventually damage the structural integrity as these structures are old enough to deteriorate and are prone to repeated weathering and unforeseen natural calamities such as earth-quakes, ﬂoods, etc. In this study, a very old masonry arch bridge ‘Puranapul’ bridge inaugurated in the year 1578 across the river Musi in Hyderabad is considered for investigation of its health through basic visual inspection and non-destructive testing. Furthermore, the same is numerically modeled using the available ﬁnite element analysis software ANSYS in three dimensions for assessing the basic mode shapes of the structure and its behavior in different loading conditions.","modal analysis, Masonry arch bridge, Health assessment, finite element method, dynamic analysis, Heritage structure, Nondestructive testing, Finite element model, seismic behavior, Visual inspection","The paper presents a numerical modeling approach for understanding the behavior of a historical masonry arch bridge. The bridge is analyzed using finite element method and the results are presented in terms of deformations, strains, and stresses. The modal analysis is performed to understand the behavior and characteristics of the bridge under dynamic loads. The dynamic analysis is carried out to simulate the seismic behavior of the bridge and the results show that the bridge is quite adequate for lateral loads."
Venkata Suresh Vulusala G,SMES application in electrical power and energy systems,"This paper discusses the application of Superconducting Magnetic Energy Storage (SMES) in electrical power and energy systems. SMES is used to enhance the frequency regulation, power delivery, and power quality in microgrid systems. The paper presents the results of a study on the implementation of SMES in a microgrid system with a 1.6 MJ SMES and a 3-MVA wind farm. The results show that SMES can effectively reduce the total harmonic distortion (THD) in the system and maintain a constant DC link voltage during sudden changes in factory load.","plug-in hybrid electrical vehicles, power quality, SMES, microgrids, power delivery, frequency regulation, microgrid, superconducting magnetic energy storage","The paper discusses the application of SMES in electrical power and energy systems, particularly in microgrid systems. SMES is used to enhance the frequency regulation, power delivery, and power quality in these systems. The results of a study on the implementation of SMES in a microgrid system are presented, showing the effectiveness of SMES in reducing THD and maintaining a constant DC link voltage during sudden changes in factory load."
Venkatanareshbabu K.,Advances in Machine Learning and Data Science—Recent Achievements and Research Directives,ooperation to publish the proceedings as a volume of “Advances in Machine Learning and Data Science—Recent Achievements and Research Directives.” We wish to extend our gratitude to all the keynote speakers and participants who enabled the success of this year’s edition of LAMDA.,"Data Science, Research Directives, Recent Achievements, Machine Learning","The proceedings of LAMDA 2017, a conference on machine learning and data science, are published as a volume of Advances in Machine Learning and Data Science—Recent Achievements and Research Directives. The editors extend their gratitude to the keynote speakers and participants who made the conference a success."
Venkatanareshbabu Kuppili,Automatic disease diagnosis using optimised weightless neural networks for low-power wearable devices,"Low-power wearable devices for disease diagnosis are used at anytime and anywhere. These are non-invasive and pain-free for the better quality of life. However, these devices are resource constrained in terms of memory and processing capability. Memory constraint allows these devices to store a limited number of patterns and processing constraint provides delayed response. It is a challenging task to design a robust classiﬁcation system under above constraints with high accuracy. In this Letter, to resolve this problem, a novel architecture for weightless neural networks (WNNs) has been proposed. It uses variable sized random access memories to optimise the memory usage and a modiﬁed binary TRIE data structure for reducing the test time. In addition, a bio-inspired-based genetic algorithm has been employed to improve the accuracy. The proposed architecture is experimented on various disease datasets using its software and hardware realisations. The experimental results prove that the proposed architecture achieves better performance in terms of accuracy, memory saving and test time as compared to standard WNNs. It also outperforms in terms of accuracy as compared to conventional neural network-based classiﬁers.","low-power wearable devices, binary TRIE data structure, TRIE data structure, genetic algorithm, neuron memory search, weightless neural networks, VG-RAM, VVG-RAM, disease diagnosis, modified TRIE data structure","A novel architecture for weightless neural networks (WNNs) is proposed to improve the classiﬁcation accuracy, reduce the memory usage, and decrease the test time for low-power wearable devices. The proposed architecture uses variable sized random access memories and a modiﬁed binary TRIE data structure. A bio-inspired-based genetic algorithm is employed to improve the accuracy. The experimental results show that the proposed architecture outperforms the standard WNNs and conventional neural network-based classiﬁers in terms of accuracy, memory saving, and test time."
Venkatesh Gunda,Blockchain as the Backbone of Retail Supply Chain Management,"Developing a Software for handling the production of goods in the end-to-end tracking of a Product Lifecycle in FMCG Retail companies from the point of raw material procurement to the point of purchase by the consumer which is the final aim. This system is built on the blockchain technology which provides transparency, efficiency and uncorrupted data to the companies and the customers if the companies choose to reveal the information of the product lifecycle. It is based on the Ethereum blockchain. Ethereum uses the concept of Proof-of-State for reduced computational power and increased speed compared to the traditional Proof-of-Work. In this project, the blockchain is run privately (the other alternative is public blockchain where information is open and available globally which has a higher level of security but also needs higher computing power) because most of the companies prefer using their own infrastructure for running the day-to-day operations. This project gives a detailed explain on the architecture of the application, the development and the backend technology etc.","IPFS, Supply Chain Management, India, Merkle Tree, Blockchain, Ethereum, FMCG","The project aims to develop a software for end-to-end tracking of product lifecycle in FMCG retail companies using blockchain technology. The system is built on Ethereum blockchain and provides transparency, efficiency, and uncorrupted data to companies and customers. The project gives a detailed explanation of the architecture, development, and backend technology."
Vibhu Sehra,Early Detection of Alzheimer’s Disease using Deep Learning Models and Word Embeddings,"Alzheimer’s Disease (AD) is an irrecoverable, progressive neurodegenerative disorder that deteriorates the cognitive and linguistic abilities of a person over time. Ample research has been done on the early detection of AD; it remains a challenging task. Doctors use the patient’s history, laboratory tests, and change in behaviour to diagnose the disease. Natural Language Processing(NLP) techniques can help automate the detection of AD, as Language impairments accompany this disease. This work aims to analyze the effect of different Embedding models on the DementiaBank dataset in order to detect the disease.","Natural Language Processing, Deep Learning, Alzheimer’s Disease, early detection, Cookie theft Description task, Word Embeddings","This paper explores the effect of different embedding algorithms and neural architectures on early detection of Alzheimer’s Disease using the DementiaBank dataset. The study uses both generic and domain-specific Word Embeddings on three deep learning models - CNN, Bidirectional LSTM(BLSTM), and CNN+BLSTM. Results indicate that domain-specific Word Embeddings tend to work better for a specific picture description task like cookie theft description. The study also discusses how results are affected by the use of different Embedding models (Fasttext, Word2Vec, GloVe)."
Vidhi Khanduja,"A Fragile Watermarking Scheme for Decision Systems ||| A Robust Watermarking Approach for Non Numeric Relational Database ||| A Robust Watermarking Technique for Ownership Proof and Information Recovery in Relational Databases ||| A Scheme for Robust Biometric Watermarking in Web Databases for Ownership Proof with Identification ||| Database Watermarking Research ||| Digital Watermarking for Relational Databases ||| Dynamic Watermark Injection in NoSQL Databases ||| Multifunctional HUD with Drowsy Detection and Fog Elimination Mechanism ||| Ownership and Tamper Detection of Relational Data: Framework, Techniques and Security Analysis ||| Ownership and Tamper Detection of Relational Data_ Framework, Techniques and Security Analysis ||| Secure Robust and Imperceptible Algorithm for Watermarking Relational Databases ||| Watermarking Categorical Data: Algorithm and Robustness Analysis ||| Watermarking Categorical Data_ Algorithm and Robustness Analysis. ||| WATERMARKING RELATIONAL DATABASES USING OPTIMIZATION BASED TECHNIQUES","The wheels of modern society are driven by multitudes of databases that serve as repositories of valuable information. Several applications can fruitfully learn from special repositories called Decision Systems.DS are databases that contain records of objects described by condition attributes and labeled by decision attributes that categorize them into distinct classes. Rough Set Theory can be applied to derive high quality classification rules from them to predict accurate decisions on freshly gathered data. For security, it is necessary to protect this core information from vulnerabilities in the Internet. No prior work is done on watermarked protection of Decision Systems. To fulfill this gap, we propose a new fragile and blind watermarking scheme for tamper detection in Decision Systems which detects even the slightest integrity losses that may damage the classificatory information encapsulated within a Decision System. ||| This paper proposes a novel robust method for watermarking non-numeric attributes in databases. The approach embeds a vowel in the attributes depending upon the key value generated. Experimental results show that the method maintains integrity of the database even under various attacks. ||| Digital databases serve as the vehicles for compiling, disseminating and utilizing all forms of information that are pivotal for societal development. A major challenge that needs to be tackled is to recover crucial information that may be lost due to malicious attacks on database integrity. In the domain of digital watermarking, past research has focused on robust watermarking for establishing database ownership and fragile watermarking for tamper detection. In this paper, we propose a new technique for multiple watermarking of relational databases that provides a unified solution to two major security concerns; ownership identification and information recovery. ||| We propose a robust technique for watermarking relational databases using voice as a biometric identifier of ownership. The choice of voice as the distinguishing factor is influenced by its uniqueness, stability, universality and ease of use. The watermark is generated by creating a statistical model of the features extracted from the owner’s voice. This biometric watermark is then securely embedded into selected positions of the fractional parts of selected numeric attributes using a reversible bit encoding technique. In case of a dispute regarding true ownership, the relative scores of the extracted watermark are generated by comparing features of the disputed voices with the extracted one. ||| Digital Databases dynamically generates a major proportion of the internet content. The databases are created, stored and accessed digitally and transmitted through computer networks. This has grown the potential, sizes and performance of databases in exponential magnitudes. Thus, the need to protect digital databases arises due to the increased vulnerability to copyright and piracy threats originating from the Internet. Both legal and technological measures must be utilized in a synergetic manner to ensure an adequate level of protection. TPMs backed by legal anti-circumvention measures offer a cost-effective solution to database protection. We provide the current state-of-art and analyses of the arena of digital database protection from a combined legal and technical perspective. Our work is more focused on security analysis of the work done so far and providing readers with detailed discussion on the future directions in the domain of digital watermarking of databases. ||| Proving ownership rights on outsourced relational databases is a crucial issue in today's internet-based application environments and in many content distribution applications. In this dissertation, a mechanism is presented for proof of ownership and ownership identification based on the secure embedding of a robust imperceptible watermark in relational data. ||| With the advent of gathering real time information, the need of Not Only SQL (NoSQL) databases has skyrocketed. No prior work is done on watermarked protection of such Schema-less databases. Traditional watermarking techniques cannot be applied as NoSQL databases are dynamically increasing and often have irregularities in schema. In this paper, a new perspective of embedding watermark into such databases is proposed. Watermark that acts as a signature is securely prepared for each tuple individually. The proposal deals with the issues by leveraging the flexible schema features provided by NoSQL database. A new attribute is dynamically injected into the tuple before inserting or updating it in database. Experimental results and analyses demonstrate that with even the slightest modification of up to 5% alteration in tuples, the watermark recreated from the suspected database changes by as much as 20%, thus facilitating immediate detection with localization up to tuple level in the database. ||| People are conscious of the risk of drinking and driving but don't realize the danger of drowsiness. Prior state of art reveals very little work on designing the automated system that measures the driver drowsiness. Our research lodge a system for the drivers and travelers who drive various means of transportation and alerts them when a driver is in a drowsy state. We have amalgamated the HUD (Head-up Display) facilities, drowsy detection system, and fog elimination system altogether to help the driver reach the destination safely by providing navigation, visual indication and many useful applications of mobile phones on HUD. Experimental results reveal that our proposed system is superior to existing HUDs and provide more features for the benefit of drivers. ||| Databases play a pivotal role in all domains of technology, encompassing data mining, medical records, stock market data, e-commerce etc. With this elevated need for databases and their wide distribution in the web sphere, their security has become a major concern today. It is in this context that watermarked protection of databases has started receiving increasing attention from researchers. ||| This paper proposes a secure robust and imperceptible algorithm for watermarking relational databases. The algorithm divides the embedding algorithm into three phases: Watermark preparator, watermark position detector, and watermark embedder. The ownership identification issue is resolved by embedding owner's identity as watermark in Preparator phase. ||| The importance of watermarking digital databases has increased by leaps and bounds due to the high vulnerability of digital assets to piracy attempts when they traverse through the internet. To deter piracy, we propose a robust watermarking scheme for relational databases containing categorical data that resolves ownership issues.","Rough Set theory, ownership proof, Head-Up Display, Fog Elimination, Relational Database, Non Numeric Attributes, Head-Up Display (HUD), robustness analysis, Fragile Watermarking, Watermark, Copyright protection, Right Protection, genetic algorithms, Drowsiness Detection, Night vision Infrared (IR) camera, copyright issues, Reducts and Rules, rules, Dynamic Watermark Injection, Ownership Protection, non-numeric attributes, Tamper Detection, Data Recovery, Facial landmark detection, watermarking, information recovery, databases, digital watermarking, reducts, relational database, Decision Systems, Security, ownership, relational databases, Big Data, imperceptible algorithm, categorical data, algorithm, optimization, robust algorithm, Information security, Drowsy detection, database protection, Robustness, Information Security, Digital Watermarking, Copyright Issues, OpenCV, secure data hiding, watermarked protection, robust watermarking techniques, bacterial foraging, piracy detection, database watermarking, Voice Biometrics, Ownership identification, Relational Databases, digital content protection, tamper detection, NoSQL databases, Proof of ownership, Robust Watermarking, security","This paper proposes a fragile and blind watermarking scheme for tamper detection in Decision Systems. The scheme detects even the slightest integrity losses that may damage the classificatory information encapsulated within a Decision System. The technique characterizes the type of attack and then localizes the perturbation upto an attribute’s value level. In case of alteration in reducts, proposed technique can recover the original value. ||| The proposed method is robust against various attacks, including subset deletion, addition, and modification attacks. The experimental results show that the method maintains integrity of the database even under these attacks, making it suitable for real-world applications. ||| This paper proposes a new technique for multiple watermarking of relational databases that provides a unified solution to two major security concerns; ownership identification and information recovery. The proposed scheme regenerates crucial information encoded in the data in the event of both illegal alterations in the data as well as deletion of data. The granularity of the recoverable information is decided beforehand by the user. ||| This paper proposes a robust biometric watermarking technique for relational databases using voice as a biometric identifier of ownership. The technique generates a statistical model of the features extracted from the owner’s voice and securely embeds it into the database using a reversible bit encoding technique. The paper demonstrates the robustness of the technique against various attacks and shows that it can identify the correct owner even when 60% of the watermark suffers degradation. ||| This paper discusses the importance of protecting digital databases from copyright and piracy threats. It provides an overview of digital watermarking as a technological protective measure and analyzes the current state-of-art in the field. The paper also discusses the future directions in digital watermarking of databases and highlights the need for a combined legal and technical approach to ensure adequate protection. ||| The rapid growth of the Internet and related technologies has offered an unprecedented ability to access and redistribute digital contents. In such a context, enforcing data ownership is an important requirement, which requires articulated solutions, encompassing technical, organizational, and legal aspects. ||| This paper proposes a new technique for protecting NoSQL databases from tampering by dynamically injecting a watermark into each tuple. The technique leverages the flexible schema features of NoSQL databases and allows for immediate detection and localization of tampering with a high degree of accuracy. ||| The proposed system is a smart camera that uses machine learning algorithm to detect drowsiness in drivers. It captures the face of the driver using a Night vision Infrared (IR) camera and detects the eyes using facial landmark detection technique. The system generates an alert and alarm if the eyes are closed for more than 5 seconds, making it a safe and efficient way to detect drowsiness in drivers. ||| The paper proposes a robust watermarking model for relational databases to detect piracy and ownership. The model consists of a watermark preparator, a watermark embedder, and a watermark extractor. The watermark preparator selects and secures the watermark with a secret key, while the watermark embedder embeds the watermark into the database. The model also discusses the importance of usability constraints and the selection of candidate attributes and bit positions for embedding the watermark. ||| The paper proposes a new robust secure and imperceptible embedding mechanism to resolve the two important concerns namely; owner identification and proof of ownership. The proposed mechanism involves encoding and decoding on numerical attribute of relational database in three phases; 1)Watermark preparator, 2)Watermark position detector and 3) Watermark Embedder or Detector. ||| The paper proposes a technique for watermarking categorical data, which involves embedding a watermark in the database by re-arranging the tuples partition-wise. The technique is entirely distortion free and provides a high level of security against attacks."
Vijaypal Singh Dhaka,A deep learning model for mass screening of COVID-19 ||| Cardiovascular Disease Detection Model ||| Range Limited Double Threshold Weighted Histogram Equalization with Dynamic Range Stretching (RLDTWHE-DRS) ||| Recent Developments in Plant Leaf Disease Identification and Classification ||| Transforming view of medical images using deep learning,"The objective of this research is to develop a convolutional neural network model ‘COVID-Screen-Net’ for multi-class classification of chest X-ray images into three classes viz. COVID-19, bacterial pneumonia, and normal. ||| This paper proposes a cardiovascular disease detection model that uses a combination of techniques such as Naïve Bayes, neural network, and feature selection to achieve high accuracy rates. The model is implemented using a virtual environment in Python and uses a decision tree classifier to classify patients as infected or disinfected. The results show that the proposed model can obtain infected persons from the training data with low losses, which can help doctors in real-time to categorize patients based on certain characteristics. ||| In the recent era, a boom was observed in the field of information retrieval from images. Digital images with high contrast are sources of abundant information. The gathered information is useful in the precise detection of an object, event, or anomaly captured in an image scene. Existing systems do uniform distribution of intensities and apply intensity histogram equalization. These improve the characteristics of an image in terms of visual appearance. The problem of over enhancement and the increase in noise level produces undesirable visual artefacts. The use of Otsu’s single threshold method in existing systems is inefficient for segmenting an image with multiple objects and complex background. Additionally, these are incapable to improve the yield of the maximum entropy and brightness preservation. The aforementioned limitations motivate us to propose an efficient statistical pipelined approach, the Range Limited Double Threshold Weighted Histogram Equalization (RLDTWHE). This approach is an integration of Otsu’s double threshold, dynamic range stretching, weighted distribution, adaptive gamma correction, and homomorphic filtering. It provides optimum contrast enhancement by selecting the best appropriate threshold value for image segmentation. The proposed approach is efficient in the enhancement of low contrast medical MRI images and digital natural scene images. It effectively preserves all essential information recorded in an image. Experimental results prove its efficacy in terms of maximum entropy preservation, brightness preservation, contrast enhancement, and retaining the natural appearance of an image. ||| In the modern era, deep learning techniques have emerged as powerful tools in image recognition. Convolutional Neural Networks, one of the deep learning tools, have attained an impressive outcome in this area. The effectiveness of Convolutional Neural Networks in image recognition motivates the researchers to extend its applications in the field of agriculture for recognition of plant species, yield management, weed detection, soil, and water management, fruit counting, diseases, and pest detection, evaluating the nutrient status of plants, and much more. ||| Since the last decade, there is a significant change in the procedure of medical diagnosis and treatment. Specifically, when internal tissues, organs such as heart, lungs, brain, kidneys and bones are the target regions, a doctor recommends ‘computerized tomography’ scan and/or magnetic resonance imaging to get a clear picture of the damaged portion of an organ or a bone. This is important for correct examination of the medical deformities such as bone fracture, arthritis, and brain tumor. It ensures prescription of the best possible treatment. But ‘computerized tomography’ scan exposes a patient to high ionizing radiation. These rays make a person more prone to cancer. Magnetic resonance imaging requires a strong magnetic field. Thus, it becomes impractical for patients with implants in their body. Moreover, the high cost makes the above-stated techniques unaffordable for low economy class of society. The above-mentioned challenges of ‘computerized tomography’ scan and magnetic resonance imaging motivate researchers to focus on developing a technique for conversion of 2-dimensional view of medical images into their corresponding multiple views. In this manuscript, the authors design and develop a deep learning model that makes an effective use of conditional generative adversarial network, an extension of generative adversarial network for the transformation of 2-dimensional views of human bone into the corresponding multiple views at different angles. The model will prove useful for both doctors and patients.","leaf, CT scan, Homomorphic Filtering, Machine Learning, Deep learning, Classification, MRI, Optimum Contrast Enhancement, dynamic range stretching, Range Stretching, 2-Dimensional, deep learning models, disease, Histogram Weighting, Adaptive Gamma Correction, DCGAN, contrast enhancement, X-ray, SRGAN, Conditional generative adversarial network, weighted distribution, CCAN, SGAN, CNN model, 3-Dimensional, Optimization Techniques, convolutional neural networks, cardiovascular disease detection, survey, ACGAN, InfoGAN, Generative Adversarial Networks, Coronary Artery Diseases, Corona, COVID-19, Automatic Threshold Selection, deep learning, feature selection, machine learning models, plant leaf disease identification, Image-to-Image Translation, decision tree classifier, agriculture, global pandemic, histogram equalization","The authors developed a deep learning model ‘COVID-Screen-Net’ for mass screening of COVID-19 from chest X-ray images. The model achieves an average accuracy of 97.71% and a maximum recall of 100%. It outperforms existing systems for screening of COVID-19 and may prove a useful tool for quick and low-cost mass screening of patients. ||| The proposed model uses a combination of techniques to achieve high accuracy rates in cardiovascular disease detection. The model is implemented using a virtual environment in Python and uses a decision tree classifier to classify patients as infected or disinfected. The results show that the proposed model can obtain infected persons from the training data with low losses. ||| This paper proposes a new approach for digital image contrast enhancement, called Range Limited Double Threshold Weighted Histogram Equalization (RLDTWHE). The approach integrates several techniques, including Otsu’s double threshold, dynamic range stretching, weighted distribution, adaptive gamma correction, and homomorphic filtering. The proposed approach is efficient in enhancing low contrast medical MRI images and digital natural scene images, and effectively preserves all essential information recorded in an image. ||| This manuscript presents a survey of the existing literature in applying deep Convolutional Neural Networks to predict plant diseases from leaf images. It presents an exemplary comparison of the pre-processing techniques, Convolutional Neural Network models, frameworks, and optimization techniques applied to detect and classify plant diseases using leaf images as a data set. ||| The paper discusses the application of GANs in image-to-image translation and presents various techniques such as InfoGAN, SGAN, SRGAN, CCAN, DCGAN, and ACGAN. The paper highlights the advantages and disadvantages of each technique and provides a clear idea about the extension of the application area of the existing work."
Vikasendu Agrawal,"Seroprevalence of SARS-CoV-2 Antibodies in Uttar Pradesh, India: A Cross-Sectional Study","Population-based serological antibody test for SARS-CoV-2 infection helps in estimating the exposure in the community. We present the findings of the first district representative seroepidemiological survey conducted between 4 and 10 September 2020 among the population aged 5 years and above in the state of Uttar Pradesh, India. Multi-stage cluster sampling was used to select participants from 495 primary sampling units (villages in rural areas and wards in urban areas) across 11 selected districts to provide district-level seroprevalence disaggregated by place of residence (rural/urban), age (5–17 years/aged 18 +) and gender. A venous blood sample was collected to determine seroprevalence. Of 16,012 individuals enrolled in the study, 22.2% [95% CI 21.5–22.9] equating to about 10.4 million population in 11 districts were already exposed to SARS-CoV-2 infection by mid-September 2020. The overall seroprevalence was significantly higher in urban areas (30.6%, 95% CI 29.4–31.7) compared to rural areas (14.7%, 95% CI 13.9–15.6), and among aged 18 + years (23.2%, 95% CI 22.4–24.0) compared to aged 5–17 years (18.4%, 95% CI 17.0–19.9). No differences were observed by gender. Individuals exposed to a COVID confirmed case or residing in a COVID containment zone had higher seroprevalence (34.5% and 26.0%, respectively). There was also a wide variation (10.7–33.0%) in seropositivity across 11 districts indicating that population exposed to COVID was not uniform at the time of the study. Since about 78% of the population (36.5 million) in these districts were still susceptible to infection, public health measures remain essential to reduce further spread.","COVID-19, Seroprevalence, India, SARS-CoV-2, Heterogeneity, Uttar Pradesh","This study presents the first district-level seroprevalence survey of SARS-CoV-2 infection in Uttar Pradesh, India. Conducted in September 2020, the survey found that 22.2% of the population had been exposed to the virus by that time. Seroprevalence was significantly higher in urban areas and among individuals aged 18 and older. The findings highlight the importance of continued public health measures to reduce further spread of the virus."
Virendra Kumar,"Magnetic Resonance Materials in Physics, Biology and Medicine",Objective  To implement an advanced spatial penalty-based reconstruction to constrain the intravoxel incoherent motion (IVIM)–diffusion kurtosis imaging (DKI) model and investigate whether it provides a suitable alternative at 1.5 T to the traditional IVIM–DKI model at 3 T for clinical characterization of prostate cancer (PCa) and benign prostatic hyperplasia (BPH).,"TV penalty function, Prostate cancer, Benign prostatic hyperplasia, Total variation penalty function, MRI, Diffusion kurtosis imaging, Intravoxel incoherent motion, IVIM–DKI model","This study compares the use of IVIM–DKI at 1.5 T and 3 T MRI for differentiating between prostate cancer and benign prostatic hyperplasia. The results show that IVIM–DKI modeled with a novel model at 1.5 T produced parameter maps with lower coefficient of variation than the traditional model at 3 T. The novel model estimated higher D with lower D*, f, and k values at both field strengths compared to the traditional model. The study concludes that the proposed novel model can be utilized for improved detection of prostate lesions."
Vivek Sharma,Technological Advancements in Automated Crop Pest and Disease Detection: A Review & Ongoing Research,"Automated crop pests and disease detection have fateful effects on food safety, leading to significant deterioration in agriculture products. The effects of crop diseases and pests can be so severe that a harvest may even be ruined entirely. Therefore, automatic recognition and diagnosis of crop disease is required in the agricultural field. However, Fast and accurate crop disease detection is still a challenging and error-prone task. Earlier, traditional methods were used to detect abnormalities in crops caused by fungus, pests and nutritional deficiency. Moreover, in some cases, it is time-consuming, expensive and impractical. To overcome these issues, experimental research is being performed into the use of image processing techniques for crop disease detection using machine learning, artificial intelligence, deep learning, generative adversarial networks and the internet of things. In this study, a comprehensive literature review of current studies is performed in crop disease and pest recognition using image processing to extract the features and algorithms used in prediction studies. In particular, several models have reported better accuracy on specific data sets. In contrast, in the case of different data sets or field conditions, the performance of the models degraded significantly. Despite this, progress has been encouraging so far. Furthermore, different inputs gained from the literature indicate that the aforementioned techniques provide better accuracy in comparison with existing techniques. Additionally, a detailed study has been performed on several unresolved challenges to develop a framework for automated crop pests and disease detection to use in real field conditions.","GANs, Deep learning, transfer learning, crop disease detection, leaf disease recognition, Internet of things, Machine learning, Generative adversarial networks","The paper presents a comprehensive review of the current state of leaf disease recognition using deep learning techniques. It discusses the use of pre-trained CNNs, transfer learning, and GANs for generating synthetic images and addressing the problem of data scarcity. The paper also presents several architectures and methods for leaf disease recognition, including the use of YOLOv3 and AlexNet for predicting bounding boxes and the use of a softmax layer and a CNN architecture for crop disease recognition."
W. C. Yeh,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
W. H. Lau,Unique Local Features in Lip Images for Recognition,"The experiments are carried out from images taken with a camera that is used for the regular use. And the color features of a lip are not explored in the proposed research. Still the recognition system exploits the grayscale local features of a lip images and eﬃciently matches it with local features of another lip image. If the color properties of a lip image is explored for recognition along with local features, the accuracy values would increase further.","grayscale features, Lip Pattern Recognition, SIFT, lip recognition, color features, Biometric, Local Feature Extraction, local features, SURF",The paper presents the results of experiments on lip recognition using local features. The recognition system exploits the grayscale local features of lip images and achieves high accuracy. The authors suggest that exploring color properties of lip images could further improve the accuracy.
W. Purnami,Diabetes Classiﬁcation using Radial Basis Function Network by Combining Cluster Validity Index and BAT Optimization with Novel Fitness Function,This paper discusses the use of cluster validity indices for diabetes diagnosis. The authors present a literature survey related to the problem and propose a methodology for identifying the optimal number of clusters. The experimental outcomes confirm the performance of the proposed methodology. The paper also reviews the performance of various neural network-based classifiers on the Pima Indians data set.,"diabetes diagnosis, Optimal number of clusters, Medical Diagnosis, Classiﬁcation, methodology, Diabetes, literature survey, Bat Algorithm, Radial Basis Function Networks, cluster validity indices, neural network-based classifiers","This paper presents a new model based on cluster validity index with radial basis neural network for classiﬁcation of diabetic patients data. The proposed model is tested on Pima Indians Diabetes data set and synthetic data sets, and experimental results proved that our approach performs better in terms of accuracy, sensitivity, speciﬁcity, classiﬁcation time, training time, network complexity and computational time compared to conventional radial basis function neural network."
W. Wahlster,Lecture Notes in Artificial Intelligence 6465,"This work is subject to copyright. All rights are reserved, whether the whole or part of the material is concerned, specifically the rights of translation, reprinting, re-use of illustrations, recitation, broadcasting, reproduction on microfilms or in any other way, and storage in data banks. Duplication of this publication or parts thereof is permitted only under the provisions of the German Copyright Law of September 9, 1965, in its current version, and permission for use must always be obtained from Springer. Violations are liable to prosecution under the German Copyright Law.","Artificial Intelligence, Computational Linguistics, Sanskrit","The 4th International Sanskrit Computational Linguistics Symposium (4i-SCLS) was hosted by the Jawaharlal Nehru University, the premier research University of India during (December 10–12, 2010) at the Special Center for Sanskrit Studies. The event saw excellent response from the scholars, with more than 31 papers received, which were examined by the Program Committee members to shortlist 18 papers for publication presented in this volume."
WANG et al.,Convergence of Cyclic and Almost-Cyclic Learning with Momentum for Feedforward Neural Networks,"Two backpropagation algorithms with momentum for feedforward neural networks with a single hidden layer are considered. It is assumed that the training samples are supplied to the network in a cyclic or an almost-cyclic fashion in the learning procedure, i.e., in each training cycle, each sample of the training set is supplied in a fixed or a stochastic order respectively to the network exactly once. A restart strategy for the momentum is adopted such that the momentum coefficient is set to zero at the beginning of each training cycle. Corresponding weak and strong convergence results are then proved, indicating that the gradient of the error function goes to zero and the weight sequence goes to a fixed point, respectively. The convergence conditions on the learning rate, the momentum coefficient, and the activation functions are much relaxed compared with those of the existing results.","almost-cyclic learning, convergence results, feedforward neural networks, cyclic learning, feedforward NNs, momentum, cyclic, Almost-cyclic, convergence, backpropagation","This paper considers two backpropagation algorithms with momentum for feedforward neural networks with a single hidden layer. The training samples are supplied to the network in a cyclic or an almost-cyclic fashion in the learning procedure. A restart strategy for the momentum is adopted, and corresponding weak and strong convergence results are proved."
WEN et al.,Lag Synchronization of Switched Neural Networks via Neural Activation Function and Applications in Image Encryption,"This paper investigates the lag synchronization of switched neural networks. A novel controller is designed to achieve lag synchronization. The main results are presented in the form of lemmas and theorems. The conditions for lag synchronization are derived, and some criteria for globally exponential stability are presented.","controller design, switched neural networks, globally exponential stability, Exponential stability, lag synchronization","The paper presents a novel controller for achieving lag synchronization of switched neural networks. The main results are presented in the form of lemmas and theorems, and the conditions for lag synchronization are derived. Some criteria for globally exponential stability are also presented."
WEN-CHIEH LIN,Robust Feature-Based Automated Multi-View Human Action Recognition System,"Automated human action recognition has the potential to play an important role in public security, for example, in relation to the multiview surveillance videos taken in public places, such as train stations or airports. This paper compares three practical, reliable, and generic systems for multiview video-based human action recognition, namely, the nearest neighbor classiﬁer, Gaussian mixture model classiﬁer, and the nearest mean classiﬁer. To describe the different actions performed in different views, view-invariant features are proposed to address multiview action recognition. These features are obtained by extracting the holistic features from different temporal scales which are modeled as points of interest which represent the global spatial-temporal distribution. Experiments and cross-data testing are conducted on the KTH, WEIZMANN, and MuHAVi datasets. The system does not need to be retrained when scenarios are changed which means the trained database can be applied in a wide variety of environments, such as view angle or background changes. The experiment results show that the proposed approach outperforms the existing methods on the KTH and WEIZMANN datasets.","feature extraction, points of interest extraction, background subtraction, machine learning, moving object localization, multi-view human action recognition, action recognition, Multi-view video, classiﬁcation","This paper proposes a robust feature-based automated multi-view human action recognition system. The system uses view-invariant features to address multi-view action recognition from a range of perspectives. The proposed approach labels the beginning and end of an action sequence in a video stream automatically and captures sequence motions and occlusions at a low computational cost. The system is evaluated using the KTH, WEIZMAN, and MuHAVi datasets and outperforms existing methods on the KTH and WEIZMANN datasets."
Wajahat Ullah Khan,Study the modern biochemical analysis techniques of proteins and alkaline phasphtase enzyme system from biological sample chicken liver,"The objective of the study was the biochemical analysis of proteins and Alkaline Phosphatase enzyme system from biological sample Chicken Liver using modern biochemical analysis techniques, including protein extraction, fractionation and electrophoresis separation technique and enzyme analysis.","Amino acids, alkaline phosphatase, Enzymes, Biochemical analysis, peroxidases, acid phosphatase, Protein chains, proteases, Proteins","The paper discusses the biochemical analysis of proteins and alkaline phosphatase enzyme system from chicken liver using modern biochemical analysis techniques. It covers topics such as protein synthesis, structure, and purification, and highlights the importance of proteins in living organisms."
Wang et al.,A Multiobjective Genetic Programming-Based Ensemble for Simultaneous Feature Selection and Classiﬁcation,"We present an integrated algorithm for simultaneous feature selection (FS) and designing of diverse classiﬁers using a steady state multiobjective genetic programming (GP), which minimizes three objectives: 1) false positives (FPs); 2) false negatives (FNs); and 3) the number of leaf nodes in the tree.","ensemble, Classiﬁcation, feature selection, classification, genetic programming, genetic programming (GP), MOGP, feature selection (FS)","The paper proposes a multiobjective genetic programming-based ensemble for simultaneous feature selection and classiﬁcation. The method divides a c-class problem into c binary classiﬁcation problems and evolves c sets of genetic programs to create c ensembles. The classiﬁers of ith class determine the net belongingness of an unknown data point to the ith class using a weighted voting scheme. The method is tested on eight microarray and 11 text data sets with diverse number of classes, large number of features, and high feature-to-sample ratio."
"Wang, X. F., et al. (2014)",Quantum-inspired evolutionary approach for selection of optimal parameters of fuzzy clustering,"Recently, Fuzzy c-Means (FCM) algorithm is most widely used because of its efficiency and simplicity. However, FCM is sensitive to the initialization of fuzziness factor (m) and the number of clusters (c) due to which it easily trapped in local optima. A selection of these parameters is a critical issue because an adverse selection can blur the clusters in the data.","Fuzzy clustering, Cluster validity index, Quantum-Inspired Evolutionary Fuzzy c-Means, Fuzzy c-Means algorithm, Fuzzy c-Means, Quantum computing","This paper proposes a hybrid fuzzy clustering algorithm, Quantum-Inspired Evolutionary Fuzzy c-Means (QIE–FCM), which uses the merits of quantum computing for finding the global optimal value of m and its corresponding value of c in the FCM. The proposed approach improves the way of initialization of the fuzziness factor (m) in the FCM and provides the diversity in selecting the optimal value of m and c from a large quantum search space."
Wei Chen,Endogenous IRAK-M Attenuates Postinfarction Remodeling Through Effects on Macrophages and Fibroblasts,"Quantitative polymerase chain reaction analysis demonstrated significant IRAK-M mRNA upregulation in the infarcted myocardium. The time course of IRAK-M induction showed a biphasic response (Figure 1), characterized by marked early upregulation after 6 hours of reperfusion, followed by a second peak after 7 days of reperfusion (Figure 1A). IRAK-M Is Localized in Infarct Macrophages and Myofibroblasts Dual immunofluorescence was used to study IRAK-M localization in the infarcted myocardium. IRAK-M immunoreactivity in the infarcted heart was localized in Mac2+ infarct macrophages and in spindle-shaped, α–smooth muscle actin–positive myofibroblasts (Figure 1B and 1C). Moreover, infarct myofibroblasts and CD11b+ leukocytes isolated from the infarcted heart after 72 hours of reperfusion exhibited IRAK-M expression (Figure 1D–1G). To study cell-type specific changes in the timing of IRAK-M expression, we assessed IRAK-M mRNA levels in cardiac fibroblasts and CD11b+ leukocytes harvested from the infarcted heart. Isolated fibroblasts had a 3-fold increase in IRAK-M mRNA levels after 24 hours to 72 hours of reperfusion in comparison with control cardiac fibroblasts. When compared with control CD11b+ cells harvested from normal hearts, leukocytes isolated after 6 hours of reperfusion showed a trend toward increased IRAK-M mRNA expression (Figure I in the online-only Data Supplement). IRAK-M Loss Is Associated With Enhanced Adverse Remodeling Despite the Absence of Effects on the Size of the Infarct IRAK-M−null and WT animals had comparable mortality after myocardial infarction (P=NS). Triphenyltetrazolium chloride/Evans blue staining demonstrated that IRAK-M loss does not affect the size of the infarct after 1 hour of ischemia and 24 hours of reperfusion (Figure 1H–1J). Two independent techniques, echocardiographic imaging (Figure 2A–2G; Table I in the online-only Data Supplement) and quantitative morphometry (Figure 2H–2L), demonstrated that IRAK-M loss was associated with enhanced adverse remodeling after myocardial infarction. Systolic and diastolic chamber dimensions measured through echocardiography (left ventricular end-diastolic dimension, left ventricular end-systolic dimension, left ventricular end-systolic volume, and left ventricular end-diastolic volume; Figure 2A–2G) and morphometrically-derived left ventricular end-diastolic volume and left ventricular end-diastolic dimension (Figure 2H–2L) were significantly higher in IRAK-M−null mice after 7 and 28 days of reperfusion, indicating increased chamber dilation. Left ventricular mass was also significantly higher in infarcted IRAK-M−null hearts, suggesting accentuated hypertrophic remodeling. Increased adverse remodeling in the absence of IRAK-M was associated with reduced fractional shortening (FS), reflecting worse systolic dysfunction (Figure 2D). Because acute infarct size was comparable between WT and IRAK-M−null mice (Figure 1H–1J), accentuated adverse remodeling in IRAK-M−null hearts was not a result of more extensive cardiomyocyte injury. Moreover, scar size after 7 to 28 days of reperfusion was comparable between IRAK-M−/− and WT animals (Figure 2I). IRAK-M−/− Mice Have Enhanced Postinfarction Inflammation Exhibiting Increased Myocardial Cytokine mRN","metalloproteinases, cytokines, immune system, macrophages, cardiac remodeling","This study investigates the role of Interleukin-1 receptor-associated kinase (IRAK)-M in myocardial infarction.  Key findings include: 

* IRAK-M mRNA is significantly upregulated in the infarcted myocardium, with a biphasic response.
* IRAK-M is localized in macrophages and myofibroblasts within the infarcted heart.
* IRAK-M loss is associated with enhanced adverse remodeling after myocardial infarction, characterized by increased chamber dilation and hypertrophy, despite no effect on infarct size.
* IRAK-M−/− mice exhibit increased postinfarction inflammation with elevated myocardial cytokine mRNA levels."
Wei Tsang Ooi,Cloud-Based Secured Medical Data Visualization Pipeline ||| Secure Cloud-Based Volume Ray-Casting,"Outsourcing the tasks of medical data visualization to cloud centers presents new security challenges. In this paper, we propose a framework for cloud-based remote medical data visualization that protects the security of data at the cloud centers. ||| Secure Cloud-based Volume Ray-Casting","cloud-based, visualization, pipeline, 3D Medical Data Visualization, secured, Secret Sharing, Cloud Computing, medical, data, Ray Casting","The proposed pipeline protects patient's 3D medical data by distributing shares among n different data centers, allowing clients to reconstruct the secret image from any k shares. ||| Secure Cloud-based Volume Ray-Casting is a framework for secure medical data visualization. It addresses security and privacy challenges by using secure pre-classification and post-classification volume ray-casting techniques."
Wei Wu,Convergence Analysis of Online Gradient Methods for Feedforward Neural Networks,"This paper considers a class of online gradient learning methods for backpropagation (BP) neural networks with a single hidden layer. We assume that in each training cycle, each sample in the training set is supplied in a stochastic order to the network exactly once. It is interesting that these stochastic learning methods can be shown to be deterministically convergent. This paper presents some weak and strong convergence results for the learning methods, indicating that the gradient of the error function goes to zero and the weight sequence goes to a fixed point, respectively. The conditions on the activation function and the learning rate to guarantee the convergence are relaxed compared with the existing results. Our convergence results are valid for not only S–S type neural networks (both the output and hidden neurons are Sigmoid functions), but also for P–P, P–S and S–P type neural networks, where S and P represent Sigmoid and polynomial functions, respectively.","Backpropagation learning, Strong convergence, feedforward neural networks, Online gradient method, convergence analysis, OGM-SS, Weak convergence, online gradient methods, Neural networks, OGM-F","This paper presents a comprehensive study on the weak and strong convergence for OGM-F and OGM-SS, indicating that the gradient of the error function goes to zero and the weight sequence goes to a fixed point, respectively. The conditions on the activation function and the learning rate to guarantee the convergence are much relaxed compared with the existing results."
Wei Zhang,Global Exponential Synchronization of Multiple Riemann-Liouville Neural Networks with Time-Varying Impulsive Delays,"This paper investigates the global exponential synchronization of multiple Riemann-Liouville neural networks with time-varying impulsive delays. By constructing a suitable Lyapunov function and using the linear matrix inequality (LMI) technique, some sufficient conditions are derived to ensure the global exponential synchronization of the considered neural networks. The obtained results are expressed in terms of the network parameters, impulsive delays, and coupling strengths. Finally, two numerical examples are provided to demonstrate the effectiveness of the proposed synchronization scheme.","time-varying impulsive delays, memristor, global exponential synchronization, Lyapunov function, recurrent neural networks, linear matrix inequality, synchronization, time-varying delay, Impulse, Riemann-Liouville neural networks","This paper presents a study on the global exponential synchronization of multiple Riemann-Liouville neural networks with time-varying impulsive delays. The authors derive sufficient conditions for synchronization using a Lyapunov function and linear matrix inequality (LMI) technique. The results are expressed in terms of network parameters, impulsive delays, and coupling strengths. Two numerical examples are provided to demonstrate the effectiveness of the proposed synchronization scheme."
Wei et. al.,Rumour Source Detection Using Game Theory,"Social networks have become a critical part of our lives as they enable us to interact with a lot of people. These networks have become the main sources for creating, sharing and also extracting information regarding various subjects. But all this information may not be true and may contain a lot of unverified rumours that have the potential of spreading incorrect information to the masses, which may even lead to situations of widespread panic. Thus, it is of great importance to identify those nodes and edges that play a crucial role in a network in order to find the most influential sources of rumour spreading. Generally, the basic idea is to classify the nodes and edges in a network with the highest criticality. Most of the existing work regarding the same focuses on using simple centrality measures which focus on the individual contribution of a node in a network. Game-theoretic approaches such as Shapley Value (SV) algorithms suggest that individual marginal contribution should be measured for a given player as the weighted average marginal increase in the yield of any coalition that this player might join. For our experiment, we have played five SV-based games to find the top 10 most influential nodes on three network datasets (Enron, USAir97 and Les Misérables). We have compared our results to the ones obtained by using primitive centrality measures. Our results show that SV-based approach is better at understanding the marginal contribution, and therefore the actual influence, of each node to the entire network.","influential nodes, Jaccard Similarity Coefficient, cooperative game, Rumour Source Detection (RSD), centrality measures, network analysis, Shapley Value (SV), Game-Theory, Network Centrality",This paper aims to identify the most influential nodes in a network that are the primary sources of rumour propagation. The authors propose a game-theoretic approach using the Shapley Value algorithm to find the most influential nodes. They compare their results with primitive centrality measures and show that the SV-based approach is better at understanding the marginal contribution of each node to the entire network.
Weiping Ding,A Layered-Coevolution-Based Attribute-Boosted Reduction Using Adaptive Quantum Behavior PSO and Its Consistent Segmentation for Neonates Brain Tissue ||| A Review of Clustering Techniques and Developments,"The main challenge of attribute reduction in large data applications is to develop a new algorithm to deal with large, noisy, and uncertain large data linking multiple relevant data sources, structured or unstructured. This paper proposes a new and efficient layered-coevolution-based attribute-boosted reduction algorithm (LCQ-ABR*) using adaptive quantum behavior particle swarm optimization (PSO). ||| This paper presents a comprehensive study on clustering: exiting methods and developments made at various times. Clustering is defined as an unsupervised learning where the objects are grouped on the basis of some similarity inherent among them. There are different methods for clustering the objects such as hierarchical, partitional, grid, density based and model based. The approaches used in these methods are discussed with their respective states of art and applicability. The measures of similarity as well as the evaluation criteria, which are the central components of clustering are also presented in the paper. The applications of clustering in some fields like image segmentation, object and character recognition and data mining are highlighted.","Unsupervised learning, Clustering, sulci and gyrus estimate, Data mining, Neonatal Brain Tissue 3D-MRI, Hierarchical Clustering, Self-Adaptive Memeplexes, layered-coevolution with multi-agent interaction, ROCK, Quantum-Behavior PSO, Similarity measures, Clustering Approaches, consistent segmentation for neonates brain tissue, Pattern recognition, BIRCH, Layered Co-Evolutionary Model, Taxonomy, adaptive quantum behavior PSO, Attribute-boosted reduction, CURE, Multi-Agent Interaction, CHAMELEON","This paper proposes a new attribute reduction algorithm using quantum behavior PSO, which aims to choose attribute subsets for large-scale, noisy, and uncertain datasets. The algorithm is evaluated on several benchmark datasets and compared with other representative algorithms. The results show that the proposed algorithm has better feasibility and effectiveness than the compared algorithms. ||| This paper reviews clustering techniques and developments, discussing methods such as hierarchical, partitional, grid, density-based, and model-based clustering, as well as measures of similarity and evaluation criteria. The applications of clustering in fields like image segmentation, object recognition, and data mining are highlighted."
Weizhe Zhang,Adaptive Energy-Aware Algorithms for Minimizing Energy Consumption and SLA Violation in Cloud Computing,"In cloud computing, high energy consumption and service-level agreements (SLAs) violation are the challenging issues considering that the demand for computational power is growing rapidly, thereby requiring large-scale cloud data centers. This paper proposes three adaptive models, namely, gradient descent-based regression (Gdr), maximize correlation percentage (MCP), and bandwidth-aware selection policy (Bw), that can significantly minimize energy consumption and SLA violation.","regression method, energy-efﬁciency, service level agreements, SLA violation, host overloaded detection, energy efficiency, cloud data center, VM consolidation, Cloud computing, meta-heuristic approach, green computing","This paper proposes three adaptive models to minimize energy consumption and SLA violation in cloud computing. The models are based on gradient descent-based regression, maximize correlation percentage, and bandwidth-aware selection policy. The proposed algorithms reduce energy consumption while maintaining the required performance levels in a cloud data center."
Wen-Chieh Lin,Deep Sparse Representation Classifier for Facial Recognition  and Detection System,"This paper proposes a two-layer Convolutional Neural Network (CNN) to learn the high-level features which utilizes to the face identification via sparse representation. Feature extraction plays a vital role in real-world pattern recognition and classification tasks. The details description of the given input face image, significantly improve the performance of the facial recognition system. Sparse Representation Classifier (SRC) is a popular face classifier that sparsely represents the face image by a subset of training data, which is known as insensitive to the choice of feature space. The proposed method shows the performance improvement of SRC via a precisely selected feature exactor. The experimental results show that the proposed method outperform other methods on given datasets.","Sparse Feature Extraction, Convolutional neural network, Deep learning, CNN, Sparse representation classifier, Face recognition, Support Vector Machines, Feature extraction","This paper presents a robust face recognition framework based on the combination of sparse feature extraction using Convolutional Neural Networks (CNNs) and Support Vector Machines (SVMs). The proposed framework is evaluated on four widely used face datasets, including Extended YALE B database, AR database, MIT faces database, and ORL faces database. The experimental results show that the proposed framework outperforms the state-of-the-art methods in terms of recognition rate."
William A. Fischer,First-­in-­Human Study of Bamlanivimab in a Randomized Trial of Hospitalized Patients With COVID-­19,"This first-in-human study in hospitalized patients with COVID-19 was supported by studies assessing in vitro viral neutralization combined with a single-dose non-human primate PK study. The nonclinical safety package to support subsequent studies included tissue cross-reactivity studies on human, rat, and monkey tissues and an in vivo toxicology study.  A complete physical examination was conducted at the screening visit, and one of three bamlanivimab doses or placebo was administered i.v. at the baseline visit (D1) with infusion rates as follows: bamlanivimab 700 mg (50 mL) administered 100 mL/hr for 30 minutes; 2,800 mg (75 mL) administered 100 mL/hr for 45 minutes; and 7,000 mg administered 100 mL/hr for 60 minutes. Placebo infusion was 0.9% normal saline, administered at the same volume and rate as the corresponding bamlanivimab dose cohort. Safety and tolerability were reviewed for sentinel participants up to 24 hours after dosing, at which point the investigators and sponsor team determined whether safety and tolerability were acceptable to continue with dosing subsequent participants. The decision to dose the next cohort was made when all participants from the previous cohort had been dosed and safety data assessed for at least 4 days after the i.v. infusion by the investigators and sponsor team in consultation with an independent safety assessment committee. Blood samples were obtained for assessment of exploratory biomarkers, serology, clinical laboratory assessments, and PD on days 1, 3, 7, 11, 15, 22, and 29, and every 7 days until discharge or day 60, if still an inpatient. Samples for the virology assay were collected using nasopharyngeal (preferred) or mid-turbinate methods. Blood samples obtained for PK analyses were assessed on days 1 (pre-infusion and just before end of infusion), 4, 15, and 29, and follow-up visits up to day 60. Symptom-related physical examinations and assessments of clinical symptoms were performed on days 1, 2, 3, 4, 7, 11, 15, 22, and 29, and the day of discharge from the hospital, with additional follow-up examinations every 7 days thereafter until day 60 if the patient was not discharged from the hospital by day 29. Participants’ clinical status and concurrent procedures of special interest were recorded, including limitation on activities due to COVID-19 and any requirements for the following procedures of special interest, such as ongoing hospital medical care, supplemental oxygen, noninvasive ventilation or a high flow oxygen device, mechanical ventilation, extracorporeal membrane oxygenation, additional organ support, or consciousness status using alert, consciousness, verbal, pain, unresponsive scale. Hospitalization events were recorded, including dates of hospital admission and discharge, admission to the intensive care unit (ICU), discharge from the ICU, and discharge location including to an extended care facility or home. Outcomes The primary objective was to assess safety and tolerability, including adverse events (AEs), serious adverse events (SAEs), and discontinuations due to AEs. Other objectives included PKs (e.g., mean concentration at day 29); PD viral load, area under the response time curve (AUC, from day 1 to day 29), and change from baseline time course; total symptom score; time to symptom resolution; duration of hospitalization; National Institute of Allergy and Infectious Diseases (NIAID), World Health Organization (WHO) scales, and National Early Warning Score (NEWS2); and analysis of viral resistance. Any hypothesis tests were conducted for treatment comparisons without adjustment for multiplicity except for the evaluation of treatment effect on endogenous antibody titers. Success for the trial was claimed using a Bayesian criterion if any of the 3 bamlanivimab doses had at least 60% probability to reduce at least 30% mean AUC (28-day viral load) over placebo.",,"This first-in-human study evaluated the safety, tolerability, pharmacokinetics, clinical course, and viral dynamics of bamlanivimab, a fully human neutralizing monoclonal antibody targeting SARS-CoV-2, in hospitalized patients with moderate to severe COVID-19.  The study found bamlanivimab to be safe and well-tolerated, with no serious adverse events or deaths reported.  Further research is needed to determine the efficacy of bamlanivimab in treating COVID-19."
Wu et al.,Understanding Spreading Patterns on Social Networks Based on Network Topology,"The study of meme propagation and the prediction of meme trajectory are emerging areas of interest in the field of complex networks research. In addition to the properties of the meme itself, the structural properties of the underlying network decides the speed and the trajectory of the propagating meme.","information spreading, SCCP networks, meme propagation, network topology, social status, social networks, tie strength",This paper proposes a novel framework for studying meme propagation patterns based on network topology. The framework includes a synthetic network that simulates a real-world network and acts as a testbed for meme simulation. The proposed spreading model is based on the diversity of edges in the network and is validated by the propagation of the Higgs boson meme on Twitter as well as many real-world social networks.
X. Chen,Secure Robust and Imperceptible Algorithm for Watermarking Relational Databases,"This paper proposes a secure robust and imperceptible algorithm for watermarking relational databases. The algorithm divides the embedding algorithm into three phases: Watermark preparator, watermark position detector, and watermark embedder. The ownership identification issue is resolved by embedding owner's identity as watermark in Preparator phase.","imperceptible algorithm, Ownership identification, robust algorithm, Relational Database, watermarking, Watermark, Copyright protection, Proof of ownership, relational databases","The paper proposes a new robust secure and imperceptible embedding mechanism to resolve the two important concerns namely; owner identification and proof of ownership. The proposed mechanism involves encoding and decoding on numerical attribute of relational database in three phases; 1)Watermark preparator, 2)Watermark position detector and 3) Watermark Embedder or Detector."
X. Cui,Secure Robust and Imperceptible Algorithm for Watermarking Relational Databases,"This paper proposes a secure robust and imperceptible algorithm for watermarking relational databases. The algorithm divides the embedding algorithm into three phases: Watermark preparator, watermark position detector, and watermark embedder. The ownership identification issue is resolved by embedding owner's identity as watermark in Preparator phase.","imperceptible algorithm, Ownership identification, robust algorithm, Relational Database, watermarking, Watermark, Copyright protection, Proof of ownership, relational databases","The paper proposes a new robust secure and imperceptible embedding mechanism to resolve the two important concerns namely; owner identification and proof of ownership. The proposed mechanism involves encoding and decoding on numerical attribute of relational database in three phases; 1)Watermark preparator, 2)Watermark position detector and 3) Watermark Embedder or Detector."
X.-M. Jin,Secure Robust and Imperceptible Algorithm for Watermarking Relational Databases,"This paper proposes a secure robust and imperceptible algorithm for watermarking relational databases. The algorithm divides the embedding algorithm into three phases: Watermark preparator, watermark position detector, and watermark embedder. The ownership identification issue is resolved by embedding owner's identity as watermark in Preparator phase.","imperceptible algorithm, Ownership identification, robust algorithm, Relational Database, watermarking, Watermark, Copyright protection, Proof of ownership, relational databases","The paper proposes a new robust secure and imperceptible embedding mechanism to resolve the two important concerns namely; owner identification and proof of ownership. The proposed mechanism involves encoding and decoding on numerical attribute of relational database in three phases; 1)Watermark preparator, 2)Watermark position detector and 3) Watermark Embedder or Detector."
XIANGJIAN HE,Privacy-Preserving Mechanism in Smart Home Using Blockchain,"The IoT, or Internet of Things has been a major talking point amongst technology enthusiasts in recent years. The internet of thing (IoT) has been emerged and evolved rapidly, making the world’s fabric around us smarter and more responsive. The smart home uses one such transformation of IoT, which seems to be the wave of the future. However, with the increasing wide adoption of IoT, data security, and privacy concerns about how our data is collected and shared with others, has also risen. To solve these challenges, an approach to data privacy and security in a smart home using blockchain technology is proposed in this paper. We propose authentication scheme that combines attribute-based access control with smart contracts and edge computing to create a secure framework for IoT devices in smart home systems. The edge server adds scalability to the system by offloading heavy processing activities and using a differential privacy method to aggregate data to the cloud securely and privately. We present several aspects of testing and implementing smart contracts, the differential private stochastic gradient descent algorithm, and system architecture and design. We demonstrate the efficacy of our proposed system by fully examining its security and privacy goals in terms of confidentiality, integrity, and availability. Our framework achieves desired security and privacy goals and is resilient against modification, DoS attacks, data mining and linkage attacks. Finally, we undertake a performance evaluation to demonstrate the proposed scheme’s feasibility and efficiency.","edge computing, cyber threats, smart home, access control, differential privacy, Blockchain, smart contract","This paper proposes a privacy-preserving mechanism in smart homes using blockchain technology. The proposed system combines attribute-based access control with smart contracts and edge computing to create a secure framework for IoT devices in smart home systems. The edge server adds scalability to the system by offloading heavy processing activities and using a differential privacy method to aggregate data to the cloud securely and privately. The proposed system achieves desired security and privacy goals and is resilient against modification, DoS attacks, data mining and linkage attacks."
Xian Shia,A new method for rock brittleness evaluation in tight oil formation from conventional logs and petrophysical data,"Brittleness is a critical indicator for hydraulic fracturing candidate screening in unconventional reservoirs. Current rock brittleness estimation models are often inferred from mechanical parameters and mineralogical data, which primarily use empirical equations. However, the absence of shear sonic velocity data and insufficient mineral data sometimes restricts its wide application. In this article, our objective is to illustrate the application of a data-driven approach for rock brittleness estimation that employs computational intelligence technologies (multilayer perception and radial basis function models) that use conventional well logs as inputs.","Rock brittleness, Multilayer perception, production, brittleness, Computational intelligence, Hydraulic fracturing, Tight oil, oil and gas exploration, rock mechanics, Radial basis function","The paper reviews the current state of brittleness calculation methods and their limitations, highlighting the need for a universally applicable model. It discusses the importance of mineral composition, strain rate, temperature, pore pressure, saturation, and stress state in controlling rock brittleness."
"Xiao, Y. F., et al. (2010)",Quantum-inspired evolutionary approach for selection of optimal parameters of fuzzy clustering,"Recently, Fuzzy c-Means (FCM) algorithm is most widely used because of its efficiency and simplicity. However, FCM is sensitive to the initialization of fuzziness factor (m) and the number of clusters (c) due to which it easily trapped in local optima. A selection of these parameters is a critical issue because an adverse selection can blur the clusters in the data.","Fuzzy clustering, Cluster validity index, Quantum-Inspired Evolutionary Fuzzy c-Means, Fuzzy c-Means algorithm, Fuzzy c-Means, Quantum computing","This paper proposes a hybrid fuzzy clustering algorithm, Quantum-Inspired Evolutionary Fuzzy c-Means (QIE–FCM), which uses the merits of quantum computing for finding the global optimal value of m and its corresponding value of c in the FCM. The proposed approach improves the way of initialization of the fuzziness factor (m) in the FCM and provides the diversity in selecting the optimal value of m and c from a large quantum search space."
Xiaobo Shen,Scalable GPs,"The vast quantity of information brought by big data as well as the evolving computer hardware encourages success stories in the machine learning community. In the meanwhile, it poses challenges for the Gaussian process (GP) regression, a well-known non-parametric and interpretable Bayesian model, which suffers from cubic complexity to data size. To improve the scalability while retaining desirable prediction quality, a variety of scalable GPs have been presented. But they have not yet been comprehensively reviewed and analyzed in order to be well understood by both academia and industry.","big data, Scalable GPs, local approximations, Gaussian Processes, Gaussian process regression, sparse approximations, scalability","This paper reviews state-of-the-art scalable GPs involving two main categories: global approximations which distillate the entire data and local approximations which divide the data for subspace learning. Recent advances for improving the scalability and capability of scalable GPs are reviewed. Finally, the extensions and open issues regarding the implementation of scalable GPs in various scenarios are reviewed and discussed to inspire novel ideas for future research avenues."
Xiaopeng Ma,History Matching of Naturally Fractured Reservoirs Using a Deep Sparse Autoencoder,"This work proposes a new characterization method and a method to reduce dimensionality for history matching of naturally fractured reservoirs. The forward simulator is modeled after the EDFM given its computational efficiency. The fracture network can be represented with length, orientation, and position, including large-scale fractures and small-scale fractures.","History matching, characterization method, EDFM, Naturally fractured reservoirs, Deep sparse autoencoder, dimensionality reduction, fracture network","This paper proposes a new characterization method for the multiscale fracture network, and a powerful dimensionality-reduction method by means of an autoencoder for model parameters. The characterization method of the fracture network is dependent on the length, orientation, and position of fractures, including large-scale and small-scale fractures."
Xin-She Yang,Artificial Bee Colony (ABC) Algorithm,"Artificial bee colony (ABC) optimisation algorithm is a relatively simple and recent population-based probabilistic approach for global optimisation. The solution search equation of ABC is significantly influenced by a random quantity which helps in exploration at the cost of exploitation of the search space. In the ABC, there is a high chance to skip the true solution due to its large step sizes. In order to balance between diversity and convergence in the ABC, a Lévy flight inspired search strategy is proposed and integrated with ABC. The proposed strategy is named as Lévy Flight ABC (LFABC) has both the local and global search capability simultaneously and can be achieved by tuning the Lévy flight parameters and thus automatically tuning the step sizes.","ABC algorithm, Honey bees, swarm intelligence, numerical optimisation, Food foraging, memetic algorithm, Artificial Bee Colony, Lévy flight local search, Optimisation","This paper proposes a Lévy flight inspired search strategy to balance between diversity and convergence in the artificial bee colony (ABC) optimisation algorithm. The proposed strategy, named as Lévy Flight ABC (LFABC), has both local and global search capability simultaneously and can be achieved by tuning the Lévy flight parameters. The performance of the proposed strategy is analysed over test problems and five real-world engineering optimisation problems."
Xing He,Global Exponential Synchronization of Multiple Riemann-Liouville Neural Networks with Time-Varying Impulsive Delays,"This paper investigates the global exponential synchronization of multiple Riemann-Liouville neural networks with time-varying impulsive delays. By constructing a suitable Lyapunov function and using the linear matrix inequality (LMI) technique, some sufficient conditions are derived to ensure the global exponential synchronization of the considered neural networks. The obtained results are expressed in terms of the network parameters, impulsive delays, and coupling strengths. Finally, two numerical examples are provided to demonstrate the effectiveness of the proposed synchronization scheme.","time-varying impulsive delays, memristor, global exponential synchronization, Lyapunov function, recurrent neural networks, linear matrix inequality, synchronization, time-varying delay, Impulse, Riemann-Liouville neural networks","This paper presents a study on the global exponential synchronization of multiple Riemann-Liouville neural networks with time-varying impulsive delays. The authors derive sufficient conditions for synchronization using a Lyapunov function and linear matrix inequality (LMI) technique. The results are expressed in terms of network parameters, impulsive delays, and coupling strengths. Two numerical examples are provided to demonstrate the effectiveness of the proposed synchronization scheme."
Xing Zhang,A Cost-Efficient Communication Framework For Battery Switch Based Electric Vehicle Charging,"This paper proposes a battery switch service for electric vehicles (EVs) using a publish/subscribe (P/S) communication paradigm. The system consists of road side units (RSUs), electric vehicles (EVs), and charging stations (CSs). RSUs act as brokers to bridge the information flow from CSs to EVs, while EVs and CSs interact through RSUs. The system enables efficient radio resource utilization and alleviates interference to EVs.","Electric Vehicles, publish/subscribe, road side units, Smart Cities, Communication Framework, Charging Management, Battery Switch, charging stations","This article presents a cost-efﬁcient communication framework for battery switch based electric vehicle charging. The framework is provisioned to support the EV charging service and considers urban travel uncertainties, e.g., trafﬁc congestions and drivers’ preferences. Results demonstrate a guidance for the provisioning of P/S communication framework to improve EV drivers’ experience, e.g., charging waiting time and total trip duration."
Xingyan Li,Gesture Recognition,"Hand Gesture detection is now getting a lot of attention because it has a lot of uses and the specialty to connect with machines around efficiently by human interaction to computers. In this we are trying to make a knowhow of hand gesture detection system. The problems of hand gesture detection system are also discussed in this. Conclusion of results, methods, data and difference between different phases are also mentioned. Pros and cons are also discussed. In this project we are trying to understand how the image processing works and how can we use it to make a hand gesture detection system so that we can operate the computer without any physical contact with the machine itself. There are many researches that are done before and are still undergoing. Many big companies are currently working on this technology so that they can make their products even more useful that they are now because this technology has very high scope in the upcoming future. The people that are not mentally stable or weak from mind can also benefit by technology and can operate the computer. We can use this technology to make the computer even more accessible for humans.","Feature Extract, Tools for classification, Neural Networks, Posture of Hand, Gesture, Interaction of human with computer (HCI), Phases of recognition, brightness factor matching, fuzzy c-means clustering algorithm, gesture recognition",The main motive to build a hand gesture detection system is to make an interaction between human and computer that can be done by recognizing gestures for controlling robots or a simple computer. How do we make this system is understood and interpreted by the computer. The interaction of humans with computer is also called as man-machine interaction (MMI). Since A computer is insignificant if it not being utilized by human. There are some features that should be looked before we design this system. The function of the system and the use of the system. Function means the things that the system gives to its user and use means the scope of the system that it can be used efficiently. The system which has these both properties is known as powerful system.
Xinmin Ge,A new method for rock brittleness evaluation in tight oil formation from conventional logs and petrophysical data,"Brittleness is a critical indicator for hydraulic fracturing candidate screening in unconventional reservoirs. Current rock brittleness estimation models are often inferred from mechanical parameters and mineralogical data, which primarily use empirical equations. However, the absence of shear sonic velocity data and insufficient mineral data sometimes restricts its wide application. In this article, our objective is to illustrate the application of a data-driven approach for rock brittleness estimation that employs computational intelligence technologies (multilayer perception and radial basis function models) that use conventional well logs as inputs.","Rock brittleness, Multilayer perception, production, brittleness, Computational intelligence, Hydraulic fracturing, Tight oil, oil and gas exploration, rock mechanics, Radial basis function","The paper reviews the current state of brittleness calculation methods and their limitations, highlighting the need for a universally applicable model. It discusses the importance of mineral composition, strain rate, temperature, pore pressure, saturation, and stress state in controlling rock brittleness."
Xu Zhang,Mobile Edge Computing for Big Data-Enabled Electric Vehicle Charging,"As one of the key drivers of smart grid, Electric Vehicles (EVs) are environment-friendly to alleviate CO2 pollution. Big data analytics could enable the move from Internet of EVs, to optimized EV charging in smart transportation. In this paper, we propose a Mobile Edge Computing (MEC) based system, in line with a big data-driven planning strategy on which Charging Station (CS) to charge.","Big Data, MEC Based System, EV Charging, Communication Technologies, Network Entities, Smart Transportation, Smart Cities, Decentralized Charging Management, Centralized Charging Management, Charging Planning, Smart Grid, Big Data-Enabled Electric Vehicle Charging, Mobile Edge Computing","This paper proposes a Mobile Edge Computing (MEC) based system for big data-enabled electric vehicle charging. The system integrates big data analytics to opportunistically disseminate the outcome from a Global Controller and collect driving big data from mobile clients. The MEC servers implement big data mining and aggregation in a decentralized way, alleviating the size of data to be processed by the Global Controller."
Y. Cheng,Iris Detection,"For iris boundary detection, circular summation of intensity approach is used as proposed in [5]. The original grayscale image is blurred using median filter to remove external noise. After filtering, the contrast of image is enhanced to have sharp variation at image boundaries using histogram equalisation as shown in Figure 5(a). This contrast enhanced image is used for finding the outer iris boundary by drawing concentric circles (Figure 5(b) shows an example) of different radii from the pupil center and the intensities lying over the perimeter of the circle are summed up.","Adaptive Threshold, Circular Hough Transform, Spectrum Image, histogram equalisation, iris recognition, circular summation of intensity, Connected Components, Iris detection, pupil boundary, Iris Segmentation",The proposed system has been tested on two publicly available databases BATH and CASIA V3. From experimental analysis it has been observed that the system is capable of handling unconstrained scenarios as well. The system is capable of performing segmentation for unconstrained scenarios in significantly less time compared to Hough transform.
Y. Hong,Unique Local Features in Lip Images for Recognition,"The experiments are carried out from images taken with a camera that is used for the regular use. And the color features of a lip are not explored in the proposed research. Still the recognition system exploits the grayscale local features of a lip images and eﬃciently matches it with local features of another lip image. If the color properties of a lip image is explored for recognition along with local features, the accuracy values would increase further.","grayscale features, Lip Pattern Recognition, SIFT, lip recognition, color features, Biometric, Local Feature Extraction, local features, SURF",The paper presents the results of experiments on lip recognition using local features. The recognition system exploits the grayscale local features of lip images and achieves high accuracy. The authors suggest that exploring color properties of lip images could further improve the accuracy.
Y. J. Oyang,Diabetes Classiﬁcation using Radial Basis Function Network by Combining Cluster Validity Index and BAT Optimization with Novel Fitness Function,This paper discusses the use of cluster validity indices for diabetes diagnosis. The authors present a literature survey related to the problem and propose a methodology for identifying the optimal number of clusters. The experimental outcomes confirm the performance of the proposed methodology. The paper also reviews the performance of various neural network-based classifiers on the Pima Indians data set.,"diabetes diagnosis, Optimal number of clusters, Medical Diagnosis, Classiﬁcation, methodology, Diabetes, literature survey, Bat Algorithm, Radial Basis Function Networks, cluster validity indices, neural network-based classifiers","This paper presents a new model based on cluster validity index with radial basis neural network for classiﬁcation of diabetic patients data. The proposed model is tested on Pima Indians Diabetes data set and synthetic data sets, and experimental results proved that our approach performs better in terms of accuracy, sensitivity, speciﬁcity, classiﬁcation time, training time, network complexity and computational time compared to conventional radial basis function neural network."
Y. Ju,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
Y. Liao,TWO-STAGE AUTHENTICATION FOR WIRELESS NETWORKS USING DUAL SIGNATURE AND SYMMETRIC KEY PROTOCOL,"Wired networks differ from wireless networks in that they can support computationally intensive security protocols, have high bandwidth and offer high reliability. Strong authentication schemes can be applied to wired networks. Wireless networks on the other hand suffer from packet losses and bit errors, often have low bandwidth and have resource constraints such as computation overhead and storage.","Wireless Networks, Security, Symmetric Key Encryption, Authentication, Mutual Authentication, IKE Strong Authentication, Multi-server Environment",This paper proposes a secure dynamic id based remote user authentication scheme for multi-server environment. The scheme uses a dynamic id to authenticate users and provides security against various attacks. The scheme is efficient and can be used in various applications.
Y. Liu,Secure Robust and Imperceptible Algorithm for Watermarking Relational Databases,"This paper proposes a secure robust and imperceptible algorithm for watermarking relational databases. The algorithm divides the embedding algorithm into three phases: Watermark preparator, watermark position detector, and watermark embedder. The ownership identification issue is resolved by embedding owner's identity as watermark in Preparator phase.","imperceptible algorithm, Ownership identification, robust algorithm, Relational Database, watermarking, Watermark, Copyright protection, Proof of ownership, relational databases","The paper proposes a new robust secure and imperceptible embedding mechanism to resolve the two important concerns namely; owner identification and proof of ownership. The proposed mechanism involves encoding and decoding on numerical attribute of relational database in three phases; 1)Watermark preparator, 2)Watermark position detector and 3) Watermark Embedder or Detector."
Y. Tsuchihashi,Unique Local Features in Lip Images for Recognition,"The experiments are carried out from images taken with a camera that is used for the regular use. And the color features of a lip are not explored in the proposed research. Still the recognition system exploits the grayscale local features of a lip images and eﬃciently matches it with local features of another lip image. If the color properties of a lip image is explored for recognition along with local features, the accuracy values would increase further.","grayscale features, Lip Pattern Recognition, SIFT, lip recognition, color features, Biometric, Local Feature Extraction, local features, SURF",The paper presents the results of experiments on lip recognition using local features. The recognition system exploits the grayscale local features of lip images and achieves high accuracy. The authors suggest that exploring color properties of lip images could further improve the accuracy.
Y. Wang,Differential Evolution: A Survey of the State-of-the-Art ||| Iris Detection,"This paper presents a novel differential evolution (DE) variant, called CoBiDE, which includes two main components: covariance matrix learning and bimodal distribution parameter setting. CoBiDE has been tested on 25 benchmark test functions and a variety of real-world application problems. The experimental results suggest that the performance of CoBiDE is better than that of four other DE variants and three other state-of-the-art EAs. ||| For iris boundary detection, circular summation of intensity approach is used as proposed in [5]. The original grayscale image is blurred using median filter to remove external noise. After filtering, the contrast of image is enhanced to have sharp variation at image boundaries using histogram equalisation as shown in Figure 5(a). This contrast enhanced image is used for finding the outer iris boundary by drawing concentric circles (Figure 5(b) shows an example) of different radii from the pupil center and the intensities lying over the perimeter of the circle are summed up.","Adaptive Threshold, Bimodal distribution parameter setting, Circular Hough Transform, Spectrum Image, histogram equalisation, Differential evolution, iris recognition, Survey, circular summation of intensity, Iris Segmentation, State-of-the-Art, Connected Components, Iris detection, pupil boundary, Global numerical and engineering optimization, Covariance matrix learning, Optimization Algorithm","This paper presents a novel DE variant, CoBiDE, which includes two main components: covariance matrix learning and bimodal distribution parameter setting. CoBiDE has been tested on 25 benchmark test functions and a variety of real-world application problems. ||| The proposed system has been tested on two publicly available databases BATH and CASIA V3. From experimental analysis it has been observed that the system is capable of handling unconstrained scenarios as well. The system is capable of performing segmentation for unconstrained scenarios in significantly less time compared to Hough transform."
Y. Yu,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
Y.D. Ma,Iris Detection,"For iris boundary detection, circular summation of intensity approach is used as proposed in [5]. The original grayscale image is blurred using median filter to remove external noise. After filtering, the contrast of image is enhanced to have sharp variation at image boundaries using histogram equalisation as shown in Figure 5(a). This contrast enhanced image is used for finding the outer iris boundary by drawing concentric circles (Figure 5(b) shows an example) of different radii from the pupil center and the intensities lying over the perimeter of the circle are summed up.","Adaptive Threshold, Circular Hough Transform, Spectrum Image, histogram equalisation, iris recognition, circular summation of intensity, Connected Components, Iris detection, pupil boundary, Iris Segmentation",The proposed system has been tested on two publicly available databases BATH and CASIA V3. From experimental analysis it has been observed that the system is capable of handling unconstrained scenarios as well. The system is capable of performing segmentation for unconstrained scenarios in significantly less time compared to Hough transform.
Y.P. Sundriyal,Impact of Eurasian Snow Cover on Indian Summer Monsoon Rainfall over the Northwestern Himalayas,"The entire Indo-Himalayan region from northwest (Kashmir) to northeast (Assam) is facing prevalence of floods and landslides in recent years causing massive loss of property, human and animal lives, infrastructure, and eventually threatening tourist activities substantially. Extremely intense rainfall event of A.D. 2013 (between 15 and 17 June) kicked off mammoth flash floods in the Kedarnath area of Uttarakhand state, resulting in huge socioeconomic losses to the state and country.","Eurasian snow cover, extreme rainfall events, flash floods, gridded data sets, Himalayas, Arctic Oscillation, northwestern Himalayas, Indian summer monsoon rainfall","The study investigates ~100-year-long monthly rainfall and air temperature time series data for a selected grid covering most parts of Uttarakhand state. The results indicate that under warming scenario, JJ rainfall (over AS) may further increase with occasional extreme rainfall spells when AO index (March) is negative."
YU-FENG LIN,Robust Feature-Based Automated Multi-View Human Action Recognition System,"Automated human action recognition has the potential to play an important role in public security, for example, in relation to the multiview surveillance videos taken in public places, such as train stations or airports. This paper compares three practical, reliable, and generic systems for multiview video-based human action recognition, namely, the nearest neighbor classiﬁer, Gaussian mixture model classiﬁer, and the nearest mean classiﬁer. To describe the different actions performed in different views, view-invariant features are proposed to address multiview action recognition. These features are obtained by extracting the holistic features from different temporal scales which are modeled as points of interest which represent the global spatial-temporal distribution. Experiments and cross-data testing are conducted on the KTH, WEIZMANN, and MuHAVi datasets. The system does not need to be retrained when scenarios are changed which means the trained database can be applied in a wide variety of environments, such as view angle or background changes. The experiment results show that the proposed approach outperforms the existing methods on the KTH and WEIZMANN datasets.","feature extraction, points of interest extraction, background subtraction, machine learning, moving object localization, multi-view human action recognition, action recognition, Multi-view video, classiﬁcation","This paper proposes a robust feature-based automated multi-view human action recognition system. The system uses view-invariant features to address multi-view action recognition from a range of perspectives. The proposed approach labels the beginning and end of an action sequence in a video stream automatically and captures sequence motions and occlusions at a low computational cost. The system is evaluated using the KTH, WEIZMAN, and MuHAVi datasets and outperforms existing methods on the KTH and WEIZMANN datasets."
YU-KAI WANG,IoT-Based Wireless Polysomnography Intelligent System for Sleep Monitoring,"Polysomnography (PSG) is considered the gold standard in the diagnosis of obstructive sleep apnea (OSA). The diagnosis of OSA requires an overnight sleep experiment in a laboratory. However, due to limitations in relation to the number of labs and beds available, patients often need to wait a long time before being diagnosed and eventually treated. In addition, the unfamiliar environment and restricted mobility when a patient is being tested with a polysomnogram may disturb their sleep, resulting in an incomplete or corrupted test. Therefore, it is posed that a PSG conducted in the patient’s home would be more reliable and convenient. The Internet of Things (IoT) plays a vital role in the e-Health system. In this paper, we implement an IoT-based wireless polysomnography system for sleep monitoring, which utilizes a battery-powered, miniature, wireless, portable, and multipurpose recorder. A Java-based PSG recording program in the personal computer is designed to save several bio-signals and transfer them into the European data format. These PSG records can be used to determine a patient’s sleep stages and diagnose OSA. This system is portable, lightweight, and has low power-consumption. To demonstrate the feasibility of the proposed PSG system, a comparison was made between the standard PSG-Alice 5 Diagnostic Sleep System and the proposed system. Several healthy volunteer patients participated in the PSG experiment and were monitored by both the standard PSG-Alice 5 Diagnostic Sleep System and the proposed system simultaneously, under the supervision of specialists at the Sleep Laboratory in Taipei Veteran General Hospital. A comparison of the results of the time-domain waveform and sleep stage of the two systems shows that the proposed system is reliable and can be applied in practice. The proposed system can facilitate the long-term tracing and research of personal sleep monitoring at home.","sleep monitoring, wireless, Internet of Things, wireless PSG, JAVA, Polysomnography (PSG), IoT","This paper proposes an IoT-based wireless polysomnography system for sleep monitoring, which utilizes a battery-powered, miniature, wireless, portable, and multipurpose recorder. The system is designed to save several bio-signals and transfer them into the European data format, allowing for the determination of a patient’s sleep stages and diagnosis of OSA. The proposed system is compared to the standard PSG-Alice 5 Diagnostic Sleep System and shows reliable results, making it a viable option for long-term tracing and research of personal sleep monitoring at home."
YVR Reddy,Understanding Helicoverpa armigera Pest Population Dynamics related to Chickpea Crop Using Neural Networks,Insect pests are a major cause of crop loss globally. Pest management will be effective and efficient if we can predict the occurrence of peak activities of a given pest. Research efforts are going on to understand the pest dynamics by applying analytical and other techniques on pest surveillance data sets. In this study we make an effort to understand pest population dynamics using Neural Networks by analyzing  pest surveillance data set of Helicoverpa armigera or Pod borer on chickpea (Cicer arietinum L.)  crop. The results show that neural network method successfully predicts the pest attack incidences for one week in advance.,"Climatic Data, Pest Population Dynamics, Neural Networks, Pest Surveillance Databases, Chickpea Crop, Helicoverpa armigera, Neural Network, Pest Attack Prediction","The experimental results show that it is possible to predict the pest attack with high probability for one week in advance. These predictions would help the farmers in pest management programs by avoiding the crop losses with improved environment quality, as it can avoid unnecessary sprays of chemical pesticides."
Ya Su,Opposing Actions of Fibroblast and Cardiomyocyte Smad3 Signaling in the Infarcted Myocardium,"Transforming growth factor (TGF)–βs are highly pleiotropic mediators with critical roles in regulating cellular phenotype and function in embryonic development, tissue homeostasis, and disease. Normal tissues contain stores of latent TGF-β bound to the extracellular matrix through its association with a large binding protein, the latent TGF-β binding protein. Tissue injury is associated with marked induction of TGF-β isoforms and activation of TGF-β signaling cascades. Parenchymal cells, extravasated leukocytes, and platelets synthesize and release large amounts of TGF-β in the injury site. Reactive oxygen species, proteases, matricellular proteins, and integrins cooperate to trigger the release of bioactive TGF-β from the latent stores. Subsequent binding of the active TGF-β dimer to the type II TGF-β receptor, followed by transphosphorylation of the type I receptor, triggers the TGF-β signaling response. The cellular effects of TGF-β are mediated through a canonical pathway involving a series of intracellular effectors, the Smads, or through activation of noncanonical signaling cascades. Activation of TGF-β signaling induces phosphorylation of the receptor-activated Smads, Smad2 and Smad3, which can form heteromeric complexes with the common Smad, Smad4. These complexes are transported to the nucleus, where they regulate gene transcription. TGF–β receptors and Smads are ubiquitously expressed by all cell types. Thus, all cells are responsive to the actions of TGF-β. Cardiac injury is associated with the marked induction of TGF-β and activation of TGF-β cascades. Our laboratory and other investigators have documented activation of Smad2 and Smad3 signaling in the infarcted myocardium, localized in both cardiomyocytes and interstitial cells. In isolated cardiac fibroblasts, Smad3 signaling accentuates myofibroblast transdifferentiation and stimulates a matrix-preserving program. In a model of reperfused infarction, global loss of Smad3 attenuated remodeling after infarction. However, considering the ubiquitous expression of Smad3 in all cell types, the cell biological basis for the actions of Smad3 in the infarcted heart remains unknown. Our study dissects the cell-specific actions of Smad3 signaling in the infarcted myocardium by developing and studying mice with cell-specific loss of Smad3 in activated fibroblasts and cardiomyocytes. It is surprising that fibroblast-specific loss of Smad3 worsened remodeling after infarction, resulting in accentuated chamber dilation. The deleterious consequences of fibroblast-specific Smad3 loss reflected unrestrained fibroblast proliferation, defective scar remodeling, and perturbed organization of myofibroblast arrays in the border zone. Smad3 signaling regulated fibroblast function, activating integrin-mediated nicotinamide adenine dinucleotide phosphate (NADPH) oxidase (NOX)–2 expression. In contrast, cardiomyocyte-specific loss of Smad3 protected the infarcted heart from dysfunction after infarction. The protective effects of cardiomyocyte-specific Smad3 loss were associated with attenuated cardiomyocyte apoptosis in remodeling myocardium and accompanied by decreased NOX2 levels, reduced nitrosative stress, and decreased matrix metalloproteinase (MMP)–2 expression.","SMAD, fibroblast, heart failure, cardiomyocyte, remodeling","This study investigates the role of Smad3 in cardiac fibroblasts following myocardial infarction. Using a mouse model with fibroblast-specific Smad3 deletion (FS3KO), the researchers found that loss of Smad3 in fibroblasts exacerbated dilative remodeling and worsened systolic dysfunction after both reperfused and nonreperfused infarction.  While acute infarct size was not affected, FS3KO mice exhibited larger scars, increased myofibroblast density, and enhanced myofibroblast proliferation. These findings suggest that Smad3 plays a protective role in cardiac fibroblasts and its loss contributes to adverse cardiac remodeling after infarction."
"Yadav, A., Nacher, V., & Woodward, C.",Children's interaction with touchscreen devices: Performance and validity of Fitts' law,"This study investigates whether the interaction between children and a touchscreen obeys Fitts' law, which describes the relationship between the index of difficulty and movement time. The study involved 30 children aged 4-10 years who performed a touchscreen task using a smartphone app. The results show that the ability of children to acquire onscreen targets improves with age and depends on the touchscreen gesture used.","movement time, Fitts' law, children, touchscreen, smartphone, movement task, index of difficulty, touchscreen interaction","This study aimed to assess the ability of children to acquire onscreen targets while using smartphones and determine if their interaction with smartphones follows Fitts' law. The study found that the interaction of children with smartphones does not obey Fitts' law, and recommends that smartphone apps for children be developed taking into consideration their ability to acquire onscreen targets."
Yakov Usoltsev,Generation of an EDS Key Based on a Graphic Image of a Subject’s Face Using the RC4 Algorithm,"Modern facial recognition algorithms make it possible to identify system users by their appearance with a high level of accuracy. In such cases, an image of the user’s face is converted to parameters that later are used in a recognition process. On the other hand, the obtained parameters can be used as data for pseudo-random number generators. However, the closeness of the sequence generated by such a generator to a truly random one is questionable. This paper proposes a system which is able to authenticate users by their face, and generate pseudo-random values based on the facial image that will later serve to generate an encryption key. The generator of a random value was tested with the NIST Statistical Test Suite. The subsystem of image recognition was also tested under various conditions of taking the image. The test results of the random value generator show a satisfactory level of randomness, i.e., an average of 0.47 random generation (NIST test), with 95% accuracy of the system as a whole.","random number generation, digital signatures, authenticity, neural networks, digital signature, python, NIST test battery, computer vision, programming, algorithms, cryptography, facial recognition, security","This paper proposes a system for authenticating users by their face and generating pseudo-random values based on facial images. The system uses a combination of mathematical procedures for facial recognition and a pseudo-random number generator. The generator of a random value was tested with the NIST Statistical Test Suite, and the subsystem of image recognition was tested under various conditions of taking the image. The test results show a satisfactory level of randomness and 95% accuracy of the system as a whole."
Yang Cao,Mobile Edge Computing for Big Data-Enabled Electric Vehicle Charging,"As one of the key drivers of smart grid, Electric Vehicles (EVs) are environment-friendly to alleviate CO2 pollution. Big data analytics could enable the move from Internet of EVs, to optimized EV charging in smart transportation. In this paper, we propose a Mobile Edge Computing (MEC) based system, in line with a big data-driven planning strategy on which Charging Station (CS) to charge.","Big Data, MEC Based System, EV Charging, Communication Technologies, Network Entities, Smart Transportation, Smart Cities, Decentralized Charging Management, Centralized Charging Management, Charging Planning, Smart Grid, Big Data-Enabled Electric Vehicle Charging, Mobile Edge Computing","This paper proposes a Mobile Edge Computing (MEC) based system for big data-enabled electric vehicle charging. The system integrates big data analytics to opportunistically disseminate the outcome from a Global Controller and collect driving big data from mobile clients. The MEC servers implement big data mining and aggregation in a decentralized way, alleviating the size of data to be processed by the Global Controller."
Yann Busnel,Cube Sampled K-Prototype Algorithm for Clustering,This paper proposes a novel algorithm called Cube Sampled K-Prototype for clustering mixed data types. The algorithm integrates the K-Means and K-Modes algorithms and uses cube sampling to reduce the computational complexity. The proposed algorithm is compared with other clustering algorithms and shows better performance in terms of clustering accuracy.,"Mixed Data Types, Cube Sampling, Principal Component Analysis, K-Prototype Clustering, Clustering Accuracy, Sampling, Clustering, K-Prototype",This paper proposes a probabilistic sampling technique called cube sampling along with K-Prototype clustering. Cube sampling is used because of its accurate sample selection. The novelty of this work is in obtaining the crucial inclusion probabilities for cube sampling using Principal Component Analysis (PCA).
Yanqing Wen,Fractional-Order BP Algorithm for Training Fractional FNNs,"Fractional calculus has been found to be a promising area of research for information processing and modeling of some physical systems. In this paper, we propose a fractional gradient descent method for the backpropagation (BP) training of neural networks. In particular, the Caputo derivative is employed to evaluate the fractional-order gradient of the error defined as the traditional quadratic energy function. The monotonicity and weak (strong) convergence of the proposed approach are proved in detail. Two simulations have been implemented to illustrate the performance of presented fractional-order BP algorithm on three small datasets and one large dataset. The numerical simulations effectively verify the theoretical observations of this paper as well.","BP algorithm, Caputo derivative, fractional-order neural networks, Backpropagation, Fractional calculus, Caputo fractional-order derivative, training FNNs, Monotonicity, Convergence","This paper proposes a fractional gradient descent method for the backpropagation (BP) training of neural networks, employing the Caputo derivative to evaluate the fractional-order gradient of the error. The monotonicity and weak (strong) convergence of the proposed approach are proved in detail, and numerical simulations are implemented to illustrate its performance on various datasets."
Yanti Andriyani,Agile Processes in Software Engineering and Extreme Programming,"The 18th XP conference was held 2017 in the wonderful city of Cologne, Germany. In the spirit of past XP conferences, XP 2017 was a place where researchers and practitioners met to exchange new ideas and present their work. These proceedings contain the full research papers, short research papers, and doctoral symposium papers presented at the conference.","Teams, Reflection, Reflective practice, Levels of reflection, Agile software development, Agile retrospective meeting","The conference featured 46 research papers, with 14 accepted as full research papers and 6 as short research papers. The selected papers cover a wide range of agile techniques and approaches, including empirical studies and technology studies relevant to both researchers and practitioners."
Yatindra Nath Singh,A Correlation Model for Sensor Networks,"Wireless sensor networks (WSN) are densely deployed to promise the fine-grain monitoring in various applications. For example, it may be as high as 20 nodes/m3 or more [1]. Due to high density of sensor nodes, spatially correlated information is observed and transmitted by surrounding sensor nodes once an interest of event detected. Thus, there exists spatial correlation among the sensor observations. The spatial correlation brings significant potential advantages along with collaborative nature of the WSN in energy-efficient design of communication protocols. This paper presents a novel spatial correlation model for wireless sensor networks. Based on sensor coverage model and location of sensor nodes, a spatial correlation function is derived to describe the correlation characteristics of measurements observed by sensor nodes. The case studies using correlation function are performed to study the correlation relationship between sensor nodes. Finally, based on case studies, their results, and discussions, a correlated cell construction algorithm is proposed and possible approaches are explored to exploit spatial correlation for efficient medium access and clustering protocols for WSN.","Clustering protocol, spatial correlation, sensor networks, data aggregation, Wireless Sensor Networks, correlation model, MAC protocol, distributed source coding",This paper presents a novel spatial correlation model for wireless sensor networks. The model derives a spatial correlation function to describe the correlation characteristics of measurements observed by sensor nodes. The case studies using correlation function are performed to study the correlation relationship between sensor nodes. A correlated cell construction algorithm is proposed and possible approaches are explored to exploit spatial correlation for efficient medium access and clustering protocols for WSN.
Yayati Gupta,Cost Effective Influence Maximisation ||| Cost Eﬀective Inﬂuence Maximisation ||| Leveraging Network Similarity Measures for Recommendation Systems ||| Modeling Memetics using Edge Diversity ||| Pseudo-Cores: The Terminus of an Intelligent Viral Meme's Trajectory ||| Quantifying Influential Communities in Information Diffusion Dynamics ||| Shifting Behaviour of Users: Towards Understanding the Fundamental Law of Social Networks ||| Understanding Spreading Patterns on Social Networks Based on Network Topology,"In the context of virality prediction, many researchers have leveraged the existence of a core-periphery structure in a network to identify the super-spreaders of information. Topologically, the nodes in the core of a network are the most eﬃcient spreaders. However, these nodes are less susceptible, i.e., unlikely to be inﬂuenced by the periphery nodes. Consequently, large payoﬀs are required to market information (ideas, products, memes, etc.) via them. In this paper, we show the presence of several non-core nodes whose spreading power is close to that of the core nodes. ||| With the growth of e-commerce websites, efficient recommendation systems are desired to reduce the turnaround time for servicing a customer. This study focuses on understanding the various techniques and algorithms that are used to model real-life recommendation systems. We present a recommendation engine for Amazon products that uses collaborative filtering (CF). Given a list of users and their reviews of Amazon products, our CF-based recommendation engine generates a ranked list of the top k products for individual users. The generated recommendations are based on the preferences of similar users and past purchases. ||| The study of meme propagation and the prediction of meme trajectory are emerging areas of interest in the field of complex networks research. In addition to the properties of the meme itself, the structural properties of the underlying network decides the speed and the trajectory of the propagating meme. ||| Comprehending the virality of a meme can help scientists address problems pertaining to disciplines like epidemiology and digital marketing. Therefore, it does not come as a surprise that meme virality stands out as an integral component of research in complex networks, today. In this paper, we explore the possibility of artificially inducing virality in a meme by intelligently directing a meme’s trajectory in the network. ||| This paper studies the information diffusion process in networks and quantifies influential communities. The authors propose a method to study the intertwining of community structure and core-periphery structure. ||| Social Networking Sites (SNSs) are powerful marketing and communication tools. There are hundreds of SNSs that have entered and exited the market over time. The coexistence of multiple SNSs is a rarely observed phenomenon. Most coexisting SNSs either serve different purposes for its users or have cultural differences among them. The introduction of a new SNS with a better set of features can lead to the demise of an existing SNS, as observed in the transition from Orkut to Facebook. The paper proposes a model for analyzing the transition of users from one SNS to another, when a new SNS is introduced in the system. The game theoretic model proposed considers two major factors in determining the success of a new SNS. The first being time that an old SNS gets to stabilise. We study whether the time that a SNS like Facebook received to monopolize its reach had a distinguishable effect. The second factor is the set of features showcased by the new SNS. The results of the model are also experimentally verified with data collected by means of a survey.","meme virality, Information diﬀusion, cost-effective, game theory, model-based CF, Meme Propagation, collaborative filtering, matrix factorization, modeling, social networking, social networks, K-Shell Decomposition, similarity metrics, hill climbing algorithms, Virality, bipartite graph, information spreading, artificially inducing virality, recommendation systems, k-shell decomposition, Game Theoretic Model, SCCP networks, social network analysis, core-periphery structure, coreness, viral marketing, Amazon electronics reviews, Inﬂuence maximisation, Network Structure, Core-periphery structure, information diffusion, entropy, recommendation system, complex networks research, Cascading Pattern, tie strength, singular value decomposition, information propagation, complex networks, meme propagation models, community structure, Pseudo-Cores, memory-based CF, networks, meme propagation, Diffusive Shift, Social Networking Sites, network topology, social status, influence maximisation","A cost-effective information diffusion strategy has been proposed that only requires the neighborhood information (friendship connections) of a node to make a meme go viral. Digital marketing agencies with a limited advertising budget can use the proposed strategy to popularise their product. ||| This paper proposes a cost-eﬀective strategy to make a meme reach the super-spreaders without the need for global information. The proposed hill-climbing based strategy can be eﬀectively used with both, global as well as local characteristics of the nodes in a network. In terms of the cost metric, it outperforms the conventional independent cascade model by more than 5 times for the core and 2 times for the non-core super-spreaders. ||| This paper presents a recommendation engine for Amazon products that uses collaborative filtering (CF). The engine generates a ranked list of the top k products for individual users based on the preferences of similar users and past purchases. The authors also propose a graph-based recommendation technique that generates a list of the most similar products using network-based local similarity metrics. ||| The paper proposes a framework for studying meme propagation patterns using a synthetic network and a spreading model based on the diversity of edges in the network. The framework is validated against the real-world spreading of the Higgs boson meme on Twitter. ||| The authors propose a new approach to decompose a network into multiple shells of inﬂuence and investigate the properties of all the shells in a network. They observe that the core is the shell with the least diameter and that the high density of the core is one of the reason for the high spreading power of the core. ||| The paper investigates the information diffusion process in networks and proposes a method to quantify influential communities. The authors show that core nodes are densely packed in the same community and that the core-periphery structure and community structure are intertwined. ||| This paper proposes a model for analyzing the transition of users from one Social Networking Site (SNS) to another when a new SNS is introduced in the system. The model considers two major factors in determining the success of a new SNS: the time an old SNS gets to stabilize and the set of features showcased by the new SNS. The results of the model are experimentally verified with data collected by means of a survey. ||| This paper proposes a novel framework for studying meme propagation patterns based on network topology. The framework includes a synthetic network that simulates a real-world network and acts as a testbed for meme simulation. The proposed spreading model is based on the diversity of edges in the network and is validated by the propagation of the Higgs boson meme on Twitter as well as many real-world social networks."
Yew-Soon Ong,A fast pruned-extreme learning machine for classification problem ||| A Multi-Facet Survey on Memetic Computation ||| Combining Global and Local Surrogate Models ||| Consistencies and Contradictions of Performance Metrics in Multiobjective Optimization ||| Generalizing Surrogate-Assisted Evolutionary Computation ||| Local Surrogate Modeling for Parallel Evolutionary Optimization of Computationally Expensive Problems ||| Meta Lamarckian ||| Multifactorial Optimization: A Paradigm Inspired by Multifactorial Inheritance ||| Scalable GPs ||| Wrapper-Filter Feature Selection Algorithm Using A Memetic Framework,"Extreme learning machine (ELM) represents one of the recent successful approaches in machine learning, particularly for performing pattern classification. One key strength of ELM is the significantly low computational time required for training new classifiers since the weights of the hidden and output nodes are randomly chosen and analytically determined, respectively. ||| This paper presents a comprehensive multi-facet exposition of recent research in memetic computation. It begins with a brief review on the early manifestations of memetic computation within the context of evolutionary computation, and then takes a focus on the recent developments of hybrids and adaptive hybrids. The paper highlights “Memetic Automaton,” a natural progression toward establishing “meme” as the focal point of memetic computation and pinpoints some noteworthy emerging research trends in the field that have remained under-explored. ||| An important consideration of Multiobjective Optimization (MOO) is the quantitative metrics used for defining the optimality of different solution sets, which is also the basic principle for the design and evaluation of MOO algorithms. ||| Using surrogate models in evolutionary search provides an efficient means of handling today’s complex applications plagued with increasing high-computational needs. Recent surrogate-assisted evolutionary frameworks have relied on the use of a variety of different modeling approaches to approximate the complex problem landscape. ||| This paper presents a local surrogate modeling algorithm for parallel evolutionary optimization of computationally expensive problems. The algorithm uses radial basis function networks to construct local surrogate models in the spirit of transductive inference. The proposed algorithm can be efficiently parallelized on grid computing architectures and does not compromise on the intrinsic parallelism offered by evolutionary algorithms. ||| The design of evolutionary algorithms has typically been focused on efficiently solving a single optimization problem at a time. Despite the implicit parallelism of population-based search, no attempt has yet been made to multitask, i.e., to solve multiple optimization problems simultaneously using a single population of evolving individuals. Accordingly, this paper introduces evolutionary multitasking as a new paradigm in the field of optimization and evolutionary computation. We first formalize the concept of evolutionary multitasking and then propose an algorithm to handle such problems. The methodology is inspired by bio-cultural models of multifactorial inheritance, which explain the transmission of complex developmental traits to offspring through the interactions of genetic and cultural factors. Furthermore, we develop a cross-domain optimization platform that allows one to solve diverse problems concurrently. The numerical experiments reveal several potential advantages of implicit genetic transfer in a multitasking environment. Most notably, we discover that the creation and transfer of refined genetic material can often lead to accelerated convergence for a variety of complex optimization functions. ||| The vast quantity of information brought by big data as well as the evolving computer hardware encourages success stories in the machine learning community. In the meanwhile, it poses challenges for the Gaussian process (GP) regression, a well-known non-parametric and interpretable Bayesian model, which suffers from cubic complexity to data size. To improve the scalability while retaining desirable prediction quality, a variety of scalable GPs have been presented. But they have not yet been comprehensively reviewed and analyzed in order to be well understood by both academia and industry. ||| This paper presents a hybrid genetic algorithm for feature selection, which combines the strengths of filter and wrapper methods. The algorithm uses a filter ranking method to select the most relevant features and a local search strategy to improve the solution. The authors investigate three different local search strategies and compare their performance on several benchmark and biological datasets.","Discrete Optimization, Extreme learning machine (ELM), Capacity, surrogate-assisted evolutionary algorithms, Hypervolume, Gaussian process regression, multiagent system, Transductive inference, Performance Metrics, Local surrogate modeling, metamodels, Multifactorial Inheritance, Evolutionary Algorithms, sparse approximations, adaptive hybrids, Evolutionary Multitasking, Hidden Node Size, memetic algorithms, memetic automaton, Multiobjective Optimization, surrogate-assisted evolutionary computation, memetic algorithms in uncertain environments, Feedforward networks, local approximations, evolutionary optimization, Statistical Relevance Measures, Gaussian Processes, Memetic Algorithm, Pattern classification, memetic computation, surrogate models, Gain Ratio, multidisciplinary optimization, Radial basis function networks, Filter Ranking Method, Wrapper, optimization, evolution and learning, Multifactorial Optimization, big data, Approximation models, surrogate-assisted memetic algorithms, Adaptive memetic algorithms, surrogate modeling, Parallel evolutionary optimization, Filter, memes imitation, Diversity, computationally expensive problems, Genetic Algorithm, Scalable GPs, Pruned ELM, hybrids, evolutionary search, memetic algorithm design issues, Continuous Optimization, Memetic Computation, Feature Selection, multiobjective memetic algorithms, Hybrid Genetic Algorithm, Local Search Strategy, Extreme Learning Machine, hybridization, approximation techniques, scalability, Generalization Ability, Chi-Square, Relief, Convergence","This paper presents a pruned-ELM (P-ELM) algorithm as a systematic and automated approach for designing ELM classifier network. P-ELM uses statistical methods to measure the relevance of hidden nodes and provides a systematic approach for designing the network architecture of the ELM classifier. ||| The paper presents a comprehensive survey of recent research in memetic computation, including simple hybrids, adaptive hybrids, and memetic automaton. It highlights the importance of hybridization in memetic computation and discusses the main issues in simple hybrids, including the types of population-based search methods and reﬁnement procedures, the levels of hybridization, modes of inheritance as well as the types of domain-speciﬁc information incorporated into simple hybrids. ||| This paper investigates the relationships among representative group metrics in Multiobjective Optimization, including Generational Distance (GD), ϵ-indicator (I1ϵ+), Spread (∆), Generalized Spread (∆∗), Inverted Generational Distance (IGD) and Hypervolume (HV). Experimental results indicated that these six metrics show high consistencies when Pareto fronts (PFs) are convex, whereas they show certain contradictions on concave PFs. ||| This paper describes a generalization of surrogate-assisted evolutionary frameworks for optimization of problems with objectives and constraints that are computationally expensive to evaluate. The generalized evolutionary framework unifies diverse surrogate models synergistically in the evolutionary search. ||| The paper presents a parallel evolutionary optimization algorithm that uses surrogate models to solve computationally expensive design problems with general constraints on a limited computational budget. The algorithm combines an evolutionary algorithm with a feasible sequential quadratic programming solver and uses a trust-region approach to leverage exact and surrogate models during local search. ||| This paper introduces evolutionary multitasking as a new paradigm in the field of optimization and evolutionary computation. It proposes an algorithm to handle multiple optimization problems simultaneously using a single population of evolving individuals, inspired by bio-cultural models of multifactorial inheritance. The numerical experiments reveal several potential advantages of implicit genetic transfer in a multitasking environment. ||| This paper reviews state-of-the-art scalable GPs involving two main categories: global approximations which distillate the entire data and local approximations which divide the data for subspace learning. Recent advances for improving the scalability and capability of scalable GPs are reviewed. Finally, the extensions and open issues regarding the implementation of scalable GPs in various scenarios are reviewed and discussed to inspire novel ideas for future research avenues. ||| The paper proposes a hybrid genetic algorithm for feature selection, which combines the strengths of filter and wrapper methods. The algorithm uses a filter ranking method to select the most relevant features and a local search strategy to improve the solution. The authors investigate three different local search strategies and compare their performance on several benchmark and biological datasets."
Yida Gou,Fractional-Order BP Algorithm for Training Fractional FNNs,"Fractional calculus has been found to be a promising area of research for information processing and modeling of some physical systems. In this paper, we propose a fractional gradient descent method for the backpropagation (BP) training of neural networks. In particular, the Caputo derivative is employed to evaluate the fractional-order gradient of the error defined as the traditional quadratic energy function. The monotonicity and weak (strong) convergence of the proposed approach are proved in detail. Two simulations have been implemented to illustrate the performance of presented fractional-order BP algorithm on three small datasets and one large dataset. The numerical simulations effectively verify the theoretical observations of this paper as well.","BP algorithm, Caputo derivative, fractional-order neural networks, Backpropagation, Fractional calculus, Caputo fractional-order derivative, training FNNs, Monotonicity, Convergence","This paper proposes a fractional gradient descent method for the backpropagation (BP) training of neural networks, employing the Caputo derivative to evaluate the fractional-order gradient of the error. The monotonicity and weak (strong) convergence of the proposed approach are proved in detail, and numerical simulations are implemented to illustrate its performance on various datasets."
Yide Zhang,Adaptive Lag Synchronization of Memristive Neural Networks with Unknown Connection Weights,"This paper investigates the adaptive lag synchronization of memristive neural networks with unknown connection weights. A new fuzzy model is proposed to simplify memristive systems, and the idea of PDC is applied to achieve synchronization between subsystems. The adaptive lag synchronization algorithm is designed, and the update law for the connection weights and controller gain is derived. The stability of the closed-loop system is analyzed, and the synchronization error is shown to be globally exponentially convergent to zero.","Adaptive lag synchronization, neural networks, memristor, synchronization error, memristive neural networks, PDC, fuzzy model, unknown connection weights, pseudorandom number generator (PRNG)","This paper presents a new approach to the adaptive lag synchronization of memristive neural networks with unknown connection weights. The proposed fuzzy model simplifies the memristive systems, and the PDC idea is applied to achieve synchronization between subsystems. The adaptive lag synchronization algorithm is designed, and the update law for the connection weights and controller gain is derived. The stability of the closed-loop system is analyzed, and the synchronization error is shown to be globally exponentially convergent to zero."
Ying Grace Li,First-­in-­Human Study of Bamlanivimab in a Randomized Trial of Hospitalized Patients With COVID-­19,"This first-in-human study in hospitalized patients with COVID-19 was supported by studies assessing in vitro viral neutralization combined with a single-dose non-human primate PK study. The nonclinical safety package to support subsequent studies included tissue cross-reactivity studies on human, rat, and monkey tissues and an in vivo toxicology study.  A complete physical examination was conducted at the screening visit, and one of three bamlanivimab doses or placebo was administered i.v. at the baseline visit (D1) with infusion rates as follows: bamlanivimab 700 mg (50 mL) administered 100 mL/hr for 30 minutes; 2,800 mg (75 mL) administered 100 mL/hr for 45 minutes; and 7,000 mg administered 100 mL/hr for 60 minutes. Placebo infusion was 0.9% normal saline, administered at the same volume and rate as the corresponding bamlanivimab dose cohort. Safety and tolerability were reviewed for sentinel participants up to 24 hours after dosing, at which point the investigators and sponsor team determined whether safety and tolerability were acceptable to continue with dosing subsequent participants. The decision to dose the next cohort was made when all participants from the previous cohort had been dosed and safety data assessed for at least 4 days after the i.v. infusion by the investigators and sponsor team in consultation with an independent safety assessment committee. Blood samples were obtained for assessment of exploratory biomarkers, serology, clinical laboratory assessments, and PD on days 1, 3, 7, 11, 15, 22, and 29, and every 7 days until discharge or day 60, if still an inpatient. Samples for the virology assay were collected using nasopharyngeal (preferred) or mid-turbinate methods. Blood samples obtained for PK analyses were assessed on days 1 (pre-infusion and just before end of infusion), 4, 15, and 29, and follow-up visits up to day 60. Symptom-related physical examinations and assessments of clinical symptoms were performed on days 1, 2, 3, 4, 7, 11, 15, 22, and 29, and the day of discharge from the hospital, with additional follow-up examinations every 7 days thereafter until day 60 if the patient was not discharged from the hospital by day 29. Participants’ clinical status and concurrent procedures of special interest were recorded, including limitation on activities due to COVID-19 and any requirements for the following procedures of special interest, such as ongoing hospital medical care, supplemental oxygen, noninvasive ventilation or a high flow oxygen device, mechanical ventilation, extracorporeal membrane oxygenation, additional organ support, or consciousness status using alert, consciousness, verbal, pain, unresponsive scale. Hospitalization events were recorded, including dates of hospital admission and discharge, admission to the intensive care unit (ICU), discharge from the ICU, and discharge location including to an extended care facility or home. Outcomes The primary objective was to assess safety and tolerability, including adverse events (AEs), serious adverse events (SAEs), and discontinuations due to AEs. Other objectives included PKs (e.g., mean concentration at day 29); PD viral load, area under the response time curve (AUC, from day 1 to day 29), and change from baseline time course; total symptom score; time to symptom resolution; duration of hospitalization; National Institute of Allergy and Infectious Diseases (NIAID), World Health Organization (WHO) scales, and National Early Warning Score (NEWS2); and analysis of viral resistance. Any hypothesis tests were conducted for treatment comparisons without adjustment for multiplicity except for the evaluation of treatment effect on endogenous antibody titers. Success for the trial was claimed using a Bayesian criterion if any of the 3 bamlanivimab doses had at least 60% probability to reduce at least 30% mean AUC (28-day viral load) over placebo.",,"This first-in-human study evaluated the safety, tolerability, pharmacokinetics, clinical course, and viral dynamics of bamlanivimab, a fully human neutralizing monoclonal antibody targeting SARS-CoV-2, in hospitalized patients with moderate to severe COVID-19.  The study found bamlanivimab to be safe and well-tolerated, with no serious adverse events or deaths reported.  Further research is needed to determine the efficacy of bamlanivimab in treating COVID-19."
Yinghong Susan Wei,h-value touch points between IoT mobile Apps and their users,"Business models help firms to set a right path to create, grow and retain their business value. While previous research shows that business model affects the performance of entrepreneurial firms, there is still limited understanding about how likely different business model selections of Internet of Things (IoT) startup firms retain their value and whether the venture capital investment intensity does play any role in the business model’s value retention process.","Instrumental variable regression, Business model, Value retention, Mobile application, venture capital, mobile Apps, China, Internet of things, IoT","This study investigates the impact of e-business models on value retention for start-ups in the Internet of Things (IoT) and Mobile Applications (Apps) business. The study finds that e-efficiency-centred and complementarities-centred e-business models increase value retention, while lock-in centred e-business model reduces value retention. The study also finds that venture capitalist’s involvement moderates the relationship between e-business models and value retention."
Yogendra Singh Rajpoot,EXPERIMENTAL STUDY OF REGENERATIVE BRAKING SYSTEM (RBS),"In this era, the automobile sector is facing a major challenge to reduce consumption of fuel and greenhouse gases emission, this is often because limited fuel reserves and continuous degrade in air quality. An experimental setup is made for the current study to reduce the loss of energy by reusing it. In this present study, an alternator is connected to the driver shaft through chain and sprocket. When brakes are applied to slow the vehicle down or make it come to a halt, the alternator is activated with an electromagnetic clutch, and the energy lost during braking is utilized to generate electrical energy.","Generator, Automobile, Regenerative braking, Electromagnetic clutch, Energy recovery system","This paper presents an experimental study of regenerative braking system (RBS) to reduce energy loss during braking. An experimental setup is designed to reuse the energy lost during braking by activating an alternator with an electromagnetic clutch. The study shows that 16.32% of brake energy was recovered, and the current from the alternator increases with engine speed."
Yongfei Yang,History Matching of Naturally Fractured Reservoirs Using a Deep Sparse Autoencoder,"This work proposes a new characterization method and a method to reduce dimensionality for history matching of naturally fractured reservoirs. The forward simulator is modeled after the EDFM given its computational efficiency. The fracture network can be represented with length, orientation, and position, including large-scale fractures and small-scale fractures.","History matching, characterization method, EDFM, Naturally fractured reservoirs, Deep sparse autoencoder, dimensionality reduction, fracture network","This paper proposes a new characterization method for the multiscale fracture network, and a powerful dimensionality-reduction method by means of an autoencoder for model parameters. The characterization method of the fracture network is dependent on the length, orientation, and position of fractures, including large-scale and small-scale fractures."
Yosr Jarraya,A Simple Dynamic Decision Making System for Filtering Out DoS Attacks in SDN,The Software Deﬁned Networking (SDN) paradigm is expected to heavily integrate into future networks. Enterprises have already started migrating their networks to SDNs. Billions of smart devices constituting the Internet of Things will be connected to these high speed networks and will be communicating over these networks. The ubiquity of these networks along with the user devices connected to them becomes of paramount importance for the end users. This work presents a SDN switch based module to detect a Denial Of Service attack on the network and its connected components.,"Trafﬁc Filtering, Denial of Service Attacks, SDN, Internet of Things, DoS attacks, packet filtering, Software Deﬁned Networks, decision making system","This paper discusses the different Denial of Service attacks that are possible on Software Deﬁned Networks, along with various methods to identify and detect such attacks, and finally the methods to mitigate these attacks."
Your Name,A Robust Watermarking Technique for Ownership Proof and Information Recovery in Relational Databases ||| Event Detection in Soccer Videos Using 3D Convolutional Neural Networks ||| Slow Rate Denial of Service Attacks Against HTTP/2 and Detection,"Digital databases serve as the vehicles for compiling, disseminating and utilizing all forms of information that are pivotal for societal development. A major challenge that needs to be tackled is to recover crucial information that may be lost due to malicious attacks on database integrity. In the domain of digital watermarking, past research has focused on robust watermarking for establishing database ownership and fragile watermarking for tamper detection. In this paper, we propose a new technique for multiple watermarking of relational databases that provides a unified solution to two major security concerns; ownership identification and information recovery. ||| This paper presents a novel approach for event detection in soccer videos using 3D convolutional neural networks. The proposed method, called GAWAC, is designed to capture both spatial and temporal dependencies between frames of a video. The model is trained on a large dataset of soccer videos, called Soccer-8k, which contains 7942 action clips of six different soccer actions. The results show that GAWAC outperforms other state-of-the-art models on the Soccer-8k dataset. ||| HTTP/2 is a newly standardized protocol designed to efficiently utilize the TCP’s transmission rate and has other advantages compared to HTTP/1.1. However its threat vectors are not completely understood yet. Our contribution in this paper is threefold. First we describe few new threat vectors of HTTP/2 which are Slow Rate DoS attacks and can be launched by injecting specially crafted HTTP requests. We perform an empirical evaluation of these attacks against popular web servers and report that majority of web servers are vulnerable to these attacks. We also test the effectiveness of proposed attacks using both clear text and encrypted HTTP/2 requests and find that the attack is effective independent of the request type. Second we compare structurally similar attacks with HTTP/1.1 and report that HTTP/2 has more threat vectors compared to its predecessor. Third we propose an anomaly detection scheme which uses chi-square (χ2) test between traffic profiles generated in normal and attack scenarios to detect these attacks.","ownership proof, Vulnerability Assessment, Right Protection, Action Recognition, HTTP/2, 3D Convolutional Neural Networks, Tamper Detection, Data Recovery, watermarking, information recovery, Soccer Videos, Deep Learning, Chi-square Test, relational databases, Slow Rate DoS attacks, DOS scenario, Anomaly Detection, Robustness, Digital Watermarking, Soccer, HTTP/1.1, Fine Grained, Sports Analytics, DoS Attacks, Event Detection","This paper proposes a new technique for multiple watermarking of relational databases that provides a unified solution to two major security concerns; ownership identification and information recovery. The proposed scheme regenerates crucial information encoded in the data in the event of both illegal alterations in the data as well as deletion of data. The granularity of the recoverable information is decided beforehand by the user. ||| This paper proposes a novel framework for fine-grained action recognition in soccer, which can automatically recognize actions of players in live football games. The framework consists of two modules: Event Detector and Action Classiﬁer. The Event Detector module identiﬁes the desired events and generates a video clip containing the actions surrounding the event. The Action Classiﬁer module classiﬁes the input clip using the GAWAC architecture. The framework and the Soccer-8k dataset are the main contributions of this paper. ||| This paper presents few new threat vectors of HTTP/2 which are Slow Rate DoS attacks. The authors propose a statistical abnormality measurement technique that uses chi-square statistic test to detect any deviation in the HTTP/2 traffic profile created with normal HTTP/2 traffic. The method can identify deviations in network traffic patterns due to presence of anomalous connections originating from these Slow Rate attacks."
Yousef-Awwad Daraghmi,Accurate Trafﬁc Flow Prediction in Heterogeneous Vehicular Networks in an Intelligent Transport System Using a Supervised Non-Parametric Classiﬁer,"Heterogeneous vehicular networks (HETVNETs) evolve from vehicular ad hoc networks (VANETs), which allow vehicles to always be connected so as to obtain safety services within intelligent transportation systems (ITSs). The services and data provided by HETVNETs should be neither interrupted nor delayed. Therefore, Quality of Service (QoS) improvement of HETVNETs is one of the topics attracting the attention of researchers and the manufacturing community.","QoS, SVM, Radial Basis Function, Prediction Accuracy, RBF, internet of vehicles, Support Vector Machines, HETVNET, Vehicular Ad Hoc Network",This paper proposes a prediction model based on support vector machines (SVMs) to improve Quality of Service (QoS) in Heterogeneous Vehicular Networks (HETVNETs). The model uses a radial basis function (RBF) kernel and outperforms other prediction methods in terms of accuracy and computational complexity.
Yu-Chu Tian,Adaptive Energy-Aware Algorithms for Minimizing Energy Consumption and SLA Violation in Cloud Computing,"In cloud computing, high energy consumption and service-level agreements (SLAs) violation are the challenging issues considering that the demand for computational power is growing rapidly, thereby requiring large-scale cloud data centers. This paper proposes three adaptive models, namely, gradient descent-based regression (Gdr), maximize correlation percentage (MCP), and bandwidth-aware selection policy (Bw), that can significantly minimize energy consumption and SLA violation.","regression method, energy-efﬁciency, service level agreements, SLA violation, host overloaded detection, energy efficiency, cloud data center, VM consolidation, Cloud computing, meta-heuristic approach, green computing","This paper proposes three adaptive models to minimize energy consumption and SLA violation in cloud computing. The models are based on gradient descent-based regression, maximize correlation percentage, and bandwidth-aware selection policy. The proposed algorithms reduce energy consumption while maintaining the required performance levels in a cloud data center."
Yuan Zhuang,Mobile Edge Computing for Big Data-Enabled Electric Vehicle Charging,"As one of the key drivers of smart grid, Electric Vehicles (EVs) are environment-friendly to alleviate CO2 pollution. Big data analytics could enable the move from Internet of EVs, to optimized EV charging in smart transportation. In this paper, we propose a Mobile Edge Computing (MEC) based system, in line with a big data-driven planning strategy on which Charging Station (CS) to charge.","Big Data, MEC Based System, EV Charging, Communication Technologies, Network Entities, Smart Transportation, Smart Cities, Decentralized Charging Management, Centralized Charging Management, Charging Planning, Smart Grid, Big Data-Enabled Electric Vehicle Charging, Mobile Edge Computing","This paper proposes a Mobile Edge Computing (MEC) based system for big data-enabled electric vehicle charging. The system integrates big data analytics to opportunistically disseminate the outcome from a Global Controller and collect driving big data from mobile clients. The MEC servers implement big data mining and aggregation in a decentralized way, alleviating the size of data to be processed by the Global Controller."
Yue Cao,A Cost-Efficient Communication Framework For Battery Switch Based Electric Vehicle Charging ||| A Novel EV Charging Management Scheme Considering Mobility Uncertainty ||| Mobile Edge Computing for Big Data-Enabled Electric Vehicle Charging ||| Towards Video Streaming in IoT Environments: Vehicular Communication Perspective ||| Virtualization in Wireless Sensor Networks: Fault Tolerant Embedding for Internet of Things,"This paper proposes a battery switch service for electric vehicles (EVs) using a publish/subscribe (P/S) communication paradigm. The system consists of road side units (RSUs), electric vehicles (EVs), and charging stations (CSs). RSUs act as brokers to bridge the information flow from CSs to EVs, while EVs and CSs interact through RSUs. The system enables efficient radio resource utilization and alleviates interference to EVs. ||| This paper proposes a novel EV charging management scheme that considers mobility uncertainty due to traffic jams in a city. The scheme uses a centralized aggregator to manage charging plans for all EVs in the network, and each EV reports its charging reservation to the aggregator, including its expected arrival time and charging time. The aggregator then makes CS-selection decisions based on the reported information and updates the reservations periodically to adjust for mobility uncertainty. ||| As one of the key drivers of smart grid, Electric Vehicles (EVs) are environment-friendly to alleviate CO2 pollution. Big data analytics could enable the move from Internet of EVs, to optimized EV charging in smart transportation. In this paper, we propose a Mobile Edge Computing (MEC) based system, in line with a big data-driven planning strategy on which Charging Station (CS) to charge. ||| Multimedia oriented Internet of Things (IoT) enables pervasive and real-time communication of video, audio and image data among devices in immediate surroundings. Today’s vehicles have the capability of supporting real time multimedia acquisition. Vehicles with high illuminating infrared cameras and customized sensors can communicate with other on-road devices using dedicated short-range communication (DSRC) and 5G enabled communication technologies. Real time incidence of both urban and highway vehicular traffic environment can be captured and transmitted using vehicle-to-vehicle and vehicle-to-infrastructure communication modes. Video streaming in vehicular IoT (VSV-IoT) environments is in growing stage with several challenges that need to be addressed ranging from limited resources in IoT devices, intermittent connection in vehicular networks, heterogeneous devices, dynamism and scalability in video encoding, bandwidth underutilization in video delivery, and attaining application-precise quality of service in video streaming. In this context, this paper presents a comprehensive review on video streaming in IoT environments focusing on vehicular communication perspective. Specifically, the significance of video streaming in vehicular IoT environments is highlighted focusing on the integration of vehicular communication with 5G enabled IoT technologies, and smart city oriented application areas for VSV-IoT. A taxonomy is presented for the classification of related literature on video streaming in vehicular network environments. Following the taxonomy, critical review of literature is performed focusing on major functional model, strengths and weaknesses. Metrics for video streaming in vehicular IoT environments are derived and comparatively analyzed in terms of their usage and evaluation capabilities. Open research challenges in VSV-IoT are identified as future directions of research in the area. The survey would benefit both IoT and vehicle industry practitioners and researchers, in terms of augmenting understanding of vehicular video streaming and its IoT related trends and issues. ||| Recently, virtualization in wireless sensor networks (WSNs) has witnessed significant attention due to the growing service domain for IoT. Related literature on virtualization in WSNs explored resource optimization without considering communication failure in WSNs environments. The failure of a communication link in WSNs impacts many virtual networks running IoT services. In this context, this paper proposes a framework for optimizing fault tolerance in virtualization in WSNs, focusing on heterogeneous networks for service-oriented IoT applications.","Charging System, Communication Technologies, Internet of vehicles, Vehicular Communication, CS-Selection Decision Making, CS-Selection, Electric Vehicle, Driver's Trip Duration, Mobile Edge Computing, traffic safety, Network Entities, Fault Tolerant Embedding, Smart Transportation, Charging Planning, Internet of Things, Traffic Jams, Smart Grid, Battery Switch, Electric Vehicles, Big Data, Mobility Uncertainty, Decentralized Charging Management, publish/subscribe, Big Data-Enabled Electric Vehicle Charging, Electric Vehicle Charging, charging stations, road side units, MEC Based System, EV Charging, Wireless sensor networks, Video streaming, vehicular ad-hoc networks, Smart Cities, Communication Framework, Centralized Charging Management, Intelligent transportation system, Virtualization, Charging Management, Centralized Aggregator, Internet of things, IoT","This article presents a cost-efﬁcient communication framework for battery switch based electric vehicle charging. The framework is provisioned to support the EV charging service and considers urban travel uncertainties, e.g., trafﬁc congestions and drivers’ preferences. Results demonstrate a guidance for the provisioning of P/S communication framework to improve EV drivers’ experience, e.g., charging waiting time and total trip duration. ||| This paper proposes an EV charging management system that considers drivers' trip duration and mobility uncertainty. The system selects charging stations based on reported EVs' reservation information and parking duration, minimizing trip duration for on-the-move EVs. ||| This paper proposes a Mobile Edge Computing (MEC) based system for big data-enabled electric vehicle charging. The system integrates big data analytics to opportunistically disseminate the outcome from a Global Controller and collect driving big data from mobile clients. The MEC servers implement big data mining and aggregation in a decentralized way, alleviating the size of data to be processed by the Global Controller. ||| The paper discusses the significance of video streaming in vehicular IoT environments, presents a taxonomy for the classification of literature on video streaming over vehicular ad-hoc networks, derives performance metrics for video streaming in vehicular IoT environments, and identifies open research issues and challenges in vehicular video streaming under IoT environments. ||| The paper discusses the importance of virtualization in WSNs for IoT applications, focusing on fault-tolerant embedding. It reviews existing proposals on virtualization in WSNs, highlighting their limitations and proposing a new approach to enhance fault tolerance."
Yunqi Jiang,Reservoir Characterization and Productivity Forecast Based on Knowledge Interaction Neural Network,"The reservoir characterization aims to provide the analysis and quantification of the injection-production relationship, which is the fundamental work for production management. The connectivity between injectors and producers is dominated by geological properties, especially permeability. However, the permeability parameters are very heterogenous in oil reservoirs, and expensive to collect by well logging. The commercial simulators enable to get accurate simulation but require sufficient geological properties and consume excessive computation resources.","knowledge interaction neural network, machine learning, productivity prediction, reservoir characterization, Productivity Forecast, Physical Knowledge, embedded model","The goal of this study is to improve the accuracy and stableness of the inter-well connectivity characterization and enhance the prediction precision on well productivity, by combining the physical knowledge with machine learning techniques. An innovative neural network is proposed to handle the reservoir characterization and productivity forecast problems, in which the material balance equation is embedded via three high transparent modules, thereby ensuring the physical sense of model parameters."
Z.  Li,Secure Robust and Imperceptible Algorithm for Watermarking Relational Databases,"This paper proposes a secure robust and imperceptible algorithm for watermarking relational databases. The algorithm divides the embedding algorithm into three phases: Watermark preparator, watermark position detector, and watermark embedder. The ownership identification issue is resolved by embedding owner's identity as watermark in Preparator phase.","imperceptible algorithm, Ownership identification, robust algorithm, Relational Database, watermarking, Watermark, Copyright protection, Proof of ownership, relational databases","The paper proposes a new robust secure and imperceptible embedding mechanism to resolve the two important concerns namely; owner identification and proof of ownership. The proposed mechanism involves encoding and decoding on numerical attribute of relational database in three phases; 1)Watermark preparator, 2)Watermark position detector and 3) Watermark Embedder or Detector."
Z. Cao,Secure Robust and Imperceptible Algorithm for Watermarking Relational Databases,"This paper proposes a secure robust and imperceptible algorithm for watermarking relational databases. The algorithm divides the embedding algorithm into three phases: Watermark preparator, watermark position detector, and watermark embedder. The ownership identification issue is resolved by embedding owner's identity as watermark in Preparator phase.","imperceptible algorithm, Ownership identification, robust algorithm, Relational Database, watermarking, Watermark, Copyright protection, Proof of ownership, relational databases","The paper proposes a new robust secure and imperceptible embedding mechanism to resolve the two important concerns namely; owner identification and proof of ownership. The proposed mechanism involves encoding and decoding on numerical attribute of relational database in three phases; 1)Watermark preparator, 2)Watermark position detector and 3) Watermark Embedder or Detector."
Z. Chen,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
Z. Hu,Secure Robust and Imperceptible Algorithm for Watermarking Relational Databases,"This paper proposes a secure robust and imperceptible algorithm for watermarking relational databases. The algorithm divides the embedding algorithm into three phases: Watermark preparator, watermark position detector, and watermark embedder. The ownership identification issue is resolved by embedding owner's identity as watermark in Preparator phase.","imperceptible algorithm, Ownership identification, robust algorithm, Relational Database, watermarking, Watermark, Copyright protection, Proof of ownership, relational databases","The paper proposes a new robust secure and imperceptible embedding mechanism to resolve the two important concerns namely; owner identification and proof of ownership. The proposed mechanism involves encoding and decoding on numerical attribute of relational database in three phases; 1)Watermark preparator, 2)Watermark position detector and 3) Watermark Embedder or Detector."
Z. Liu,Secure Robust and Imperceptible Algorithm for Watermarking Relational Databases,"This paper proposes a secure robust and imperceptible algorithm for watermarking relational databases. The algorithm divides the embedding algorithm into three phases: Watermark preparator, watermark position detector, and watermark embedder. The ownership identification issue is resolved by embedding owner's identity as watermark in Preparator phase.","imperceptible algorithm, Ownership identification, robust algorithm, Relational Database, watermarking, Watermark, Copyright protection, Proof of ownership, relational databases","The paper proposes a new robust secure and imperceptible embedding mechanism to resolve the two important concerns namely; owner identification and proof of ownership. The proposed mechanism involves encoding and decoding on numerical attribute of relational database in three phases; 1)Watermark preparator, 2)Watermark position detector and 3) Watermark Embedder or Detector."
Z. R. Struzik,DWT based hybrid ARIMA-FLANN model for financial time series forecasting,"In this study, a DWT based hybrid ARIMA-FLANN model is introduced for financial time series forecasting. The most challenging task is to determine the exact nature of a real-world time series. ARIMA assumes linear data generation function, whereas FLANN is suitable for nonlinear financial time series. The DWT based hybrid method provides prior decomposition of time series data into low and high frequency components. So, that ARIMA is fitted on the high frequency linear part and FLANN is fitted on the low frequency nonlinear part. The final combined forecasts obtained for proposed hybrid method outperforms FLANN model.","FLANN, wavelet transform, financial time series forecasting, ARIMA, hybrid ARIMA-FLANN model, DWT","This paper introduces a DWT based hybrid ARIMA-FLANN model for financial time series forecasting. The model uses wavelet transform to decompose the time series into low and high frequency components, and then uses ARIMA and FLANN to forecast the linear and nonlinear parts of the time series, respectively. The results show that the proposed model outperforms the FLANN model in forecasting accuracy."
Z.-H. Zhang,Secure Robust and Imperceptible Algorithm for Watermarking Relational Databases,"This paper proposes a secure robust and imperceptible algorithm for watermarking relational databases. The algorithm divides the embedding algorithm into three phases: Watermark preparator, watermark position detector, and watermark embedder. The ownership identification issue is resolved by embedding owner's identity as watermark in Preparator phase.","imperceptible algorithm, Ownership identification, robust algorithm, Relational Database, watermarking, Watermark, Copyright protection, Proof of ownership, relational databases","The paper proposes a new robust secure and imperceptible embedding mechanism to resolve the two important concerns namely; owner identification and proof of ownership. The proposed mechanism involves encoding and decoding on numerical attribute of relational database in three phases; 1)Watermark preparator, 2)Watermark position detector and 3) Watermark Embedder or Detector."
Z.F. Zhang,Iris Detection,"For iris boundary detection, circular summation of intensity approach is used as proposed in [5]. The original grayscale image is blurred using median filter to remove external noise. After filtering, the contrast of image is enhanced to have sharp variation at image boundaries using histogram equalisation as shown in Figure 5(a). This contrast enhanced image is used for finding the outer iris boundary by drawing concentric circles (Figure 5(b) shows an example) of different radii from the pupil center and the intensities lying over the perimeter of the circle are summed up.","Adaptive Threshold, Circular Hough Transform, Spectrum Image, histogram equalisation, iris recognition, circular summation of intensity, Connected Components, Iris detection, pupil boundary, Iris Segmentation",The proposed system has been tested on two publicly available databases BATH and CASIA V3. From experimental analysis it has been observed that the system is capable of handling unconstrained scenarios as well. The system is capable of performing segmentation for unconstrained scenarios in significantly less time compared to Hough transform.
Zalasinski et al.,Deformation Adjustment with Single Real Signature Image for Biometric Verification Using CNN,"Signature verification is the widely used biometric verification method for maintaining individual privacy. It is generally used in legal documents and in financial transactions. A vast range of research has been done so far to tackle different system issues, but there are various hot issues that remain unaddressed. The scale and orientation of the signatures are some issues to address, and the deformation of the signature within the genuine examples is the most critical for the verification system.","biometric authentication, Single real signature image, soft biometrics, deep learning, hard biometrics, CNN, Signature verification, Deformation adjustment, Biometric verification, writer-independent","This work proposes a two-phase system requiring only one target signature image to verify a query signature image. It takes care of the target signature's scaling, orientation, and spatial translation in the first phase. The second phase uses this transformed sample image and verifies the given sample as the target signature with the help of another deep neural network."
Zdzislaw I. Pawlak,Abstract Sensor Fusion Problem for Wireless Sensor Network,The accuracy of a system is measured by the deviation of the system’s results from the actual results. Information fusion deals with the combination of information from same source or different sources to obtain improved fused estimate with greater quality or greater relevance.,"rough set, Sensor Fusion, Wireless Sensor Network, Median",This paper proposes a novel Median based sensor fusion function named D function. It is shown that the proposed D function satisfies the lipschitz condition. The paper also presents some of the ideas which can open new areas for research in fusion problem.
Zehong Cao,A Layered-Coevolution-Based Attribute-Boosted Reduction Using Adaptive Quantum Behavior PSO and Its Consistent Segmentation for Neonates Brain Tissue,"The main challenge of attribute reduction in large data applications is to develop a new algorithm to deal with large, noisy, and uncertain large data linking multiple relevant data sources, structured or unstructured. This paper proposes a new and efficient layered-coevolution-based attribute-boosted reduction algorithm (LCQ-ABR*) using adaptive quantum behavior particle swarm optimization (PSO).","Layered Co-Evolutionary Model, Quantum-Behavior PSO, adaptive quantum behavior PSO, Attribute-boosted reduction, Multi-Agent Interaction, Neonatal Brain Tissue 3D-MRI, sulci and gyrus estimate, consistent segmentation for neonates brain tissue, Self-Adaptive Memeplexes, layered-coevolution with multi-agent interaction","This paper proposes a new attribute reduction algorithm using quantum behavior PSO, which aims to choose attribute subsets for large-scale, noisy, and uncertain datasets. The algorithm is evaluated on several benchmark datasets and compared with other representative algorithms. The results show that the proposed algorithm has better feasibility and effectiveness than the compared algorithms."
"Zettlemoyer, L.",A Multi-Task Approach to Open Domain Suggestion Mining,"Consumer reviews online may contain suggestions useful for improving the target products and services. Mining suggestions is challenging because the field lacks large labelled and balanced datasets. Furthermore, most prior studies have only focused on mining suggestions in a single domain. In this work, we introduce a novel up-sampling technique to address the problem of class imbalance, and propose a multi-task deep learning approach for mining suggestions from multiple domains.","Deep Learning, Suggestion Mining, Artificial Intelligence, Class Imbalance, Multi-Task Learning","This paper presents a multi-task approach to open domain suggestion mining, addressing the class imbalance problem using a novel up-sampling technique and a multi-task deep learning framework. Experimental results show that the proposed approach outperforms state-of-the-art models in terms of F-1 measure and AUC."
Zexuan Zhu,A fast pruned-extreme learning machine for classification problem,"Extreme learning machine (ELM) represents one of the recent successful approaches in machine learning, particularly for performing pattern classification. One key strength of ELM is the significantly low computational time required for training new classifiers since the weights of the hidden and output nodes are randomly chosen and analytically determined, respectively.","Extreme learning machine (ELM), Feedforward networks, Pruned ELM, Statistical Relevance Measures, Extreme Learning Machine, Pattern classification, Generalization Ability, Hidden Node Size",This paper presents a pruned-ELM (P-ELM) algorithm as a systematic and automated approach for designing ELM classifier network. P-ELM uses statistical methods to measure the relevance of hidden nodes and provides a systematic approach for designing the network architecture of the ELM classifier.
Zhan et al.,Archive-Based Steady-State Micro Genetic Algorithm (ASMiGA),"We propose a new archive-based steady-state micro genetic algorithm (ASMiGA). In this context, a new archive maintenance strategy is proposed, which maintains a set of nondominated solutions in the archive unless the archive size falls below a minimum allowable size. It makes the archive size adaptive and dynamic. We have proposed a new environmental selection strategy and a new mating selection strategy. The environmental selection strategy reduces the exploration in less probable objective spaces. The mating selection increases searching in more probable search regions by enhancing the exploitation of existing solutions. A new crossover strategy DE-3 is proposed here. ASMiGA is compared with five well-known multiobjective optimization algorithms of different types—generational evolutionary algorithms (SPEA2 and NSGA-II), archive-based hybrid scatter search, decomposition-based evolutionary approach, and archive-based micro genetic algorithm. For comparison purposes, four performance measures (HV, GD, IGD, and GS) are used on 33 test problems, of which seven problems are constrained. The proposed algorithm outperforms the other five algorithms.","Genetic Algorithm, multiobjective evolutionary optimization, Archive-based algorithm, ASMiGA, genetic algorithms, Pareto front, Multi-Objective Optimization, Archive-Based Steady-State Micro Genetic Algorithm, MOEAs",This paper proposes a new archive-based steady-state micro genetic algorithm (ASMiGA) to address the issues of multiobjective optimization problems. The proposed algorithm combines old and new evolutionary algorithmic components and uses a new environmental selection strategy and a new mating selection strategy. The algorithm is compared with five well-known multiobjective optimization algorithms and outperforms them on 33 test problems.
Zhang,Deformation Adjustment with Single Real Signature Image for Biometric Verification Using CNN,"Signature verification is the widely used biometric verification method for maintaining individual privacy. It is generally used in legal documents and in financial transactions. A vast range of research has been done so far to tackle different system issues, but there are various hot issues that remain unaddressed. The scale and orientation of the signatures are some issues to address, and the deformation of the signature within the genuine examples is the most critical for the verification system.","biometric authentication, Single real signature image, soft biometrics, deep learning, hard biometrics, CNN, Signature verification, Deformation adjustment, Biometric verification, writer-independent","This work proposes a two-phase system requiring only one target signature image to verify a query signature image. It takes care of the target signature's scaling, orientation, and spatial translation in the first phase. The second phase uses this transformed sample image and verifies the given sample as the target signature with the help of another deep neural network."
Zhengxue Li,Convergence Analysis of Online Gradient Methods for Feedforward Neural Networks,"This paper considers a class of online gradient learning methods for backpropagation (BP) neural networks with a single hidden layer. We assume that in each training cycle, each sample in the training set is supplied in a stochastic order to the network exactly once. It is interesting that these stochastic learning methods can be shown to be deterministically convergent. This paper presents some weak and strong convergence results for the learning methods, indicating that the gradient of the error function goes to zero and the weight sequence goes to a fixed point, respectively. The conditions on the activation function and the learning rate to guarantee the convergence are relaxed compared with the existing results. Our convergence results are valid for not only S–S type neural networks (both the output and hidden neurons are Sigmoid functions), but also for P–P, P–S and S–P type neural networks, where S and P represent Sigmoid and polynomial functions, respectively.","Backpropagation learning, Strong convergence, feedforward neural networks, Online gradient method, convergence analysis, OGM-SS, Weak convergence, online gradient methods, Neural networks, OGM-F","This paper presents a comprehensive study on the weak and strong convergence for OGM-F and OGM-SS, indicating that the gradient of the error function goes to zero and the weight sequence goes to a fixed point, respectively. The conditions on the activation function and the learning rate to guarantee the convergence are much relaxed compared with the existing results."
Zhenyu Wen,"Explainable AI (XAI): Core Ideas, Techniques and Solutions","As our dependence on intelligent machines continues to grow, so does the demand for more transparent and interpretable models. In addition, the ability to explain the model generally is now the gold standard for building trust and deployment of Artificial Intelligence (AI) systems in critical domains. Explainable Artificial Intelligence (XAI) aims to provide a suite of machine learning (ML) techniques that enable human users to understand, appropriately trust, and produce more explainable models.","Explainable AI, Stakeholders, Machine Learning, Software toolkits, Programming framework, Bias, Robustness, Interpretable AI, Explainable Artiﬁcial Intelligence, XAI, Decision Making","The paper presents the core ideas, techniques, and solutions of XAI, emphasizing its importance in various phases of the machine learning process. It discusses the stakeholders involved in these phases, including developers, theorists, data scientists, users, consumers, businesses, regulators, and scientists, and highlights the use cases of XAI in detecting bias, scientific understanding, building robust models, and better decision making."
Zhenyun Ye,Fractional-Order BP Algorithm for Training Fractional FNNs,"Fractional calculus has been found to be a promising area of research for information processing and modeling of some physical systems. In this paper, we propose a fractional gradient descent method for the backpropagation (BP) training of neural networks. In particular, the Caputo derivative is employed to evaluate the fractional-order gradient of the error defined as the traditional quadratic energy function. The monotonicity and weak (strong) convergence of the proposed approach are proved in detail. Two simulations have been implemented to illustrate the performance of presented fractional-order BP algorithm on three small datasets and one large dataset. The numerical simulations effectively verify the theoretical observations of this paper as well.","BP algorithm, Caputo derivative, fractional-order neural networks, Backpropagation, Fractional calculus, Caputo fractional-order derivative, training FNNs, Monotonicity, Convergence","This paper proposes a fractional gradient descent method for the backpropagation (BP) training of neural networks, employing the Caputo derivative to evaluate the fractional-order gradient of the error. The monotonicity and weak (strong) convergence of the proposed approach are proved in detail, and numerical simulations are implemented to illustrate its performance on various datasets."
Zhigang Zeng,Adaptive Lag Synchronization of Memristive Neural Networks with Unknown Connection Weights,"This paper investigates the adaptive lag synchronization of memristive neural networks with unknown connection weights. A new fuzzy model is proposed to simplify memristive systems, and the idea of PDC is applied to achieve synchronization between subsystems. The adaptive lag synchronization algorithm is designed, and the update law for the connection weights and controller gain is derived. The stability of the closed-loop system is analyzed, and the synchronization error is shown to be globally exponentially convergent to zero.","Adaptive lag synchronization, neural networks, memristor, synchronization error, memristive neural networks, PDC, fuzzy model, unknown connection weights, pseudorandom number generator (PRNG)","This paper presents a new approach to the adaptive lag synchronization of memristive neural networks with unknown connection weights. The proposed fuzzy model simplifies the memristive systems, and the PDC idea is applied to achieve synchronization between subsystems. The adaptive lag synchronization algorithm is designed, and the update law for the connection weights and controller gain is derived. The stability of the closed-loop system is analyzed, and the synchronization error is shown to be globally exponentially convergent to zero."
Zhong,Agriculture Extension System in India: A Meta-analysis,"Agriculture extension system bridges the gap between research labs to a farmer’s field. Agricultural research, education and extension are said to be the most critical for promoting farm productivity and enhancing farmer’s income. The public sector is major extension service provider and the reach of the public extension is limited in India and in addition it is burdened with non-extension responsibilities such as the distribution of subsidies and inputs, with little time left to attend to core extension activities.","Investment, Extension approaches, Farmers Producers' Organizations, India, Agriculture extension, Meta analysis, ICT, Manpower","The article reviews the agricultural extension system in India to suggest pathways for better extension system in India. The public extension services are highly skewed towards crop husbandry ignoring allied sectors in India. The growth in the High-Value Agriculture sector has been twice or sometimes even thrice that of the crop production. However, Agriculture extension services for such sectors almost nil or unorganized."
Zhongying Han,A new method for rock brittleness evaluation in tight oil formation from conventional logs and petrophysical data,"Brittleness is a critical indicator for hydraulic fracturing candidate screening in unconventional reservoirs. Current rock brittleness estimation models are often inferred from mechanical parameters and mineralogical data, which primarily use empirical equations. However, the absence of shear sonic velocity data and insufficient mineral data sometimes restricts its wide application. In this article, our objective is to illustrate the application of a data-driven approach for rock brittleness estimation that employs computational intelligence technologies (multilayer perception and radial basis function models) that use conventional well logs as inputs.","Rock brittleness, Multilayer perception, production, brittleness, Computational intelligence, Hydraulic fracturing, Tight oil, oil and gas exploration, rock mechanics, Radial basis function","The paper reviews the current state of brittleness calculation methods and their limitations, highlighting the need for a universally applicable model. It discusses the importance of mineral composition, strain rate, temperature, pore pressure, saturation, and stress state in controlling rock brittleness."
"Zhou et al., 2014",Supervised Heterogeneous Domain Adaptation via Random Forests,This paper proposes a novel approach to heterogeneous domain adaptation using random forests. The algorithm leverages the common label information between the source and target domains as the pivot for knowledge transfer. The proposed algorithm determines the mapping PS between source and target features based on the estimate of the contribution of the features towards creating data partitions having similar label distributions.,"Label Information, Supervised Heterogeneous Domain Adaptation, Feature Mapping, Heterogeneous Domain Adaptation, Random Forests, Knowledge Transfer, Feature Transfer, Domain Adaptation",The paper proposes a novel supervised domain adaptation algorithm (SHDA-RF) that learns the mapping between heterogeneous features of different dimensions. The algorithm uses the shared label distributions present across the domains as pivots for learning a sparse feature transformation. The shared label distributions and the relationship between the feature spaces and the label distributions are estimated in a supervised manner using random forests.
Zhou et. al.,Rumour Source Detection Using Game Theory,"Social networks have become a critical part of our lives as they enable us to interact with a lot of people. These networks have become the main sources for creating, sharing and also extracting information regarding various subjects. But all this information may not be true and may contain a lot of unverified rumours that have the potential of spreading incorrect information to the masses, which may even lead to situations of widespread panic. Thus, it is of great importance to identify those nodes and edges that play a crucial role in a network in order to find the most influential sources of rumour spreading. Generally, the basic idea is to classify the nodes and edges in a network with the highest criticality. Most of the existing work regarding the same focuses on using simple centrality measures which focus on the individual contribution of a node in a network. Game-theoretic approaches such as Shapley Value (SV) algorithms suggest that individual marginal contribution should be measured for a given player as the weighted average marginal increase in the yield of any coalition that this player might join. For our experiment, we have played five SV-based games to find the top 10 most influential nodes on three network datasets (Enron, USAir97 and Les Misérables). We have compared our results to the ones obtained by using primitive centrality measures. Our results show that SV-based approach is better at understanding the marginal contribution, and therefore the actual influence, of each node to the entire network.","influential nodes, Jaccard Similarity Coefficient, cooperative game, Rumour Source Detection (RSD), centrality measures, network analysis, Shapley Value (SV), Game-Theory, Network Centrality",This paper aims to identify the most influential nodes in a network that are the primary sources of rumour propagation. The authors propose a game-theoretic approach using the Shapley Value algorithm to find the most influential nodes. They compare their results with primitive centrality measures and show that the SV-based approach is better at understanding the marginal contribution of each node to the entire network.
Zitzler et al.,Multi-Objective Genetic Algorithm for Optimization of Catalytic Reaction,"This paper discusses the use of a multi-objective genetic algorithm (MOGA) for the optimization of a catalytic reaction. The MOGA is used to find a set of solutions that are close to the Pareto front, well spread, and cover the whole spectrum of the Pareto front. The algorithm is applied to a competitive enzyme inhibition reaction scheme and the results are discussed.","Genetic Algorithm, Cellular Automata, Optimization, Enzyme kinetics, Pareto Front, Multi-Objective Optimization, Multi-Objective Genetic Algorithm, Catalytic Reaction","The paper presents a multi-objective genetic algorithm for the optimization of a catalytic reaction. The algorithm is used to find a set of solutions that are close to the Pareto front, well spread, and cover the whole spectrum of the Pareto front. The results of the algorithm are discussed and compared with other optimization methods."
Zouari et al.,Deformation Adjustment with Single Real Signature Image for Biometric Verification Using CNN,"Signature verification is the widely used biometric verification method for maintaining individual privacy. It is generally used in legal documents and in financial transactions. A vast range of research has been done so far to tackle different system issues, but there are various hot issues that remain unaddressed. The scale and orientation of the signatures are some issues to address, and the deformation of the signature within the genuine examples is the most critical for the verification system.","biometric authentication, Single real signature image, soft biometrics, deep learning, hard biometrics, CNN, Signature verification, Deformation adjustment, Biometric verification, writer-independent","This work proposes a two-phase system requiring only one target signature image to verify a query signature image. It takes care of the target signature's scaling, orientation, and spatial translation in the first phase. The second phase uses this transformed sample image and verifies the given sample as the target signature with the help of another deep neural network."
[10],IoT Challenges and Opportunities,"This paper discusses the challenges and opportunities in the Internet of Things (IoT) era. It highlights the need for a unified addressing scheme, energy-efficient network architecture, and intelligent routing mechanism. The paper also explores the challenges of big data management, energy consumption, devices/links heterogeneity, and transmission media in IoT applications.","Big Data, Transmission Media, Energy Efficiency, Internet of things (IoT), Devices/Links Heterogeneity, challenges and opportunities, wireless sensor networks (WSNs), Addressing Scheme, IoT","The paper presents a comprehensive overview of the challenges and opportunities in IoT applications. It highlights the need for a unified addressing scheme, energy-efficient network architecture, and intelligent routing mechanism. The paper also explores the challenges of big data management, energy consumption, devices/links heterogeneity, and transmission media in IoT applications."
[11],IoT Challenges and Opportunities,"This paper discusses the challenges and opportunities in the Internet of Things (IoT) era. It highlights the need for a unified addressing scheme, energy-efficient network architecture, and intelligent routing mechanism. The paper also explores the challenges of big data management, energy consumption, devices/links heterogeneity, and transmission media in IoT applications.","Big Data, Transmission Media, Energy Efficiency, Internet of things (IoT), Devices/Links Heterogeneity, challenges and opportunities, wireless sensor networks (WSNs), Addressing Scheme, IoT","The paper presents a comprehensive overview of the challenges and opportunities in IoT applications. It highlights the need for a unified addressing scheme, energy-efficient network architecture, and intelligent routing mechanism. The paper also explores the challenges of big data management, energy consumption, devices/links heterogeneity, and transmission media in IoT applications."
[12],IoT Challenges and Opportunities,"This paper discusses the challenges and opportunities in the Internet of Things (IoT) era. It highlights the need for a unified addressing scheme, energy-efficient network architecture, and intelligent routing mechanism. The paper also explores the challenges of big data management, energy consumption, devices/links heterogeneity, and transmission media in IoT applications.","Big Data, Transmission Media, Energy Efficiency, Internet of things (IoT), Devices/Links Heterogeneity, challenges and opportunities, wireless sensor networks (WSNs), Addressing Scheme, IoT","The paper presents a comprehensive overview of the challenges and opportunities in IoT applications. It highlights the need for a unified addressing scheme, energy-efficient network architecture, and intelligent routing mechanism. The paper also explores the challenges of big data management, energy consumption, devices/links heterogeneity, and transmission media in IoT applications."
[13],IoT Challenges and Opportunities,"This paper discusses the challenges and opportunities in the Internet of Things (IoT) era. It highlights the need for a unified addressing scheme, energy-efficient network architecture, and intelligent routing mechanism. The paper also explores the challenges of big data management, energy consumption, devices/links heterogeneity, and transmission media in IoT applications.","Big Data, Transmission Media, Energy Efficiency, Internet of things (IoT), Devices/Links Heterogeneity, challenges and opportunities, wireless sensor networks (WSNs), Addressing Scheme, IoT","The paper presents a comprehensive overview of the challenges and opportunities in IoT applications. It highlights the need for a unified addressing scheme, energy-efficient network architecture, and intelligent routing mechanism. The paper also explores the challenges of big data management, energy consumption, devices/links heterogeneity, and transmission media in IoT applications."
[14],IoT Challenges and Opportunities,"This paper discusses the challenges and opportunities in the Internet of Things (IoT) era. It highlights the need for a unified addressing scheme, energy-efficient network architecture, and intelligent routing mechanism. The paper also explores the challenges of big data management, energy consumption, devices/links heterogeneity, and transmission media in IoT applications.","Big Data, Transmission Media, Energy Efficiency, Internet of things (IoT), Devices/Links Heterogeneity, challenges and opportunities, wireless sensor networks (WSNs), Addressing Scheme, IoT","The paper presents a comprehensive overview of the challenges and opportunities in IoT applications. It highlights the need for a unified addressing scheme, energy-efficient network architecture, and intelligent routing mechanism. The paper also explores the challenges of big data management, energy consumption, devices/links heterogeneity, and transmission media in IoT applications."
[15],IoT Challenges and Opportunities,"This paper discusses the challenges and opportunities in the Internet of Things (IoT) era. It highlights the need for a unified addressing scheme, energy-efficient network architecture, and intelligent routing mechanism. The paper also explores the challenges of big data management, energy consumption, devices/links heterogeneity, and transmission media in IoT applications.","Big Data, Transmission Media, Energy Efficiency, Internet of things (IoT), Devices/Links Heterogeneity, challenges and opportunities, wireless sensor networks (WSNs), Addressing Scheme, IoT","The paper presents a comprehensive overview of the challenges and opportunities in IoT applications. It highlights the need for a unified addressing scheme, energy-efficient network architecture, and intelligent routing mechanism. The paper also explores the challenges of big data management, energy consumption, devices/links heterogeneity, and transmission media in IoT applications."
[16],IoT Challenges and Opportunities,"This paper discusses the challenges and opportunities in the Internet of Things (IoT) era. It highlights the need for a unified addressing scheme, energy-efficient network architecture, and intelligent routing mechanism. The paper also explores the challenges of big data management, energy consumption, devices/links heterogeneity, and transmission media in IoT applications.","Big Data, Transmission Media, Energy Efficiency, Internet of things (IoT), Devices/Links Heterogeneity, challenges and opportunities, wireless sensor networks (WSNs), Addressing Scheme, IoT","The paper presents a comprehensive overview of the challenges and opportunities in IoT applications. It highlights the need for a unified addressing scheme, energy-efficient network architecture, and intelligent routing mechanism. The paper also explores the challenges of big data management, energy consumption, devices/links heterogeneity, and transmission media in IoT applications."
[17],IoT Challenges and Opportunities,"This paper discusses the challenges and opportunities in the Internet of Things (IoT) era. It highlights the need for a unified addressing scheme, energy-efficient network architecture, and intelligent routing mechanism. The paper also explores the challenges of big data management, energy consumption, devices/links heterogeneity, and transmission media in IoT applications.","Big Data, Transmission Media, Energy Efficiency, Internet of things (IoT), Devices/Links Heterogeneity, challenges and opportunities, wireless sensor networks (WSNs), Addressing Scheme, IoT","The paper presents a comprehensive overview of the challenges and opportunities in IoT applications. It highlights the need for a unified addressing scheme, energy-efficient network architecture, and intelligent routing mechanism. The paper also explores the challenges of big data management, energy consumption, devices/links heterogeneity, and transmission media in IoT applications."
[18],IoT Challenges and Opportunities,"This paper discusses the challenges and opportunities in the Internet of Things (IoT) era. It highlights the need for a unified addressing scheme, energy-efficient network architecture, and intelligent routing mechanism. The paper also explores the challenges of big data management, energy consumption, devices/links heterogeneity, and transmission media in IoT applications.","Big Data, Transmission Media, Energy Efficiency, Internet of things (IoT), Devices/Links Heterogeneity, challenges and opportunities, wireless sensor networks (WSNs), Addressing Scheme, IoT","The paper presents a comprehensive overview of the challenges and opportunities in IoT applications. It highlights the need for a unified addressing scheme, energy-efficient network architecture, and intelligent routing mechanism. The paper also explores the challenges of big data management, energy consumption, devices/links heterogeneity, and transmission media in IoT applications."
[4],IoT Challenges and Opportunities,"This paper discusses the challenges and opportunities in the Internet of Things (IoT) era. It highlights the need for a unified addressing scheme, energy-efficient network architecture, and intelligent routing mechanism. The paper also explores the challenges of big data management, energy consumption, devices/links heterogeneity, and transmission media in IoT applications.","Big Data, Transmission Media, Energy Efficiency, Internet of things (IoT), Devices/Links Heterogeneity, challenges and opportunities, wireless sensor networks (WSNs), Addressing Scheme, IoT","The paper presents a comprehensive overview of the challenges and opportunities in IoT applications. It highlights the need for a unified addressing scheme, energy-efficient network architecture, and intelligent routing mechanism. The paper also explores the challenges of big data management, energy consumption, devices/links heterogeneity, and transmission media in IoT applications."
[7],IoT Challenges and Opportunities,"This paper discusses the challenges and opportunities in the Internet of Things (IoT) era. It highlights the need for a unified addressing scheme, energy-efficient network architecture, and intelligent routing mechanism. The paper also explores the challenges of big data management, energy consumption, devices/links heterogeneity, and transmission media in IoT applications.","Big Data, Transmission Media, Energy Efficiency, Internet of things (IoT), Devices/Links Heterogeneity, challenges and opportunities, wireless sensor networks (WSNs), Addressing Scheme, IoT","The paper presents a comprehensive overview of the challenges and opportunities in IoT applications. It highlights the need for a unified addressing scheme, energy-efficient network architecture, and intelligent routing mechanism. The paper also explores the challenges of big data management, energy consumption, devices/links heterogeneity, and transmission media in IoT applications."
[8],IoT Challenges and Opportunities,"This paper discusses the challenges and opportunities in the Internet of Things (IoT) era. It highlights the need for a unified addressing scheme, energy-efficient network architecture, and intelligent routing mechanism. The paper also explores the challenges of big data management, energy consumption, devices/links heterogeneity, and transmission media in IoT applications.","Big Data, Transmission Media, Energy Efficiency, Internet of things (IoT), Devices/Links Heterogeneity, challenges and opportunities, wireless sensor networks (WSNs), Addressing Scheme, IoT","The paper presents a comprehensive overview of the challenges and opportunities in IoT applications. It highlights the need for a unified addressing scheme, energy-efficient network architecture, and intelligent routing mechanism. The paper also explores the challenges of big data management, energy consumption, devices/links heterogeneity, and transmission media in IoT applications."
[9],IoT Challenges and Opportunities,"This paper discusses the challenges and opportunities in the Internet of Things (IoT) era. It highlights the need for a unified addressing scheme, energy-efficient network architecture, and intelligent routing mechanism. The paper also explores the challenges of big data management, energy consumption, devices/links heterogeneity, and transmission media in IoT applications.","Big Data, Transmission Media, Energy Efficiency, Internet of things (IoT), Devices/Links Heterogeneity, challenges and opportunities, wireless sensor networks (WSNs), Addressing Scheme, IoT","The paper presents a comprehensive overview of the challenges and opportunities in IoT applications. It highlights the need for a unified addressing scheme, energy-efficient network architecture, and intelligent routing mechanism. The paper also explores the challenges of big data management, energy consumption, devices/links heterogeneity, and transmission media in IoT applications."
[UNKNOWN AUTHOR],Graph Evolution and Change ||| Maternal Use of Hydroxychloroquine ||| On rule pruning using fuzzy NN ||| Population dynamics,,,
[Unknown],The Design of a Pedagogical Operating System,"Operating systems are indispensable part of all computer systems used today. The concepts and principles used to design and implement operating systems have been evolving over the decades. However, the researchers are still busy in improving the operating systems and imparting new properties in them. One such desired property is that of being pedagogical in nature. In the current paper, the primal design of a pedagogical operating system is being developed. To attain respectable modularity and flexibility, the multiple server microkernel based architecture has been used. Additionally, object oriented methodologies and software engineering principles has been employed to obtain a well designed and well documented operating system. The pedagogical operating system whose design is being developed in this paper is expected to be helpful in teaching and learning courses on operating systems in various universities and other educational organizations on its completion. Furthermore, the proficient design of the operating system, obtained by employing various august paradigms and introducing new features, aims at enlivening academic atmosphere and promoting scientific innovation.","pedagogical, verbose server, object oriented operating system, microkernel, Operating system, message passing, reincarnation server, pedagogical operating system","The paper introduces a novel operating system design with a focus on pedagogy. The system consists of five layers and uses a message passing mechanism for communication. Two novel features, the reincarnation server and the verbose server, are also introduced."
de Bie,"Reliability, validity and responsiveness of the Western Ontario McMaster Osteoarthritis Index (WOMAC) in the elderly population with a femoral neck fracture","Background: Patient-reported outcome measures are gaining importance in clinical research. The WOMAC has been extensively evaluated in populations suffering from osteoarthritis, yet not in femoral neck fracture populations. This study aimed to determine the reliability, construct validity, and responsiveness of WOMAC, compared with SF-12 and EQ-5D, in elderly with a femoral neck fracture. Methods: Reliability was tested by assessing Cronbach’s alpha. Construct validity was determined by the Pearson correlation coefficient. Change scores were calculated from the 10 week and 12 months follow-up. Standardized response means (SRM; responsiveness) and floor and ceiling effects were determined. Analyses were performed for patients <80 versus ≥80 years of age. Results: The WOMAC mean total score was 89 points prefracture in younger patients, increasing from 70 (10 weeks) to 81 (24 months). In the oldest old (i.e., ≥ 80 years), these scores were 86, 75, and 78. The stiffness scores were 83, 67, and 76 in the younger group and 85, 80, and 80 in the oldest old. Pain scores were 92, 76, and 87 in the younger and 92, 84, and 93 in the older group. Function scores were 89, 68, and 79 in the younger and 84, 71, and 73 in the older group. Cronbach’s alpha for pain, stiffness, function, and the total scale ranged 0.83-0.98 for the younger and 0.79-0.97 for the older group. Construct validity was good with 82% and 79% of predefined hypotheses confirmed in the younger and older group, respectively. Responsiveness was moderate. No floor effects were found. Moderate to large ceiling effects were found for the Pain and Stiffness scales at 10 weeks and 12 months in younger patients (18-36%) and in the oldest old (38-53%). Conclusions: The WOMAC showed a good reliability, construct validity, and responsiveness in both age groups with a femoral neck fracture who were physically and mentally fit prefracture. The instrument is suitable for use in future clinical studies in these populations. Level of Evidence: Diagnostic studies, level I","WOMAC, Responsiveness, Validity, Hip Fracture, Reliability, Elderly","This study investigated the reliability, validity, and responsiveness of the Western Ontario McMaster Osteoarthritis Index (WOMAC) in elderly patients with a femoral neck fracture. The WOMAC showed good reliability, construct validity, and moderate responsiveness in both younger and older patients. The instrument is suitable for use in future clinical studies in these populations."
de Boer,"Reliability, validity and responsiveness of the Western Ontario McMaster Osteoarthritis Index (WOMAC) in the elderly population with a femoral neck fracture","Background: Patient-reported outcome measures are gaining importance in clinical research. The WOMAC has been extensively evaluated in populations suffering from osteoarthritis, yet not in femoral neck fracture populations. This study aimed to determine the reliability, construct validity, and responsiveness of WOMAC, compared with SF-12 and EQ-5D, in elderly with a femoral neck fracture. Methods: Reliability was tested by assessing Cronbach’s alpha. Construct validity was determined by the Pearson correlation coefficient. Change scores were calculated from the 10 week and 12 months follow-up. Standardized response means (SRM; responsiveness) and floor and ceiling effects were determined. Analyses were performed for patients <80 versus ≥80 years of age. Results: The WOMAC mean total score was 89 points prefracture in younger patients, increasing from 70 (10 weeks) to 81 (24 months). In the oldest old (i.e., ≥ 80 years), these scores were 86, 75, and 78. The stiffness scores were 83, 67, and 76 in the younger group and 85, 80, and 80 in the oldest old. Pain scores were 92, 76, and 87 in the younger and 92, 84, and 93 in the older group. Function scores were 89, 68, and 79 in the younger and 84, 71, and 73 in the older group. Cronbach’s alpha for pain, stiffness, function, and the total scale ranged 0.83-0.98 for the younger and 0.79-0.97 for the older group. Construct validity was good with 82% and 79% of predefined hypotheses confirmed in the younger and older group, respectively. Responsiveness was moderate. No floor effects were found. Moderate to large ceiling effects were found for the Pain and Stiffness scales at 10 weeks and 12 months in younger patients (18-36%) and in the oldest old (38-53%). Conclusions: The WOMAC showed a good reliability, construct validity, and responsiveness in both age groups with a femoral neck fracture who were physically and mentally fit prefracture. The instrument is suitable for use in future clinical studies in these populations. Level of Evidence: Diagnostic studies, level I","WOMAC, Responsiveness, Validity, Hip Fracture, Reliability, Elderly","This study investigated the reliability, validity, and responsiveness of the Western Ontario McMaster Osteoarthritis Index (WOMAC) in elderly patients with a femoral neck fracture. The WOMAC showed good reliability, construct validity, and moderate responsiveness in both younger and older patients. The instrument is suitable for use in future clinical studies in these populations."
de Graaf,Ontology Driven Software Development for Automated Documentation,"Recent outsourcing /off-shoring software development practices testify that any development done without a proper sharing mechanism leads to the generation of inconsistent information, which further results in an undesired, error-prone software. Further, with the business process automation, a significant way to minimize human effort involves various development, support and maintenance activities to reuse available information. Thus, reusing and sharing information in a standardized way is the key operative challenges which foster the need to identify and exploit novel knowledge-based frameworks. The proposed research provides a tool-based solution to automate the software documentation process using ontologies. This multi-phase framework has overall six phases where each phase output contributes to the final automated documentation. To evaluate the extent of automated documentation it is compared using free and open source software known as WCopyfind to the existing manual documentation for a Result Management System case study. Preliminary results show a highest automation of 60 percent, which is clearly noteworthy.","Ontology driven, Ontology, software architecture documentation, Software’s documentation, Automatic documentation, technical documentation, ontology driven software development, Semantic Web, automated documentation, Software engineering","The paper presents a framework for ontology driven software development for automated documentation, which is divided into six phases. The framework is designed to capture key concepts of the domain under consideration and generate documentation in both human and machine-understandable forms. The paper also discusses the related work in the field of ontology driven software development and automated documentation."
de Graaf et al.,Ontology Driven Software Development for Automated Documentation,"Recent outsourcing /off-shoring software development practices testify that any development done without a proper sharing mechanism leads to the generation of inconsistent information, which further results in an undesired, error-prone software. Further, with the business process automation, a significant way to minimize human effort involves various development, support and maintenance activities to reuse available information. Thus, reusing and sharing information in a standardized way is the key operative challenges which foster the need to identify and exploit novel knowledge-based frameworks. The proposed research provides a tool-based solution to automate the software documentation process using ontologies. This multi-phase framework has overall six phases where each phase output contributes to the final automated documentation. To evaluate the extent of automated documentation it is compared using free and open source software known as WCopyfind to the existing manual documentation for a Result Management System case study. Preliminary results show a highest automation of 60 percent, which is clearly noteworthy.","Ontology driven, Ontology, software architecture documentation, Software’s documentation, Automatic documentation, technical documentation, ontology driven software development, Semantic Web, automated documentation, Software engineering","The paper presents a framework for ontology driven software development for automated documentation, which is divided into six phases. The framework is designed to capture key concepts of the domain under consideration and generate documentation in both human and machine-understandable forms. The paper also discusses the related work in the field of ontology driven software development and automated documentation."
de Vries,"Reliability, validity and responsiveness of the Western Ontario McMaster Osteoarthritis Index (WOMAC) in the elderly population with a femoral neck fracture","Background: Patient-reported outcome measures are gaining importance in clinical research. The WOMAC has been extensively evaluated in populations suffering from osteoarthritis, yet not in femoral neck fracture populations. This study aimed to determine the reliability, construct validity, and responsiveness of WOMAC, compared with SF-12 and EQ-5D, in elderly with a femoral neck fracture. Methods: Reliability was tested by assessing Cronbach’s alpha. Construct validity was determined by the Pearson correlation coefficient. Change scores were calculated from the 10 week and 12 months follow-up. Standardized response means (SRM; responsiveness) and floor and ceiling effects were determined. Analyses were performed for patients <80 versus ≥80 years of age. Results: The WOMAC mean total score was 89 points prefracture in younger patients, increasing from 70 (10 weeks) to 81 (24 months). In the oldest old (i.e., ≥ 80 years), these scores were 86, 75, and 78. The stiffness scores were 83, 67, and 76 in the younger group and 85, 80, and 80 in the oldest old. Pain scores were 92, 76, and 87 in the younger and 92, 84, and 93 in the older group. Function scores were 89, 68, and 79 in the younger and 84, 71, and 73 in the older group. Cronbach’s alpha for pain, stiffness, function, and the total scale ranged 0.83-0.98 for the younger and 0.79-0.97 for the older group. Construct validity was good with 82% and 79% of predefined hypotheses confirmed in the younger and older group, respectively. Responsiveness was moderate. No floor effects were found. Moderate to large ceiling effects were found for the Pain and Stiffness scales at 10 weeks and 12 months in younger patients (18-36%) and in the oldest old (38-53%). Conclusions: The WOMAC showed a good reliability, construct validity, and responsiveness in both age groups with a femoral neck fracture who were physically and mentally fit prefracture. The instrument is suitable for use in future clinical studies in these populations. Level of Evidence: Diagnostic studies, level I","WOMAC, Responsiveness, Validity, Hip Fracture, Reliability, Elderly","This study investigated the reliability, validity, and responsiveness of the Western Ontario McMaster Osteoarthritis Index (WOMAC) in elderly patients with a femoral neck fracture. The WOMAC showed good reliability, construct validity, and moderate responsiveness in both younger and older patients. The instrument is suitable for use in future clinical studies in these populations."
et al,Controlled synthesis of size-tunable nickel and nickel oxide nanoparticles using water-in-oil microemulsions ||| Oxygen Barrier Properties of Xylan-Nanocrystalline Cellulose Composite Films ||| Synchronization of delayed chaotic systems with parameter mismatches by using intermittent linear state feedback,"Industrial demands have generated a growing need to synthesize pure metal and metal–oxide nanoparticles of a desired size. We report a novel and convenient method for the synthesis of spherical, size tunable, well dispersed, stable nickel and nickel oxide nanoparticles by reduction of nickel nitrate at room temperature in a TX-100/n-hexanol/cyclohexane/water system by a reverse microemulsion route. We determined that reduction with alkaline sodium borohydrate in nitrogen atmosphere leads to the formation of nickel nanoparticles, while the use of hydrazine hydrate in aerobic conditions leads to the formation of nickel oxide nanoparticles. The inﬂuence of several reaction parameters on the size of nickel and nickel oxide nanoparticles were evaluated in detail. It was found that the size can be easily controlled either by changing the molar ratio of water to surfactant or by simply altering the concentration of the reducing agent. The morphology and structure of the nanoparticles were characterized by quasi-elastic light scattering (QELS), transmission electron microscopy (TEM), x-ray diffraction (XRD), electron diffraction analysis (EDA) and energy dispersive x-ray (EDX) spectroscopy. The results show that synthesized nanoparticles are of high purity and have an average size distribution of 5–100 nm. The nanoparticles prepared by our simple methodology have been successfully used for catalyzing various chemical reactions. ||| This study examines the oxygen barrier properties of xylan-nanocrystalline cellulose composite films. By AFM analysis, the sulfonated nanocrystalline cellulosic were observed to have rod like structure with an average length of 150-200 nm and a width of less than 20 nm (Fig. 1). AFM images, acquired using tapping mode, of the xylan/sorbitol films reinforced with nanocrystalline cellulose show well dispersed sulfonated nanocrystalline cellulose on xylan surface in comparison to more open structure of xylan/sorbitol control films (Fig. 2).  The specific oxygen transmission rate of the xylan nanocomposite films are shown in Table 1. The transmission rate decreased drastically upon reinforcement with nanocrystalline cellulose. The measured oxygen permeability is lower or comparable to the often used barrier plastic ethylene vinyl alcohol (EVOH) [33] and the films made from microfibrillar cellulose [34], see Table 1.  Oxygen permeability values were calculated by dividing the oxygen transmission rates by the differential partial pressure of oxygen across the film (1 atm or 101.3 kPa) and multiplying by the film thickness in microns [5]. Table 2 summarized the oxygen permeability of some of the literature work and current work. The oxygen transmission rates as summarized in Table 1 at 25% and 50% dosage of nanocrystalline cellulose decreased drastically with respect to control xylan films and are the two lowest values that we obtained in this study.  It will be an interesting subject to explore the porosity, bulk density and tortuosity factor at these two levels and the control xylan films. As summarized in Table 3, the density and tortuosity factor of the composite film increased while the pore diameter and porosity decreased as the loading of sulfonated nanocrystalline cellulose increased in the xylan-based films.  SEM images of the control xylan film surface showed agglomerated structures on the surface in comparison to a more uniform surface for the nanocrystalline cellulose-xylan films (Fig. 3 (a) and 3 (b)).  Oxygen transmission rate at 5% and 10% charge of nanocrystalline cellulose doesn’t differ much but a significant drop of transmission rate as compared to control. We studied xylan-10% nanocrystalline cellulose film under SEM (Fig. 3) and AFM (Fig. 2b) and found that control xylan film surface in Fig. 3 (a) shows agglomeration in comparison to well dispersed sulfonated nanocrystalline cellulose on xylan surface in Fig. 3 (b). The uneven structure and agglomeration of the xylan can be the cause of higher oxygen transmission rate of control xylan film in comparison to xylan reinforced with 10% sulfonated nanocrystalline cellulose.  SEM cross-section images of freeze fracture of control xylan films showed a rough texture with small cracks in the film as summarized in Fig. 4(a) and 4(b). The same analysis for the xylan film reinforced with nanocrystalline cellulose exhibited smooth fractured surface and less porous structure (see Fig. 4(c) and Fig. 4(d)). ||| This paper investigates the synchronization of coupled chaotic systems with time delay in the presence of parameter mismatches by using intermittent linear state feedback control. Quasi-synchronization criteria are obtained by means of a Lyapunov function and the differential inequality method. Numerical simulations on the chaotic systems are presented to demonstrate the effectiveness of the theoretical results.","non-ionic surfactant, synthesis, nickel, composite films, nickel oxide, nanocrystalline cellulose, nanoparticles, microemulsion, time delay, water-in-oil microemulsions, xylan, synchronization, intermittent linear state feedback, chaotic systems, barrier properties, nickel nanoparticles, parameter mismatches, oxygen permeability, nickel oxide nanoparticles, reducing agent, water-to-surfactant ratio, intermittent feedback control","This paper describes a novel method for synthesizing nickel and nickel oxide nanoparticles using a water-in-oil microemulsion system. The method allows for control over the size of the nanoparticles by adjusting reaction parameters such as the water-to-surfactant ratio and the concentration of the reducing agent. The synthesized nanoparticles were characterized using various techniques and found to be of high purity with an average size distribution of 5-100 nm. These nanoparticles have potential applications as catalysts in various chemical reactions. ||| This study investigates the oxygen barrier properties of xylan-nanocrystalline cellulose composite films.  The addition of nanocrystalline cellulose significantly reduces oxygen transmission rates, resulting in films with permeability comparable to or lower than commonly used barrier plastics like EVOH.  SEM and AFM analysis reveal a more uniform and dense structure in the composite films compared to the control xylan films, which likely contributes to the improved barrier properties. ||| The paper studies the synchronization of non-identical chaotic systems with delays in the presence of parameter mismatches using intermittent control. Some criteria for synchronization of the drive-response chaotic systems with delays up to a relatively small error bound are derived by means of a Lyapunov function, differential inequality and linear matrix inequality. Numerical simulations are presented to validate the effectiveness of the theoretical results."
et al.,An approach for decision making using intuitionistic trapezoidal fuzzy soft set ||| A non-invertible cancelable fingerprint template generation based on ridge feature transformation ||| Differential Evolution: A Survey of the State-of-the-Art ||| Moisture barrier properties of xylan composite films ||| Non-invasive intravoxel incoherent motion MRI in prediction of histopathological response to neoadjuvant chemotherapy and survival outcome in osteosarcoma at the time of diagnosis ||| Object Extraction Based on Rough Entropy ||| ROLE OF TRUST IN DISTRIBUTED AGILE SOFTWARE DEVELOPMENT TEAMS - A LIGHT WEIGHT SYSTEMATIC LITERATURE REVIEW,"Introduction of soft sets by Molodtsov (1999) has evolved a revolution in the decision making paradigm. Researchers have used soft sets with different extensions of fuzzy sets to satisfy the various types of uncertainties involved with real life decision making problems. This paper introduces intuitionistic trapezoidal fuzzy soft set (ITrFSS) by combining intuitionistic trapezoidal fuzzy set (ITrFS) with soft set. Firstly, we generalize the adjustable approach applied to intuitionistic fuzzy soft set (IFSS) based decision making developed by Jiang et al. (2011) and then present an approach to ITrFSS based decision making using threshold ITrFSs and level soft sets. ||| In a biometric verification system, leakage of biometric data leads to permanent identity loss since original biometric data is inherently linked to a user. Further, various types of attacks on a biometric system may reveal the original template and utility in other applications. To address these security and privacy concerns cancelable biometric has been introduced. Cancelable biometric constructs a protected template from the original biometric template using transformation functions and performs the comparison between templates in the transformed domain. ||| This paper presents a novel differential evolution (DE) variant, called CoBiDE, which includes two main components: covariance matrix learning and bimodal distribution parameter setting. CoBiDE has been tested on 25 benchmark test functions and a variety of real-world application problems. The experimental results suggest that the performance of CoBiDE is better than that of four other DE variants and three other state-of-the-art EAs. ||| This study examines the reinforcement of xylan/sorbitol films with nanocrystalline cellulose, bleached acacia fiber and softwood kraft fibers and its impact on water transmission. By AFM analysis, nanocrystalline cellulose was observed to have rod like structure with an average length of sulfuric nanocrystalline cellulose in range of 150–200 nm and a width of less than 20 nm while hydrochloric nanocrystalline cellulose had an average length of 200–300 nm and a width slightly less than 20 nm. These results are consistent with the literature reported for nanocrystalline cellulose prepared from softwood kraft pulps using sulfuric acid and hydrochloric acid. Recently, studies by Saxena et al. (2009) have reported that oat-spelt xylan, plasticized with sorbitol and reinforced with 7% sulfuric nanocrystalline cellulose increased the tensile energy absorption of the xylan films by 445% and the tensile strength of the film by 141% with respect to control xylan film. Saxena and Ragauskas (2009) have also shown that when xylan films are reinforced with 10% sulfuric nanocrystalline cellulose, WVTR reduces from 304 g/h m2 for control to 174 g mil/h m2 for xylan–sulfuric nanocrystalline cellulose films. To determine the impact of alternative cellulosic fillers on water transmission properties, a series of xylan composite films were prepared and analyzed using the water vapor transmission test. In the current work, similar experiments were performed using acacia fiber and hydrochloric prepared nanocrystalline cellulose as reinforcement in a xylan film. Because the thickness of the xylan–sulfonated nanocrystalline cellulose, xylan–softwood fiber and xylan–acacia fiber are different, the WVTR was normalized to film thickness (l) with units in mm to obtain the specific water vapor transmission rate (R = WVTR × l) with units of g mm/d m2 (Hu, Topolkaraev, Hiltner, & Baer, 2000). Xylan films reinforced with 10% acacia fiber and 10% hydrochloric nanocrystalline cellulose exhibited virtually no improvement in specific water vapor transmission rate in comparison to control. Xylan film reinforced with 10% sulfuric nanocrystalline cellulose exhibited lowest specific water transmission rate of 174 g mil/h m2 and xylan film with softwood fiber exhibited highest water transmission rate as summarized in Table 1. The water transmission rate at other levels is summarized in Fig. 1. It was found that the addition of 5% softwood kraft pulp fibers yielded a xylan film with increased specific water vapor transmission rate and a significant high water vapor transmission rate at 50% dosage with respect to control. The addition of softwood kraft fibers in the xylan film causes a significant high specific water vapor transmission rate at any dosages (5%, 10% and 50%). The addition of hydrochloric acid prepared nanocrystalline cellulose to xylan films was also analyzed for specific water transmission rate. The specific WVTR values decreased as the content of HCl generated nanocrystalline cellulose in the xylan film increased from 0% ||| This study evaluates the effectiveness of chemotherapy in patients with osteosarcoma and its impact on long-term survival outcome. The study includes 11 patients who underwent neoadjuvant chemotherapy (NACT) and were followed up for a median of 4.5 years. The results show that patients who responded well to NACT had better overall survival and event-free survival compared to those who did not respond well. The study also found that certain imaging parameters, such as ADC and D*, were associated with chemotherapy response and survival outcome. ||| This paper presents a method of object enhancement/extraction based on the principle of minimizing the roughness of both object and background regions, i.e., maximizing RET. The determination of T* by maximization of rough entropy or minimization of roughness depends on the granule size. ||| This systematic literature review aims to investigate the role of trust in distributed agile software development teams. We identified 16 studies that mentioned the role of trust in distributed agile software development in one way or another. Fourteen are primary studies and two are secondary studies. The studies were classified based on different research methods used, database sources, and year of publication. The results show that trust is a crucial ingredient for blending agility with distributed software development. Trust among distributed team members is important to bridge spatial, temporal, and socio-cultural distances, it’s important for them to work together as one team. Trust fuels team performance and contribute in building an effective and cohesive team.","feature extraction, granule size, Nanocrystalline cellulose, biometric, alignment-free, Weighted ITrFSSs, Survey, Moisture barrier, Cancelable fingerprint template, intuitionistic trapezoidal fuzzy set, privacy, Intravoxel incoherent motion, Image segmentation, Optimization Algorithm, Agile Software Development, Non-invertible template, Xylan, chemotherapy, decision making, Intuitionistic trapezoidal fuzzy soft set, level soft set, Differential evolution, Adjustable Approach, Biomarkers, imaging parameters, Revocability, Survival outcome, Peer Reviewed Conferences, cancelable biometrics, Rough sets, Global numerical and engineering optimization, Entropy, rough entropy, object extraction, trust, fingerprint, systematic literature review, Composites, minutiae, Diffusion weighted imaging, Diversity, Bimodal distribution parameter setting, Chemotherapy response evaluation, neoadjuvant chemotherapy, Books, Ridge feature transformation, long-term survival outcome, Osteosarcoma, Covariance matrix learning, Journals, State-of-the-Art, Set approximation, Intuitionistic Trapezoidal Fuzzy Soft Sets, distributed agile software development, security, Granules","This paper introduces a new approach for decision making using intuitionistic trapezoidal fuzzy soft set. The approach combines intuitionistic trapezoidal fuzzy set with soft set and uses threshold intuitionistic trapezoidal fuzzy sets and level soft sets to make decisions. The paper also proposes weighted intuitionistic trapezoidal fuzzy soft set and applies it to a decision making problem. The outcome of the adjustable approaches based on intuitionistic trapezoidal fuzzy soft set and weighted intuitionistic trapezoidal fuzzy soft set is validated using closeness coefficient measure. Two illustrative examples are provided to show the feasibility of the proposed approaches in real life decision making problems. ||| This paper proposes a novel non-invertible ridge feature transformation method to protect the original fingerprint template information. The proposed method partitions the fingerprint region into a number of sectors with reference to each minutia point employing a ridge-based co-ordinate system. The nearest neighbor minutiae in each sector are identified, and ridge-based features are computed. Further, a cancelable template is generated by applying the Cantor pairing function followed by random projection. ||| This paper presents a novel DE variant, CoBiDE, which includes two main components: covariance matrix learning and bimodal distribution parameter setting. CoBiDE has been tested on 25 benchmark test functions and a variety of real-world application problems. ||| This study investigates the moisture barrier properties of xylan films reinforced with various cellulosic materials, including nanocrystalline cellulose, acacia kraft pulp fibers, and softwood kraft fibers.  The researchers found that films reinforced with 10% sulfuric acid-prepared nanocrystalline cellulose exhibited the lowest water vapor transmission rate, significantly outperforming films reinforced with other materials. The morphology and interactions between the reinforcing agents and the xylan matrix were also examined. ||| This study aimed to evaluate the predictive value of IVIM MRI for response to neoadjuvant chemotherapy and survival outcome in osteosarcoma. The results showed that IVIM parameters obtained with a 1.5T scanner along with novel BETV method and their histogram analysis indicating tumour heterogeneity were informative in characterizing NACT response and survival outcome in osteosarcoma. ||| This paper addresses the problem of image object extraction in the framework of rough sets and granular computing. A measure called 'rough entropy of image' is defined based on the concept of image granules. Its maximization results in minimization of roughness in both object and background regions; thereby determining the threshold of partitioning. ||| This study aims to investigate the role of trust in distributed agile software development teams. The results show that trust is a crucial ingredient for blending agility with distributed software development."
ov,A Computational Intelligence Based Online Data Imputation Method: An Application For Banking,"All the imputation techniques proposed so far in literature for data imputation are offline techniques as they require a number of iterations to learn the characteristics of data during training and they also consume a lot of computational time. Hence, these techniques are not suitable for applications that require the imputation to be performed on demand and near real-time. The paper proposes a computational intelligence based architecture for online data imputation and extended versions of an existing offline data imputation method as well.","computational intelligence, K-Means clustering, Evolving Clustering Method (ECM), banking, K-Medoids clustering, General Regression Neural Network (GRNN), GRNN, Imputation, MLP, online data imputation, Data Imputation","The proposed online imputation technique has 2 stages. In stage 1, Evolving Clustering Method (ECM) is used to replace the missing values with cluster centers, as part of the local learning strategy. Stage 2 refines the resultant approximate values using a General Regression Neural Network (GRNN) as part of the global approximation strategy."
ruchi sharma,Automated Competitor Analysis Using Big Data and NLP ||| Credit Financing in Economic Ordering Policies for Defective Items with Order Overlapping ||| Effect of Cutting Source and Size on the Poplar (Populus deltoides Marsh.) Nursery Performance,"Competitor analysis is a key component in operations management. Most business decisions are rooted in the analysis of rival products inferred from market structure. Relative to more traditional competitor analysis methods, the purpose of this paper is to provide operations managers with an innovative tool to monitor a firm’s market position and competitors in real time at higher resolution and lower cost than more traditional competitor analysis methods. ||| In the classical inventory models, most of the time the issue of quality of the items has not been given due attention. However, in realistic environment, it can be observed that there may be some defective items in an ordered lot, because of these defective items retailer may incurs additional cost due to rejection, repair and refund etc. Thus, inspection/screening of lot becomes essential in most of the organizations. ||| The study investigates the effect of cutting position on rooting and growth of Populus deltoides. The results show that cuttings taken from the basal position exhibit better survival and growth characteristics compared to those taken from the middle and upper positions.","permissible delay, Populus deltoides, inventory model, Inventory, overlapping, User segment overlapping, imperfect items, Operational strategy, profit maximization, supplier credit period, optimal order quantity, growth, Naïve Bayes, Probabilistic topic modelling, NLP, management theories, cutting position, Mobile apps, poplar, rooting, competitor analysis, Nursery, Big data","The paper presents an innovative tool for competitor analysis using big data analytics, which can monitor a firm’s market position and competitors in real time at higher resolution and lower cost than traditional methods. The tool combines Web Crawler, Natural Language Processing, and Machine Learning algorithms with data visualization to develop a big data competitor-analysis system. ||| This paper develops an inventory model for imperfect quality items under permissible delay in payments. The screening rate is assumed to be more than the demand rate. An order is placed during the screening process at the time when inventory level is good enough to meet demand. The proposed model optimizes retailer's order quantity by maximizing his expected total profit. ||| The study aimed to standardize appropriate cutting size and position of cutting collection from donor nursery plants for poplar clones. The results showed that longer cuttings taken from the lower parts of the plant produce better results, but with rise in demand for quality planting stock, the use of longer cuttings from basal portion only is not worthwhile."
unspecified,Variations of Logistic Models to Data of Covid-19 Pandemic in India,"An early analysis of growth dynamics for infectious diseases, like COVID-19, is needed to dissect the crucial driving factors that result in rapid disease transmission, refine the measures taken to control the pandemic and improve disease forecast.","COVID-19, Confidence Intervals, Generalized Growth Model, Logistic Models, Logistic Growth, India, Phenomenological models, Epidemic Growth Models, Pandemic, Generalized Logistic Model, Bootstrap Resampling Method, Data Prediction, Growth parameters","The research paper uses Levenberg–Marquardt algorithm for parameter estimation to carry-out least square nonlinear minimization for curve fitting in Python and calculates confidence intervals with 95% average accuracy, using bootstrap resampling method, where 200 simulations are performed using Poisson error structure."
van der Heijden,"Reliability, validity and responsiveness of the Western Ontario McMaster Osteoarthritis Index (WOMAC) in the elderly population with a femoral neck fracture","Background: Patient-reported outcome measures are gaining importance in clinical research. The WOMAC has been extensively evaluated in populations suffering from osteoarthritis, yet not in femoral neck fracture populations. This study aimed to determine the reliability, construct validity, and responsiveness of WOMAC, compared with SF-12 and EQ-5D, in elderly with a femoral neck fracture. Methods: Reliability was tested by assessing Cronbach’s alpha. Construct validity was determined by the Pearson correlation coefficient. Change scores were calculated from the 10 week and 12 months follow-up. Standardized response means (SRM; responsiveness) and floor and ceiling effects were determined. Analyses were performed for patients <80 versus ≥80 years of age. Results: The WOMAC mean total score was 89 points prefracture in younger patients, increasing from 70 (10 weeks) to 81 (24 months). In the oldest old (i.e., ≥ 80 years), these scores were 86, 75, and 78. The stiffness scores were 83, 67, and 76 in the younger group and 85, 80, and 80 in the oldest old. Pain scores were 92, 76, and 87 in the younger and 92, 84, and 93 in the older group. Function scores were 89, 68, and 79 in the younger and 84, 71, and 73 in the older group. Cronbach’s alpha for pain, stiffness, function, and the total scale ranged 0.83-0.98 for the younger and 0.79-0.97 for the older group. Construct validity was good with 82% and 79% of predefined hypotheses confirmed in the younger and older group, respectively. Responsiveness was moderate. No floor effects were found. Moderate to large ceiling effects were found for the Pain and Stiffness scales at 10 weeks and 12 months in younger patients (18-36%) and in the oldest old (38-53%). Conclusions: The WOMAC showed a good reliability, construct validity, and responsiveness in both age groups with a femoral neck fracture who were physically and mentally fit prefracture. The instrument is suitable for use in future clinical studies in these populations. Level of Evidence: Diagnostic studies, level I","WOMAC, Responsiveness, Validity, Hip Fracture, Reliability, Elderly","This study investigated the reliability, validity, and responsiveness of the Western Ontario McMaster Osteoarthritis Index (WOMAC) in elderly patients with a femoral neck fracture. The WOMAC showed good reliability, construct validity, and moderate responsiveness in both younger and older patients. The instrument is suitable for use in future clinical studies in these populations."
van der Horst,"Reliability, validity and responsiveness of the Western Ontario McMaster Osteoarthritis Index (WOMAC) in the elderly population with a femoral neck fracture","Background: Patient-reported outcome measures are gaining importance in clinical research. The WOMAC has been extensively evaluated in populations suffering from osteoarthritis, yet not in femoral neck fracture populations. This study aimed to determine the reliability, construct validity, and responsiveness of WOMAC, compared with SF-12 and EQ-5D, in elderly with a femoral neck fracture. Methods: Reliability was tested by assessing Cronbach’s alpha. Construct validity was determined by the Pearson correlation coefficient. Change scores were calculated from the 10 week and 12 months follow-up. Standardized response means (SRM; responsiveness) and floor and ceiling effects were determined. Analyses were performed for patients <80 versus ≥80 years of age. Results: The WOMAC mean total score was 89 points prefracture in younger patients, increasing from 70 (10 weeks) to 81 (24 months). In the oldest old (i.e., ≥ 80 years), these scores were 86, 75, and 78. The stiffness scores were 83, 67, and 76 in the younger group and 85, 80, and 80 in the oldest old. Pain scores were 92, 76, and 87 in the younger and 92, 84, and 93 in the older group. Function scores were 89, 68, and 79 in the younger and 84, 71, and 73 in the older group. Cronbach’s alpha for pain, stiffness, function, and the total scale ranged 0.83-0.98 for the younger and 0.79-0.97 for the older group. Construct validity was good with 82% and 79% of predefined hypotheses confirmed in the younger and older group, respectively. Responsiveness was moderate. No floor effects were found. Moderate to large ceiling effects were found for the Pain and Stiffness scales at 10 weeks and 12 months in younger patients (18-36%) and in the oldest old (38-53%). Conclusions: The WOMAC showed a good reliability, construct validity, and responsiveness in both age groups with a femoral neck fracture who were physically and mentally fit prefracture. The instrument is suitable for use in future clinical studies in these populations. Level of Evidence: Diagnostic studies, level I","WOMAC, Responsiveness, Validity, Hip Fracture, Reliability, Elderly","This study investigated the reliability, validity, and responsiveness of the Western Ontario McMaster Osteoarthritis Index (WOMAC) in elderly patients with a femoral neck fracture. The WOMAC showed good reliability, construct validity, and moderate responsiveness in both younger and older patients. The instrument is suitable for use in future clinical studies in these populations."
van der Linden,"Reliability, validity and responsiveness of the Western Ontario McMaster Osteoarthritis Index (WOMAC) in the elderly population with a femoral neck fracture","Background: Patient-reported outcome measures are gaining importance in clinical research. The WOMAC has been extensively evaluated in populations suffering from osteoarthritis, yet not in femoral neck fracture populations. This study aimed to determine the reliability, construct validity, and responsiveness of WOMAC, compared with SF-12 and EQ-5D, in elderly with a femoral neck fracture. Methods: Reliability was tested by assessing Cronbach’s alpha. Construct validity was determined by the Pearson correlation coefficient. Change scores were calculated from the 10 week and 12 months follow-up. Standardized response means (SRM; responsiveness) and floor and ceiling effects were determined. Analyses were performed for patients <80 versus ≥80 years of age. Results: The WOMAC mean total score was 89 points prefracture in younger patients, increasing from 70 (10 weeks) to 81 (24 months). In the oldest old (i.e., ≥ 80 years), these scores were 86, 75, and 78. The stiffness scores were 83, 67, and 76 in the younger group and 85, 80, and 80 in the oldest old. Pain scores were 92, 76, and 87 in the younger and 92, 84, and 93 in the older group. Function scores were 89, 68, and 79 in the younger and 84, 71, and 73 in the older group. Cronbach’s alpha for pain, stiffness, function, and the total scale ranged 0.83-0.98 for the younger and 0.79-0.97 for the older group. Construct validity was good with 82% and 79% of predefined hypotheses confirmed in the younger and older group, respectively. Responsiveness was moderate. No floor effects were found. Moderate to large ceiling effects were found for the Pain and Stiffness scales at 10 weeks and 12 months in younger patients (18-36%) and in the oldest old (38-53%). Conclusions: The WOMAC showed a good reliability, construct validity, and responsiveness in both age groups with a femoral neck fracture who were physically and mentally fit prefracture. The instrument is suitable for use in future clinical studies in these populations. Level of Evidence: Diagnostic studies, level I","WOMAC, Responsiveness, Validity, Hip Fracture, Reliability, Elderly","This study investigated the reliability, validity, and responsiveness of the Western Ontario McMaster Osteoarthritis Index (WOMAC) in elderly patients with a femoral neck fracture. The WOMAC showed good reliability, construct validity, and moderate responsiveness in both younger and older patients. The instrument is suitable for use in future clinical studies in these populations."
van der Velde,"Reliability, validity and responsiveness of the Western Ontario McMaster Osteoarthritis Index (WOMAC) in the elderly population with a femoral neck fracture","Background: Patient-reported outcome measures are gaining importance in clinical research. The WOMAC has been extensively evaluated in populations suffering from osteoarthritis, yet not in femoral neck fracture populations. This study aimed to determine the reliability, construct validity, and responsiveness of WOMAC, compared with SF-12 and EQ-5D, in elderly with a femoral neck fracture. Methods: Reliability was tested by assessing Cronbach’s alpha. Construct validity was determined by the Pearson correlation coefficient. Change scores were calculated from the 10 week and 12 months follow-up. Standardized response means (SRM; responsiveness) and floor and ceiling effects were determined. Analyses were performed for patients <80 versus ≥80 years of age. Results: The WOMAC mean total score was 89 points prefracture in younger patients, increasing from 70 (10 weeks) to 81 (24 months). In the oldest old (i.e., ≥ 80 years), these scores were 86, 75, and 78. The stiffness scores were 83, 67, and 76 in the younger group and 85, 80, and 80 in the oldest old. Pain scores were 92, 76, and 87 in the younger and 92, 84, and 93 in the older group. Function scores were 89, 68, and 79 in the younger and 84, 71, and 73 in the older group. Cronbach’s alpha for pain, stiffness, function, and the total scale ranged 0.83-0.98 for the younger and 0.79-0.97 for the older group. Construct validity was good with 82% and 79% of predefined hypotheses confirmed in the younger and older group, respectively. Responsiveness was moderate. No floor effects were found. Moderate to large ceiling effects were found for the Pain and Stiffness scales at 10 weeks and 12 months in younger patients (18-36%) and in the oldest old (38-53%). Conclusions: The WOMAC showed a good reliability, construct validity, and responsiveness in both age groups with a femoral neck fracture who were physically and mentally fit prefracture. The instrument is suitable for use in future clinical studies in these populations. Level of Evidence: Diagnostic studies, level I","WOMAC, Responsiveness, Validity, Hip Fracture, Reliability, Elderly","This study investigated the reliability, validity, and responsiveness of the Western Ontario McMaster Osteoarthritis Index (WOMAC) in elderly patients with a femoral neck fracture. The WOMAC showed good reliability, construct validity, and moderate responsiveness in both younger and older patients. The instrument is suitable for use in future clinical studies in these populations."
van der Weijden,"Reliability, validity and responsiveness of the Western Ontario McMaster Osteoarthritis Index (WOMAC) in the elderly population with a femoral neck fracture","Background: Patient-reported outcome measures are gaining importance in clinical research. The WOMAC has been extensively evaluated in populations suffering from osteoarthritis, yet not in femoral neck fracture populations. This study aimed to determine the reliability, construct validity, and responsiveness of WOMAC, compared with SF-12 and EQ-5D, in elderly with a femoral neck fracture. Methods: Reliability was tested by assessing Cronbach’s alpha. Construct validity was determined by the Pearson correlation coefficient. Change scores were calculated from the 10 week and 12 months follow-up. Standardized response means (SRM; responsiveness) and floor and ceiling effects were determined. Analyses were performed for patients <80 versus ≥80 years of age. Results: The WOMAC mean total score was 89 points prefracture in younger patients, increasing from 70 (10 weeks) to 81 (24 months). In the oldest old (i.e., ≥ 80 years), these scores were 86, 75, and 78. The stiffness scores were 83, 67, and 76 in the younger group and 85, 80, and 80 in the oldest old. Pain scores were 92, 76, and 87 in the younger and 92, 84, and 93 in the older group. Function scores were 89, 68, and 79 in the younger and 84, 71, and 73 in the older group. Cronbach’s alpha for pain, stiffness, function, and the total scale ranged 0.83-0.98 for the younger and 0.79-0.97 for the older group. Construct validity was good with 82% and 79% of predefined hypotheses confirmed in the younger and older group, respectively. Responsiveness was moderate. No floor effects were found. Moderate to large ceiling effects were found for the Pain and Stiffness scales at 10 weeks and 12 months in younger patients (18-36%) and in the oldest old (38-53%). Conclusions: The WOMAC showed a good reliability, construct validity, and responsiveness in both age groups with a femoral neck fracture who were physically and mentally fit prefracture. The instrument is suitable for use in future clinical studies in these populations. Level of Evidence: Diagnostic studies, level I","WOMAC, Responsiveness, Validity, Hip Fracture, Reliability, Elderly","This study investigated the reliability, validity, and responsiveness of the Western Ontario McMaster Osteoarthritis Index (WOMAC) in elderly patients with a femoral neck fracture. The WOMAC showed good reliability, construct validity, and moderate responsiveness in both younger and older patients. The instrument is suitable for use in future clinical studies in these populations."
